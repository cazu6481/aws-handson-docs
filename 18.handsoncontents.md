# コア設計書：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化プロジェクト」（約525ページ）

## 1. プロジェクト全体像と移行戦略

## 本章の目的：オンプレミスからAWSへの移行戦略とAFT導入の位置づけを理解する

### **ハンズオン 1-1**: TechNova社の現状システム分析 

- オンプレミスシステム構成の詳細分析

- システム間連携の識別と依存関係マッピング

- パフォーマンス特性とスケーリング要件の評価

- 移行優先度の決定基準

### **ハンズオン 1-2**: マイクロサービス化戦略と境界設計 

- ドメイン駆動設計に基づくサービス境界定義

- マイクロサービスの粒度と責務範囲の決定

- サービス間連携パターンの選定

- データオーナーシップとデータ同期戦略

### **ハンズオン 1-3**: AWS移行基本設計のレビューと統合 

- 決定済みのAWS基本設計の確認

- AFT導入による実現可能性と利点の評価

- 移行フェーズの再構築と調整

- 移行のリスク評価と対策

### **ハンズオン 1-4**: AFT導入によるアカウント戦略の具体化 

- 必要アカウント構成のマッピング

- AFTによるアカウント管理自動化の範囲決定

- アカウント設計方針の確立

- アカウント間連携の設計

### **ハンズオン 1-5**: マイクロサービス実装とECS Fargate/Aurora選定の詳細化 

- コンテナ化戦略の具体化

- データベース設計と移行アプローチ

- スケーラビリティ要件とキャパシティプランニング

- パフォーマンス目標と検証方法

### **ハンズオン 1-6**: 移行ロードマップとリリース計画 

- フェーズ分割と段階的リリース計画

- 各フェーズの成功基準の定義

- 切り戻し計画と障害対応戦略

- 移行中のビジネス継続性確保策

### アンチパターン：移行戦略で失敗しやすいポイント

- 依存関係の分析が不十分で、移行順序に問題が生じる

- マイクロサービスの境界が適切に定義されず、密結合が残る

- すべてを一度に移行しようとして複雑性が増大する

- オンプレミス連携の複雑さを過小評価する

- 既存データの移行戦略が不十分で、データ整合性問題が発生する

- ビジネス部門の巻き込みが不足し、業務要件の反映が不十分になる

## 2. AWS Control TowerとOU設計（30-35ページ）

## 本章の目的：Control Tower導入とOU構造の設計手法を実践する

### **ハンズオン 2-1**: Control Tower導入と初期設定ワークショップ 

- Control Tower導入の前提条件確認

- Landing Zone構築の手順と注意点

- 管理アカウント・監査アカウント・ログアーカイブアカウントの設定

- 移行プロジェクトに最適な初期設定選択

### **ハンズオン 2-2**: OU構造設計ワークショップ 

- TechNova社の組織構造分析と業務システム反映

- 機能別OU(共通サービス、ネットワーク、セキュリティ)の設計

- 事業部門別OUの設計と環境区分（開発/テスト/本番）

- OU命名規則と構造化戦略

### **ハンズオン 2-3**: SCPポリシー設計と実装 

- セキュリティ要件分析と統制ポリシー定義

- 環境タイプ別のSCP設計（本番/テスト/開発）

- リージョン制限ポリシーの設計（東京/大阪限定）

- 最小権限原則に基づくサービス利用制限

### **ハンズオン 2-4**: OU構造のTerraform化 

- Organizations構造のコード化

- SCP割り当てのコード管理

- 既存アカウントの移行手順

- バージョン管理と変更追跡戦略

### **ハンズオン 2-5**: アカウント命名規則と分類体系の設計 

- 事業部門・機能・環境が分かる命名規則の設計

- アカウント属性のタグ設計

- アカウント一覧の管理・可視化手法

- メタデータ管理戦略

### **ハンズオン 2-6**: マイクロサービス展開を考慮したアカウント構成 

- サービス群ごとのアカウント分離戦略

- 共有リソースとクロスアカウントアクセス設計

- 環境間のデータ流通設計

- アカウント間通信のセキュリティ境界設計

### アンチパターン：OU設計で失敗しやすいポイント

- OUを細かく分けすぎて管理が複雑化する

- 将来の組織変更を考慮せず、現在の組織構造に強く紐づけた設計をする

- SCPが強すぎて運用業務や開発作業が阻害される

- OU設計が浅く、「Dev/Prod」のみの分類で終わってしまう

- アカウント命名規則が不明確で、後から何のアカウントか分からなくなる

- サービス間連携を考慮せず、アカウント間通信が複雑になりすぎる

## 3. AFT環境構築とアカウント自動化（30-35ページ）

## 本章の目的：AFT導入とアカウント自動化プロセスを構築する

### **ハンズオン 3-1**: AFT導入の前提条件と準備作業 

- Terraformバージョン・AWS CLIの準備

- GitLab環境の構築と接続設定

- 必要なIAMロールと権限の設定

- AFT管理アカウントの準備

### **ハンズオン 3-2**: AFT管理アカウントの設計と構築 

- AFT管理アカウントの位置づけと役割

- AFT実行用のIAMロール設計（最小権限の原則に基づく）

- CodePipeline/CodeBuild環境の構築

- セキュリティ監査設定

### **ハンズオン 3-3**: AFTパイプラインの設計と実装 

- パイプラインのステージ設計（Global/OU/Account）

- ワークフロー制御の実装

- エラーハンドリングと手動承認プロセスの組み込み

- パイプラインの監視とログ設定

### **ハンズオン 3-4**: アカウント申請プロセスの自動化 

- GitLabを用いたアカウント申請ワークフロー設計

- account-requests JSONテンプレートの設計

- 承認フローと監査証跡の実装

- マイクロサービス別アカウントテンプレート設計

### **ハンズオン 3-5**: AFT検証と初期アカウント作成テスト 

- テスト用アカウント作成シナリオの実行

- 作成プロセスの監視とログ確認

- 問題点の洗い出しと改善

- 性能評価と最適化

### **ハンズオン 3-6**: マイクロサービス向けアカウント構成の自動化 

- サービス群ごとのベースライン設定

- 環境別設定の差分管理

- 自動構成適用のテストと検証

- スケーラブルな構成管理アプローチ

### アンチパターン：AFT導入で失敗しやすいポイント

- AFT管理アカウントに過剰な権限を付与してしまう

- GitLab連携の認証情報が適切に保護されていない

- エラー通知設定が不足し、失敗を見逃す

- パイプラインのタイムアウト設定が不適切で長時間ハングする

- アカウント申請テンプレートに必須フィールドの検証が不足している

- マイクロサービス特有の構成要件を標準化しきれていない

## 4. IAM Identity CenterとPermission Set設計（25-30ページ）

## 本章の目的：最小権限アクセス管理と自動プロビジョニングを設計・実装する

### **ハンズオン 4-1**: Identity Center機能と基本設計 

- Identity Centerのコンセプトと機能

- IAMユーザーからの移行戦略（最小化アプローチ）

- Active Directory連携設計

- 認証フローと委任モデル

### **ハンズオン 4-2**: ユーザー・グループとアカウント構造の設計 

- ユーザー/グループ管理設計（Active Directory反映）

- 命名規則とグループ階層

- 職務分掌とセキュリティ境界設計

- グループ同期戦略

### **ハンズオン 4-3**: Permission Set設計とTerraform管理 

- 権限セットの体系設計

- 最小権限の原則に基づく設計

- AWS管理ポリシーとカスタムポリシーの使い分け

- マイクロサービス開発・運用に特化したPermission Set

### **ハンズオン 4-4**: アカウント・OU別アクセス割り当て 

- アカウントごとの権限差異設計

- OU単位の一括割り当て戦略

- 環境タイプ別の権限制限

- 特権アクセス制御と最小権限設計

### **ハンズオン 4-5**: ECS/Auroraサービスロール設計 

- コンテナタスク実行ロールの最小権限設計

- Auroraへのアクセスロール設計（IAM認証）

- クロスアカウントロール設計

- サービス間の安全な通信保証

### **ハンズオン 4-6**: アクセス監査とレビュープロセス 

- アクセス権限の定期レビュー設計

- 未使用権限の検出と削除

- CloudTrailとの統合監査

- IAM Access Analyzerの設定と連携

### アンチパターン：IAM設計で失敗しやすいポイント

- IAMユーザーへの依存が残り、統一的な認証基盤が構築できない

- Permission Setが少なすぎるか多すぎて管理が複雑化

- グループと権限設計が組織構造と合っていない

- コンテナサービスロールに過剰な権限を付与してしまう

- Aurora接続のIAM認証設定が複雑すぎて管理困難になる

- アクセスレビュープロセスが形骸化し、実効性がない

**5. ネットワークインフラ設計とDirectConnect連携（30-35ページ）**

**本章の目的：高可用性ハイブリッドネットワークの設計と実装を習得する**

### **ハンズオン 5-1**: 機能別VPC設計 

- VPC分離モデルの設計（認証/アプリケーション/DB/運用）

- CIDRプランニングと将来拡張考慮

- サブネット設計と可用性ゾーン配置

- ルーティングテーブル戦略

### **ハンズオン 5-2**: VPC間接続とTransit Gateway設計 

- Transit Gateway設計と接続トポロジー

- VPCアタッチメント設計

- ルーティング制御とセキュリティ

- Route53ドメイン設計

### **ハンズオン 5-3**: DirectConnect設計と実装 

- 冗長DirectConnectゲートウェイ設計

- Virtual Private Gatewayとの接続

- ルートポリシーとプレフィックスリスト

- BGP設定とフィルタリング

### **ハンズオン 5-4**: Site-to-Site VPNバックアップ回線設計 

- S2S VPN冗長構成設計

- フェイルオーバー戦略とテスト

- BGPルート広告とプリファレンス設定

- 回線品質モニタリング

### **ハンズオン 5-5**: オンプレミス-AWS間通信設計 

- 移行期間中のハイブリッド接続設計

- レイテンシとスループット要件分析

- トラフィックフロー最適化

- 安全なデータ転送パターン

### **ハンズオン 5-6**: マイクロサービス間ネットワーク設計 

- サービスディスカバリ設計

- サービスメッシュ検討

- 内部APIゲートウェイ設計

- サービス間通信の監視と可視化

### アンチパターン：ネットワーク設計で失敗しやすいポイント

- CIDR範囲の計画が不十分で後々拡張できない

- Transit Gateway設定が複雑すぎてルーティングが追跡困難になる

- DirectConnectとVPNのフェイルオーバーテストが不足

- オンプレミス依存が残るハイブリッド環境の複雑さを過小評価

- サービス間通信のセキュリティ境界が不明確

- マイクロサービス間の通信パターンが非効率で高遅延を引き起こす

## 6. 包括的セキュリティ設計と統合ガバナンス（35-40ページ）

## 本章の目的：多層防御のセキュリティアーキテクチャを設計・実装する

### **ハンズオン 6-1**: Security Hub統合基盤の設計 

- セキュリティ統合アーキテクチャ設計

- マルチアカウント・マルチリージョン設定

- セキュリティ標準の選択と設定

- 移行プロジェクトのセキュリティ監視体制

### **ハンズオン 6-2**: WAF + Shield Standardの実装設計 

- WAFルールセットの設計（OWASP Top 10対応）

- API Gateway、CloudFront、ALB連携設定

- WAFログ分析とアラート設定

- Shield Standardの設定と効果範囲

### **ハンズオン 6-3**: Firewall Managerとポリシー設計 

- 中央集権的ポリシー設計

- WAF、Shield、Security Group用ポリシー

- 自動修復と適用除外設計

- コンプライアンス監視設定

### **ハンズオン 6-4**: Network Firewall実装と統合 

- Network Firewall配置設計

- トラフィックインスペクションルール

- ステートフルフィルタリング設定

- ログ設定と分析基盤連携

### **ハンズオン 6-5**: コンテナとマイクロサービスのセキュリティ 

- コンテナイメージのセキュリティスキャン

- シークレット管理と安全な環境変数

- サービス間通信の暗号化

- ランタイムセキュリティ監視

### **ハンズオン 6-6**: クロスアカウントセキュリティ監視 

- 集中監視アカウント設計

- SecurityHub集約と委任管理

- アラート統合とエスカレーションフロー

- インシデント対応自動化

### **ハンズオン 6-7**: データ保護と暗号化戦略 

- Auroraデータの暗号化設計

- S3バケットのセキュリティ設定

- 転送中データの暗号化要件

- 鍵管理（KMS）戦略

### アンチパターン：セキュリティ設計で失敗しやすいポイント

- セキュリティツールの導入だけで対応が終わったと考える

- WAFルールが過剰に厳格で正常なトラフィックをブロックする

- Network Firewall配置が不適切でセキュリティギャップが生じる

- マイクロサービス間の通信セキュリティが不十分

- コンテナイメージのセキュリティスキャンが自動化されていない

- クロスアカウントセキュリティ監視の設定が複雑すぎて機能しない

## 7. ECS FargateとECR設計（25-30ページ）

## 本章の目的：マイクロサービスのコンテナ実行基盤の設計・実装を行う

### **ハンズオン 7-1**: マイクロサービスコンテナ化戦略 

- コンテナ化の原則と設計パターン

- イメージサイズ最適化とレイヤー設計

- マイクロサービス別のDockerfile設計

- ベースイメージ戦略とセキュリティ

### **ハンズオン 7-2**: ECRレポジトリ設計とライフサイクル管理 

- リポジトリ命名規則と構成

- イメージタグ付け戦略

- イメージライフサイクルポリシー設計

- 脆弱性発見時の自動更新戦略

### **ハンズオン 7-3**: ECS Fargateクラスタ設計 

- クラスタ構成と分離戦略

- タスク定義の設計

- オートスケーリング設定

- Service Discovery設計

### **ハンズオン 7-4**: コンテナログとモニタリング 

- CloudWatch Logs統合

- コンテナインサイト設定

- 分散トレーシング設計

- パフォーマンスモニタリング

### **ハンズオン 7-5**: コンテナセキュリティの設計 

- イメージスキャン自動化

- タスク実行ロールの最小権限設計

- ネットワークセキュリティ設計

- シークレット管理とランタイム保護

### **ハンズオン 7-6**: 環境間のコンテナイメージ管理戦略

- 環境別タグ付け（dev/staging/prod）

- イメージの不変性保証

- クロスアカウントイメージ共有

- イメージ推進（プロモーション）パイプライン設計

### **ハンズオン 7-7**: マルチリージョン対応（東京・大阪） 

- リージョン間のECRレプリケーション設計

- 両リージョンでのクラスター設計

- リージョン固有の構成管理

- フェイルオーバー戦略

### アンチパターン：ECS Fargate設計で失敗しやすいポイント

- コンテナイメージが肥大化し、起動時間とリソース消費が増大

- タスク定義のリソース設定が最適化されていない

- IAMロールが過剰な権限を持ち、セキュリティリスクとなる

- Auto Scalingの設定が不適切でスケーリングが効果的に機能しない

- ログ設定が不十分で、問題発生時のトラブルシューティングが困難

- 環境間のイメージ昇格プロセスが不明確で、本番環境の品質が保証できない

- 脆弱性発見時の更新プロセスが確立されておらず、古いイメージが使われ続ける

## 8. Aurora/Flywayデータベース設計（25-30ページ）

## 本章の目的：マイクロサービス向けデータベース基盤と自動マイグレーションの設計・実装を行う

### **ハンズオン 8-1**: マイクロサービスのデータ分離戦略 

- データ所有権とサービス境界設計

- マイクロサービスごとのスキーマ分離設計

- 共有データの識別と管理戦略

- 分散データの整合性確保戦略

### **ハンズオン 8-2**: Aurora設計と構成 

- クラスタータイプとサイジング選定

- マルチAZ構成とフェイルオーバー設計

- パラメータグループ最適化

- リーダーインスタンス戦略

### **ハンズオン 8-3**: IAMデータベース認証の実装 

- IAM認証フローと設定

- ECSタスクロールとの連携設計

- ユーザー/パスワード認証からの移行

- 認証監査と可視化設計

### **ハンズオン 8-4**: Flywayによるスキーママイグレーション 

- マイグレーション戦略とスクリプト設計

- バージョン管理とロールバック計画

- CI/CDとの統合

- 環境間の差分管理

### **ハンズオン 8-5**: オンプレミスからのデータ移行 

- ETL処理パイプライン設計

- S3を経由したデータ転送プロセス

- 大規模データの効率的移行手法

- 移行検証とデータ整合性確認

### **ハンズオン 8-6**: マイクロサービス間のデータ連携 

- イベント駆動データ連携パターン

- レプリケーション戦略

- データ一貫性と結果整合性の戦略

- リードモデルとライトモデルの分離

### **ハンズオン 8-7**: マルチリージョンデータ戦略 

- Aurora Global Databaseの設計

- リージョン間レプリケーション設定

- リージョン固有のデータ分離

- フェイルオーバー戦略

### アンチパターン：データベース設計で失敗しやすいポイント

- マイクロサービス間でデータベースを共有し、密結合が生じる

- Auroraのサイジングが過剰または過小で、コストまたはパフォーマンス問題が発生

- IAM認証の設定が不適切で、接続に失敗またはセキュリティリスクが生じる

- マイグレーションスクリプトのバージョン管理が不十分で、環境間の不整合が発生

- データ移行プロセスの検証が不十分で、データ損失やマッピング誤りが発生

- トランザクションの境界が不明確で、データ整合性が損なわれる

- マルチリージョン設定の複雑さを過小評価し、フェイルオーバー時に問題が発生

## 9. API GatewayとCognito認証基盤（25-30ページ）

## 本章の目的：マイクロサービスAPI層と認証基盤の設計・実装を行う

### **ハンズオン 9-1**: マイクロサービスAPIアーキテクチャ設計 

- APIファーストアプローチと設計原則

- OpenAPI仕様と標準化戦略

- APIバージョニング戦略

- エラーハンドリングとステータスコード標準化

### **ハンズオン 9-2**: API Gateway設計とBFFパターンの実装 

- API Gatewayのリソース設計

- BFFパターンのエンドポイント設計

- クライアント最適化API設計

- APIドキュメンテーション戦略

### **ハンズオン 9-3**: Cognito認証基盤の設計 

- ユーザープールとIDプールの設計

- Active Directory連携設計

- 多要素認証の実装

- ソーシャルIDプロバイダー連携

### **ハンズオン 9-4**: API認証と権限管理 

- CognitoとAPI Gatewayの統合

- JWTトークン検証フロー

- スコープベースの権限制御

- APIキー管理とUsage Plan設計

### **ハンズオン 9-5**: スロットリングと流量制御 

- リソース別のスロットリング設計

- クライアント別の使用制限設計

- WAFとの統合によるセキュリティ強化

- 異常検知と自動対応

### **ハンズオン 9-6**: クロスアカウントAPI連携 

- マイクロサービス間のAPI呼び出し設計

- 内部API認証と権限管理

- セキュリティ境界の設計

- 可観測性と障害追跡

### **ハンズオン 9-7**: マルチリージョンAPI戦略 

- リージョン間のAPI設計

- リージョン固有のエンドポイント管理

- フェイルオーバー設定

- レイテンシ最適化

### アンチパターン：API設計で失敗しやすいポイント

- APIリソース設計が不適切で管理困難やパフォーマンス低下を招く

- Cognitoの設定が複雑すぎてトラブルシューティングが困難になる

- API Gatewayのスロットリング設定が不適切で本番環境で性能問題が発生

- クロスアカウント設定のセキュリティホールが生じる

- 認証フローのユーザー体験が考慮されておらず、使いにくいシステムになる

- マイクロサービス間の依存関係が不透明で、問題発生時の原因特定が困難

- マルチリージョン考慮が不足し、リージョン障害時の可用性が確保できない

## 10. Step Functions/Lambdaによるバッチ処理自動化（25-30ページ）

## 本章の目的：マイクロサービス間連携とバッチ処理の自動化を設計・実装する

### **ハンズオン 10-1**: マイクロサービスのビジネスプロセス分析 

- オンプレミス基幹システムの業務フロー分析

- マイクロサービス間のビジネスフロー再設計

- イベント駆動アーキテクチャへの変換

- サービス連携パターンの選定

### **ハンズオン 10-2**: Step Functions ワークフロー設計 

- ステートマシン設計パターン

- 分岐と並列処理の実装

- エラー処理と復旧戦略

- サービス間連携フローの設計

### **ハンズオン 10-3**: Lambda関数の設計と実装 

- 関数分割とサイズ最適化

- 権限モデルと実行ロール設計

- エラーハンドリングとリトライ戦略

- 環境変数と設定管理

### **ハンズオン 10-4**: データ処理パイプラインの実装 

- ETL処理の設計

- 大規模データの分散処理

- 進捗追跡と状態管理

- 処理結果の検証と集約

### **ハンズオン 10-5**: バッチスケジューリングと運用管理 

- EventBridgeによるスケジュール設定

- バッチ処理の依存関係管理

- 実行ステータス監視と通知

- 失敗時のリカバリープロセス

### **ハンズオン 10-6**: クロスアカウントバッチ処理 

- アカウント間連携戦略

- セキュリティ境界とアクセス制御

- 集中監視と分散実行の両立

- 環境別の実行分離

### **ハンズオン 10-7**: マルチリージョンワークフロー対応 

- リージョン間のデータ連携設計

- リージョン固有の処理分離

- フェイルオーバー自動化

- リージョン間のステート共有

### アンチパターン：サーバーレスバッチ処理で失敗しやすいポイント

- Lambda関数が大きすぎてコールドスタート問題やタイムアウトが発生

- Step Functionsのワークフロー設計が複雑すぎて管理困難になる

- エラーハンドリング不足により、部分的失敗からの復旧が困難

- 並列処理のスケーリング制限を考慮せずに設計し、スロットリングが発生

- バッチ処理の状態管理が不十分で、実行ステータスが不明確になる

- クロスアカウント権限設定のミスでセキュリティリスクが生じる

- マルチリージョン考慮が不足し、リージョン障害時にバッチ処理が停止する

## 11. Terraform IaC設計と環境変数管理（25-30ページ）

## 本章の目的：マルチリージョン対応のIaC設計と環境変数管理の導入

### **ハンズオン 11-1**: Terraformプロジェクト構造設計 

- モジュール設計と分離戦略

- リポジトリ構造とブランチ戦略

- ディレクトリ階層と依存関係

- コード標準化とベストプラクティス

### **ハンズオン 11-2**: 環境変数によるモジュール管理 

- 環境変数設計と命名規則

- 環境別の設定分離

- 環境変数の安全な管理

- 変数のスコープと継承設計

### **ハンズオン 11-3**: マルチリージョン対応IaC設計 

- 東京・大阪両リージョン並記の実装方針

- プロバイダー構成とリージョン指定

- リージョン固有設定の分離

- 共通変数と固有変数の設計

### **ハンズオン 11-4**: 環境タグ付け戦略 

- 標準タグセットの設計

- 環境タグ（dev/staging/prod）の実装

- タグの継承と自動付与

- タグベースのリソース管理

### **ハンズオン 11-5**: Terraformステート管理戦略 

- ステートファイル分離原則

- バックエンド設定とリモートステート

- ステート参照と変数連携

- ステートロックとバージョン管理

### **ハンズオン 11-6**: Terraformコード品質管理 

- コード標準化とスタイルガイド

- 自動フォーマットと検証

- コメントとドキュメンテーション

- モジュールバージョニング

### **ハンズオン 11-7**: 秘密情報と変数管理 

- 秘密情報の安全な管理

- AWS Secrets Managerとの連携

- 変数のバリデーション設計

- デフォルト値と条件付き設定

### アンチパターン：Terraform設計で失敗しやすいポイント

- モジュールの粒度が不適切（細かすぎる/大きすぎる）で管理が複雑化

- 環境変数管理が不十分で環境間の差異が不明確

- マルチリージョン対応のプロバイダー設定不備でデプロイエラーが発生

- タグ付け戦略の一貫性がなく、リソース管理やコスト配分が困難になる

- ステート分離が不適切で構成競合やドリフトが発生

- 秘密情報がコードにハードコードされセキュリティリスクとなる

- 変数バリデーションが不足し、無効な値でデプロイが進行してしまう

## 12. CI/CDパイプラインとコード品質管理（30-35ページ）

## 本章の目的：高品質なIaCとアプリケーションのCI/CDパイプラインを設計・実装する

### **ハンズオン 12-1**: CI/CD戦略とツール選定 

- CodePipelineの位置づけと設計指針

- ブランチ戦略とGitLabワークフロー

- 環境別デプロイ戦略

- 品質ゲートと昇格基準

### **ハンズオン 12-2**: IaC向け静的解析パイプライン実装 

- tfsecの設定と統合

- TFLintの設定とルールカスタマイズ

- checkovによるコンプライアンス検証

- 解析結果のレポーティングと修正フロー

### **ハンズオン 12-3**: IaC向け動的解析の実装 

- IAM Access Analyzerの設定と統合

- terraform planの自動検証

- 検出された問題の分類と重要度判定

- セキュリティリスクの自動検知

### **ハンズオン 12-4**: 手動承認プロセスの組み込み 

- エラー検知時の手動承認フロー設計

- 承認権限の設定と分離

- エラー内容の可視化と決定支援

- 承認履歴の監査とトレーサビリティ

### **ハンズオン 12-5**: マイクロサービスビルドパイプライン 

- コードリポジトリ構成と分離

- ビルド環境の標準化

- ユニットテスト自動化

- コード品質チェックと脆弱性スキャン

### **ハンズオン 12-6**: コンテナイメージビルドとECR連携 

- イメージビルドプロセス自動化

- タグ付けとバージョン管理

- セキュリティスキャン統合

- ECRへの自動プッシュ

### **ハンズオン 12-7**: ECS Fargateデプロイパイプライン 

- デプロイ戦略（ブルー/グリーン、カナリア）

- タスク定義の自動更新

- ヘルスチェックと自動ロールバック

- デプロイ履歴と追跡

### **ハンズオン 12-8**: データベースマイグレーション自動化 

- Flywayマイグレーションの自動化

- デプロイとのマイグレーション同期

- ロールバック戦略

- データ整合性の検証

### **ハンズオン 12-9**: 環境間のプロモーションフロー 

- Dev → Test → Staging → Prodの昇格フロー

- 承認ゲートと検証プロセス

- 環境間の構成差異の管理

- リリース管理と変更履歴

### アンチパターン：CI/CD設計で失敗しやすいポイント

- 静的解析ツールの警告を無視し、セキュリティ問題が見過ごされる

- パイプラインが単一障害点となり、全デプロイが阻害される

- テスト自動化が不十分で、品質問題が検出されない

- 手動承認プロセスが形骸化し、意味のあるチェックが行われない

- 環境間の構成差異が大きく、本番デプロイの信頼性が低い

- デプロイとデータベースマイグレーションの同期が取れず、サービス障害が発生

- ロールバック戦略が不十分で、障害発生時に復旧が困難になる

- パイプラインのIAM権限が過剰で、セキュリティリスクとなる

## 13. DR戦略と東京-大阪間レプリケーション（20-25ページ）

## 本章の目的：本番環境のDR戦略と大阪リージョンへのレプリケーションを設計・実装する

### **ハンズオン 13-1**: DR要件とRTO/RPO設計 

- 業務継続性要件の分析

- サービス別の優先度とRTO/RPO定義

- フェイルオーバーとフェイルバックのシナリオ設計

- DR戦略の選定（ウォームスタンバイ/パイロットライト/マルチリージョン）

### **ハンズオン 13-2**: Aurora Global Databaseの設計と実装 

- クロスリージョンレプリケーション設定

- フェイルオーバープロセスの設計

- リードレプリカの活用戦略

- レプリケーションラグモニタリング

### **ハンズオン 13-3**: ECS/ECRのクロスリージョン設計 

- コンテナイメージのクロスリージョンレプリケーション

- マルチリージョンECSクラスタの管理

- リージョン固有の設定管理

- デプロイパイプラインのDR対応

### **ハンズオン 13-4**: APIとCognitoのDR戦略 

- API GatewayのクロスリージョンAPI管理

- Cognitoユーザーデータの同期戦略

- マルチリージョンフロントエンド設計

- DNS切り替え戦略

### **ハンズオン 13-5**: フェイルオーバー自動化とテスト 

- フェイルオーバー判断と実行の自動化

- Route 53ヘルスチェックとフェイルオーバールーティング

- DR訓練の設計と実施フロー

- フェイルバックプロセスの検証

### アンチパターン：DR設計で失敗しやすいポイント

- RTO/RPOの定義が曖昧で、実際の障害時に期待が一致しない

- レプリケーション設定が不完全で、データ損失や整合性問題が発生

- フェイルオーバー手順のテストが不足し、実際の障害時に機能しない

- マルチリージョン構成のコスト影響が過小評価される

- フェイルバックプロセスが考慮されていない

- DR環境のセキュリティ設定が本番環境と一致していない

- 東京・大阪間の通信レイテンシを考慮せず、パフォーマンス問題が発生

## 14. 監視・運用基盤の設計（20-25ページ）

## 本章の目的：マイクロサービス環境の統合監視と運用自動化を設計・実装する

### **ハンズオン 14-1**: マイクロサービスの可観測性設計 

- 3本柱（メトリクス、ログ、トレース）の実装戦略

- サービスレベル目標（SLO）とサービスレベル指標（SLI）の定義

- カスタムメトリクスの設計

- ダッシュボード構築戦略

### **ハンズオン 14-2**: 統合監視ダッシュボード構築 

- CloudWatchダッシュボード設計

- クロスアカウントメトリクス集約

- サービス健全性とビジネスKPIの可視化

- 異常検知設定

### **ハンズオン 14-3**: 分散トレーシングの実装 

- X-Ray統合の設計

- サービス間トレースの実装

- パフォーマンスボトルネック分析

- トレース検索と可視化

### **ハンズオン 14-4**: アラート通知フロー実装 

- SNSトピックとサブスクリプション設定

- アラートルーティングとエスカレーション

- オンコール管理とローテーション

- インシデント対応プロセス自動化

### **ハンズオン 14-5**: 運用自動化スクリプト実装 

- Lambda関数によるオートメーション

- 定期メンテナンスタスクの自動化

- 自己修復メカニズムの実装

- スケジュールタスク設定

### **ハンズオン 14-6**: コスト監視と最適化 

- タグベースのコスト分析

- 予算アラートと通知設定

- 異常検知と自動スケーリング最適化

- コスト配分とチャージバックモデル

### アンチパターン：監視・運用設計で失敗しやすいポイント

- メトリクスが多すぎて重要な情報が埋もれる「ダッシュボード疲れ」を引き起こす

- アラートが多すぎて「アラート疲れ」が生じ、重要な通知が見落とされる

- 分散トレーシングの実装が不完全で、問題の根本原因分析が困難になる

- 自動化スクリプトのエラーハンドリングが不足し、問題を解決せず悪化させる

- サービスレベル目標（SLO）が不明確で、運用の成功基準が評価できない

- コスト監視が表面的で、実際のコスト削減につながる洞察が得られない

- 環境タグ付けが不十分で、コスト分析が不正確になる

## 15. 移行実行計画と組織的導入（20-25ページ）

## 本章の目的：オンプレミスからの段階的移行と組織的な導入プロセスを設計する

### **ハンズオン 15-1**: 移行フェーズと優先順位付け 

- 依存関係に基づく移行順序

- ビジネスクリティカリティ評価

- 技術的複雑性分析

- フェーズ分割と成功基準設定

### **ハンズオン 15-2**: 並行運用と切り替え戦略 

- 並行運用期間中のデータ同期

- カットオーバー計画と実行手順

- ロールバック基準と手順

- 段階的なトラフィック移行戦略

### **ハンズオン 15-3**: ステークホルダーマップと組織変革計画 

- 主要ステークホルダーの特定と関与計画

- 部門間の役割と責任の再定義

- コミュニケーション戦略と進捗共有

- 意思決定フローと承認プロセス

### **ハンズオン 15-4**: トレーニングと技術移転計画 

- ロールベースのトレーニング内容

- ハンズオンワークショップの設計

- 自己学習リソース作成

- 継続的スキルアップ体制

### **ハンズオン 15-5**: 内部ドキュメント作成戦略 

- アカウント申請ガイド

- マイクロサービス開発・運用ガイドライン

- アーキテクチャ決定記録（ADR）管理

- トラブルシューティングガイド

### **ハンズオン 15-6**: AFTユーザーコミュニティ構築 

- 定期ミーティング設計

- ナレッジベース構築

- ベストプラクティス共有フォーラム

- 継続的改善プロセス

### アンチパターン：移行実行と組織的導入で失敗しやすいポイント

- 依存関係の分析が不十分で、移行順序に問題が生じる

- カットオーバー計画が不十分で、ビジネス中断リスクが生じる

- ステークホルダーの巻き込みが不足し、組織的な抵抗が発生する

- トレーニングが技術面に偏り、ビジネスプロセスの変更管理が不足する

- ドキュメントが過剰または不足し、実用性が低い

- 移行後の運用モデルへの移行が不十分で、持続的な運用に問題が生じる

- 教育・啓蒙活動が不足し、新しい技術やプロセスの採用率が低い

# 技術実装ガイド：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化実装ハンドブック」（約325ページ）

## 16. AFT環境構築実践ガイド（30-35ページ）

## 本章の目的：AFT環境の実際の構築とControl Tower連携を実装する

### **実践ハンズオン 16-1**: Control Tower・Organizations設定の実践 

- AWS Management Consoleでの設定手順

- Landing Zone構築と初期設定

- AFT前提条件のチェックリスト確認

- 詳細なスクリーンショットと操作説明

### **実践ハンズオン 16-2**: AFT管理アカウントの構築 

- Terraformモジュールの適用手順

- パラメータ設定と環境変数

- 動作検証とトラブルシューティング

- IaCのベストプラクティス実装

### **実践ハンズオン 16-3**: GitLab環境の構築とAFT連携 

- GitLabインスタンスの構築手順

- リポジトリ構造の設計と作成

- CodePipelineとの連携設定

<!-- -->

- 認証とセキュリティ対策

- ブランチ保護と承認フローの設定

### **実践ハンズオン 16-4**: AFTパイプラインの構築と設定 

- CodePipelineの設定と構成

- トリガー設定とIAM権限

- ロギングと通知設定

- 各ステージの詳細設定

### **実践ハンズオン 16-5**: 静的解析ツールの統合設定 

- tfsec, TFLint, checkovの導入と設定

- カスタムルールセットの作成

- 分析結果の通知と記録

- 継続的な改善フロー

### **実践ハンズオン 16-6**: IAM Access Analyzerの設定 

- クロスアカウント分析の設定

- 検出ルールのカスタマイズ

- アラート設定と対応フロー

- 定期的なレビュープロセス

### **実践ハンズオン 16-7**: 手動承認ステージの実装 

- ステージ間の手動承認設定

- エラー発生時の判断支援情報

- 承認者グループと権限設定

- 監査証跡の設定

### 実践ハンズオン 16-8: AFT機能検証 

- テストアカウント作成

- ログと監査証跡の確認

- トラブルシューティングとデバッグ手法

- 性能最適化とスケーリング設定

### **実践ハンズオン 16-9**: マイクロサービスアカウントテンプレート構築 

- サービス群ごとの標準アカウント設定

- 環境別のベースライン定義

- 自動プロビジョニングのテスト

- 検証と調整

### アンチパターン：AFT環境構築で失敗しやすいポイント

- AFTのバージョン互換性を確認せずに導入し、依存関係エラーが発生

- IAM権限が不足またはバケットポリシーが不適切で、パイプラインが失敗

- GitLab連携の認証情報が適切に保護されていない

- 静的解析ツールの警告を無視し、セキュリティ問題がそのまま残る

- 手動承認プロセスが形骸化し、効果的なチェックが行われない

- Access
  Analyzerの検出結果への対応が遅れ、セキュリティリスクが長期間残存

- 詳細なログ設定を省略し、問題発生時の診断が困難になる

- 通知設定が不足し、パイプライン失敗に気づかない

## 17. IAM Identity CenterとPermission Set実装（25-30ページ）

## 本章の目的：IAMユーザーに依存しないアクセス管理基盤を実装する

### **実践ハンズオン 17-1**: Identity Center初期設定 

- Identity Center有効化と基本設定

- Active Directory連携設定

- グループとユーザー同期の設定

- サインインURL設定と検証

### **実践ハンズオン 17-2**: 権限設計とPermission Set構築 

- 標準Permission Setの設計と作成

- カスタムPermission Setの作成

- インラインポリシーの活用

- 最小権限の原則の適用

### **実践ハンズオン 17-3**: アカウント割り当ての自動化 

- Terraformによる割り当て自動化

- AFTとの統合設定

- グループベースの一括割り当て

- 動的更新メカニズム

### **実践ハンズオン 17-4**: ECS/Aurora用のIAMロール実装 

- ECSタスク実行ロールの作成

- Auroraアクセス用IAMロールの作成

- ロール間の信頼関係設定

- クロスアカウントロール設定

### **実践ハンズオン 17-5**: 緊急アクセス手順の実装 

- ブレークグラスアクセスの設計

- 特権アクセスワークフローの構築

- 監査と証跡の設定

- 定期的なテスト手順

### **実践ハンズオン 17-6**: アクセス監査とレビュー自動化 

- 定期レビュー用レポート自動化

- 未使用権限の検出スクリプト

- レビュープロセスのワークフロー化

- 自動修正メカニズム

### アンチパターン：Identity Center実装で失敗しやすいポイント

- AD連携の設定不備により、正しくID同期が行われない

- Permission Setの粒度が不適切で、過剰または過小な権限が付与される

- Terraformによる自動化とコンソールでの手動変更が混在する

- ECSタスク実行ロールに過剰な権限が付与される

- 緊急アクセス手順が不明確で、障害時にアクセスできない状況が発生

- アクセスレビューが形骸化し、不要な権限が残り続ける

- ロール命名規則の不統一により、管理が複雑化する

## 18. ネットワークインフラ実装（30-35ページ）

## 本章の目的：セキュアで高可用性のネットワークインフラを実装する

### 実践ハンズオン 18-1: 機能別VPC実装 

- VPCリソースの宣言的定義

- サブネット設計と詳細構成

- ルートテーブル設定

- セキュリティグループとNACL実装

### **実践ハンズオン 18-2**: マルチリージョンVPC設定 

- 東京・大阪両リージョンでのVPC構築

- リージョン固有パラメータの設定

- リージョン間の整合性確保

- 環境変数を活用した設定管理

### **実践ハンズオン 18-3**: Transit Gateway実装 

- Transit Gateway設定

- VPCアタッチメント設定

- ルートテーブル構成

- 接続性テストとトラブルシューティング

### **実践ハンズオン 18-4**: DirectConnect設定実装 

- DirectConnect仮想インターフェース設定

- 冗長性設定とフェイルオーバー

- BGP設定と経路制御

- 接続テストとモニタリング

### **実践ハンズオン 18-5**: S2S VPNバックアップ実装 

- カスタマーゲートウェイ設定

- VPN接続設定とトンネルオプション

- ルーティングとフェイルオーバー設定

- 監視とアラート設定

### **実践ハンズオン 18-6**: Network Firewall実装 

- Firewall配置と保護対象定義

- ファイアウォールポリシー設定

- ルールグループとフィルタリング設定

- ログと監視設定

### **実践ハンズオン 18-7**: マイクロサービス通信パターン実装 

- サービスディスカバリ設定

- サービス間通信の暗号化

- 内部ロードバランサー設定

- 通信パターンのテストと検証

### アンチパターン：ネットワーク実装で失敗しやすいポイント

- サブネットCIDR設計の不備により、後からのリソース拡張が困難になる

- リージョン間の設定不整合により、フェイルオーバー時に問題が発生

- Transit Gatewayのルートテーブル設計ミスで、接続性問題が発生

- DirectConnectとVPNのフェイルオーバー設定不備で、冗長性が確保できない

- Network Firewallルールが厳格すぎて、正常なトラフィックがブロックされる

- クロスアカウントアクセス設定のミスでセキュリティリスクが生じる

- ネットワーク設計のIaC化が不完全で、手動変更と競合が発生

## 19. WAF/Shield/Firewall Manager実装（25-30ページ）

## 本章の目的：多層防御のセキュリティ境界を実装する

### **実践ハンズオン 19-1**: WAF Web ACL設計と実装 

- WAFルールグループの設計と作成

- マネージドルールの選択と設定

- カスタムルールの作成と検証

- ログ記録とモニタリング

### **実践ハンズオン 19-2**: WAFとAPI Gateway/ALB/CloudFrontの連携 

- WAFとAPI Gatewayの統合設定

- ALBへのWAF適用と検証

- CloudFrontとWAFの統合実装

- 環境別のWAF保護戦略

### **実践ハンズオン 19-3**: Shield Standard設定 

- Shield保護の有効化と設定

- DDos対策設定

- シールドレスポンスチームとの連携設定

- 保護リソースの優先順位付け

### **実践ハンズオン 19-4**: Firewall Managerポリシー実装 

- セキュリティポリシーの設計と作成

- WAF管理ポリシーの構築

- Shield管理ポリシーの構築

- セキュリティグループポリシーの実装

### **実践ハンズオン 19-5**: Network Firewall高度設定 

- ステートフルインスペクションの設定

- カスタムプロトコル解析の実装

- ドメインフィルタリング設定

- トラフィック分析ログの活用

### **実践ハンズオン 19-6**: セキュリティ自動復旧設計 

- 自動修復ワークフローの実装

- 異常検知と自動応答

- セキュリティ違反の自動修正

- インシデント対応ワークフロー

### アンチパターン：セキュリティ境界実装で失敗しやすいポイント

- WAFルールが過剰に厳しく設定され、正常なビジネストラフィックがブロックされる

- セキュリティログが適切に管理されず、問題の診断や監査に支障をきたす

- Firewall Managerによるポリシー適用が一部環境でバイパスされる

- Network Firewallの配置が不適切で、保護が不十分なセグメントが生じる

- セキュリティ対策の自動化レベルが不十分で、手動操作の依存度が高い

- 各セキュリティレイヤー間の連携が不足し、包括的な可視性が得られない

- 脅威モデルが不明確で、セキュリティ対策の有効性を評価できない

## 20. ECS Fargate/ECRマイクロサービス実装（30-35ページ）

## 本章の目的：マイクロサービスのコンテナ実行基盤を実装する

### **実践ハンズオン 20-1**: マイクロサービスのコンテナ化 

- Dockerfileベストプラクティス

- マルチステージビルドの実装

- 最小特権原則の適用

- セキュリティスキャンの統合

### **実践ハンズオン 20-2**: ECRリポジトリ構築 

- リポジトリ作成と設定

- イメージスキャン設定

- ライフサイクルポリシー設定

- クロスアカウントアクセス設定

### **実践ハンズオン 20-3**: ECRセキュリティ自動化 

- コンテナ脆弱性スキャンの自動化

- 脆弱性検出時の自動通知

- 自動修復と再ビルドパイプライン

- バージョン管理と追跡

### **実践ハンズオン 20-4**: ECS Fargateクラスター実装 

- クラスター作成と設定

- タスク定義の作成

- サービス設定とロードバランサー連携

- オートスケーリング設定

### **実践ハンズオン 20-5**: サービスメッシュとサービスディスカバリ 

- サービスディスカバリの設定

- サービス間通信の実装

- トレース統合の設定

- メッシュの監視と管理

### **実践ハンズオン 20-6**: コンテナログとモニタリング 

- FireLensログルーターの設定

- CloudWatch Logsとの統合

- カスタムメトリクスの実装

- アラート設定とダッシュボード

### **実践ハンズオン 20-7**: マイクロサービス間の安全な通信 

- 内部ロードバランサーの設定

- TLS証明書の管理と更新

- サービス間認証の実装

- トラフィック制御とリトライパターン

### **実践ハンズオン 20-8**: 環境タグ付けとイメージプロモーション 

- 環境別タグ設計（dev/staging/prod）

- イメージプロモーションフローの実装

- 環境間の構成差分管理

- 安全なリリース手順

### アンチパターン：ECS Fargate/ECR実装で失敗しやすいポイント

- コンテナイメージの肥大化によるスタートアップレイテンシやリソース効率低下

- ECRのライフサイクルポリシーの不備で古いイメージが蓄積し続ける

- 脆弱性スキャンの対応が不十分で、既知の脆弱性を含むイメージが使われ続ける

- ECSタスク定義のリソース配分が不適切でコストまたはパフォーマンス問題が発生

- サービスディスカバリの設計不備でサービス間通信に障害が発生

- ログ・モニタリング設定の不足でトラブルシューティングが困難になる

- 環境タグ付けが不十分で、環境間のイメージ混在が発生する

- イメージプロモーションプロセスが不明確で、安全性が確保できない

## 21. Aurora/Flywayデータベース実装（25-30ページ）

## 本章の目的：マイクロサービス向けデータベース基盤を実装する

### **実践ハンズオン 21-1**: Auroraクラスター実装 

- クラスター作成と構成

- マルチAZ設定と冗長性確保

- パラメータグループの最適化

- メンテナンスとバックアップ設定

### **実践ハンズオン 21-2**: リージョン間のAurora設定 

- 東京・大阪両リージョンでの設定

- リージョン固有パラメータの管理

- 環境変数を用いた設定制御

- リージョン間整合性の確保

### **実践ハンズオン 21-3**: IAMデータベース認証実装 

- IAM認証の設定

- ECS/Fargateとの統合

- 認証フローのテスト

- 監査とログ設定

### **実践ハンズオン 21-4**: Flywayマイグレーション環境構築 

- プロジェクト構造と設定

- マイグレーションスクリプト作成

- バージョン管理と変更履歴

- CI/CDパイプライン統合

### **実践ハンズオン 21-5**: オンプレミスからのデータ移行 

- ETLパイプラインの構築

- データ変換とクレンジング

- S3ステージングと検証

- 移行検証と整合性チェック

### **実践ハンズオン 21-6**: マイクロサービス別スキーマ設計 

- サービス境界に応じたスキーマ分離

- 参照整合性とデータ一貫性

- パフォーマンス最適化

- データアクセスパターン実装

### **実践ハンズオン 21-7**: データベースパフォーマンスチューニング 

- インデックス戦略の最適化

- パフォーマンスインサイトの活用

- クエリ最適化と分析

- 自動スケーリング設定

### アンチパターン：Aurora/Flyway実装で失敗しやすいポイント

- Auroraのインスタンスタイプとクラスター設定が不適切でコスト/性能問題が発生

- リージョン間の設定不整合でレプリケーションが適切に機能しない

- IAMデータベース認証の設定不備で接続エラーが発生

- Flywayマイグレーションのバージョン管理不足で異なる環境間の不整合が生じる

- データ移行の検証不足で整合性問題やデータ損失が発生

- マイクロサービス境界を超えたデータアクセスパターンが生じ、密結合状態になる

- パフォーマンスモニタリングの不足で問題の早期発見ができない

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 22. API Gateway/Cognitoの実装（25-30ページ）

## 本章の目的：API層と認証基盤を実装する

### **実践ハンズオン 22-1**: API Gateway設計と実装 

- REST APIの作成と構成

- リソース階層とメソッド定義

- 統合タイプとマッピングテンプレート

- ステージとデプロイメント管理

### **実践ハンズオン 22-2**: マルチリージョンAPI設定 

- 東京・大阪両リージョンでのAPI設定

- リージョン固有エンドポイント管理

- 環境変数による設定制御

- リージョン間整合性確保

### **実践ハンズオン 22-3**: BFFパターン実装 

- クライアント最適化APIの実装

- バックエンドサービス統合

- データ変換とアグリゲーション

- エラーハンドリングパターン

### **実践ハンズオン 22-4**: Cognitoユーザープール実装 

- ユーザープール作成と設定

- MFA設定と強力なパスワードポリシー

- Active Directory連携設定

- サインアップとサインインフロー

### 実践ハンズオン 22-5: API認証の統合 

- CognitoオーソライザーとAPI Gateway連携

- スコープとアクセス制御

- JWTトークン検証

- APIキー管理とUsage Plan設定

### 実践ハンズオン 22-6: API性能最適化 

- キャッシング設定

- スロットリング最適化

- レイテンシモニタリング

- コストと性能のバランス管理

### **実践ハンズオン 22-7**: API監視とエラー対応 

- CloudWatchダッシュボード設定

- エラー率とレイテンシアラート

- エラーパターン分析

- 自動修復メカニズム

### アンチパターン：API Gateway/Cognito実装で失敗しやすいポイント

- APIのリソース構造が不適切で管理困難やURLの不整合が生じる

- リージョン間の設定不整合でフェイルオーバー時に問題が発生

- Cognitoの設定が複雑すぎてユーザー体験が低下する

- API認証の設定ミスでセキュリティ脆弱性やアクセス問題が発生

- スロットリング設定の不備で高負荷時にサービス停止が発生

- キャッシュ設定の誤りで古いデータが提供される

- エラーハンドリングが不十分でクライアント側での問題解決が困難になる

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 23. Step Functions/Lambdaバッチ処理実装（25-30ページ）

## 本章の目的：サーバーレスバッチ処理基盤を実装する

### **実践ハンズオン 23-1**: Step Functions実装 

- ステートマシン設計と作成

- ワークフロー定義とステート設定

- 条件分岐とエラーハンドリング

- 並列処理実装

### **実践ハンズオン 23-2**: マルチリージョンワークフロー設定 

- 東京・大阪両リージョンでのワークフロー設定

- リージョン固有パラメータの管理

- 環境変数による設定制御

- リージョン間整合性の確保

### **実践ハンズオン 23-3**: Lambda関数実装 

- 関数コード開発とベストプラクティス

- タイムアウトとメモリ最適化

- エラーハンドリングとリトライ

- 環境変数とコンテキスト管理

### **実践ハンズオン 23-4**: データ処理パイプライン実装 

- ETL処理フローの構築

- 大規模データ処理の並列化

- S3イベントトリガー設定

- 処理状態の可視化

### **実践ハンズオン 23-5**: バッチスケジューリング実装 

- EventBridgeルール設定

- バッチジョブ依存関係管理

- 定期実行と監視

- 失敗処理とリカバリー

### **実践ハンズオン 23-6**: クロスアカウントワークフロー 

- アカウント間のStep Functions連携

- クロスアカウントLambda呼び出し

- IAMロールとアクセス制御

- エンドツーエンド監視

### **実践ハンズオン 23-7**: バッチ処理の監視と最適化 

- CloudWatch Logs/Metricsの設定

- X-Ray分析統合

- コスト最適化戦略

- パフォーマンスチューニング

### アンチパターン：Step Functions/Lambda実装で失敗しやすいポイント

- Lambda関数のサイズが大きすぎてコールドスタート問題が発生

- メモリ割り当てが不適切でコストまたはパフォーマンスが最適でない

- リージョン間の設定不整合でフェイルオーバー時に問題が発生

- Step Functionsのステートマシン設計が複雑すぎて管理困難になる

- エラーハンドリングの不足で障害時に回復困難になる

- 大量のイベントによるLambda同時実行数の上限到達

- クロスアカウント設定の不備でワークフローの断絶が発生

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 24. CI/CDパイプラインとデプロイ自動化実装（30-35ページ）

## 本章の目的：環境変数管理とマルチリージョン対応のCI/CDパイプラインを実装する

### **実践ハンズオン 24-1**: GitLabリポジトリとブランチ戦略 

- リポジトリ構造と設定

- ブランチ戦略とフロー定義

- マージリクエストルール

- コードレビュープロセス設定

### **実践ハンズオン 24-2**: 静的解析パイプライン実装 

- tfsec, TFLint, checkovの統合

- カスタムルール設定

- 分析結果のレポーティング

- 修正フローの自動化

### **実践ハンズオン 24-3**: IAM Access Analyzer統合 

- 動的解析プロセスの実装

- Access Analyzerのフィードバック処理

- 検出問題の分類と優先順位付け

- 修正推奨事項の自動生成

### **実践ハンズオン 24-4**: 環境変数管理システム実装 

- 環境変数階層の設計

- 環境別変数管理（dev/staging/prod）

- リージョン固有変数の管理

- 秘密情報の安全な処理

### **実践ハンズオン 24-5**: 手動承認プロセス実装 

- エラー検出時の承認フロー

- 承認情報の整理と表示

- 承認ワークフローの設定

- 承認履歴と監査記録

### **実践ハンズオン 24-6**: マイクロサービスビルド・デプロイパイプライン 

- ビルド環境の標準化

- テスト自動化

- 環境別のデプロイ戦略

- ロールバック機構の実装

### **実践ハンズオン 24-7**: マルチリージョンデプロイ 

- 東京・大阪両リージョンへの同時デプロイ

- リージョン固有設定の管理

- デプロイ順序と依存関係

- 検証と整合性確認

### **実践ハンズオン 24-8**: 環境間プロモーションフロー 

- 環境昇格プロセス（dev→staging→prod）

- 環境タグ付けとバージョン管理

- プロモーション承認フロー

- 環境間の構成差分管理

### アンチパターン：CI/CD実装で失敗しやすいポイント

- 静的解析警告を無視し、問題を残したままデプロイする

- 環境変数管理が不適切で環境間の設定が混同される

- リージョン間の設定不整合でマルチリージョンデプロイが失敗する

- 手動承認プロセスが形骸化し、実質的なチェックが行われない

- 環境タグ付けが不十分で、環境間のイメージ混在が発生する

- デプロイパイプラインが単一障害点となり、全環境のデプロイが停止する

- ロールバック手順の実装が不完全で、障害時の回復が困難になる

- 異なる環境間の構成差異が大きすぎて、環境間のプロモーションが難しくなる

## 25. DR設定と運用監視の実装（25-30ページ）

## 本章の目的：東京-大阪間の災害対策と統合監視基盤を実装する

### **実践ハンズオン 25-1**: Aurora Global Database設定 

- クロスリージョンレプリケーション設定

- レプリケーションモニタリング

- フェイルオーバー設定

- テストと検証

### **実践ハンズオン 25-2**: クロスリージョンコンテナ戦略 

- ECRレプリケーション設定

- クロスリージョンデプロイ戦略

- 構成同期メカニズム

- 動作検証手順

### **実践ハンズオン 25-3**: Route 53フェイルオーバールーティング 

- ヘルスチェック設定

- フェイルオーバーポリシー

- DNSレコード管理

- フェイルオーバーテスト

### **実践ハンズオン 25-4**: 統合監視ダッシュボード構築 

- CloudWatchクロスアカウントダッシュボード

- マイクロサービス健全性監視

- アラート集約と通知設定

- カスタムメトリクス実装

### **実践ハンズオン 25-5**: 環境タグベースの監視フィルタリング 

- 環境タグに基づく監視ビューの作成

- 環境別のアラートポリシー

- 環境タグを活用したメトリクス分析

- ダッシュボードのカスタマイズ

### **実践ハンズオン 25-6**: DR訓練とフェイルオーバー演習 

- 定期訓練の計画と実施

- フェイルオーバーチェックリスト

- パフォーマンス評価

- 改善サイクル

### アンチパターン：DR設定と運用監視で失敗しやすいポイント

- レプリケーション設定の不備でデータ同期の遅延や損失が発生

- 環境タグ付けが不十分で、環境ごとの適切なモニタリングができない

- フェイルオーバー手順のテストが不足し、実際の災害時に機能しない

- ヘルスチェックの設定不備で不要なフェイルオーバーが発生

- 監視ダッシュボードが複雑すぎて重要な情報が埋もれる

- DR環境のキャパシティが不足し、フェイルオーバー後にパフォーマンス問題が発生

- 定期的なDR訓練が行われず、手順やツールが陳腐化する

- 東京・大阪間のレイテンシ差異を考慮せず、パフォーマンス問題が生じる

## 技術ドキュメント例

## アカウント申請JSON例（生産管理マイクロサービス・テスト環境用）

json

{

"account_name": "test-production-management",

"email": "aws-test-production-management@technova.com",

"organizational_unit": "Test",

"tags": {

"Environment": "test",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "production-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "test",

"/dr_enabled": "false",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true

}

}

## マルチリージョン対応Terraform設定例

hcl

*\# プロバイダー設定 - 東京・大阪両リージョンを並記*

provider "aws" {

region = var.primary_region *\# ap-northeast-1（東京）*

alias = "tokyo"

default_tags {

tags = {

Environment = var.environment

Team = var.team

Application = var.application

ProvisionedBy = "Terraform"

PrimaryRegion = var.primary_region

}

}

}

provider "aws" {

region = var.secondary_region *\# ap-northeast-3（大阪）*

alias = "osaka"

default_tags {

tags = {

Environment = var.environment

Team = var.team

Application = var.application

ProvisionedBy = "Terraform"

SecondaryRegion = var.secondary_region

}

}

}

*\# 環境変数によるモジュール管理*

module "vpc_tokyo" {

source = "../modules/vpc"

providers = {

aws = aws.tokyo

}

environment = var.environment

vpc_cidr = var.vpc_cidr_tokyo

subnet_cidrs = var.subnet_cidrs_tokyo

availability_zones = \["ap-northeast-1a", "ap-northeast-1c"\]

*\# 環境変数に基づく条件付き設定*

enable_vpn_gateway = var.environment == "prod" ? true : false

nat_gateway_count = var.environment == "prod" ? 2 : 1

*\# 東京リージョン固有の設定*

transit_gateway_id = var.tgw_id_tokyo

tags = {

Region = "Tokyo"

}

}

module "vpc_osaka" {

source = "../modules/vpc"

providers = {

aws = aws.osaka

}

*\# DR環境は本番環境のみ構築*

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

environment = var.environment

vpc_cidr = var.vpc_cidr_osaka

subnet_cidrs = var.subnet_cidrs_osaka

availability_zones = \["ap-northeast-3a", "ap-northeast-3b"\]

*\# 環境変数に基づく条件付き設定*

enable_vpn_gateway = var.environment == "prod" ? true : false

nat_gateway_count = var.environment == "prod" ? 2 : 1

*\# 大阪リージョン固有の設定*

transit_gateway_id = var.tgw_id_osaka

tags = {

Region = "Osaka"

DR = "Enabled"

}

}

*\# 環境変数定義*

variable "environment" {

description = "Deployment environment (dev, test, staging, prod)"

type = string

validation {

condition = contains(\["dev", "test", "staging", "prod"\],
var.environment)

error_message = "Environment must be one of: dev, test, staging, prod."

}

}

variable "primary_region" {

description = "Primary AWS region"

type = string

default = "ap-northeast-1"

}

variable "secondary_region" {

description = "Secondary AWS region for DR"

type = string

default = "ap-northeast-3"

}

variable "dr_enabled" {

description = "Enable Disaster Recovery resources"

type = bool

default = false

}

## IaC静的解析とCI/CD設定例

yaml

*\# GitLab CI/CD パイプライン設定*

stages:

\- validate

\- plan

\- approve

\- apply

\- post-deploy

variables:

TF_ROOT: \${CI_PROJECT_DIR}/terraform

TF_STATE_NAME: \${CI_PROJECT_NAME}-\${CI_COMMIT_REF_SLUG}

TF_VAR_environment: \${CI_ENVIRONMENT_NAME}

AWS_DEFAULT_REGION: ap-northeast-1

*\# 静的解析ステージ*

static-analysis:

stage: validate

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform init -backend=false

\- terraform validate

*\# tfsec実行*

\- tfsec .

*\# TFLint実行*

\- tfswitch 1.2.3

\- tflint --recursive

*\# Checkov実行*

\- checkov -d .

artifacts:

reports:

junit: reports/tflint-report.xml

allow_failure:

exit_codes: \[0, 1\]

*\# 動的解析ステージ*

access-analyzer:

stage: validate

image: amazon/aws-cli:latest

script:

\- aws accessanalyzer validate-policy --policy-type IAM_POLICY
--policy-document file://policies/iam_policies.json

\- python3 scripts/analyze_access_findings.py

dependencies:

\- static-analysis

*\# Terraform計画ステージ*

terraform-plan:

stage: plan

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform init

\- terraform plan -out=tfplan

artifacts:

paths:

\- \${TF_ROOT}/tfplan

expire_in: 1 week

*\# 手動承認ステージ (エラーがあった場合も含む)*

manual-approval:

stage: approve

script:

\- echo "Terraform plan requires manual approval"

when: manual

allow_failure: false

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod" \|\| \$CI_ENVIRONMENT_NAME ==
"staging"

when: always

\- when: on_failure *\#
静的解析でエラーが発生した場合も手動承認を必要とする*

*\# 適用ステージ*

terraform-apply:

stage: apply

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform apply -auto-approve tfplan

dependencies:

\- terraform-plan

\- manual-approval

environment:

name: \${CI_ENVIRONMENT_NAME}

on_stop: destroy

when: manual

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "staging"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "dev" \|\| \$CI_ENVIRONMENT_NAME ==
"test"

when: on_success

*\# デプロイ後検証*

post-deploy-validation:

stage: post-deploy

script:

\- aws cloudformation validate-stack --stack-name
\${CI_ENVIRONMENT_NAME}-stack

\- python3 scripts/verify_deployment.py

rules:

\- if: \$CI_COMMIT_BRANCH == "main" && \$CI_ENVIRONMENT_NAME == "prod"

## ECS TaskロールとAurora IAM認証サンプル

hcl

*\# ECSタスク実行ロール*

resource "aws_iam_role" "ecs_task_execution_role" {

name = "production-mgmt-ecs-execution-role-\${var.environment}"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

Action = "sts:AssumeRole"

}\]

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECSタスクロール（アプリケーション実行権限）*

resource "aws_iam_role" "ecs_task_role" {

name = "production-mgmt-ecs-task-role-\${var.environment}"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

Action = "sts:AssumeRole"

}\]

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# Aurora IAM認証用ポリシー*

resource "aws_iam_policy" "aurora_connect_policy" {

name = "production-mgmt-aurora-connect-\${var.environment}"

description = "Allow connection to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource = \[

"arn:aws:rds-db:\${var.primary_region}:\${var.account_id}:dbuser:\${var.db_cluster_resource_id_tokyo}/\${var.db_username}",

"arn:aws:rds-db:\${var.secondary_region}:\${var.account_id}:dbuser:\${var.db_cluster_resource_id_osaka}/\${var.db_username}"

\]

}\]

})

}

*\# タスクロールにAurora接続権限をアタッチ*

resource "aws_iam_role_policy_attachment" "task_aurora_connect" {

role = aws_iam_role.ecs_task_role.name

policy_arn = aws_iam_policy.aurora_connect_policy.arn

}

*\# タスク実行に必要な基本ポリシーをアタッチ*

resource "aws_iam_role_policy_attachment" "task_execution_basic" {

role = aws_iam_role.ecs_task_execution_role.name

policy_arn =
"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"

}

*\# シークレットアクセス権限（環境変数用）*

resource "aws_iam_policy" "secrets_access" {

name = "production-mgmt-secrets-access-\${var.environment}"

description = "Allow access to secrets manager for database credentials"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = \[

"secretsmanager:GetSecretValue",

"kms:Decrypt"

\]

Resource = \[

var.db_secret_arn,

var.kms_key_arn

\]

}\]

})

}

resource "aws_iam_role_policy_attachment" "task_execution_secrets" {

role = aws_iam_role.ecs_task_execution_role.name

policy_arn = aws_iam_policy.secrets_access.arn

}

## コンテナセキュリティスキャンと自動更新の設定例

yaml

*\# コンテナセキュリティスキャンとインシデント対応の自動化 - AWS
Lambda関数*

resource "aws_lambda_function" "image_vulnerability_handler" {

function_name = "ecr-vulnerability-handler-\${var.environment}"

description = "Handle ECR image vulnerability findings and trigger
auto-remediation"

role = aws_iam_role.image_vulnerability_handler_role.arn

handler = "index.handler"

runtime = "nodejs14.x"

timeout = 300

memory_size = 512

environment {

variables = {

ECR_REPO_PREFIX = "production-mgmt-"

NOTIFICATION_SNS = aws_sns_topic.vulnerability_alerts.arn

ENVIRONMENT = var.environment

CODEBUILD_PROJECT = aws_codebuild_project.image_rebuild.name

}

}

filename = "\${path.module}/lambda/vulnerability-handler.zip"

source_code_hash =
filebase64sha256("\${path.module}/lambda/vulnerability-handler.zip")

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECRイメージスキャン結果をLambdaに通知するイベントルール*

resource "aws_cloudwatch_event_rule" "ecr_scan_findings" {

name = "ecr-scan-findings-\${var.environment}"

description = "Capture ECR image scan findings"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[{

prefix = "production-mgmt-"

}\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# イベントルールとLambda関数の連携*

resource "aws_cloudwatch_event_target" "ecr_scan_findings_lambda" {

rule = aws_cloudwatch_event_rule.ecr_scan_findings.name

target_id = "SendToLambda"

arn = aws_lambda_function.image_vulnerability_handler.arn

}

*\# コンテナイメージ再ビルドのCodeBuildプロジェクト*

resource "aws_codebuild_project" "image_rebuild" {

name = "ecr-image-rebuild-\${var.environment}"

description = "Rebuild container images when vulnerabilities are
detected"

service_role = aws_iam_role.codebuild_service_role.arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = true

environment_variable {

name = "ECR_REPOSITORY"

value = "*\#{ECR_REPOSITORY}"*

}

environment_variable {

name = "IMAGE_TAG"

value = "*\#{IMAGE_TAG}"*

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

}

source {

type = "GITHUB"

location =
"https://github.com/technova/production-management-service.git"

buildspec = "buildspec.yml"

}

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# 脆弱性アラート用SNSトピック*

resource "aws_sns_topic" "vulnerability_alerts" {

name = "ecr-vulnerability-alerts-\${var.environment}"

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# 脆弱性レポート用S3バケット*

resource "aws_s3_bucket" "vulnerability_reports" {

bucket =
"technova-ecr-vulnerability-reports-\${var.aws_account_id}-\${var.environment}"

lifecycle_rule {

id = "reports-retention"

enabled = true

expiration {

days = 90

}

}

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECRリポジトリのスキャン設定*

resource "aws_ecr_repository" "service_repo" {

name = "production-mgmt-service-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

tags = merge(var.tags, {

Environment = var.environment

})

}

## Flyway設定とマイグレーションサンプル

sql

*-- V1\_\_initial_schema.sql*

CREATE TABLE production_orders (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

order_number VARCHAR(50) NOT NULL UNIQUE,

product_code VARCHAR(50) NOT NULL,

quantity INT NOT NULL,

planned_start_date DATE NOT NULL,

planned_end_date DATE NOT NULL,

status VARCHAR(20) NOT NULL,

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP,

created_by VARCHAR(255),

updated_by VARCHAR(255)

);

CREATE TABLE production_materials (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL,

material_code VARCHAR(50) NOT NULL,

required_quantity DECIMAL(10, 2) NOT NULL,

allocated_quantity DECIMAL(10, 2) DEFAULT 0,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE

);

*-- V2\_\_add_workflow_tracking.sql*

CREATE TABLE production_workflow_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL,

step_name VARCHAR(50) NOT NULL,

start_time TIMESTAMP,

end_time TIMESTAMP,

status VARCHAR(20) NOT NULL,

notes TEXT,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE

);

yaml

*\# flyway.conf*

flyway.url=jdbc:mysql://\${AURORA_ENDPOINT}:3306/\${DB_NAME}

flyway.user=\${DB_USER}

flyway.password=\${DB_PASSWORD}

flyway.locations=filesystem:./sql

flyway.baselineOnMigrate=true

flyway.schemas=production_management

flyway.connectRetries=10

flyway.cleanDisabled=true

## Step Functions ワークフローサンプル（東京・大阪両リージョン対応）

json

{

"Comment": "Production Planning Workflow with Multi-Region Support",

"StartAt": "DetectRegion",

"States": {

"DetectRegion": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.region",

"StringEquals": "ap-northeast-1",

"Next": "FetchPendingOrdersTokyo"

},

{

"Variable": "\$.region",

"StringEquals": "ap-northeast-3",

"Next": "FetchPendingOrdersOsaka"

}

\],

"Default": "FetchPendingOrdersTokyo"

},

"FetchPendingOrdersTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:fetch-pending-orders",

"Next": "CheckOrdersExistTokyo"

},

"FetchPendingOrdersOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:fetch-pending-orders",

"Next": "CheckOrdersExistOsaka"

},

"CheckOrdersExistTokyo": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.orderCount",

"NumericEquals": 0,

"Next": "NoOrdersToProcessTokyo"

}

\],

"Default": "ProcessOrdersTokyo"

},

"CheckOrdersExistOsaka": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.orderCount",

"NumericEquals": 0,

"Next": "NoOrdersToProcessOsaka"

}

\],

"Default": "ProcessOrdersOsaka"

},

"NoOrdersToProcessTokyo": {

"Type": "Pass",

"End": true,

"Result": {

"region": "ap-northeast-1",

"processed": 0,

"message": "No orders to process in Tokyo region"

}

},

"NoOrdersToProcessOsaka": {

"Type": "Pass",

"End": true,

"Result": {

"region": "ap-northeast-3",

"processed": 0,

"message": "No orders to process in Osaka region"

}

},

"ProcessOrdersTokyo": {

"Type": "Map",

"ItemsPath": "\$.orders",

"MaxConcurrency": 10,

"Iterator": {

"StartAt": "CheckMaterialAvailabilityTokyo",

"States": {

"CheckMaterialAvailabilityTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:check-material-availability",

"Next": "MaterialsAvailableTokyo"

},

"MaterialsAvailableTokyo": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.allMaterialsAvailable",

"BooleanEquals": false,

"Next": "QueueForLaterPlanningTokyo"

}

\],

"Default": "ScheduleProductionTokyo"

},

"QueueForLaterPlanningTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:queue-for-later-planning",

"End": true

},

"ScheduleProductionTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:schedule-production",

"Next": "ReserveMaterialsTokyo"

},

"ReserveMaterialsTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:reserve-materials",

"Next": "NotifyProductionTeamTokyo"

},

"NotifyProductionTeamTokyo": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-1:123456789012:production-notifications",

"Message.\$": "\$.notificationMessage"

},

"End": true

}

}

},

"Next": "GenerateSummaryReportTokyo"

},

"ProcessOrdersOsaka": {

"Type": "Map",

"ItemsPath": "\$.orders",

"MaxConcurrency": 10,

"Iterator": {

"StartAt": "CheckMaterialAvailabilityOsaka",

"States": {

"CheckMaterialAvailabilityOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:check-material-availability",

"Next": "MaterialsAvailableOsaka"

},

"MaterialsAvailableOsaka": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.allMaterialsAvailable",

"BooleanEquals": false,

"Next": "QueueForLaterPlanningOsaka"

}

\],

"Default": "ScheduleProductionOsaka"

},

"QueueForLaterPlanningOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:queue-for-later-planning",

"End": true

},

"ScheduleProductionOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:schedule-production",

"Next": "ReserveMaterialsOsaka"

},

"ReserveMaterialsOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:reserve-materials",

"Next": "NotifyProductionTeamOsaka"

},

"NotifyProductionTeamOsaka": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-3:123456789012:production-notifications",

"Message.\$": "\$.notificationMessage"

},

"End": true

}

}

},

"Next": "GenerateSummaryReportOsaka"

},

"GenerateSummaryReportTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:generate-planning-summary",

"Next": "NotifyPlanningCompleteTokyo"

},

"GenerateSummaryReportOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:generate-planning-summary",

"Next": "NotifyPlanningCompleteOsaka"

},

"NotifyPlanningCompleteTokyo": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-1:123456789012:planning-notifications",

"Message.\$": "\$.summaryReport"

},

"End": true

},

"NotifyPlanningCompleteOsaka": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-3:123456789012:planning-notifications",

"Message.\$": "\$.summaryReport"

},

"End": true

}

}

}

#  AWS AFT ハンズオン設計書：具体的実装内容

# セキュリティとコード品質向上のための追加実装要件

AFTを活用したAWS環境構築においては、セキュリティとコード品質の確保が非常に重要です。TechNova社のプロジェクトでは、以下の追加要件を実装します：

**静的解析ツール統合**

- **tfsec**: Terraformコードのセキュリティ問題を検出

- **TFLint**: Terraformコードの問題や非推奨設定を検出

- **checkov**: IaCのセキュリティとコンプライアンス違反をスキャン

**動的解析統合**

- **IAM Access Analyzer**: 予期しないアクセス許可や権限設定の問題を検出

**CI/CDパイプラインの品質ゲート**

- 各ステージでエラーが検出された場合の手動承認プロセス

- エラー内容と影響評価に基づく継続/中止判断メカニズム

- 検出された問題の重要度に応じた通知と対応フロー

**環境管理とタグ付け**

- ステージング/本番などの環境タグ付けによるリソース管理

- 環境変数によるモジュール管理と環境別設定

- 東京リージョン(ap-northeast-1)と大阪リージョン(ap-northeast-3)の両方を統合管理

## 具体的実装サンプル

## tfsec, TFLint, checkovを統合したCI/CD設定

\# .gitlab-ci.yml

stages:

\- validate

\- plan

\- approve

\- apply

variables:

TERRAFORM_VERSION: "1.5.0"

TFLINT_VERSION: "0.47.0"

TFSEC_VERSION: "1.28.1"

CHECKOV_VERSION: "2.3.259"

before_script:

\- apt-get update && apt-get install -y curl unzip

\- curl -sSL
"https://releases.hashicorp.com/terraform/\${TERRAFORM_VERSION}/terraform\_\${TERRAFORM_VERSION}\_linux_amd64.zip"
-o terraform.zip

\- unzip terraform.zip && rm terraform.zip

\- mv terraform /usr/local/bin/

\- curl -sSL
"https://github.com/terraform-linters/tflint/releases/download/v\${TFLINT_VERSION}/tflint_linux_amd64.zip"
-o tflint.zip

\- unzip tflint.zip && rm tflint.zip

\- mv tflint /usr/local/bin/

\- curl -sSL
"https://github.com/aquasecurity/tfsec/releases/download/v\${TFSEC_VERSION}/tfsec-linux-amd64"
-o /usr/local/bin/tfsec

\- chmod +x /usr/local/bin/tfsec

\- pip install checkov==\${CHECKOV_VERSION}

\# 静的解析ジョブ

static_analysis:

stage: validate

script:

\- cd \${TF_ROOT}

\# Terraform構文チェック

\- terraform init -backend=false

\- terraform validate

\# TFLint実行

\- tflint --recursive --format junit \> tflint_report.xml

\# tfsec実行

\- tfsec . --format junit \> tfsec_report.xml

\# checkov実行

\- checkov -d . --output junitxml \> checkov_report.xml

\# 結果を表示

\- echo "Static analysis completed. Check reports for details."

artifacts:

reports:

junit:

\- tflint_report.xml

\- tfsec_report.xml

\- checkov_report.xml

paths:

\- \${TF_ROOT}/tflint_report.xml

\- \${TF_ROOT}/tfsec_report.xml

\- \${TF_ROOT}/checkov_report.xml

expire_in: 1 week

allow_failure:

exit_codes: \[0, 1, 2\]

\# IAM Access Analyzer動的解析ジョブ

access_analyzer:

stage: validate

script:

\- cd \${TF_ROOT}

\- terraform show -json tfplan \> tfplan.json

\- python3 scripts/analyze_iam_policies.py

dependencies:

\- terraform_plan

artifacts:

paths:

\- \${TF_ROOT}/access_analyzer_results.json

expire_in: 1 week

\# Terraformプランジョブ

terraform_plan:

stage: plan

script:

\- cd \${TF_ROOT}

\- terraform init

\- terraform plan -out=tfplan

artifacts:

paths:

\- \${TF_ROOT}/tfplan

expire_in: 1 week

\# 手動承認ジョブ (エラーがあった場合も含む)

manual_approval:

stage: approve

script:

\- echo "Review the analysis results and plan output before proceeding"

\- python3 scripts/summarize_findings.py

when: manual

allow_failure: false

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod" \|\| \$CI_ENVIRONMENT_NAME ==
"staging"

when: always

\- when: on_failure \#
静的解析でエラーが発生した場合も手動承認を必要とする

\# Terraform適用ジョブ

terraform_apply:

stage: apply

script:

\- cd \${TF_ROOT}

\- terraform apply -auto-approve tfplan

dependencies:

\- terraform_plan

\- manual_approval

environment:

name: \${CI_ENVIRONMENT_NAME}

when: manual

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "staging"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "dev" \|\| \$CI_ENVIRONMENT_NAME ==
"test"

when: on_success

## Access Analyzerを活用したIAMポリシー分析スクリプト

\# scripts/analyze_iam_policies.py

import json

import boto3

import sys

import os

def analyze_iam_policies(tfplan_file):

\# Terraformプランからポリシーを抽出

with open(tfplan_file, 'r') as f:

tfplan = json.load(f)

\# IAMポリシーを抽出

policies = extract_iam_policies(tfplan)

\# Access Analyzerを使用して分析

analyzer = boto3.client('accessanalyzer')

findings = \[\]

for policy_name, policy_doc in policies:

response = analyzer.validate_policy(

policyDocument=json.dumps(policy_doc),

policyType='IDENTITY_POLICY'

)

if 'findings' in response and response\['findings'\]:

for finding in response\['findings'\]:

finding\['policyName'\] = policy_name

findings.append(finding)

\# 結果を保存

with open('access_analyzer_results.json', 'w') as f:

json.dump(findings, f, indent=2)

\# 重要な問題があれば報告

critical_findings = \[f for f in findings if f\['findingType'\] in
\['ERROR', 'SECURITY_WARNING'\]\]

if critical_findings:

print(f"Found {len(critical_findings)} critical issues in IAM
policies:")

for finding in critical_findings:

print(f"- {finding\['policyName'\]}: {finding\['findingType'\]} -
{finding\['findingDetails'\]}")

if os.environ.get('CI_ENVIRONMENT_NAME') == 'prod':

print("Critical issues found in production environment policies!")

sys.exit(1) \# 本番環境では重大な問題があればパイプラインを停止

print(f"IAM Policy analysis complete. Total findings: {len(findings)}")

return len(critical_findings) == 0

def extract_iam_policies(tfplan):

\# TerraformプランからIAMポリシーを抽出するロジック

policies = \[\]

\# ...抽出ロジックの実装...

return policies

if \_\_name\_\_ == "\_\_main\_\_":

analyze_iam_policies('tfplan.json')

## 環境変数とタグを活用したマルチリージョン設定

\# environments/variables.tf

variable "environment" {

description = "Deployment environment (dev, test, staging, prod)"

type = string

validation {

condition = contains(\["dev", "test", "staging", "prod"\],
var.environment)

error_message = "Environment must be one of: dev, test, staging, prod."

}

}

variable "primary_region" {

description = "Primary AWS region (Tokyo)"

type = string

default = "ap-northeast-1"

}

variable "secondary_region" {

description = "Secondary AWS region for DR (Osaka)"

type = string

default = "ap-northeast-3"

}

variable "dr_enabled" {

description = "Enable Disaster Recovery resources in secondary region"

type = bool

default = false

}

variable "team" {

description = "Team responsible for the resources"

type = string

}

variable "application" {

description = "Application name"

type = string

}

variable "cost_center" {

description = "Cost center code for billing"

type = string

}

\# common tag structure for all resources

locals {

common_tags = {

Environment = var.environment

Team = var.team

Application = var.application

CostCenter = var.cost_center

ManagedBy = "terraform"

}

tokyo_tags = merge(local.common_tags, {

Region = "Tokyo"

PrimaryRegion = "true"

})

osaka_tags = merge(local.common_tags, {

Region = "Osaka"

DR = var.dr_enabled ? "Enabled" : "Disabled"

})

}

## 両リージョンを並記したプロバイダー設定

\# providers.tf

provider "aws" {

region = var.primary_region \# Tokyo

alias = "tokyo"

default_tags {

tags = local.tokyo_tags

}

}

provider "aws" {

region = var.secondary_region \# Osaka

alias = "osaka"

default_tags {

tags = local.osaka_tags

}

}

\# Tokyo リージョンのリソース

module "vpc_tokyo" {

source = "../modules/vpc"

providers = {

aws = aws.tokyo

}

name = "\${var.application}-\${var.environment}"

cidr_block = var.vpc_cidr_tokyo

environment = var.environment

\# 環境変数に基づく条件付き設定

nat_gateway_count = var.environment == "prod" ? 2 : 1

\# その他のパラメータ

\# ...

}

\# Osaka リージョンのリソース (本番環境の場合のみ)

module "vpc_osaka" {

source = "../modules/vpc"

providers = {

aws = aws.osaka

}

\# DR環境は本番環境のみ構築

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

cidr_block = var.vpc_cidr_osaka

environment = var.environment

\# 環境変数に基づく条件付き設定

nat_gateway_count = var.environment == "prod" ? 2 : 1

\# その他のパラメータ

\# ...

}

## 環境変数を活用したマルチリージョンのAuroraクラスター設定

\# database/aurora.tf

\# 東京リージョンのAuroraクラスター

resource "aws_rds_cluster" "aurora_tokyo" {

provider = aws.tokyo

cluster_identifier = "\${var.application}-\${var.environment}"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

database_name = replace("\${var.application}\_\${var.environment}", "-",
"\_")

master_username = var.db_master_username

master_password = var.db_master_password

backup_retention_period = var.environment == "prod" ? 7 : 1

preferred_backup_window = "16:00-17:00" \# UTC (日本時間の朝1-2時)

deletion_protection = var.environment == "prod" \|\| var.environment ==
"staging"

skip_final_snapshot = var.environment != "prod"

final_snapshot_identifier = var.environment == "prod" ?
"\${var.application}-\${var.environment}-final" : null

\# 環境変数に基づく条件付き設定

iam_database_authentication_enabled = true

storage_encrypted = true

kms_key_id = var.kms_key_arn_tokyo

\# DR設定（本番環境のみ）

global_cluster_identifier = var.environment == "prod" && var.dr_enabled
? "\${var.application}-\${var.environment}-global" : null

\# その他のクラスター設定

\# ...

tags = local.tokyo_tags

}

\# 大阪リージョンのAuroraクラスター（本番環境のDR用）

resource "aws_rds_cluster" "aurora_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

cluster_identifier = "\${var.application}-\${var.environment}"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

\# グローバルクラスターの一部として設定

global_cluster_identifier =
"\${var.application}-\${var.environment}-global"

\# レプリカのため、以下の設定は必要ない

skip_final_snapshot = true

\# その他のクラスター設定

\# ...

tags = local.osaka_tags

}

\# DBインスタンス（東京リージョン）

resource "aws_rds_cluster_instance" "aurora_instances_tokyo" {

provider = aws.tokyo

count = var.environment == "prod" ? 2 : 1

identifier = "\${var.application}-\${var.environment}-\${count.index}"

cluster_identifier = aws_rds_cluster.aurora_tokyo.id

instance_class = var.environment == "prod" ? "db.r6g.large" :
"db.r6g.medium"

engine = aws_rds_cluster.aurora_tokyo.engine

engine_version = aws_rds_cluster.aurora_tokyo.engine_version

\# パフォーマンス最適化のための設定

performance_insights_enabled = var.environment == "prod" \|\|
var.environment == "staging"

tags = local.tokyo_tags

}

\# DBインスタンス（大阪リージョン）

resource "aws_rds_cluster_instance" "aurora_instances_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

identifier = "\${var.application}-\${var.environment}-\${count.index}"

cluster_identifier = aws_rds_cluster.aurora_osaka\[0\].id

instance_class = "db.r6g.large"

engine = aws_rds_cluster.aurora_osaka\[0\].engine

engine_version = aws_rds_cluster.aurora_osaka\[0\].engine_version

tags = local.osaka_tags

}

## 手動承認ステージを実装したAFTパイプライン設定

\# AFT/account-provisioning/pipeline.tf

resource "aws_codepipeline" "aft_account_provisioning" {

name = "aft-account-provisioning-pipeline"

role_arn = aws_iam_role.aft_codepipeline_role.arn

artifact_store {

location = aws_s3_bucket.aft_codepipeline_artifacts.bucket

type = "S3"

}

stage {

name = "Source"

action {

name = "Source"

category = "Source"

owner = "AWS"

provider = "CodeStarSourceConnection"

version = "1"

output_artifacts = \["source_output"\]

configuration = {

ConnectionArn = aws_codestarconnections_connection.gitlab.arn

FullRepositoryId = var.aft_account_request_repo

BranchName = var.aft_account_request_branch

}

}

}

stage {

name = "Validate"

action {

name = "TerraformValidate"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["validate_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_validate.name

}

}

action {

name = "StaticAnalysis"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["static_analysis_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_static_analysis.name

}

}

action {

name = "IAMValidation"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["iam_validation_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_iam_validation.name

}

}

}

stage {

name = "Plan"

action {

name = "TerraformPlan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["plan_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_plan.name

}

}

}

\# 必要に応じて手動承認ステージ

stage {

name = "Approval"

action {

name = "ManualApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

\# Plan段階でIssueが検出された場合、変更の承認方法に関する説明を含める

CustomData = "Review the Terraform plan and analysis results. Any
security findings or validation errors must be acknowledged before
proceeding."

\# SNSトピックを指定して、承認通知を送信

NotificationArn = aws_sns_topic.aft_approval_notification.arn

\# 承認にExternalEntityを使用（AWS CLIを使用した承認など）

ExternalEntityLink =
"https://technova.gitlab.com/projects/\${var.aft_account_request_repo}/pipelines/\${CODEPIPELINE_EXECUTION_ID}"

}

}

}

stage {

name = "Apply"

action {

name = "TerraformApply"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output", "plan_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_apply.name

PrimarySource = "source_output"

EnvironmentVariables = jsonencode(\[

{

name = "TERRAFORM_PLAN"

value = "plan_output"

type = "PLAINTEXT"

}

\])

}

}

}

stage {

name = "Validate-Resources"

action {

name = "ValidateDeployment"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_post_deployment_validation.name

}

}

}

}

\# 承認通知用SNSトピック

resource "aws_sns_topic" "aft_approval_notification" {

name = "aft-approval-notification"

tags = {

Name = "AFT Approval Notification"

Environment = "management"

}

}

\# CodeBuildプロジェクト：静的解析

resource "aws_codebuild_project" "aft_static_analysis" {

name = "aft-static-analysis"

description = "Static analysis of Terraform code using tfsec, TFLint,
and checkov"

service_role = aws_iam_role.aft_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "TFLINT_VERSION"

value = "0.47.0"

}

environment_variable {

name = "TFSEC_VERSION"

value = "1.28.1"

}

environment_variable {

name = "CHECKOV_VERSION"

value = "2.3.259"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/static_analysis_buildspec.yml"

}

logs_config {

cloudwatch_logs {

group_name = "/aws/codebuild/aft-static-analysis"

stream_name = "%INITIATOR%-%BUILD_ID%"

}

}

tags = {

Name = "AFT Static Analysis"

Environment = "management"

}

}

\# CodeBuildプロジェクト：IAM検証

resource "aws_codebuild_project" "aft_iam_validation" {

name = "aft-iam-validation"

description = "Validate IAM policies using AWS Access Analyzer"

service_role = aws_iam_role.aft_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/iam_validation_buildspec.yml"

}

logs_config {

cloudwatch_logs {

group_name = "/aws/codebuild/aft-iam-validation"

stream_name = "%INITIATOR%-%BUILD_ID%"

}

}

tags = {

Name = "AFT IAM Validation"

Environment = "management"

}

}

## 静的解析用ビルドスペック

\# buildspecs/static_analysis_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "Installing static analysis tools"

\# TFLintのインストール

\- curl -sSL
"https://github.com/terraform-linters/tflint/releases/download/v\${TFLINT_VERSION}/tflint_linux_amd64.zip"
-o tflint.zip

\- unzip tflint.zip && rm tflint.zip

\- mv tflint /usr/local/bin/

\# tfsecのインストール

\- curl -sSL
"https://github.com/aquasecurity/tfsec/releases/download/v\${TFSEC_VERSION}/tfsec-linux-amd64"
-o /usr/local/bin/tfsec

\- chmod +x /usr/local/bin/tfsec

\# checkovのインストール

\- pip install checkov==\${CHECKOV_VERSION}

pre_build:

commands:

\- echo "Preparing for static analysis"

\- mkdir -p reports

build:

commands:

\- echo "Running static analysis"

\# TFLint実行

\- echo "Running TFLint..."

\- tflint --recursive --format=json \> reports/tflint-results.json \|\|
true

\# tfsec実行

\- echo "Running tfsec..."

\- tfsec . --format=json \> reports/tfsec-results.json \|\| true

\# checkov実行

\- echo "Running checkov..."

\- checkov -d . --output json \> reports/checkov-results.json \|\| true

post_build:

commands:

\- echo "Analyzing results..."

\- python scripts/summarize_analysis.py

\- echo "Static analysis completed"

artifacts:

files:

\- reports/\*\*/\*

\- scripts/summarize_analysis.py

discard-paths: no

reports:

static-analysis-reports:

files:

\- reports/tflint-report.xml

\- reports/tfsec-report.xml

\- reports/checkov-report.xml

file-format: "JUNITXML"

## IAM Access Analyzer用ビルドスペック

\# buildspecs/iam_validation_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "Installing tools for IAM validation"

\- pip install boto3

pre_build:

commands:

\- echo "Preparing for IAM validation"

\- mkdir -p reports

build:

commands:

\- echo "Extracting IAM policies from Terraform code..."

\- python scripts/extract_iam_policies.py

\- echo "Validating IAM policies with Access Analyzer..."

\- python scripts/validate_iam_policies.py

post_build:

commands:

\- echo "Analyzing results..."

\- python scripts/summarize_iam_findings.py

\- echo "IAM validation completed"

artifacts:

files:

\- reports/\*\*/\*

\- scripts/summarize_iam_findings.py

discard-paths: no

reports:

iam-validation-reports:

files:

\- reports/iam-findings.json

file-format: "JSON"

## 静的解析結果サマリー生成スクリプト

\# scripts/summarize_analysis.py

import json

import sys

import os

def parse_tflint_results():

try:

with open('reports/tflint-results.json', 'r') as f:

data = json.load(f)

issues = data.get('issues', \[\])

by_severity = {}

for issue in issues:

severity = issue.get('rule', {}).get('severity', 'unknown')

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(issues),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing TFLint results: {e}")

return {'total': 0, 'by_severity': {}}

def parse_tfsec_results():

try:

with open('reports/tfsec-results.json', 'r') as f:

data = json.load(f)

results = data.get('results', \[\])

by_severity = {}

for result in results:

severity = result.get('severity', 'UNKNOWN').upper()

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(results),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing tfsec results: {e}")

return {'total': 0, 'by_severity': {}}

def parse_checkov_results():

try:

with open('reports/checkov-results.json', 'r') as f:

data = json.load(f)

failed_checks = data.get('results', {}).get('failed_checks', \[\])

by_severity = {}

for check in failed_checks:

severity = check.get('severity', 'UNKNOWN').upper()

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(failed_checks),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing checkov results: {e}")

return {'total': 0, 'by_severity': {}}

def generate_summary():

tflint_results = parse_tflint_results()

tfsec_results = parse_tfsec_results()

checkov_results = parse_checkov_results()

total_issues = tflint_results\['total'\] + tfsec_results\['total'\] +
checkov_results\['total'\]

critical_issues = (

tflint_results\['by_severity'\].get('error', 0) +

tfsec_results\['by_severity'\].get('HIGH', 0) +

tfsec_results\['by_severity'\].get('CRITICAL', 0) +

checkov_results\['by_severity'\].get('HIGH', 0) +

checkov_results\['by_severity'\].get('CRITICAL', 0)

)

summary = {

'total_issues': total_issues,

'critical_issues': critical_issues,

'tool_summaries': {

'tflint': tflint_results,

'tfsec': tfsec_results,

'checkov': checkov_results

}

}

\# サマリーをJSONとして保存

with open('reports/analysis-summary.json', 'w') as f:

json.dump(summary, f, indent=2)

\# 人間が読める形式でコンソールに出力

print("===== STATIC ANALYSIS SUMMARY =====")

print(f"Total issues found: {total_issues}")

print(f"Critical issues found: {critical_issues}")

print("\nTFLint results:")

print(f" Total issues: {tflint_results\['total'\]}")

for severity, count in tflint_results\['by_severity'\].items():

print(f" {severity}: {count}")

print("\ntfsec results:")

print(f" Total issues: {tfsec_results\['total'\]}")

for severity, count in tfsec_results\['by_severity'\].items():

print(f" {severity}: {count}")

print("\ncheckov results:")

print(f" Total issues: {checkov_results\['total'\]}")

for severity, count in checkov_results\['by_severity'\].items():

print(f" {severity}: {count}")

\# 本番環境で重大な問題が見つかった場合はビルドを失敗させる

if critical_issues \> 0 and os.environ.get('DEPLOYMENT_ENV', '').lower()
== 'prod':

print("\nCRITICAL ISSUES FOUND IN PRODUCTION ENVIRONMENT!")

print("Please review and fix these issues before proceeding.")

sys.exit(1)

return summary

if \_\_name\_\_ == "\_\_main\_\_":

generate_summary()

## IAMポリシー検証スクリプト

\# scripts/validate_iam_policies.py

import json

import boto3

import os

import glob

def extract_iam_policies():

"""

Terraformファイルから抽出されたIAMポリシーを読み込む

"""

policies = \[\]

\# ポリシーファイルを探索

policy_files = glob.glob('extracted_policies/\*.json')

for filename in policy_files:

with open(filename, 'r') as f:

try:

policy_data = json.load(f)

policy_name = os.path.basename(filename).replace('.json', '')

policies.append((policy_name, policy_data))

except json.JSONDecodeError:

print(f"Warning: Failed to parse {filename} as JSON")

return policies

def validate_with_access_analyzer(policies):

"""

IAM Access Analyzerを使用してポリシーを検証

"""

client = boto3.client('accessanalyzer')

findings = \[\]

for policy_name, policy_doc in policies:

try:

print(f"Validating policy: {policy_name}")

response = client.validate_policy(

policyDocument=json.dumps(policy_doc),

policyType='IDENTITY_POLICY'

)

if 'findings' in response:

for finding in response\['findings'\]:

finding\['policyName'\] = policy_name

findings.append(finding)

except Exception as e:

print(f"Error validating policy {policy_name}: {e}")

findings.append({

'policyName': policy_name,

'findingType': 'ERROR',

'findingDetails': str(e),

'locations': \[\]

})

return findings

def summarize_findings(findings):

"""

検出結果をサマリー化して保存

"""

\# 重要度別の分類

by_severity = {}

for finding in findings:

finding_type = finding.get('findingType', 'UNKNOWN')

if finding_type not in by_severity:

by_severity\[finding_type\] = 0

by_severity\[finding_type\] += 1

\# サマリーの作成

summary = {

'total_findings': len(findings),

'by_severity': by_severity,

'findings': findings

}

\# 結果をJSONとして保存

os.makedirs('reports', exist_ok=True)

with open('reports/iam-findings.json', 'w') as f:

json.dump(summary, f, indent=2)

\# コンソールにサマリーを出力

print("\n===== IAM POLICY VALIDATION SUMMARY =====")

print(f"Total findings: {len(findings)}")

for severity, count in by_severity.items():

print(f"{severity}: {count}")

\# 重大な問題があるか確認

critical_findings = sum(\[

count for severity, count in by_severity.items()

if severity in \['ERROR', 'SECURITY_WARNING'\]

\])

if critical_findings \> 0:

print(f"\nWarning: {critical_findings} critical findings detected!")

\# 本番環境の場合は失敗

if os.environ.get('DEPLOYMENT_ENV', '').lower() == 'prod':

print("CRITICAL ISSUES FOUND IN PRODUCTION ENVIRONMENT!")

return False

return True

def main():

policies = extract_iam_policies()

print(f"Found {len(policies)} IAM policies to validate")

findings = validate_with_access_analyzer(policies)

success = summarize_findings(findings)

if not success:

exit(1)

if \_\_name\_\_ == "\_\_main\_\_":

main()

## マルチリージョン対応のECS Fargateクラスター設定

\# ecs/fargate.tf

\# 東京リージョンのECSクラスター

resource "aws_ecs_cluster" "tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}"

setting {

name = "containerInsights"

value = var.environment == "prod" \|\| var.environment == "staging" ?
"enabled" : "disabled"

}

tags = local.tokyo_tags

}

\# 大阪リージョンのECSクラスター（本番環境のDR用）

resource "aws_ecs_cluster" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

setting {

name = "containerInsights"

value = "enabled"

}

tags = local.osaka_tags

}

\# CloudWatch Logs用のロググループ（東京）

resource "aws_cloudwatch_log_group" "ecs_logs_tokyo" {

provider = aws.tokyo

name = "/ecs/\${var.application}-\${var.environment}"

retention_in_days = var.environment == "prod" ? 30 : 7

tags = local.tokyo_tags

}

\# CloudWatch Logs用のロググループ（大阪）

resource "aws_cloudwatch_log_group" "ecs_logs_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "/ecs/\${var.application}-\${var.environment}"

retention_in_days = 30

tags = local.osaka_tags

}

\# ECSタスク実行ロールの定義

resource "aws_iam_role" "ecs_task_execution_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-execution-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# ECSタスク実行ロールとポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"ecs_task_execution_role_policy" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_execution_role.name

policy_arn =
"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"

}

\# ECSタスクロールの定義（アプリケーション権限用）

resource "aws_iam_role" "ecs_task_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-task-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# 東京リージョンのAuroraアクセス用ポリシー

resource "aws_iam_policy" "aurora_access_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-aurora-access"

description = "Allow ECS tasks to connect to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource =
"arn:aws:rds-db:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${var.db_cluster_resource_id}/\${var.application}"

}\]

})

tags = local.tokyo_tags

}

\# 大阪リージョンのAuroraアクセス用ポリシー（DR用）

resource "aws_iam_policy" "aurora_access_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-aurora-access"

description = "Allow ECS tasks to connect to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource =
"arn:aws:rds-db:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${var.db_cluster_resource_id_osaka}/\${var.application}"

}\]

})

tags = local.osaka_tags

}

\# タスクロールとAuroraアクセスポリシーのアタッチ

resource "aws_iam_role_policy_attachment" "task_role_aurora_access" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_role.name

policy_arn = aws_iam_policy.aurora_access_tokyo.arn

}

\# Secrets Manager アクセスポリシー

resource "aws_iam_policy" "secrets_access" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-secrets-access"

description = "Allow access to Secrets Manager for retrieving database
credentials"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = \[

"secretsmanager:GetSecretValue",

"kms:Decrypt"

\]

Resource = \[

var.db_secrets_arn,

var.kms_key_arn

\]

}\]

})

tags = local.tokyo_tags

}

\# タスク実行ロールへのシークレットアクセス権限付与

resource "aws_iam_role_policy_attachment"
"execution_role_secrets_access" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_execution_role.name

policy_arn = aws_iam_policy.secrets_access.arn

}

\# サービスディスカバリのネームスペース（東京）

resource "aws_service_discovery_private_dns_namespace" "tokyo" {

provider = aws.tokyo

name = "\${var.environment}.\${var.application}.local"

vpc = var.vpc_id_tokyo

tags = local.tokyo_tags

}

\# サービスディスカバリのネームスペース（大阪）

resource "aws_service_discovery_private_dns_namespace" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.environment}.\${var.application}.local"

vpc = var.vpc_id_osaka

tags = local.osaka_tags

}

## マルチリージョン対応のECRリポジトリ設定

\# ecr/repositories.tf

\# 東京リージョンのECRリポジトリ

resource "aws_ecr_repository" "tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

encryption_configuration {

encryption_type = "KMS"

kms_key = var.kms_key_arn_tokyo

}

tags = local.tokyo_tags

}

\# 大阪リージョンのレプリケーションリポジトリ（本番環境のDR用）

resource "aws_ecr_repository" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

encryption_configuration {

encryption_type = "KMS"

kms_key = var.kms_key_arn_osaka

}

tags = local.osaka_tags

}

\# ECRのライフサイクルポリシー（東京）

resource "aws_ecr_lifecycle_policy" "tokyo" {

provider = aws.tokyo

repository = aws_ecr_repository.tokyo.name

policy = jsonencode({

rules = \[

{

rulePriority = 1,

description = "Keep only the last 10 untagged images",

selection = {

tagStatus = "untagged",

countType = "imageCountMoreThan",

countNumber = 10

},

action = {

type = "expire"

}

},

{

rulePriority = 2,

description = "Keep only the last 100 tagged non-prod images",

selection = {

tagStatus = "tagged",

tagPatternList = \["v\*", "dev-\*", "test-\*"\],

countType = "imageCountMoreThan",

countNumber = 100

},

action = {

type = "expire"

}

},

{

rulePriority = 3,

description = "Keep all production images",

selection = {

tagStatus = "tagged",

tagPatternList = \["prod-\*", "stable-\*"\],

countType = "imageCountMoreThan",

countNumber = 10000 \# 実質的に全て保持

},

action = {

type = "expire"

}

}

\]

})

}

\# ECRのライフサイクルポリシー（大阪）

resource "aws_ecr_lifecycle_policy" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

repository = aws_ecr_repository.osaka\[0\].name

policy = jsonencode({

rules = \[

{

rulePriority = 1,

description = "Keep only the last 10 untagged images",

selection = {

tagStatus = "untagged",

countType = "imageCountMoreThan",

countNumber = 10

},

action = {

type = "expire"

}

},

{

rulePriority = 2,

description = "Keep only the latest production images",

selection = {

tagStatus = "tagged",

tagPatternList = \["prod-\*", "stable-\*"\],

countType = "imageCountMoreThan",

countNumber = 20

},

action = {

type = "expire"

}

}

\]

})

}

\# クロスリージョンレプリケーション（本番環境のみ）

resource "aws_ecr_replication_configuration" "this" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

replication_configuration {

rule {

destination {

region = var.secondary_region

registry_id = data.aws_caller_identity.current.account_id

}

}

}

}

\# ECRイメージ脆弱性通知用のSNSトピック（東京）

resource "aws_sns_topic" "vulnerability_notification_tokyo" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-vulnerability-notification"

tags = local.tokyo_tags

}

\# ECRイメージ脆弱性通知用のSNSトピック（大阪）

resource "aws_sns_topic" "vulnerability_notification_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name =
"\${var.application}-\${var.environment}-vulnerability-notification"

tags = local.osaka_tags

}

\# ECRイベントルール - 脆弱性スキャン結果検出（東京）

resource "aws_cloudwatch_event_rule" "ecr_scan_findings_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-ecr-scan-findings"

description = "Capture ECR image scan findings for critical
vulnerabilities"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[aws_ecr_repository.tokyo.name\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = local.tokyo_tags

}

\# ECRイベントルール - SNSターゲット（東京）

resource "aws_cloudwatch_event_target" "ecr_scan_findings_to_sns_tokyo"
{

provider = aws.tokyo

rule = aws_cloudwatch_event_rule.ecr_scan_findings_tokyo.name

target_id = "SendToSNS"

arn = aws_sns_topic.vulnerability_notification_tokyo.arn

}

\# ECRイベントルール - 脆弱性スキャン結果検出（大阪）

resource "aws_cloudwatch_event_rule" "ecr_scan_findings_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-ecr-scan-findings"

description = "Capture ECR image scan findings for critical
vulnerabilities"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[aws_ecr_repository.osaka\[0\].name\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = local.osaka_tags

}

\# ECRイベントルール - SNSターゲット（大阪）

resource "aws_cloudwatch_event_target" "ecr_scan_findings_to_sns_osaka"
{

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

rule = aws_cloudwatch_event_rule.ecr_scan_findings_osaka\[0\].name

target_id = "SendToSNS"

arn = aws_sns_topic.vulnerability_notification_osaka\[0\].arn

}

## 東京-大阪間のDR設定とフェイルオーバー自動化

\# dr/failover.tf

\# Aurora Global Database（本番環境のみ）

resource "aws_rds_global_cluster" "global" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

global_cluster_identifier =
"\${var.application}-\${var.environment}-global"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

database_name = replace("\${var.application}\_\${var.environment}", "-",
"\_")

deletion_protection = true

tags = local.tokyo_tags

}

\# Route 53 ヘルスチェック（東京リージョン）

resource "aws_route53_health_check" "primary_region" {

provider = aws.tokyo

fqdn = var.api_endpoint_tokyo

port = 443

type = "HTTPS"

resource_path = "/health"

failure_threshold = 3

request_interval = 30

tags = merge(local.tokyo_tags, {

Name = "Primary Region Health Check"

})

}

\# フェイルオーバールーティングポリシー用のRoute 53レコード

resource "aws_route53_record" "api" {

provider = aws.tokyo

zone_id = var.route53_zone_id

name = "api.\${var.application}.\${var.domain_name}"

type = "CNAME"

ttl = 60

failover_routing_policy {

type = "PRIMARY"

}

set_identifier = "primary"

records = \[var.api_endpoint_tokyo\]

health_check_id = aws_route53_health_check.primary_region.id

}

\# DR用のRoute 53レコード（本番環境のみ）

resource "aws_route53_record" "api_dr" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

zone_id = var.route53_zone_id

name = "api.\${var.application}.\${var.domain_name}"

type = "CNAME"

ttl = 60

failover_routing_policy {

type = "SECONDARY"

}

set_identifier = "secondary"

records = \[var.api_endpoint_osaka\]

}

\# フェイルオーバー検知Lambda関数

resource "aws_lambda_function" "failover_detection" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

function_name =
"\${var.application}-\${var.environment}-failover-detection"

role = aws_iam_role.failover_lambda_role\[0\].arn

runtime = "nodejs14.x"

handler = "index.handler"

timeout = 60

memory_size = 128

filename = "lambda/failover-detection.zip"

environment {

variables = {

PRIMARY_REGION = var.primary_region

DR_REGION = var.secondary_region

SNS_TOPIC_ARN = aws_sns_topic.failover_notification\[0\].arn

APPLICATION = var.application

ENVIRONMENT = var.environment

}

}

tags = local.tokyo_tags

}

\# フェイルオーバー検知Lambda用のIAMロール

resource "aws_iam_role" "failover_lambda_role" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-lambda-role"

description = "Role for failover detection Lambda function"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "lambda.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# フェイルオーバー検知用のCloudWatch Events Rule

resource "aws_cloudwatch_event_rule" "route53_health_check_state_change"
{

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name =
"\${var.application}-\${var.environment}-health-check-state-change"

description = "Capture Route 53 health check state changes"

event_pattern = jsonencode({

source = \["aws.route53"\],

detail-type = \["AWS Health Event"\],

detail = {

service = \["ROUTE53"\],

eventTypeCategory = \["issue"\],

healthCheckId = \[aws_route53_health_check.primary_region.id\]

}

})

tags = local.tokyo_tags

}

\# フェイルオーバー通知用のSNSトピック

resource "aws_sns_topic" "failover_notification" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-notification"

tags = local.tokyo_tags

}

\# CloudWatch Events RuleとLambdaの連携

resource "aws_cloudwatch_event_target" "failover_lambda" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

rule =
aws_cloudwatch_event_rule.route53_health_check_state_change\[0\].name

target_id = "InvokeLambda"

arn = aws_lambda_function.failover_detection\[0\].arn

}

\# Lambda関数の実行権限

resource "aws_lambda_permission" "allow_cloudwatch" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

statement_id = "AllowExecutionFromCloudWatch"

action = "lambda:InvokeFunction"

function_name =
aws_lambda_function.failover_detection\[0\].function_name

principal = "events.amazonaws.com"

source_arn =
aws_cloudwatch_event_rule.route53_health_check_state_change\[0\].arn

}

\# フェイルオーバー検知Lambda用のポリシー

resource "aws_iam_policy" "failover_lambda_policy" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-lambda-policy"

description = "Policy for failover detection Lambda function"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource = "arn:aws:logs:\*:\*:\*"

},

{

Action = \[

"sns:Publish"

\],

Effect = "Allow",

Resource = aws_sns_topic.failover_notification\[0\].arn

},

{

Action = \[

"route53:GetHealthCheck",

"route53:GetHealthCheckStatus"

\],

Effect = "Allow",

Resource = "\*"

}

\]

})

tags = local.tokyo_tags

}

\# フェイルオーバーLambda用ポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"failover_lambda_policy_attachment" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

role = aws_iam_role.failover_lambda_role\[0\].name

policy_arn = aws_iam_policy.failover_lambda_policy\[0\].arn

}

## フェイルオーバー検知Lambdaの実装（コード例）

// lambda/index.js - フェイルオーバー検知Lambda

const AWS = require('aws-sdk');

const sns = new AWS.SNS();

const route53 = new AWS.Route53();

exports.handler = async (event) =\> {

console.log('Received event:', JSON.stringify(event, null, 2));

const primaryRegion = process.env.PRIMARY_REGION;

const drRegion = process.env.DR_REGION;

const snsTopicArn = process.env.SNS_TOPIC_ARN;

const application = process.env.APPLICATION;

const environment = process.env.ENVIRONMENT;

try {

// ヘルスチェックの状態を確認

const healthCheckId = event.detail.healthCheckId;

const healthCheckResponse = await route53.getHealthCheck({

HealthCheckId: healthCheckId

}).promise();

const healthCheckStatusResponse = await route53.getHealthCheckStatus({

HealthCheckId: healthCheckId

}).promise();

const healthCheckConfig =
healthCheckResponse.HealthCheck.HealthCheckConfig;

const healthCheckStatus =
healthCheckStatusResponse.HealthCheckObservations;

// 障害状態の確認

const failingObservations = healthCheckStatus.filter(obs =\>
obs.StatusReport.Status !== 'Success');

const failureRate = failingObservations.length /
healthCheckStatus.length;

// メッセージの構築

let message = \`Health check for \${application}-\${environment} is
experiencing issues.\n\n\`;

message += \`Primary Region: \${primaryRegion}\n\`;

message += \`DR Region: \${drRegion}\n\`;

message += \`Health Check:
\${healthCheckConfig.FullyQualifiedDomainName}\${healthCheckConfig.ResourcePath}\n\`;

message += \`Failure Rate: \${Math.round(failureRate \* 100)}%\n\n\`;

if (failureRate \> 0.5) {

message += \`ALERT: High failure rate detected. Route 53 may initiate
failover to the DR region (\${drRegion}).\n\`;

message += 'Please check the primary region infrastructure and
services.\n\n';

message += 'Actions to take:\n';

message += '1. Verify primary region services status\n';

message += '2. Check CloudWatch metrics and logs for errors\n';

message += '3. Confirm DR region is ready to handle traffic\n';

message += '4. Monitor the failover process\n';

} else {

message += 'Some observations are failing but the overall health check
is still passing.\n';

message += 'Monitor the situation closely for potential degradation.\n';

}

// SNS通知の送信

await sns.publish({

TopicArn: snsTopicArn,

Subject: \`\[\${environment.toUpperCase()}\] \${application} Health
Check Alert\`,

Message: message

}).promise();

return {

statusCode: 200,

body: JSON.stringify({

message: 'Notification sent successfully',

healthCheckId: healthCheckId,

failureRate: failureRate

})

};

} catch (error) {

console.error('Error:', error);

// エラー通知

await sns.publish({

TopicArn: snsTopicArn,

Subject: \`\[\${environment.toUpperCase()}\] \${application} Failover
Detection Error\`,

Message: \`Error in failover detection Lambda: \${error.message}\`

}).promise();

throw error;

}

};

## 環境タグ付けとCI/CDパイプラインでの自動タグ付け

\# buildspecs/build_deploy_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

nodejs: 14

commands:

\- echo "Installing dependencies..."

\- npm install -g aws-cdk

pre_build:

commands:

\- echo "Setting up environment tags..."

\- \|

\# 環境タグの設定

case "\${DEPLOYMENT_ENV}" in

"dev")

export AWS_TAG_ENVIRONMENT="dev"

export AWS_TAG_BACKUP="weekly"

export AWS_TAG_AUTOSCALING="business-hours"

;;

"test")

export AWS_TAG_ENVIRONMENT="test"

export AWS_TAG_BACKUP="weekly"

export AWS_TAG_AUTOSCALING="business-hours"

;;

"staging")

export AWS_TAG_ENVIRONMENT="staging"

export AWS_TAG_BACKUP="daily"

export AWS_TAG_AUTOSCALING="always-on"

;;

"prod")

export AWS_TAG_ENVIRONMENT="prod"

export AWS_TAG_BACKUP="daily"

export AWS_TAG_AUTOSCALING="always-on"

export AWS_TAG_DR_ENABLED="true"

;;

\*)

echo "Unknown environment: \${DEPLOYMENT_ENV}"

exit 1

;;

esac

\- echo "Environment tags set for \${DEPLOYMENT_ENV}"

build:

commands:

\- echo "Building the application..."

\- npm run build

\# コンテナイメージのビルド

\- echo "Building the Docker image..."

\- aws ecr get-login-password --region \${AWS_DEFAULT_REGION} \| docker
login --username AWS --password-stdin
\${AWS_ACCOUNT_ID}.dkr.ecr.\${AWS_DEFAULT_REGION}.amazonaws.com

\- docker build -t
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION} .

\# イメージタグにバージョンと環境タグを付与

\- COMMIT_HASH=\$(echo \$CODEBUILD_RESOLVED_SOURCE_VERSION \| cut -c
1-7)

\- VERSION=\$(jq -r '.version' package.json)

\- echo "Tagging image with version \${VERSION}, commit \${COMMIT_HASH},
and environment \${AWS_TAG_ENVIRONMENT}"

\- docker tag
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}

\- docker tag
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:\${AWS_TAG_ENVIRONMENT}-\${VERSION}

\# 本番環境の場合は安定版タグも付与

\- \|

if \[ "\${DEPLOYMENT_ENV}" = "prod" \]; then

echo "Adding stable tag for production release"

docker tag \${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:stable-\${VERSION}

docker tag \${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:latest

fi

\# イメージのプッシュ

\- echo "Pushing the Docker image..."

\- docker push
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}

\- docker push \${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}

\- docker push
\${ECR_REPOSITORY_URI}:\${AWS_TAG_ENVIRONMENT}-\${VERSION}

\- \|

if \[ "\${DEPLOYMENT_ENV}" = "prod" \]; then

docker push \${ECR_REPOSITORY_URI}:stable-\${VERSION}

docker push \${ECR_REPOSITORY_URI}:latest

fi

\# ECSタスク定義の更新

\- echo "Updating ECS task definition..."

\- aws ecs describe-task-definition --task-definition
\${ECS_TASK_DEFINITION} --region \${AWS_DEFAULT_REGION} \>
task-definition.json

\- jq '.taskDefinition \| .containerDefinitions\[0\].image =
"'\${ECR_REPOSITORY_URI}':'\${VERSION}'-'\${COMMIT_HASH}'"'
task-definition.json \> container-definition.json

\- TASK_DEF_ARN=\$(aws ecs register-task-definition --family
\${ECS_TASK_DEFINITION} --container-definitions
file://container-definition.json --task-role-arn \${ECS_TASK_ROLE_ARN}
--execution-role-arn \${ECS_EXECUTION_ROLE_ARN} --network-mode awsvpc
--requires-compatibilities FARGATE --cpu \${ECS_TASK_CPU} --memory
\${ECS_TASK_MEMORY} --tags Key=Environment,Value=\${AWS_TAG_ENVIRONMENT}
Key=Application,Value=\${APPLICATION_NAME} Key=Team,Value=\${TEAM_NAME}
Key=CostCenter,Value=\${COST_CENTER} --region \${AWS_DEFAULT_REGION} \|
jq -r '.taskDefinition.taskDefinitionArn')

\# ECSサービスの更新

\- echo "Updating the ECS service..."

\- aws ecs update-service --cluster \${ECS_CLUSTER} --service
\${ECS_SERVICE} --task-definition \${TASK_DEF_ARN} --region
\${AWS_DEFAULT_REGION}

post_build:

commands:

\- echo "Build completed on \$(date)"

\- echo "Saving metadata for testing phase..."

\- echo
"{\\ImageURI\\:\\\${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}\\,\\TaskDefinitionArn\\:\\\${TASK_DEF_ARN}\\,\\Environment\\:\\\${AWS_TAG_ENVIRONMENT}\\}"
\> build-metadata.json

artifacts:

files:

\- build-metadata.json

\- task-definition.json

\- container-definition.json

\- appspec.yaml

discard-paths: yes

## マルチリージョン対応のFlywayデータベースマイグレーション設定

\# database/flyway.tf

\# FlywayマイグレーションのCodeBuildプロジェクト（東京）

resource "aws_codebuild_project" "flyway_migration_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-migration"

description = "Flyway database migration for \${var.application} in
\${var.environment} environment"

service_role = aws_iam_role.flyway_codebuild_role.arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "DB_ENDPOINT"

value = aws_rds_cluster.aurora_tokyo.endpoint

}

environment_variable {

name = "DB_NAME"

value = aws_rds_cluster.aurora_tokyo.database_name

}

environment_variable {

name = "DB_SECRET_ARN"

value = var.db_secrets_arn

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

environment_variable {

name = "REGION"

value = var.primary_region

}

}

source {

type = "GITHUB"

location = var.flyway_repository_url

buildspec = "buildspec-flyway.yml"

git_clone_depth = 1

git_submodules_config {

fetch_submodules = true

}

}

logs_config {

cloudwatch_logs {

group_name =
"/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration"

stream_name = "tokyo"

}

}

tags = local.tokyo_tags

}

\# FlywayマイグレーションのCodeBuildプロジェクト（大阪）

resource "aws_codebuild_project" "flyway_migration_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-migration"

description = "Flyway database migration for \${var.application} in
\${var.environment} environment (DR region)"

service_role = aws_iam_role.flyway_codebuild_role_osaka\[0\].arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "DB_ENDPOINT"

value = aws_rds_cluster.aurora_osaka\[0\].endpoint

}

environment_variable {

name = "DB_NAME"

value = aws_rds_cluster.aurora_osaka\[0\].database_name

}

environment_variable {

name = "DB_SECRET_ARN"

value = var.db_secrets_arn_osaka

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

environment_variable {

name = "REGION"

value = var.secondary_region

}

}

source {

type = "GITHUB"

location = var.flyway_repository_url

buildspec = "buildspec-flyway.yml"

git_clone_depth = 1

git_submodules_config {

fetch_submodules = true

}

}

logs_config {

cloudwatch_logs {

group_name =
"/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration"

stream_name = "osaka"

}

}

tags = local.osaka_tags

}

\# Flyway CodeBuild用IAMロール（東京）

resource "aws_iam_role" "flyway_codebuild_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-codebuild-role"

description = "Role for Flyway migration CodeBuild project"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codebuild.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# Flyway CodeBuild用IAMロール（大阪）

resource "aws_iam_role" "flyway_codebuild_role_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-codebuild-role"

description = "Role for Flyway migration CodeBuild project (DR region)"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codebuild.amazonaws.com"

}

}\]

})

tags = local.osaka_tags

}

\# Flyway用IAMポリシー（東京）

resource "aws_iam_policy" "flyway_policy" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-policy"

description = "Policy for Flyway migration CodeBuild project"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource =
"arn:aws:logs:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:log-group:/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration:\*"

},

{

Action = \[

"secretsmanager:GetSecretValue"

\],

Effect = "Allow",

Resource = var.db_secrets_arn

},

{

Action = \[

"rds-db:connect"

\],

Effect = "Allow",

Resource =
"arn:aws:rds-db:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${aws_rds_cluster.aurora_tokyo.cluster_resource_id}/\*"

},

{

Action = \[

"s3:GetObject",

"s3:PutObject",

"s3:ListBucket"

\],

Effect = "Allow",

Resource = \[

"\${aws_s3_bucket.flyway_migrations.arn}",

"\${aws_s3_bucket.flyway_migrations.arn}/\*"

\]

}

\]

})

tags = local.tokyo_tags

}

\# Flyway用IAMポリシー（大阪）

resource "aws_iam_policy" "flyway_policy_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-policy"

description = "Policy for Flyway migration CodeBuild project (DR
region)"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource =
"arn:aws:logs:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:log-group:/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration:\*"

},

{

Action = \[

"secretsmanager:GetSecretValue"

\],

Effect = "Allow",

Resource = var.db_secrets_arn_osaka

},

{

Action = \[

"rds-db:connect"

\],

Effect = "Allow",

Resource =
"arn:aws:rds-db:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${aws_rds_cluster.aurora_osaka\[0\].cluster_resource_id}/\*"

},

{

Action = \[

"s3:GetObject",

"s3:PutObject",

"s3:ListBucket"

\],

Effect = "Allow",

Resource = \[

"\${aws_s3_bucket.flyway_migrations.arn}",

"\${aws_s3_bucket.flyway_migrations.arn}/\*"

\]

}

\]

})

tags = local.osaka_tags

}

\# ポリシーのアタッチ（東京）

resource "aws_iam_role_policy_attachment" "flyway_policy_attachment" {

provider = aws.tokyo

role = aws_iam_role.flyway_codebuild_role.name

policy_arn = aws_iam_policy.flyway_policy.arn

}

\# ポリシーのアタッチ（大阪）

resource "aws_iam_role_policy_attachment"
"flyway_policy_attachment_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

role = aws_iam_role.flyway_codebuild_role_osaka\[0\].name

policy_arn = aws_iam_policy.flyway_policy_osaka\[0\].arn

}

\# Flywayマイグレーションスクリプト用S3バケット

resource "aws_s3_bucket" "flyway_migrations" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-flyway-migrations-\${data.aws_caller_identity.current.account_id}"

tags = local.tokyo_tags

}

\# S3バケットバージョニング

resource "aws_s3_bucket_versioning" "flyway_migrations_versioning" {

provider = aws.tokyo

bucket = aws_s3_bucket.flyway_migrations.id

versioning_configuration {

status = "Enabled"

}

}

\# S3バケット暗号化

resource "aws_s3_bucket_server_side_encryption_configuration"
"flyway_migrations_encryption" {

provider = aws.tokyo

bucket = aws_s3_bucket.flyway_migrations.id

rule {

apply_server_side_encryption_by_default {

sse_algorithm = "AES256"

}

}

}

\# マイグレーション実行用CloudWatchイベントルール

resource "aws_cloudwatch_event_rule" "flyway_migration_schedule" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-flyway-migration-schedule"

description = "Schedule for automatic database migrations"

schedule_expression = var.environment == "prod" ? "cron(0 20 ? \* SUN
\*)" : "cron(0 20 ? \* MON-FRI \*)"

tags = local.tokyo_tags

}

\# CloudWatchイベントターゲット

resource "aws_cloudwatch_event_target" "flyway_migration_target" {

provider = aws.tokyo

rule = aws_cloudwatch_event_rule.flyway_migration_schedule.name

target_id = "RunFlywayMigration"

arn = aws_codebuild_project.flyway_migration_tokyo.arn

role_arn = aws_iam_role.events_to_codebuild_role.arn

}

\# イベントからCodeBuildを実行するためのロール

resource "aws_iam_role" "events_to_codebuild_role" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-events-to-codebuild-role"

description = "Role for CloudWatch Events to start CodeBuild project"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "events.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# イベントからCodeBuildを実行するためのポリシー

resource "aws_iam_policy" "events_to_codebuild_policy" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-events-to-codebuild-policy"

description = "Policy for CloudWatch Events to start CodeBuild project"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "codebuild:StartBuild"

Effect = "Allow"

Resource = aws_codebuild_project.flyway_migration_tokyo.arn

}\]

})

tags = local.tokyo_tags

}

\# ポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"events_to_codebuild_policy_attachment" {

provider = aws.tokyo

role = aws_iam_role.events_to_codebuild_role.name

policy_arn = aws_iam_policy.events_to_codebuild_policy.arn

}

## Flyway用のビルドスペック例

\# buildspec-flyway.yml

version: 0.2

phases:

install:

runtime-versions:

java: corretto11

commands:

\- echo "Installing tools..."

\- yum install -y jq wget unzip

\- wget -qO-
https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/8.5.0/flyway-commandline-8.5.0-linux-x64.tar.gz
\| tar xvz

\- mv flyway-8.5.0 /opt/flyway

\- ln -s /opt/flyway/flyway /usr/local/bin/flyway

pre_build:

commands:

\- echo "Retrieving database credentials..."

\- DB_CREDS=\$(aws secretsmanager get-secret-value --secret-id
\$DB_SECRET_ARN --region \$REGION --query SecretString --output text)

\- DB_USERNAME=\$(echo \$DB_CREDS \| jq -r .username)

\- DB_PASSWORD=\$(echo \$DB_CREDS \| jq -r .password)

\- echo "Configuring Flyway..."

\- mkdir -p flyway/conf

\- echo "flyway.url=jdbc:mysql://\${DB_ENDPOINT}:3306/\${DB_NAME}" \>
flyway/conf/flyway.conf

\- echo "flyway.user=\${DB_USERNAME}" \>\> flyway/conf/flyway.conf

\- echo "flyway.password=\${DB_PASSWORD}" \>\> flyway/conf/flyway.conf

\- echo "flyway.locations=filesystem:./migrations" \>\>
flyway/conf/flyway.conf

\- echo "flyway.schemas=\${DB_NAME}" \>\> flyway/conf/flyway.conf

\- echo "flyway.baselineOnMigrate=true" \>\> flyway/conf/flyway.conf

\- echo "flyway.validateOnMigrate=true" \>\> flyway/conf/flyway.conf

\- mkdir -p flyway/migrations

\- echo "Downloading migration scripts from S3..."

\- aws s3 sync
s3://\${APPLICATION}-\${ENVIRONMENT}-flyway-migrations-\${AWS_ACCOUNT_ID}/migrations/
flyway/migrations/

build:

commands:

\- echo "Running Flyway migration..."

\- cd flyway

\- flyway info

\# 実行前のバックアップ（本番環境のみ）

\- \|

if \[ "\${ENVIRONMENT}" = "prod" \]; then

echo "Running in production - creating database backup before
migration..."

BACKUP_TIMESTAMP=\$(date +%Y%m%d%H%M%S)

echo "Creating SQL dump..."

\# Backup logic here

echo "Backup completed and stored at \${BACKUP_FILE}"

fi

\# マイグレーション実行

\- echo "Executing migration..."

\- flyway migrate

\# マイグレーション後の検証

\- echo "Verifying migration..."

\- flyway validate

\- flyway info

post_build:

commands:

\- echo "Migration completed at \$(date)"

\- \|

if \[ \$CODEBUILD_BUILD_SUCCEEDING -eq 1 \]; then

MIGRATION_STATUS="SUCCESS"

else

MIGRATION_STATUS="FAILED"

fi

\# 実行結果の通知（SNS）

\- \|

aws sns publish \\

--topic-arn
arn:aws:sns:\${REGION}:\${AWS_ACCOUNT_ID}:\${APPLICATION}-\${ENVIRONMENT}-db-migration-notification
\\

--subject "\[\${ENVIRONMENT}\] \${APPLICATION} Database Migration
\${MIGRATION_STATUS}" \\

--message "Database migration for \${APPLICATION} in \${ENVIRONMENT}
environment completed with status: \${MIGRATION_STATUS}.\n\nRegion:
\${REGION}\nTimestamp: \$(date)\n\nSee CodeBuild logs for details:
https://console.aws.amazon.com/codesuite/codebuild/projects/\${APPLICATION}-\${ENVIRONMENT}-flyway-migration/build/detail?region=\${REGION}"
\\

--region \${REGION}

artifacts:

files:

\- flyway/logs/\*\*/\*

discard-paths: no

## マルチリージョン対応のAFTカスタムベースラインの例

\# aft/custom-baselines/main.tf

\# 東京リージョンのCFnスタック

resource "aws_cloudformation_stack" "baseline_tokyo" {

provider = aws.tokyo

name = "aft-account-baseline"

template_body = file("\${path.module}/templates/baseline.yaml")

parameters = {

Environment = var.environment

Application = var.application

Team = var.team

CostCenter = var.cost_center

Region = "Tokyo"

PrimaryRegion = "true"

}

capabilities = \["CAPABILITY_NAMED_IAM"\]

tags = local.tokyo_tags

}

\# 大阪リージョンのCFnスタック（本番環境のDR用）

resource "aws_cloudformation_stack" "baseline_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "aft-account-baseline"

template_body = file("\${path.module}/templates/baseline.yaml")

parameters = {

Environment = var.environment

Application = var.application

Team = var.team

CostCenter = var.cost_center

Region = "Osaka"

PrimaryRegion = "false"

DREnabled = "true"

}

capabilities = \["CAPABILITY_NAMED_IAM"\]

tags = local.osaka_tags

}

\# セキュリティ通知用SNSトピック（東京）

resource "aws_sns_topic" "security_notifications_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-security-notifications"

tags = local.tokyo_tags

}

\# セキュリティ通知用SNSトピック（大阪）

resource "aws_sns_topic" "security_notifications_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-security-notifications"

tags = local.osaka_tags

}

\# EC2インスタンスプロファイル（共通ベースライン用）

resource "aws_iam_instance_profile" "ec2_baseline_profile" {

provider = aws.tokyo

name = "ec2-baseline-profile-\${var.environment}"

role = aws_iam_role.ec2_baseline_role.name

tags = local.tokyo_tags

}

\# EC2ベースラインロール

resource "aws_iam_role" "ec2_baseline_role" {

provider = aws.tokyo

name = "ec2-baseline-role-\${var.environment}"

description = "Baseline IAM role for EC2 instances"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ec2.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# CloudWatch Logsへのアクセスポリシー

resource "aws_iam_policy" "cloudwatch_logs_access" {

provider = aws.tokyo

name = "cloudwatch-logs-access-\${var.environment}"

description = "Allow writing to CloudWatch Logs"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents",

"logs:DescribeLogStreams"

\],

Effect = "Allow",

Resource = "arn:aws:logs:\*:\*:\*"

}\]

})

tags = local.tokyo_tags

}

\# SSMエージェント用ポリシー

resource "aws_iam_policy" "ssm_access" {

provider = aws.tokyo

name = "ssm-access-\${var.environment}"

description = "Allow SSM agent to communicate with SSM service"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = \[

"ssm:DescribeAssociation",

"ssm:GetDeployablePatchSnapshotForInstance",

"ssm:GetDocument",

"ssm:DescribeDocument",

"ssm:GetManifest",

"ssm:GetParameter",

"ssm:GetParameters",

"ssm:ListAssociations",

"ssm:ListInstanceAssociations",

"ssm:PutInventory",

"ssm:PutComplianceItems",

"ssm:PutConfigurePackageResult",

"ssm:UpdateAssociationStatus",

"ssm:UpdateInstanceAssociationStatus",

"ssm:UpdateInstanceInformation"

\],

Effect = "Allow",

Resource = "\*"

},

{

Action = \[

"ssmmessages:CreateControlChannel",

"ssmmessages:CreateDataChannel",

"ssmmessages:OpenControlChannel",

"ssmmessages:OpenDataChannel"

\],

Effect = "Allow",

Resource = "\*"

},

{

Action = \[

"ec2messages:AcknowledgeMessage",

"ec2messages:DeleteMessage",

"ec2messages:FailMessage",

"ec2messages:GetEndpoint",

"ec2messages:GetMessages",

"ec2messages:SendReply"

\],

Effect = "Allow",

Resource = "\*"

}\]

})

tags = local.tokyo_tags

}

\# IAMポリシーアタッチメント

resource "aws_iam_role_policy_attachment" "cloudwatch_logs_attachment" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = aws_iam_policy.cloudwatch_logs_access.arn

}

resource "aws_iam_role_policy_attachment" "ssm_attachment" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = aws_iam_policy.ssm_access.arn

}

resource "aws_iam_role_policy_attachment" "ssm_managed_instance_core" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"

}

\# S3アクセスログバケット（東京）

resource "aws_s3_bucket" "access_logs_tokyo" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-access-logs-\${data.aws_caller_identity.current.account_id}-\${var.primary_region}"

tags = local.tokyo_tags

}

\# S3アクセスログバケット（大阪）

resource "aws_s3_bucket" "access_logs_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket =
"\${var.application}-\${var.environment}-access-logs-\${data.aws_caller_identity.current.account_id}-\${var.secondary_region}"

tags = local.osaka_tags

}

\# S3アクセスログバケットポリシー（東京）

resource "aws_s3_bucket_policy" "access_logs_policy_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.access_logs_tokyo.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSLogDeliveryWrite"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:PutObject"

Resource = "\${aws_s3_bucket.access_logs_tokyo.arn}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

},

{

Sid = "AWSLogDeliveryAclCheck"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.access_logs_tokyo.arn

}

\]

})

}

\# S3アクセスログバケットポリシー（大阪）

resource "aws_s3_bucket_policy" "access_logs_policy_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket = aws_s3_bucket.access_logs_osaka\[0\].id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSLogDeliveryWrite"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:PutObject"

Resource = "\${aws_s3_bucket.access_logs_osaka\[0\].arn}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

},

{

Sid = "AWSLogDeliveryAclCheck"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.access_logs_osaka\[0\].arn

}

\]

})

}

\# S3バケットライフサイクルポリシー（東京）

resource "aws_s3_bucket_lifecycle_configuration"
"access_logs_lifecycle_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.access_logs_tokyo.id

rule {

id = "log-expiration"

status = "Enabled"

expiration {

days = var.environment == "prod" ? 365 : 90

}

transition {

days = 30

storage_class = "STANDARD_IA"

}

transition {

days = var.environment == "prod" ? 90 : 60

storage_class = "GLACIER"

}

}

}

\# S3バケットライフサイクルポリシー（大阪）

resource "aws_s3_bucket_lifecycle_configuration"
"access_logs_lifecycle_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket = aws_s3_bucket.access_logs_osaka\[0\].id

rule {

id = "log-expiration"

status = "Enabled"

expiration {

days = 365

}

transition {

days = 30

storage_class = "STANDARD_IA"

}

transition {

days = 90

storage_class = "GLACIER"

}

}

}

\# CloudTrail設定（東京）

resource "aws_cloudtrail" "baseline_cloudtrail_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-trail"

s3_bucket_name = aws_s3_bucket.cloudtrail_logs_tokyo.id

include_global_service_events = true

is_multi_region_trail = true

enable_log_file_validation = true

event_selector {

read_write_type = "All"

include_management_events = true

data_resource {

type = "AWS::S3::Object"

values = \["arn:aws:s3:::"\]

}

}

tags = local.tokyo_tags

}

\# CloudTrailログ用S3バケット（東京）

resource "aws_s3_bucket" "cloudtrail_logs_tokyo" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-cloudtrail-logs-\${data.aws_caller_identity.current.account_id}"

tags = local.tokyo_tags

}

\# CloudTrailログ用S3バケットポリシー（東京）

resource "aws_s3_bucket_policy" "cloudtrail_logs_policy_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.cloudtrail_logs_tokyo.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSCloudTrailAclCheck"

Effect = "Allow"

Principal = { Service = "cloudtrail.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.cloudtrail_logs_tokyo.arn

},

{

Sid = "AWSCloudTrailWrite"

Effect = "Allow"

Principal = { Service = "cloudtrail.amazonaws.com" }

Action = "s3:PutObject"

Resource =
"\${aws_s3_bucket.cloudtrail_logs_tokyo.arn}/AWSLogs/\${data.aws_caller_identity.current.account_id}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

}

\]

})

}

## AFTカスタムベースラインのCloudFormationテンプレート例

\# aft/custom-baselines/templates/baseline.yaml

AWSTemplateFormatVersion: '2010-09-09'

Description: 'AFT Account Baseline Configuration for TechNova
Microservices'

Parameters:

Environment:

Type: String

Description: 'Deployment environment name'

AllowedValues:

\- 'dev'

\- 'test'

\- 'staging'

\- 'prod'

Default: 'dev'

Application:

Type: String

Description: 'Application name'

Team:

Type: String

Description: 'Team name'

CostCenter:

Type: String

Description: 'Cost center code'

Region:

Type: String

Description: 'AWS region name (e.g., Tokyo, Osaka)'

PrimaryRegion:

Type: String

Description: 'Whether this is the primary region (true/false)'

AllowedValues:

\- 'true'

\- 'false'

Default: 'true'

DREnabled:

Type: String

Description: 'Whether DR is enabled for this account (true/false)'

AllowedValues:

\- 'true'

\- 'false'

Default: 'false'

Conditions:

IsProd: !Equals \[ !Ref Environment, 'prod' \]

IsPrimary: !Equals \[ !Ref PrimaryRegion, 'true' \]

IsDREnabled: !Equals \[ !Ref DREnabled, 'true' \]

IsTokyo: !Or \[ !Equals \[ !Ref Region, 'Tokyo' \], !Equals \[ !Ref
Region, 'tokyo' \] \]

IsOsaka: !Or \[ !Equals \[ !Ref Region, 'Osaka' \], !Equals \[ !Ref
Region, 'osaka' \] \]

\# 組み合わせ条件

IsProdPrimary: !And \[ !Condition IsProd, !Condition IsPrimary \]

IsProdDR: !And \[ !Condition IsProd, !Condition IsDREnabled, !Not \[
!Condition IsPrimary \] \]

Resources:

\# セキュリティグループ基本設定 - 内部アクセス用

InternalAccessSecurityGroup:

Type: 'AWS::EC2::SecurityGroup'

Properties:

GroupDescription: 'Internal access security group'

VpcId: !ImportValue 'DefaultVPC'

Tags:

\- Key: Name

Value: !Sub '\${Application}-\${Environment}-internal-sg'

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# CloudWatch Logsロググループ

ApplicationLogGroup:

Type: 'AWS::Logs::LogGroup'

Properties:

LogGroupName: !Sub '/aws/\${Application}/\${Environment}'

RetentionInDays: !If \[ IsProd, 365, 30 \]

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# Config Recorder設定

ConfigRecorder:

Type: 'AWS::Config::ConfigurationRecorder'

Properties:

Name: !Sub '\${Application}-\${Environment}-config-recorder'

RecordingGroup:

AllSupported: true

IncludeGlobalResourceTypes: !Condition IsPrimary

RoleARN: !GetAtt ConfigRole.Arn

\# Config Delivery Channel

ConfigDeliveryChannel:

Type: 'AWS::Config::DeliveryChannel'

Properties:

Name: !Sub '\${Application}-\${Environment}-config-delivery'

ConfigSnapshotDeliveryProperties:

DeliveryFrequency: !If \[ IsProd, 'One_Hour', 'Six_Hours' \]

S3BucketName: !Ref ConfigBucket

S3KeyPrefix: !Ref Application

\# Config用IAMロール

ConfigRole:

Type: 'AWS::IAM::Role'

Properties:

AssumeRolePolicyDocument:

Version: '2012-10-17'

Statement:

\- Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 'sts:AssumeRole'

ManagedPolicyArns:

\- 'arn:aws:iam::aws:policy/service-role/AWS_ConfigRole'

Path: /

\# Config用S3バケット

ConfigBucket:

Type: 'AWS::S3::Bucket'

Properties:

BucketName: !Sub
'\${Application}-\${Environment}-config-\${AWS::AccountId}-\${AWS::Region}'

VersioningConfiguration:

Status: Enabled

BucketEncryption:

ServerSideEncryptionConfiguration:

\- ServerSideEncryptionByDefault:

SSEAlgorithm: AES256

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# Config用バケットポリシー

ConfigBucketPolicy:

Type: 'AWS::S3::BucketPolicy'

Properties:

Bucket: !Ref ConfigBucket

PolicyDocument:

Version: '2012-10-17'

Statement:

\- Sid: AWSConfigBucketPermissionsCheck

Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 's3:GetBucketAcl'

Resource: !Sub 'arn:aws:s3:::\${ConfigBucket}'

\- Sid: AWSConfigBucketDelivery

Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 's3:PutObject'

Resource: !Sub
'arn:aws:s3:::\${ConfigBucket}/AWSLogs/\${AWS::AccountId}/\*'

Condition:

StringEquals:

's3:x-amz-acl': 'bucket-owner-full-control'

\# GuardDuty Detector（本番環境のみ）

GuardDutyDetector:

Type: 'AWS::GuardDuty::Detector'

Condition: IsProd

Properties:

Enable: true

FindingPublishingFrequency: 'FIFTEEN_MINUTES'

\# 本番環境用Security Hub有効化

SecurityHub:

Type: 'AWS::SecurityHub::Hub'

Condition: IsProd

Properties:

Tags:

Environment: !Ref Environment

Application: !Ref Application

Team: !Ref Team

CostCenter: !Ref CostCenter

Region: !Ref Region

ManagedBy: 'AFT'

\# バックアップボールト（本番環境のみ）

BackupVault:

Type: 'AWS::Backup::BackupVault'

Condition: IsProd

Properties:

BackupVaultName: !Sub '\${Application}-\${Environment}-vault'

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# バックアップポリシー（本番環境のみ）

BackupPolicy:

Type: 'AWS::Backup::BackupPlan'

Condition: IsProd

Properties:

BackupPlan:

BackupPlanName: !Sub '\${Application}-\${Environment}-backup-plan'

BackupPlanRule:

\- RuleName: 'DailyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 \* \* ? \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 30

\- RuleName: 'WeeklyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 ? \* SAT \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 90

MoveToColdStorageAfterDays: 30

\- RuleName: 'MonthlyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 1 \* ? \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 365

MoveToColdStorageAfterDays: 90

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

Outputs:

InternalSecurityGroupId:

Description: 'ID of the internal access security group'

Value: !Ref InternalAccessSecurityGroup

Export:

Name: !Sub '\${Application}-\${Environment}-internal-sg-id'

LogGroupName:

Description: 'Name of the application log group'

Value: !Ref ApplicationLogGroup

Export:

Name: !Sub '\${Application}-\${Environment}-log-group-name'

ConfigBucketName:

Description: 'Name of the AWS Config bucket'

Value: !Ref ConfigBucket

Export:

Name: !Sub '\${Application}-\${Environment}-config-bucket-name'

## AFTアカウント申請JSONのサンプル（本番環境用のマルチリージョン対応）

{

"account_name": "prod-manufacturing-management",

"email": "aws-prod-manufacturing@technova.com",

"organizational_unit": "Production",

"tags": {

"Environment": "prod",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "manufacturing-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "prod",

"/dr_enabled": "true",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3",

"/vpc_cidr_tokyo": "10.0.0.0/16",

"/vpc_cidr_osaka": "10.1.0.0/16",

"/backup_retention_days": "30",

"/backup_schedule": "cron(0 1 \* \* ? \*)",

"/high_availability": "true",

"/auto_scaling_min": "2",

"/auto_scaling_max": "10"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true,

"terraform_version": "1.5.0",

"static_analyzers": \["tfsec", "tflint", "checkov"\],

"dynamic_analyzers": \["iam_access_analyzer"\],

"enable_dr": true,

"dr_region": "ap-northeast-3"

}

}

## 開発環境用のAFTアカウント申請JSONサンプル

{

"account_name": "dev-manufacturing-management",

"email": "aws-dev-manufacturing@technova.com",

"organizational_unit": "Development",

"tags": {

"Environment": "dev",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "manufacturing-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "dev",

"/dr_enabled": "false",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3",

"/vpc_cidr_tokyo": "10.10.0.0/16",

"/backup_retention_days": "7",

"/backup_schedule": "cron(0 1 ? \* SAT \*)",

"/high_availability": "false",

"/auto_scaling_min": "1",

"/auto_scaling_max": "3"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true,

"terraform_version": "1.5.0",

"static_analyzers": \["tfsec", "tflint", "checkov"\],

"dynamic_analyzers": \["iam_access_analyzer"\],

"enable_dr": false

}

}

## 実用的なFlywayマイグレーションスクリプト例

-- V1\_\_initial_schema.sql - 生産管理マイクロサービスの初期スキーマ

CREATE TABLE production_orders (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

order_number VARCHAR(50) NOT NULL UNIQUE COMMENT '生産指示番号',

product_code VARCHAR(50) NOT NULL COMMENT '製品コード',

quantity INT NOT NULL COMMENT '生産数量',

planned_start_date DATE NOT NULL COMMENT '予定開始日',

planned_end_date DATE NOT NULL COMMENT '予定完了日',

status VARCHAR(20) NOT NULL COMMENT 'ステータス(PLANNED, IN_PROGRESS,
COMPLETED, CANCELLED)',

priority INT NOT NULL DEFAULT 3 COMMENT '優先度(1=高, 2=中, 3=低)',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

created_by VARCHAR(255) COMMENT '作成者',

updated_by VARCHAR(255) COMMENT '更新者',

INDEX idx_order_number (order_number),

INDEX idx_product_code (product_code),

INDEX idx_status (status),

INDEX idx_dates (planned_start_date, planned_end_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE production_materials (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

material_code VARCHAR(50) NOT NULL COMMENT '原材料コード',

required_quantity DECIMAL(10, 2) NOT NULL COMMENT '必要数量',

allocated_quantity DECIMAL(10, 2) DEFAULT 0 COMMENT '引当数量',

unit VARCHAR(10) NOT NULL COMMENT '単位',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_material_code (material_code)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE production_workflow_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

step_name VARCHAR(50) NOT NULL COMMENT '工程名',

step_order INT NOT NULL COMMENT '工程順序',

start_time TIMESTAMP NULL COMMENT '開始時刻',

end_time TIMESTAMP NULL COMMENT '終了時刻',

status VARCHAR(20) NOT NULL COMMENT 'ステータス(PENDING, IN_PROGRESS,
COMPLETED, SKIPPED)',

notes TEXT COMMENT '備考',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE inventory_transactions (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

transaction_type VARCHAR(20) NOT NULL COMMENT
'トランザクションタイプ(ALLOCATION, DEALLOCATION, CONSUMPTION)',

material_code VARCHAR(50) NOT NULL COMMENT '原材料コード',

quantity DECIMAL(10, 2) NOT NULL COMMENT '数量',

unit VARCHAR(10) NOT NULL COMMENT '単位',

production_order_id BIGINT NULL COMMENT '関連生産指示ID',

transaction_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT
'トランザクション時刻',

created_by VARCHAR(255) COMMENT '作成者',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE SET NULL,

INDEX idx_material_code (material_code),

INDEX idx_production_order_id (production_order_id),

INDEX idx_transaction_time (transaction_time)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 監査ログテーブル

CREATE TABLE audit_logs (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

entity_type VARCHAR(50) NOT NULL COMMENT 'エンティティタイプ',

entity_id BIGINT NOT NULL COMMENT 'エンティティID',

action VARCHAR(20) NOT NULL COMMENT 'アクション(CREATE, UPDATE,
DELETE)',

changed_data JSON COMMENT '変更内容',

user_id VARCHAR(255) COMMENT 'ユーザーID',

timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'タイムスタンプ',

INDEX idx_entity (entity_type, entity_id),

INDEX idx_user_id (user_id),

INDEX idx_timestamp (timestamp)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- V2\_\_add_workcenters_and_resources.sql -
生産工程マスターデータの追加

-- 作業区画テーブルの作成

CREATE TABLE work_centers (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

center_code VARCHAR(20) NOT NULL UNIQUE COMMENT '作業区画コード',

center_name VARCHAR(100) NOT NULL COMMENT '作業区画名',

location VARCHAR(50) COMMENT '場所',

capacity INT NOT NULL DEFAULT 1 COMMENT '処理可能同時数',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

INDEX idx_center_code (center_code),

INDEX idx_is_active (is_active)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 作業区画の担当工程テーブルの作成

CREATE TABLE work_center_capabilities (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

process_name VARCHAR(50) NOT NULL COMMENT '工程名',

setup_time INT NOT NULL DEFAULT 0 COMMENT '段取時間(分)',

process_time_per_unit INT NOT NULL COMMENT '1個あたり処理時間(分)',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_process (work_center_id, process_name),

INDEX idx_process_name (process_name)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産指示と作業区画の割り当てテーブルの作成

CREATE TABLE production_work_center_assignments (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '割り当て日時',

assigned_by VARCHAR(255) COMMENT '割り当て者',

status VARCHAR(20) NOT NULL DEFAULT 'ASSIGNED' COMMENT
'ステータス(ASSIGNED, IN_PROGRESS, COMPLETED, CANCELLED)',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_work_center_id (work_center_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 機械設備マスターテーブルの作成

CREATE TABLE equipment (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

equipment_code VARCHAR(20) NOT NULL UNIQUE COMMENT '設備コード',

equipment_name VARCHAR(100) NOT NULL COMMENT '設備名',

equipment_type VARCHAR(50) NOT NULL COMMENT '設備タイプ',

work_center_id BIGINT COMMENT '配置作業区画ID',

status VARCHAR(20) NOT NULL DEFAULT 'OPERATIONAL' COMMENT
'ステータス(OPERATIONAL, MAINTENANCE, BREAKDOWN)',

last_maintenance_date DATE COMMENT '最終メンテナンス日',

next_maintenance_date DATE COMMENT '次回メンテナンス予定日',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE SET
NULL,

INDEX idx_equipment_code (equipment_code),

INDEX idx_work_center_id (work_center_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 設備割り当てテーブルの作成

CREATE TABLE equipment_assignments (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

equipment_id BIGINT NOT NULL COMMENT '設備ID',

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

start_time TIMESTAMP NULL COMMENT '開始時刻',

end_time TIMESTAMP NULL COMMENT '終了時刻',

status VARCHAR(20) NOT NULL DEFAULT 'SCHEDULED' COMMENT
'ステータス(SCHEDULED, IN_USE, COMPLETED, CANCELLED)',

FOREIGN KEY (equipment_id) REFERENCES equipment(id) ON DELETE CASCADE,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

INDEX idx_equipment_id (equipment_id),

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_status (status),

INDEX idx_time_range (start_time, end_time)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 作業区画の作業日カレンダーテーブルの作成

CREATE TABLE work_center_calendar (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

calendar_date DATE NOT NULL COMMENT '日付',

shift_pattern VARCHAR(20) NOT NULL DEFAULT 'REGULAR' COMMENT
'シフトパターン(REGULAR, EXTENDED, HOLIDAY)',

start_time TIME NOT NULL DEFAULT '09:00:00' COMMENT '開始時刻',

end_time TIME NOT NULL DEFAULT '17:00:00' COMMENT '終了時刻',

capacity_adjustment DECIMAL(5, 2) DEFAULT 1.0 COMMENT '能力調整係数',

notes VARCHAR(255) COMMENT '備考',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_date (work_center_id, calendar_date),

INDEX idx_calendar_date (calendar_date),

INDEX idx_shift_pattern (shift_pattern)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 既存の生産ワークフロー工程テーブルにワークセンター参照を追加

ALTER TABLE production_workflow_steps

ADD COLUMN work_center_id BIGINT NULL COMMENT '担当作業区画ID' AFTER
step_order,

ADD CONSTRAINT fk_workflow_step_work_center FOREIGN KEY (work_center_id)
REFERENCES work_centers(id) ON DELETE SET NULL;

-- V3\_\_add_production_plan_tables.sql - 生産計画テーブルの追加

-- 生産計画テーブルの作成

CREATE TABLE production_plans (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

plan_number VARCHAR(50) NOT NULL UNIQUE COMMENT '計画番号',

plan_name VARCHAR(100) NOT NULL COMMENT '計画名',

plan_start_date DATE NOT NULL COMMENT '計画開始日',

plan_end_date DATE NOT NULL COMMENT '計画終了日',

status VARCHAR(20) NOT NULL DEFAULT 'DRAFT' COMMENT 'ステータス(DRAFT,
APPROVED, IN_PROGRESS, COMPLETED, CANCELLED)',

version INT NOT NULL DEFAULT 1 COMMENT 'バージョン',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

created_by VARCHAR(255) COMMENT '作成者',

updated_by VARCHAR(255) COMMENT '更新者',

INDEX idx_plan_number (plan_number),

INDEX idx_date_range (plan_start_date, plan_end_date),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産指示に計画ID参照を追加

ALTER TABLE production_orders

ADD COLUMN production_plan_id BIGINT NULL COMMENT '生産計画ID' AFTER
order_number,

ADD CONSTRAINT fk_order_plan FOREIGN KEY (production_plan_id) REFERENCES
production_plans(id) ON DELETE SET NULL;

-- 生産能力計画テーブルの作成

CREATE TABLE capacity_plans (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

plan_date DATE NOT NULL COMMENT '計画日',

capacity_hours DECIMAL(5, 2) NOT NULL COMMENT '能力時間',

planned_hours DECIMAL(5, 2) DEFAULT 0 COMMENT '計画済時間',

available_hours DECIMAL(5, 2) GENERATED ALWAYS AS (capacity_hours -
planned_hours) STORED COMMENT '利用可能時間',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_date (work_center_id, plan_date),

INDEX idx_plan_date (plan_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産予定表テーブルの作成

CREATE TABLE production_schedules (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

scheduled_start_date DATE NOT NULL COMMENT '予定開始日',

scheduled_end_date DATE NOT NULL COMMENT '予定終了日',

scheduled_start_time TIME COMMENT '予定開始時刻',

scheduled_end_time TIME COMMENT '予定終了時刻',

estimated_hours DECIMAL(5, 2) NOT NULL COMMENT '見積時間',

is_fixed BOOLEAN NOT NULL DEFAULT FALSE COMMENT '固定フラグ',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_work_center_id (work_center_id),

INDEX idx_scheduled_dates (scheduled_start_date, scheduled_end_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品マスターテーブルの作成

CREATE TABLE products (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_code VARCHAR(50) NOT NULL UNIQUE COMMENT '製品コード',

product_name VARCHAR(100) NOT NULL COMMENT '製品名',

product_category VARCHAR(50) COMMENT '製品カテゴリ',

unit VARCHAR(10) NOT NULL DEFAULT 'PCS' COMMENT '単位',

lead_time_days INT NOT NULL DEFAULT 1 COMMENT 'リードタイム(日)',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

INDEX idx_product_code (product_code),

INDEX idx_product_category (product_category),

INDEX idx_is_active (is_active)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品工程テーブルの作成

CREATE TABLE product_routings (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_id BIGINT NOT NULL COMMENT '製品ID',

routing_version VARCHAR(20) NOT NULL DEFAULT '1.0' COMMENT
'工程表バージョン',

is_default BOOLEAN NOT NULL DEFAULT TRUE COMMENT 'デフォルトフラグ',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

effective_from DATE NOT NULL COMMENT '有効開始日',

effective_to DATE COMMENT '有効終了日',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (product_id) REFERENCES products(id) ON DELETE CASCADE,

UNIQUE KEY uk_product_routing_version (product_id, routing_version),

INDEX idx_is_default (is_default),

INDEX idx_is_active (is_active),

INDEX idx_effective_range (effective_from, effective_to)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品工程詳細テーブルの作成

CREATE TABLE product_routing_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_routing_id BIGINT NOT NULL COMMENT '製品工程ID',

step_order INT NOT NULL COMMENT '工程順序',

step_name VARCHAR(50) NOT NULL COMMENT '工程名',

work_center_id BIGINT COMMENT '推奨作業区画ID',

setup_time INT NOT NULL DEFAULT 0 COMMENT '段取時間(分)',

process_time_per_unit INT NOT NULL COMMENT '1個あたり処理時間(分)',

wait_time INT NOT NULL DEFAULT 0 COMMENT '待機時間(分)',

description TEXT COMMENT '工程説明',

FOREIGN KEY (product_routing_id) REFERENCES product_routings(id) ON
DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE SET
NULL,

UNIQUE KEY uk_routing_step_order (product_routing_id, step_order),

INDEX idx_step_name (step_name),

INDEX idx_work_center_id (work_center_id)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品と生産指示の関連付け

ALTER TABLE production_orders

ADD COLUMN product_id BIGINT NULL COMMENT '製品ID' AFTER product_code,

ADD CONSTRAINT fk_order_product FOREIGN KEY (product_id) REFERENCES
products(id) ON DELETE SET NULL;

上記のようなFlywayのマイグレーションスクリプトを実装することで、データベーススキーマの段階的な進化と変更追跡が可能になります。このアプローチによって、TechNova社は環境間で一貫性のあるデータベーススキーマを確保し、安全なデータベース変更を実現できます。

## まとめ

以上の実装例を通じて、TechNova社のオンプレミス基幹システムのAWS移行・マイクロサービス化プロジェクトにおける、主要な追加要件の対応方法を具体的に示しました。

1.  **静的解析ツールの統合（tfsec、TFLint、checkov）**

    - CI/CDパイプラインへの統合により、セキュリティ問題やベストプラクティス違反を早期に検出可能

    - 検出結果のレポート化と手動承認プロセスの組み込みによる問題対応の促進

2.  **動的解析（IAM Access Analyzer）**

    - IAMポリシーの自動分析によるセキュリティリスクの検出

    - 本番環境へのデプロイ前の重要なセキュリティ問題の特定と修正

3.  **CI/CD手動承認プロセス**

    - 重要な変更やエラーが検出された場合の手動承認ワークフロー

    - エラー情報の可視化と決定支援による安全なデプロイ

4.  **環境タグ付けと環境変数管理**

    - 環境（dev/test/staging/prod）に基づく一貫したタグ付け

    - 環境変数を活用したモジュール管理と設定制御

5.  **マルチリージョン対応（東京・大阪）**

    - 両リージョンを並記したプロバイダー設定

    - リージョン固有のリソース設定と環境変数による制御

    - DR（災害対策）環境の条件付き構築（本番環境のみ）

これらの実装は、セキュリティ、品質、可用性を確保しながら、TechNova社の基幹システムを効率的にAWS環境に移行するための重要な基盤となります。特に、静的/動的解析ツールの統合と手動承認プロセスは、安全かつ高品質なインフラ構築を実現し、マルチリージョン対応はビジネス継続性を強化します。
