# 内容

[**AWS AFT
ハンズオン設計書作成プロンプト：TechNova社オンプレミス基幹システムのAWS移行・マイクロサービス化プロジェクト**
[9](#aws-aft-ハンズオン設計書作成プロンプトtechnova社オンプレミス基幹システムのaws移行マイクロサービス化プロジェクト)](#aws-aft-ハンズオン設計書作成プロンプトtechnova社オンプレミス基幹システムのaws移行マイクロサービス化プロジェクト)

[**プロジェクト背景と要件**
[9](#プロジェクト背景と要件)](#プロジェクト背景と要件)

[**プロジェクト状況と課題**
[10](#プロジェクト状況と課題)](#プロジェクト状況と課題)

[**事業部門別アカウント構成**
[13](#事業部門別アカウント構成)](#事業部門別アカウント構成)

[**業務マイクロサービス要件**
[16](#業務マイクロサービス要件)](#業務マイクロサービス要件)

[**インフラ要件** [28](#インフラ要件)](#インフラ要件)

[**セキュリティ要件** [81](#セキュリティ要件)](#セキュリティ要件)

[**主要サービス対応表** [162](#_Toc199105014)](#_Toc199105014)

[**IaC & CI/CD要件** [163](#iac-cicd要件)](#iac-cicd要件)

[**AWSアカウント・権限設計（基本方針）**
[319](#awsアカウント権限設計基本方針)](#awsアカウント権限設計基本方針)

[自動化要件 - TechNova社マルチアカウント環境
[393](#自動化要件---technova社マルチアカウント環境)](#自動化要件---technova社マルチアカウント環境)

[コア設計書：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化プロジェクト」（約525ページ）
[525](#コア設計書technova社オンプレミス基幹システムaws移行マイクロサービス化プロジェクト約525ページ)](#コア設計書technova社オンプレミス基幹システムaws移行マイクロサービス化プロジェクト約525ページ)

[1. プロジェクト全体像と移行戦略
[525](#プロジェクト全体像と移行戦略)](#プロジェクト全体像と移行戦略)

[本章の目的：オンプレミスからAWSへの移行戦略とAFT導入の位置づけを理解する
[525](#本章の目的オンプレミスからawsへの移行戦略とaft導入の位置づけを理解する)](#本章の目的オンプレミスからawsへの移行戦略とaft導入の位置づけを理解する)

[**ハンズオン 1-1**: TechNova社の現状システム分析
[525](#ハンズオン-1-1-technova社の現状システム分析)](#ハンズオン-1-1-technova社の現状システム分析)

[**ハンズオン 1-2**: マイクロサービス化戦略と境界設計
[525](#ハンズオン-1-2-マイクロサービス化戦略と境界設計)](#ハンズオン-1-2-マイクロサービス化戦略と境界設計)

[**ハンズオン 1-3**: AWS移行基本設計のレビューと統合
[525](#ハンズオン-1-3-aws移行基本設計のレビューと統合)](#ハンズオン-1-3-aws移行基本設計のレビューと統合)

[**ハンズオン 1-4**: AFT導入によるアカウント戦略の具体化
[525](#ハンズオン-1-4-aft導入によるアカウント戦略の具体化)](#ハンズオン-1-4-aft導入によるアカウント戦略の具体化)

[**ハンズオン 1-5**: マイクロサービス実装とECS
Fargate/Aurora選定の詳細化
[526](#ハンズオン-1-5-マイクロサービス実装とecs-fargateaurora選定の詳細化)](#ハンズオン-1-5-マイクロサービス実装とecs-fargateaurora選定の詳細化)

[**ハンズオン 1-6**: 移行ロードマップとリリース計画
[526](#ハンズオン-1-6-移行ロードマップとリリース計画)](#ハンズオン-1-6-移行ロードマップとリリース計画)

[アンチパターン：移行戦略で失敗しやすいポイント
[526](#アンチパターン移行戦略で失敗しやすいポイント)](#アンチパターン移行戦略で失敗しやすいポイント)

[2. AWS Control TowerとOU設計（30-35ページ）
[526](#aws-control-towerとou設計30-35ページ)](#aws-control-towerとou設計30-35ページ)

[本章の目的：Control Tower導入とOU構造の設計手法を実践する
[526](#本章の目的control-tower導入とou構造の設計手法を実践する)](#本章の目的control-tower導入とou構造の設計手法を実践する)

[**ハンズオン 2-1**: Control Tower導入と初期設定ワークショップ
[526](#ハンズオン-2-1-control-tower導入と初期設定ワークショップ)](#ハンズオン-2-1-control-tower導入と初期設定ワークショップ)

[**ハンズオン 2-2**: OU構造設計ワークショップ
[526](#ハンズオン-2-2-ou構造設計ワークショップ)](#ハンズオン-2-2-ou構造設計ワークショップ)

[**ハンズオン 2-3**: SCPポリシー設計と実装
[527](#ハンズオン-2-3-scpポリシー設計と実装)](#ハンズオン-2-3-scpポリシー設計と実装)

[**ハンズオン 2-4**: OU構造のTerraform化
[527](#ハンズオン-2-4-ou構造のterraform化)](#ハンズオン-2-4-ou構造のterraform化)

[**ハンズオン 2-5**: アカウント命名規則と分類体系の設計
[527](#ハンズオン-2-5-アカウント命名規則と分類体系の設計)](#ハンズオン-2-5-アカウント命名規則と分類体系の設計)

[**ハンズオン 2-6**: マイクロサービス展開を考慮したアカウント構成
[527](#ハンズオン-2-6-マイクロサービス展開を考慮したアカウント構成)](#ハンズオン-2-6-マイクロサービス展開を考慮したアカウント構成)

[アンチパターン：OU設計で失敗しやすいポイント
[527](#アンチパターンou設計で失敗しやすいポイント)](#アンチパターンou設計で失敗しやすいポイント)

[3. AFT環境構築とアカウント自動化（30-35ページ）
[528](#aft環境構築とアカウント自動化30-35ページ)](#aft環境構築とアカウント自動化30-35ページ)

[本章の目的：AFT導入とアカウント自動化プロセスを構築する
[528](#本章の目的aft導入とアカウント自動化プロセスを構築する)](#本章の目的aft導入とアカウント自動化プロセスを構築する)

[**ハンズオン 3-1**: AFT導入の前提条件と準備作業
[528](#ハンズオン-3-1-aft導入の前提条件と準備作業)](#ハンズオン-3-1-aft導入の前提条件と準備作業)

[**ハンズオン 3-2**: AFT管理アカウントの設計と構築
[528](#ハンズオン-3-2-aft管理アカウントの設計と構築)](#ハンズオン-3-2-aft管理アカウントの設計と構築)

[**ハンズオン 3-3**: AFTパイプラインの設計と実装
[528](#ハンズオン-3-3-aftパイプラインの設計と実装)](#ハンズオン-3-3-aftパイプラインの設計と実装)

[**ハンズオン 3-4**: アカウント申請プロセスの自動化
[528](#ハンズオン-3-4-アカウント申請プロセスの自動化)](#ハンズオン-3-4-アカウント申請プロセスの自動化)

[**ハンズオン 3-5**: AFT検証と初期アカウント作成テスト
[528](#ハンズオン-3-5-aft検証と初期アカウント作成テスト)](#ハンズオン-3-5-aft検証と初期アカウント作成テスト)

[**ハンズオン 3-6**: マイクロサービス向けアカウント構成の自動化
[529](#ハンズオン-3-6-マイクロサービス向けアカウント構成の自動化)](#ハンズオン-3-6-マイクロサービス向けアカウント構成の自動化)

[アンチパターン：AFT導入で失敗しやすいポイント
[529](#アンチパターンaft導入で失敗しやすいポイント)](#アンチパターンaft導入で失敗しやすいポイント)

[4. IAM Identity CenterとPermission Set設計（25-30ページ）
[529](#iam-identity-centerとpermission-set設計25-30ページ)](#iam-identity-centerとpermission-set設計25-30ページ)

[本章の目的：最小権限アクセス管理と自動プロビジョニングを設計・実装する
[529](#本章の目的最小権限アクセス管理と自動プロビジョニングを設計実装する)](#本章の目的最小権限アクセス管理と自動プロビジョニングを設計実装する)

[**ハンズオン 4-1**: Identity Center機能と基本設計
[529](#ハンズオン-4-1-identity-center機能と基本設計)](#ハンズオン-4-1-identity-center機能と基本設計)

[**ハンズオン 4-2**: ユーザー・グループとアカウント構造の設計
[529](#ハンズオン-4-2-ユーザーグループとアカウント構造の設計)](#ハンズオン-4-2-ユーザーグループとアカウント構造の設計)

[**ハンズオン 4-3**: Permission Set設計とTerraform管理
[529](#ハンズオン-4-3-permission-set設計とterraform管理)](#ハンズオン-4-3-permission-set設計とterraform管理)

[**ハンズオン 4-4**: アカウント・OU別アクセス割り当て
[530](#ハンズオン-4-4-アカウントou別アクセス割り当て)](#ハンズオン-4-4-アカウントou別アクセス割り当て)

[**ハンズオン 4-5**: ECS/Auroraサービスロール設計
[530](#ハンズオン-4-5-ecsauroraサービスロール設計)](#ハンズオン-4-5-ecsauroraサービスロール設計)

[**ハンズオン 4-6**: アクセス監査とレビュープロセス
[530](#ハンズオン-4-6-アクセス監査とレビュープロセス)](#ハンズオン-4-6-アクセス監査とレビュープロセス)

[アンチパターン：IAM設計で失敗しやすいポイント
[530](#アンチパターンiam設計で失敗しやすいポイント)](#アンチパターンiam設計で失敗しやすいポイント)

[**ハンズオン 5-1**: 機能別VPC設計
[530](#ハンズオン-5-1-機能別vpc設計)](#ハンズオン-5-1-機能別vpc設計)

[**ハンズオン 5-2**: VPC間接続とTransit Gateway設計
[531](#ハンズオン-5-2-vpc間接続とtransit-gateway設計)](#ハンズオン-5-2-vpc間接続とtransit-gateway設計)

[**ハンズオン 5-3**: DirectConnect設計と実装
[531](#ハンズオン-5-3-directconnect設計と実装)](#ハンズオン-5-3-directconnect設計と実装)

[**ハンズオン 5-4**: Site-to-Site VPNバックアップ回線設計
[531](#ハンズオン-5-4-site-to-site-vpnバックアップ回線設計)](#ハンズオン-5-4-site-to-site-vpnバックアップ回線設計)

[**ハンズオン 5-5**: オンプレミス-AWS間通信設計
[531](#ハンズオン-5-5-オンプレミス-aws間通信設計)](#ハンズオン-5-5-オンプレミス-aws間通信設計)

[**ハンズオン 5-6**: マイクロサービス間ネットワーク設計
[531](#ハンズオン-5-6-マイクロサービス間ネットワーク設計)](#ハンズオン-5-6-マイクロサービス間ネットワーク設計)

[アンチパターン：ネットワーク設計で失敗しやすいポイント
[532](#アンチパターンネットワーク設計で失敗しやすいポイント)](#アンチパターンネットワーク設計で失敗しやすいポイント)

[6. 包括的セキュリティ設計と統合ガバナンス（35-40ページ）
[532](#包括的セキュリティ設計と統合ガバナンス35-40ページ)](#包括的セキュリティ設計と統合ガバナンス35-40ページ)

[本章の目的：多層防御のセキュリティアーキテクチャを設計・実装する
[532](#本章の目的多層防御のセキュリティアーキテクチャを設計実装する)](#本章の目的多層防御のセキュリティアーキテクチャを設計実装する)

[**ハンズオン 6-1**: Security Hub統合基盤の設計
[532](#ハンズオン-6-1-security-hub統合基盤の設計)](#ハンズオン-6-1-security-hub統合基盤の設計)

[**ハンズオン 6-2**: WAF + Shield Standardの実装設計
[532](#ハンズオン-6-2-waf-shield-standardの実装設計)](#ハンズオン-6-2-waf-shield-standardの実装設計)

[**ハンズオン 6-3**: Firewall Managerとポリシー設計
[532](#ハンズオン-6-3-firewall-managerとポリシー設計)](#ハンズオン-6-3-firewall-managerとポリシー設計)

[**ハンズオン 6-4**: Network Firewall実装と統合
[532](#ハンズオン-6-4-network-firewall実装と統合)](#ハンズオン-6-4-network-firewall実装と統合)

[**ハンズオン 6-5**: コンテナとマイクロサービスのセキュリティ
[533](#ハンズオン-6-5-コンテナとマイクロサービスのセキュリティ)](#ハンズオン-6-5-コンテナとマイクロサービスのセキュリティ)

[**ハンズオン 6-6**: クロスアカウントセキュリティ監視
[533](#ハンズオン-6-6-クロスアカウントセキュリティ監視)](#ハンズオン-6-6-クロスアカウントセキュリティ監視)

[**ハンズオン 6-7**: データ保護と暗号化戦略
[533](#ハンズオン-6-7-データ保護と暗号化戦略)](#ハンズオン-6-7-データ保護と暗号化戦略)

[アンチパターン：セキュリティ設計で失敗しやすいポイント
[533](#アンチパターンセキュリティ設計で失敗しやすいポイント)](#アンチパターンセキュリティ設計で失敗しやすいポイント)

[7. ECS FargateとECR設計（25-30ページ）
[533](#ecs-fargateとecr設計25-30ページ)](#ecs-fargateとecr設計25-30ページ)

[本章の目的：マイクロサービスのコンテナ実行基盤の設計・実装を行う
[533](#本章の目的マイクロサービスのコンテナ実行基盤の設計実装を行う)](#本章の目的マイクロサービスのコンテナ実行基盤の設計実装を行う)

[**ハンズオン 7-1**: マイクロサービスコンテナ化戦略
[533](#ハンズオン-7-1-マイクロサービスコンテナ化戦略)](#ハンズオン-7-1-マイクロサービスコンテナ化戦略)

[**ハンズオン 7-2**: ECRレポジトリ設計とライフサイクル管理
[534](#ハンズオン-7-2-ecrレポジトリ設計とライフサイクル管理)](#ハンズオン-7-2-ecrレポジトリ設計とライフサイクル管理)

[**ハンズオン 7-3**: ECS Fargateクラスタ設計
[534](#ハンズオン-7-3-ecs-fargateクラスタ設計)](#ハンズオン-7-3-ecs-fargateクラスタ設計)

[**ハンズオン 7-4**: コンテナログとモニタリング
[534](#ハンズオン-7-4-コンテナログとモニタリング)](#ハンズオン-7-4-コンテナログとモニタリング)

[**ハンズオン 7-5**: コンテナセキュリティの設計
[534](#ハンズオン-7-5-コンテナセキュリティの設計)](#ハンズオン-7-5-コンテナセキュリティの設計)

[**ハンズオン 7-6**: 環境間のコンテナイメージ管理戦略
[534](#ハンズオン-7-6-環境間のコンテナイメージ管理戦略)](#ハンズオン-7-6-環境間のコンテナイメージ管理戦略)

[**ハンズオン 7-7**: マルチリージョン対応（東京・大阪）
[535](#ハンズオン-7-7-マルチリージョン対応東京大阪)](#ハンズオン-7-7-マルチリージョン対応東京大阪)

[アンチパターン：ECS Fargate設計で失敗しやすいポイント
[535](#アンチパターンecs-fargate設計で失敗しやすいポイント)](#アンチパターンecs-fargate設計で失敗しやすいポイント)

[8. Aurora/Flywayデータベース設計（25-30ページ）
[535](#auroraflywayデータベース設計25-30ページ)](#auroraflywayデータベース設計25-30ページ)

[本章の目的：マイクロサービス向けデータベース基盤と自動マイグレーションの設計・実装を行う
[535](#本章の目的マイクロサービス向けデータベース基盤と自動マイグレーションの設計実装を行う)](#本章の目的マイクロサービス向けデータベース基盤と自動マイグレーションの設計実装を行う)

[**ハンズオン 8-1**: マイクロサービスのデータ分離戦略
[535](#ハンズオン-8-1-マイクロサービスのデータ分離戦略)](#ハンズオン-8-1-マイクロサービスのデータ分離戦略)

[**ハンズオン 8-2**: Aurora設計と構成
[535](#ハンズオン-8-2-aurora設計と構成)](#ハンズオン-8-2-aurora設計と構成)

[**ハンズオン 8-3**: IAMデータベース認証の実装
[536](#ハンズオン-8-3-iamデータベース認証の実装)](#ハンズオン-8-3-iamデータベース認証の実装)

[**ハンズオン 8-4**: Flywayによるスキーママイグレーション
[536](#ハンズオン-8-4-flywayによるスキーママイグレーション)](#ハンズオン-8-4-flywayによるスキーママイグレーション)

[**ハンズオン 8-5**: オンプレミスからのデータ移行
[536](#ハンズオン-8-5-オンプレミスからのデータ移行)](#ハンズオン-8-5-オンプレミスからのデータ移行)

[**ハンズオン 8-6**: マイクロサービス間のデータ連携
[536](#ハンズオン-8-6-マイクロサービス間のデータ連携)](#ハンズオン-8-6-マイクロサービス間のデータ連携)

[**ハンズオン 8-7**: マルチリージョンデータ戦略
[536](#ハンズオン-8-7-マルチリージョンデータ戦略)](#ハンズオン-8-7-マルチリージョンデータ戦略)

[アンチパターン：データベース設計で失敗しやすいポイント
[536](#アンチパターンデータベース設計で失敗しやすいポイント)](#アンチパターンデータベース設計で失敗しやすいポイント)

[9. API GatewayとCognito認証基盤（25-30ページ）
[537](#api-gatewayとcognito認証基盤25-30ページ)](#api-gatewayとcognito認証基盤25-30ページ)

[本章の目的：マイクロサービスAPI層と認証基盤の設計・実装を行う
[537](#本章の目的マイクロサービスapi層と認証基盤の設計実装を行う)](#本章の目的マイクロサービスapi層と認証基盤の設計実装を行う)

[**ハンズオン 9-1**: マイクロサービスAPIアーキテクチャ設計
[537](#ハンズオン-9-1-マイクロサービスapiアーキテクチャ設計)](#ハンズオン-9-1-マイクロサービスapiアーキテクチャ設計)

[**ハンズオン 9-2**: API Gateway設計とBFFパターンの実装
[537](#ハンズオン-9-2-api-gateway設計とbffパターンの実装)](#ハンズオン-9-2-api-gateway設計とbffパターンの実装)

[**ハンズオン 9-3**: Cognito認証基盤の設計
[537](#ハンズオン-9-3-cognito認証基盤の設計)](#ハンズオン-9-3-cognito認証基盤の設計)

[**ハンズオン 9-4**: API認証と権限管理
[537](#ハンズオン-9-4-api認証と権限管理)](#ハンズオン-9-4-api認証と権限管理)

[**ハンズオン 9-5**: スロットリングと流量制御
[538](#ハンズオン-9-5-スロットリングと流量制御)](#ハンズオン-9-5-スロットリングと流量制御)

[**ハンズオン 9-6**: クロスアカウントAPI連携
[538](#ハンズオン-9-6-クロスアカウントapi連携)](#ハンズオン-9-6-クロスアカウントapi連携)

[**ハンズオン 9-7**: マルチリージョンAPI戦略
[538](#ハンズオン-9-7-マルチリージョンapi戦略)](#ハンズオン-9-7-マルチリージョンapi戦略)

[アンチパターン：API設計で失敗しやすいポイント
[538](#アンチパターンapi設計で失敗しやすいポイント)](#アンチパターンapi設計で失敗しやすいポイント)

[10. Step Functions/Lambdaによるバッチ処理自動化（25-30ページ）
[539](#step-functionslambdaによるバッチ処理自動化25-30ページ)](#step-functionslambdaによるバッチ処理自動化25-30ページ)

[本章の目的：マイクロサービス間連携とバッチ処理の自動化を設計・実装する
[539](#本章の目的マイクロサービス間連携とバッチ処理の自動化を設計実装する)](#本章の目的マイクロサービス間連携とバッチ処理の自動化を設計実装する)

[**ハンズオン 10-1**: マイクロサービスのビジネスプロセス分析
[539](#ハンズオン-10-1-マイクロサービスのビジネスプロセス分析)](#ハンズオン-10-1-マイクロサービスのビジネスプロセス分析)

[**ハンズオン 10-2**: Step Functions ワークフロー設計
[539](#ハンズオン-10-2-step-functions-ワークフロー設計)](#ハンズオン-10-2-step-functions-ワークフロー設計)

[**ハンズオン 10-3**: Lambda関数の設計と実装
[539](#ハンズオン-10-3-lambda関数の設計と実装)](#ハンズオン-10-3-lambda関数の設計と実装)

[**ハンズオン 10-4**: データ処理パイプラインの実装
[539](#ハンズオン-10-4-データ処理パイプラインの実装)](#ハンズオン-10-4-データ処理パイプラインの実装)

[**ハンズオン 10-5**: バッチスケジューリングと運用管理
[539](#ハンズオン-10-5-バッチスケジューリングと運用管理)](#ハンズオン-10-5-バッチスケジューリングと運用管理)

[**ハンズオン 10-6**: クロスアカウントバッチ処理
[540](#ハンズオン-10-6-クロスアカウントバッチ処理)](#ハンズオン-10-6-クロスアカウントバッチ処理)

[**ハンズオン 10-7**: マルチリージョンワークフロー対応
[540](#ハンズオン-10-7-マルチリージョンワークフロー対応)](#ハンズオン-10-7-マルチリージョンワークフロー対応)

[アンチパターン：サーバーレスバッチ処理で失敗しやすいポイント
[540](#アンチパターンサーバーレスバッチ処理で失敗しやすいポイント)](#アンチパターンサーバーレスバッチ処理で失敗しやすいポイント)

[11. Terraform IaC設計と環境変数管理（25-30ページ）
[540](#terraform-iac設計と環境変数管理25-30ページ)](#terraform-iac設計と環境変数管理25-30ページ)

[本章の目的：マルチリージョン対応のIaC設計と環境変数管理の導入
[540](#本章の目的マルチリージョン対応のiac設計と環境変数管理の導入)](#本章の目的マルチリージョン対応のiac設計と環境変数管理の導入)

[**ハンズオン 11-1**: Terraformプロジェクト構造設計
[540](#ハンズオン-11-1-terraformプロジェクト構造設計)](#ハンズオン-11-1-terraformプロジェクト構造設計)

[**ハンズオン 11-2**: 環境変数によるモジュール管理
[541](#ハンズオン-11-2-環境変数によるモジュール管理)](#ハンズオン-11-2-環境変数によるモジュール管理)

[**ハンズオン 11-3**: マルチリージョン対応IaC設計
[541](#ハンズオン-11-3-マルチリージョン対応iac設計)](#ハンズオン-11-3-マルチリージョン対応iac設計)

[**ハンズオン 11-4**: 環境タグ付け戦略
[541](#ハンズオン-11-4-環境タグ付け戦略)](#ハンズオン-11-4-環境タグ付け戦略)

[**ハンズオン 11-5**: Terraformステート管理戦略
[541](#ハンズオン-11-5-terraformステート管理戦略)](#ハンズオン-11-5-terraformステート管理戦略)

[**ハンズオン 11-6**: Terraformコード品質管理
[541](#ハンズオン-11-6-terraformコード品質管理)](#ハンズオン-11-6-terraformコード品質管理)

[**ハンズオン 11-7**: 秘密情報と変数管理
[541](#ハンズオン-11-7-秘密情報と変数管理)](#ハンズオン-11-7-秘密情報と変数管理)

[アンチパターン：Terraform設計で失敗しやすいポイント
[542](#アンチパターンterraform設計で失敗しやすいポイント)](#アンチパターンterraform設計で失敗しやすいポイント)

[12. CI/CDパイプラインとコード品質管理（30-35ページ）
[542](#cicdパイプラインとコード品質管理30-35ページ)](#cicdパイプラインとコード品質管理30-35ページ)

[本章の目的：高品質なIaCとアプリケーションのCI/CDパイプラインを設計・実装する
[542](#本章の目的高品質なiacとアプリケーションのcicdパイプラインを設計実装する)](#本章の目的高品質なiacとアプリケーションのcicdパイプラインを設計実装する)

[**ハンズオン 12-1**: CI/CD戦略とツール選定
[542](#ハンズオン-12-1-cicd戦略とツール選定)](#ハンズオン-12-1-cicd戦略とツール選定)

[**ハンズオン 12-2**: IaC向け静的解析パイプライン実装
[542](#ハンズオン-12-2-iac向け静的解析パイプライン実装)](#ハンズオン-12-2-iac向け静的解析パイプライン実装)

[**ハンズオン 12-3**: IaC向け動的解析の実装
[542](#ハンズオン-12-3-iac向け動的解析の実装)](#ハンズオン-12-3-iac向け動的解析の実装)

[**ハンズオン 12-4**: 手動承認プロセスの組み込み
[543](#ハンズオン-12-4-手動承認プロセスの組み込み)](#ハンズオン-12-4-手動承認プロセスの組み込み)

[**ハンズオン 12-5**: マイクロサービスビルドパイプライン
[543](#ハンズオン-12-5-マイクロサービスビルドパイプライン)](#ハンズオン-12-5-マイクロサービスビルドパイプライン)

[**ハンズオン 12-6**: コンテナイメージビルドとECR連携
[543](#ハンズオン-12-6-コンテナイメージビルドとecr連携)](#ハンズオン-12-6-コンテナイメージビルドとecr連携)

[**ハンズオン 12-7**: ECS Fargateデプロイパイプライン
[543](#ハンズオン-12-7-ecs-fargateデプロイパイプライン)](#ハンズオン-12-7-ecs-fargateデプロイパイプライン)

[**ハンズオン 12-8**: データベースマイグレーション自動化
[543](#ハンズオン-12-8-データベースマイグレーション自動化)](#ハンズオン-12-8-データベースマイグレーション自動化)

[**ハンズオン 12-9**: 環境間のプロモーションフロー
[543](#ハンズオン-12-9-環境間のプロモーションフロー)](#ハンズオン-12-9-環境間のプロモーションフロー)

[アンチパターン：CI/CD設計で失敗しやすいポイント
[544](#アンチパターンcicd設計で失敗しやすいポイント)](#アンチパターンcicd設計で失敗しやすいポイント)

[13. DR戦略と東京-大阪間レプリケーション（20-25ページ）
[544](#dr戦略と東京-大阪間レプリケーション20-25ページ)](#dr戦略と東京-大阪間レプリケーション20-25ページ)

[本章の目的：本番環境のDR戦略と大阪リージョンへのレプリケーションを設計・実装する
[544](#本章の目的本番環境のdr戦略と大阪リージョンへのレプリケーションを設計実装する)](#本章の目的本番環境のdr戦略と大阪リージョンへのレプリケーションを設計実装する)

[**ハンズオン 13-1**: DR要件とRTO/RPO設計
[544](#ハンズオン-13-1-dr要件とrtorpo設計)](#ハンズオン-13-1-dr要件とrtorpo設計)

[**ハンズオン 13-2**: Aurora Global Databaseの設計と実装
[544](#ハンズオン-13-2-aurora-global-databaseの設計と実装)](#ハンズオン-13-2-aurora-global-databaseの設計と実装)

[**ハンズオン 13-3**: ECS/ECRのクロスリージョン設計
[544](#ハンズオン-13-3-ecsecrのクロスリージョン設計)](#ハンズオン-13-3-ecsecrのクロスリージョン設計)

[**ハンズオン 13-4**: APIとCognitoのDR戦略
[545](#ハンズオン-13-4-apiとcognitoのdr戦略)](#ハンズオン-13-4-apiとcognitoのdr戦略)

[**ハンズオン 13-5**: フェイルオーバー自動化とテスト
[545](#ハンズオン-13-5-フェイルオーバー自動化とテスト)](#ハンズオン-13-5-フェイルオーバー自動化とテスト)

[アンチパターン：DR設計で失敗しやすいポイント
[545](#アンチパターンdr設計で失敗しやすいポイント)](#アンチパターンdr設計で失敗しやすいポイント)

[14. 監視・運用基盤の設計（20-25ページ）
[545](#監視運用基盤の設計20-25ページ)](#監視運用基盤の設計20-25ページ)

[本章の目的：マイクロサービス環境の統合監視と運用自動化を設計・実装する
[545](#本章の目的マイクロサービス環境の統合監視と運用自動化を設計実装する)](#本章の目的マイクロサービス環境の統合監視と運用自動化を設計実装する)

[**ハンズオン 14-1**: マイクロサービスの可観測性設計
[545](#ハンズオン-14-1-マイクロサービスの可観測性設計)](#ハンズオン-14-1-マイクロサービスの可観測性設計)

[**ハンズオン 14-2**: 統合監視ダッシュボード構築
[546](#ハンズオン-14-2-統合監視ダッシュボード構築)](#ハンズオン-14-2-統合監視ダッシュボード構築)

[**ハンズオン 14-3**: 分散トレーシングの実装
[546](#ハンズオン-14-3-分散トレーシングの実装)](#ハンズオン-14-3-分散トレーシングの実装)

[**ハンズオン 14-4**: アラート通知フロー実装
[546](#ハンズオン-14-4-アラート通知フロー実装)](#ハンズオン-14-4-アラート通知フロー実装)

[**ハンズオン 14-5**: 運用自動化スクリプト実装
[546](#ハンズオン-14-5-運用自動化スクリプト実装)](#ハンズオン-14-5-運用自動化スクリプト実装)

[**ハンズオン 14-6**: コスト監視と最適化
[546](#ハンズオン-14-6-コスト監視と最適化)](#ハンズオン-14-6-コスト監視と最適化)

[アンチパターン：監視・運用設計で失敗しやすいポイント
[546](#アンチパターン監視運用設計で失敗しやすいポイント)](#アンチパターン監視運用設計で失敗しやすいポイント)

[15. 移行実行計画と組織的導入（20-25ページ）
[547](#移行実行計画と組織的導入20-25ページ)](#移行実行計画と組織的導入20-25ページ)

[本章の目的：オンプレミスからの段階的移行と組織的な導入プロセスを設計する
[547](#本章の目的オンプレミスからの段階的移行と組織的な導入プロセスを設計する)](#本章の目的オンプレミスからの段階的移行と組織的な導入プロセスを設計する)

[**ハンズオン 15-1**: 移行フェーズと優先順位付け
[547](#ハンズオン-15-1-移行フェーズと優先順位付け)](#ハンズオン-15-1-移行フェーズと優先順位付け)

[**ハンズオン 15-2**: 並行運用と切り替え戦略
[547](#ハンズオン-15-2-並行運用と切り替え戦略)](#ハンズオン-15-2-並行運用と切り替え戦略)

[**ハンズオン 15-3**: ステークホルダーマップと組織変革計画
[547](#ハンズオン-15-3-ステークホルダーマップと組織変革計画)](#ハンズオン-15-3-ステークホルダーマップと組織変革計画)

[**ハンズオン 15-4**: トレーニングと技術移転計画
[547](#ハンズオン-15-4-トレーニングと技術移転計画)](#ハンズオン-15-4-トレーニングと技術移転計画)

[**ハンズオン 15-5**: 内部ドキュメント作成戦略
[548](#ハンズオン-15-5-内部ドキュメント作成戦略)](#ハンズオン-15-5-内部ドキュメント作成戦略)

[**ハンズオン 15-6**: AFTユーザーコミュニティ構築
[548](#ハンズオン-15-6-aftユーザーコミュニティ構築)](#ハンズオン-15-6-aftユーザーコミュニティ構築)

[アンチパターン：移行実行と組織的導入で失敗しやすいポイント
[548](#アンチパターン移行実行と組織的導入で失敗しやすいポイント)](#アンチパターン移行実行と組織的導入で失敗しやすいポイント)

[技術実装ガイド：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化実装ハンドブック」（約325ページ）
[548](#技術実装ガイドtechnova社オンプレミス基幹システムaws移行マイクロサービス化実装ハンドブック約325ページ)](#技術実装ガイドtechnova社オンプレミス基幹システムaws移行マイクロサービス化実装ハンドブック約325ページ)

[16. AFT環境構築実践ガイド（30-35ページ）
[548](#aft環境構築実践ガイド30-35ページ)](#aft環境構築実践ガイド30-35ページ)

[本章の目的：AFT環境の実際の構築とControl Tower連携を実装する
[548](#本章の目的aft環境の実際の構築とcontrol-tower連携を実装する)](#本章の目的aft環境の実際の構築とcontrol-tower連携を実装する)

[**実践ハンズオン 16-1**: Control Tower・Organizations設定の実践
[548](#実践ハンズオン-16-1-control-towerorganizations設定の実践)](#実践ハンズオン-16-1-control-towerorganizations設定の実践)

[**実践ハンズオン 16-2**: AFT管理アカウントの構築
[549](#実践ハンズオン-16-2-aft管理アカウントの構築)](#実践ハンズオン-16-2-aft管理アカウントの構築)

[**実践ハンズオン 16-3**: GitLab環境の構築とAFT連携
[549](#実践ハンズオン-16-3-gitlab環境の構築とaft連携)](#実践ハンズオン-16-3-gitlab環境の構築とaft連携)

[**実践ハンズオン 16-4**: AFTパイプラインの構築と設定
[549](#実践ハンズオン-16-4-aftパイプラインの構築と設定)](#実践ハンズオン-16-4-aftパイプラインの構築と設定)

[**実践ハンズオン 16-5**: 静的解析ツールの統合設定
[549](#実践ハンズオン-16-5-静的解析ツールの統合設定)](#実践ハンズオン-16-5-静的解析ツールの統合設定)

[**実践ハンズオン 16-6**: IAM Access Analyzerの設定
[549](#実践ハンズオン-16-6-iam-access-analyzerの設定)](#実践ハンズオン-16-6-iam-access-analyzerの設定)

[**実践ハンズオン 16-7**: 手動承認ステージの実装
[550](#実践ハンズオン-16-7-手動承認ステージの実装)](#実践ハンズオン-16-7-手動承認ステージの実装)

[実践ハンズオン 16-8: AFT機能検証
[550](#実践ハンズオン-16-8-aft機能検証)](#実践ハンズオン-16-8-aft機能検証)

[**実践ハンズオン 16-9**: マイクロサービスアカウントテンプレート構築
[550](#実践ハンズオン-16-9-マイクロサービスアカウントテンプレート構築)](#実践ハンズオン-16-9-マイクロサービスアカウントテンプレート構築)

[アンチパターン：AFT環境構築で失敗しやすいポイント
[550](#アンチパターンaft環境構築で失敗しやすいポイント)](#アンチパターンaft環境構築で失敗しやすいポイント)

[17. IAM Identity CenterとPermission Set実装（25-30ページ）
[550](#iam-identity-centerとpermission-set実装25-30ページ)](#iam-identity-centerとpermission-set実装25-30ページ)

[本章の目的：IAMユーザーに依存しないアクセス管理基盤を実装する
[550](#本章の目的iamユーザーに依存しないアクセス管理基盤を実装する)](#本章の目的iamユーザーに依存しないアクセス管理基盤を実装する)

[**実践ハンズオン 17-1**: Identity Center初期設定
[550](#実践ハンズオン-17-1-identity-center初期設定)](#実践ハンズオン-17-1-identity-center初期設定)

[**実践ハンズオン 17-2**: 権限設計とPermission Set構築
[551](#実践ハンズオン-17-2-権限設計とpermission-set構築)](#実践ハンズオン-17-2-権限設計とpermission-set構築)

[**実践ハンズオン 17-3**: アカウント割り当ての自動化
[551](#実践ハンズオン-17-3-アカウント割り当ての自動化)](#実践ハンズオン-17-3-アカウント割り当ての自動化)

[**実践ハンズオン 17-4**: ECS/Aurora用のIAMロール実装
[551](#実践ハンズオン-17-4-ecsaurora用のiamロール実装)](#実践ハンズオン-17-4-ecsaurora用のiamロール実装)

[**実践ハンズオン 17-5**: 緊急アクセス手順の実装
[551](#実践ハンズオン-17-5-緊急アクセス手順の実装)](#実践ハンズオン-17-5-緊急アクセス手順の実装)

[**実践ハンズオン 17-6**: アクセス監査とレビュー自動化
[551](#実践ハンズオン-17-6-アクセス監査とレビュー自動化)](#実践ハンズオン-17-6-アクセス監査とレビュー自動化)

[アンチパターン：Identity Center実装で失敗しやすいポイント
[552](#アンチパターンidentity-center実装で失敗しやすいポイント)](#アンチパターンidentity-center実装で失敗しやすいポイント)

[18. ネットワークインフラ実装（30-35ページ）
[552](#ネットワークインフラ実装30-35ページ)](#ネットワークインフラ実装30-35ページ)

[本章の目的：セキュアで高可用性のネットワークインフラを実装する
[552](#本章の目的セキュアで高可用性のネットワークインフラを実装する)](#本章の目的セキュアで高可用性のネットワークインフラを実装する)

[実践ハンズオン 18-1: 機能別VPC実装
[552](#実践ハンズオン-18-1-機能別vpc実装)](#実践ハンズオン-18-1-機能別vpc実装)

[**実践ハンズオン 18-2**: マルチリージョンVPC設定
[552](#実践ハンズオン-18-2-マルチリージョンvpc設定)](#実践ハンズオン-18-2-マルチリージョンvpc設定)

[**実践ハンズオン 18-3**: Transit Gateway実装
[552](#実践ハンズオン-18-3-transit-gateway実装)](#実践ハンズオン-18-3-transit-gateway実装)

[**実践ハンズオン 18-4**: DirectConnect設定実装
[552](#実践ハンズオン-18-4-directconnect設定実装)](#実践ハンズオン-18-4-directconnect設定実装)

[**実践ハンズオン 18-5**: S2S VPNバックアップ実装
[553](#実践ハンズオン-18-5-s2s-vpnバックアップ実装)](#実践ハンズオン-18-5-s2s-vpnバックアップ実装)

[**実践ハンズオン 18-6**: Network Firewall実装
[553](#実践ハンズオン-18-6-network-firewall実装)](#実践ハンズオン-18-6-network-firewall実装)

[**実践ハンズオン 18-7**: マイクロサービス通信パターン実装
[553](#実践ハンズオン-18-7-マイクロサービス通信パターン実装)](#実践ハンズオン-18-7-マイクロサービス通信パターン実装)

[アンチパターン：ネットワーク実装で失敗しやすいポイント
[553](#アンチパターンネットワーク実装で失敗しやすいポイント)](#アンチパターンネットワーク実装で失敗しやすいポイント)

[19. WAF/Shield/Firewall Manager実装（25-30ページ）
[554](#wafshieldfirewall-manager実装25-30ページ)](#wafshieldfirewall-manager実装25-30ページ)

[本章の目的：多層防御のセキュリティ境界を実装する
[554](#本章の目的多層防御のセキュリティ境界を実装する)](#本章の目的多層防御のセキュリティ境界を実装する)

[**実践ハンズオン 19-1**: WAF Web ACL設計と実装
[554](#実践ハンズオン-19-1-waf-web-acl設計と実装)](#実践ハンズオン-19-1-waf-web-acl設計と実装)

[**実践ハンズオン 19-2**: WAFとAPI Gateway/ALB/CloudFrontの連携
[554](#実践ハンズオン-19-2-wafとapi-gatewayalbcloudfrontの連携)](#実践ハンズオン-19-2-wafとapi-gatewayalbcloudfrontの連携)

[**実践ハンズオン 19-3**: Shield Standard設定
[554](#実践ハンズオン-19-3-shield-standard設定)](#実践ハンズオン-19-3-shield-standard設定)

[**実践ハンズオン 19-4**: Firewall Managerポリシー実装
[554](#実践ハンズオン-19-4-firewall-managerポリシー実装)](#実践ハンズオン-19-4-firewall-managerポリシー実装)

[**実践ハンズオン 19-5**: Network Firewall高度設定
[554](#実践ハンズオン-19-5-network-firewall高度設定)](#実践ハンズオン-19-5-network-firewall高度設定)

[**実践ハンズオン 19-6**: セキュリティ自動復旧設計
[555](#実践ハンズオン-19-6-セキュリティ自動復旧設計)](#実践ハンズオン-19-6-セキュリティ自動復旧設計)

[アンチパターン：セキュリティ境界実装で失敗しやすいポイント
[555](#アンチパターンセキュリティ境界実装で失敗しやすいポイント)](#アンチパターンセキュリティ境界実装で失敗しやすいポイント)

[20. ECS Fargate/ECRマイクロサービス実装（30-35ページ）
[555](#ecs-fargateecrマイクロサービス実装30-35ページ)](#ecs-fargateecrマイクロサービス実装30-35ページ)

[本章の目的：マイクロサービスのコンテナ実行基盤を実装する
[555](#本章の目的マイクロサービスのコンテナ実行基盤を実装する)](#本章の目的マイクロサービスのコンテナ実行基盤を実装する)

[**実践ハンズオン 20-1**: マイクロサービスのコンテナ化
[555](#実践ハンズオン-20-1-マイクロサービスのコンテナ化)](#実践ハンズオン-20-1-マイクロサービスのコンテナ化)

[**実践ハンズオン 20-2**: ECRリポジトリ構築
[555](#実践ハンズオン-20-2-ecrリポジトリ構築)](#実践ハンズオン-20-2-ecrリポジトリ構築)

[**実践ハンズオン 20-3**: ECRセキュリティ自動化
[555](#実践ハンズオン-20-3-ecrセキュリティ自動化)](#実践ハンズオン-20-3-ecrセキュリティ自動化)

[**実践ハンズオン 20-4**: ECS Fargateクラスター実装
[556](#実践ハンズオン-20-4-ecs-fargateクラスター実装)](#実践ハンズオン-20-4-ecs-fargateクラスター実装)

[**実践ハンズオン 20-5**: サービスメッシュとサービスディスカバリ
[556](#実践ハンズオン-20-5-サービスメッシュとサービスディスカバリ)](#実践ハンズオン-20-5-サービスメッシュとサービスディスカバリ)

[**実践ハンズオン 20-6**: コンテナログとモニタリング
[556](#実践ハンズオン-20-6-コンテナログとモニタリング)](#実践ハンズオン-20-6-コンテナログとモニタリング)

[**実践ハンズオン 20-7**: マイクロサービス間の安全な通信
[556](#実践ハンズオン-20-7-マイクロサービス間の安全な通信)](#実践ハンズオン-20-7-マイクロサービス間の安全な通信)

[**実践ハンズオン 20-8**: 環境タグ付けとイメージプロモーション
[556](#実践ハンズオン-20-8-環境タグ付けとイメージプロモーション)](#実践ハンズオン-20-8-環境タグ付けとイメージプロモーション)

[アンチパターン：ECS Fargate/ECR実装で失敗しやすいポイント
[557](#アンチパターンecs-fargateecr実装で失敗しやすいポイント)](#アンチパターンecs-fargateecr実装で失敗しやすいポイント)

[21. Aurora/Flywayデータベース実装（25-30ページ）
[557](#auroraflywayデータベース実装25-30ページ)](#auroraflywayデータベース実装25-30ページ)

[本章の目的：マイクロサービス向けデータベース基盤を実装する
[557](#本章の目的マイクロサービス向けデータベース基盤を実装する)](#本章の目的マイクロサービス向けデータベース基盤を実装する)

[**実践ハンズオン 21-1**: Auroraクラスター実装
[557](#実践ハンズオン-21-1-auroraクラスター実装)](#実践ハンズオン-21-1-auroraクラスター実装)

[**実践ハンズオン 21-2**: リージョン間のAurora設定
[557](#実践ハンズオン-21-2-リージョン間のaurora設定)](#実践ハンズオン-21-2-リージョン間のaurora設定)

[**実践ハンズオン 21-3**: IAMデータベース認証実装
[557](#実践ハンズオン-21-3-iamデータベース認証実装)](#実践ハンズオン-21-3-iamデータベース認証実装)

[**実践ハンズオン 21-4**: Flywayマイグレーション環境構築
[557](#実践ハンズオン-21-4-flywayマイグレーション環境構築)](#実践ハンズオン-21-4-flywayマイグレーション環境構築)

[**実践ハンズオン 21-5**: オンプレミスからのデータ移行
[558](#実践ハンズオン-21-5-オンプレミスからのデータ移行)](#実践ハンズオン-21-5-オンプレミスからのデータ移行)

[**実践ハンズオン 21-6**: マイクロサービス別スキーマ設計
[558](#実践ハンズオン-21-6-マイクロサービス別スキーマ設計)](#実践ハンズオン-21-6-マイクロサービス別スキーマ設計)

[**実践ハンズオン 21-7**: データベースパフォーマンスチューニング
[558](#実践ハンズオン-21-7-データベースパフォーマンスチューニング)](#実践ハンズオン-21-7-データベースパフォーマンスチューニング)

[アンチパターン：Aurora/Flyway実装で失敗しやすいポイント
[558](#アンチパターンauroraflyway実装で失敗しやすいポイント)](#アンチパターンauroraflyway実装で失敗しやすいポイント)

[22. API Gateway/Cognitoの実装（25-30ページ）
[559](#api-gatewaycognitoの実装25-30ページ)](#api-gatewaycognitoの実装25-30ページ)

[本章の目的：API層と認証基盤を実装する
[559](#本章の目的api層と認証基盤を実装する)](#本章の目的api層と認証基盤を実装する)

[**実践ハンズオン 22-1**: API Gateway設計と実装
[559](#実践ハンズオン-22-1-api-gateway設計と実装)](#実践ハンズオン-22-1-api-gateway設計と実装)

[**実践ハンズオン 22-2**: マルチリージョンAPI設定
[559](#実践ハンズオン-22-2-マルチリージョンapi設定)](#実践ハンズオン-22-2-マルチリージョンapi設定)

[**実践ハンズオン 22-3**: BFFパターン実装
[559](#実践ハンズオン-22-3-bffパターン実装)](#実践ハンズオン-22-3-bffパターン実装)

[**実践ハンズオン 22-4**: Cognitoユーザープール実装
[559](#実践ハンズオン-22-4-cognitoユーザープール実装)](#実践ハンズオン-22-4-cognitoユーザープール実装)

[実践ハンズオン 22-5: API認証の統合
[559](#実践ハンズオン-22-5-api認証の統合)](#実践ハンズオン-22-5-api認証の統合)

[実践ハンズオン 22-6: API性能最適化
[560](#実践ハンズオン-22-6-api性能最適化)](#実践ハンズオン-22-6-api性能最適化)

[**実践ハンズオン 22-7**: API監視とエラー対応
[560](#実践ハンズオン-22-7-api監視とエラー対応)](#実践ハンズオン-22-7-api監視とエラー対応)

[アンチパターン：API Gateway/Cognito実装で失敗しやすいポイント
[560](#アンチパターンapi-gatewaycognito実装で失敗しやすいポイント)](#アンチパターンapi-gatewaycognito実装で失敗しやすいポイント)

[23. Step Functions/Lambdaバッチ処理実装（25-30ページ）
[560](#step-functionslambdaバッチ処理実装25-30ページ)](#step-functionslambdaバッチ処理実装25-30ページ)

[本章の目的：サーバーレスバッチ処理基盤を実装する
[560](#本章の目的サーバーレスバッチ処理基盤を実装する)](#本章の目的サーバーレスバッチ処理基盤を実装する)

[**実践ハンズオン 23-1**: Step Functions実装
[560](#実践ハンズオン-23-1-step-functions実装)](#実践ハンズオン-23-1-step-functions実装)

[**実践ハンズオン 23-2**: マルチリージョンワークフロー設定
[560](#実践ハンズオン-23-2-マルチリージョンワークフロー設定)](#実践ハンズオン-23-2-マルチリージョンワークフロー設定)

[**実践ハンズオン 23-3**: Lambda関数実装
[561](#実践ハンズオン-23-3-lambda関数実装)](#実践ハンズオン-23-3-lambda関数実装)

[**実践ハンズオン 23-4**: データ処理パイプライン実装
[561](#実践ハンズオン-23-4-データ処理パイプライン実装)](#実践ハンズオン-23-4-データ処理パイプライン実装)

[**実践ハンズオン 23-5**: バッチスケジューリング実装
[561](#実践ハンズオン-23-5-バッチスケジューリング実装)](#実践ハンズオン-23-5-バッチスケジューリング実装)

[**実践ハンズオン 23-6**: クロスアカウントワークフロー
[561](#実践ハンズオン-23-6-クロスアカウントワークフロー)](#実践ハンズオン-23-6-クロスアカウントワークフロー)

[**実践ハンズオン 23-7**: バッチ処理の監視と最適化
[561](#実践ハンズオン-23-7-バッチ処理の監視と最適化)](#実践ハンズオン-23-7-バッチ処理の監視と最適化)

[アンチパターン：Step Functions/Lambda実装で失敗しやすいポイント
[562](#アンチパターンstep-functionslambda実装で失敗しやすいポイント)](#アンチパターンstep-functionslambda実装で失敗しやすいポイント)

[24. CI/CDパイプラインとデプロイ自動化実装（30-35ページ）
[562](#cicdパイプラインとデプロイ自動化実装30-35ページ)](#cicdパイプラインとデプロイ自動化実装30-35ページ)

[本章の目的：環境変数管理とマルチリージョン対応のCI/CDパイプラインを実装する
[562](#本章の目的環境変数管理とマルチリージョン対応のcicdパイプラインを実装する)](#本章の目的環境変数管理とマルチリージョン対応のcicdパイプラインを実装する)

[**実践ハンズオン 24-1**: GitLabリポジトリとブランチ戦略
[562](#実践ハンズオン-24-1-gitlabリポジトリとブランチ戦略)](#実践ハンズオン-24-1-gitlabリポジトリとブランチ戦略)

[**実践ハンズオン 24-2**: 静的解析パイプライン実装
[562](#実践ハンズオン-24-2-静的解析パイプライン実装)](#実践ハンズオン-24-2-静的解析パイプライン実装)

[**実践ハンズオン 24-3**: IAM Access Analyzer統合
[562](#実践ハンズオン-24-3-iam-access-analyzer統合)](#実践ハンズオン-24-3-iam-access-analyzer統合)

[**実践ハンズオン 24-4**: 環境変数管理システム実装
[563](#実践ハンズオン-24-4-環境変数管理システム実装)](#実践ハンズオン-24-4-環境変数管理システム実装)

[**実践ハンズオン 24-5**: 手動承認プロセス実装
[563](#実践ハンズオン-24-5-手動承認プロセス実装)](#実践ハンズオン-24-5-手動承認プロセス実装)

[**実践ハンズオン 24-6**: マイクロサービスビルド・デプロイパイプライン
[563](#実践ハンズオン-24-6-マイクロサービスビルドデプロイパイプライン)](#実践ハンズオン-24-6-マイクロサービスビルドデプロイパイプライン)

[**実践ハンズオン 24-7**: マルチリージョンデプロイ
[563](#実践ハンズオン-24-7-マルチリージョンデプロイ)](#実践ハンズオン-24-7-マルチリージョンデプロイ)

[**実践ハンズオン 24-8**: 環境間プロモーションフロー
[563](#実践ハンズオン-24-8-環境間プロモーションフロー)](#実践ハンズオン-24-8-環境間プロモーションフロー)

[アンチパターン：CI/CD実装で失敗しやすいポイント
[563](#アンチパターンcicd実装で失敗しやすいポイント)](#アンチパターンcicd実装で失敗しやすいポイント)

[25. DR設定と運用監視の実装（25-30ページ）
[564](#dr設定と運用監視の実装25-30ページ)](#dr設定と運用監視の実装25-30ページ)

[本章の目的：東京-大阪間の災害対策と統合監視基盤を実装する
[564](#本章の目的東京-大阪間の災害対策と統合監視基盤を実装する)](#本章の目的東京-大阪間の災害対策と統合監視基盤を実装する)

[**実践ハンズオン 25-1**: Aurora Global Database設定
[564](#実践ハンズオン-25-1-aurora-global-database設定)](#実践ハンズオン-25-1-aurora-global-database設定)

[**実践ハンズオン 25-2**: クロスリージョンコンテナ戦略
[564](#実践ハンズオン-25-2-クロスリージョンコンテナ戦略)](#実践ハンズオン-25-2-クロスリージョンコンテナ戦略)

[**実践ハンズオン 25-3**: Route 53フェイルオーバールーティング
[564](#実践ハンズオン-25-3-route-53フェイルオーバールーティング)](#実践ハンズオン-25-3-route-53フェイルオーバールーティング)

[**実践ハンズオン 25-4**: 統合監視ダッシュボード構築
[564](#実践ハンズオン-25-4-統合監視ダッシュボード構築)](#実践ハンズオン-25-4-統合監視ダッシュボード構築)

[**実践ハンズオン 25-5**: 環境タグベースの監視フィルタリング
[565](#実践ハンズオン-25-5-環境タグベースの監視フィルタリング)](#実践ハンズオン-25-5-環境タグベースの監視フィルタリング)

[**実践ハンズオン 25-6**: DR訓練とフェイルオーバー演習
[565](#実践ハンズオン-25-6-dr訓練とフェイルオーバー演習)](#実践ハンズオン-25-6-dr訓練とフェイルオーバー演習)

[アンチパターン：DR設定と運用監視で失敗しやすいポイント
[565](#アンチパターンdr設定と運用監視で失敗しやすいポイント)](#アンチパターンdr設定と運用監視で失敗しやすいポイント)

[技術ドキュメント例 [565](#技術ドキュメント例)](#技術ドキュメント例)

[アカウント申請JSON例（生産管理マイクロサービス・テスト環境用）
[565](#アカウント申請json例生産管理マイクロサービステスト環境用)](#アカウント申請json例生産管理マイクロサービステスト環境用)

[マルチリージョン対応Terraform設定例
[566](#マルチリージョン対応terraform設定例)](#マルチリージョン対応terraform設定例)

[IaC静的解析とCI/CD設定例
[569](#iac静的解析とcicd設定例)](#iac静的解析とcicd設定例)

[ECS TaskロールとAurora IAM認証サンプル
[572](#ecs-taskロールとaurora-iam認証サンプル)](#ecs-taskロールとaurora-iam認証サンプル)

[コンテナセキュリティスキャンと自動更新の設定例
[574](#コンテナセキュリティスキャンと自動更新の設定例)](#コンテナセキュリティスキャンと自動更新の設定例)

[Flyway設定とマイグレーションサンプル
[578](#flyway設定とマイグレーションサンプル)](#flyway設定とマイグレーションサンプル)

[Step Functions ワークフローサンプル（東京・大阪両リージョン対応）
[580](#step-functions-ワークフローサンプル東京大阪両リージョン対応)](#step-functions-ワークフローサンプル東京大阪両リージョン対応)

[AWS AFT ハンズオン設計書：具体的実装内容
[585](#aws-aft-ハンズオン設計書具体的実装内容)](#aws-aft-ハンズオン設計書具体的実装内容)

[セキュリティとコード品質向上のための追加実装要件
[585](#セキュリティとコード品質向上のための追加実装要件)](#セキュリティとコード品質向上のための追加実装要件)

[具体的実装サンプル [586](#具体的実装サンプル)](#具体的実装サンプル)

[tfsec, TFLint, checkovを統合したCI/CD設定
[586](#tfsec-tflint-checkovを統合したcicd設定)](#tfsec-tflint-checkovを統合したcicd設定)

[Access Analyzerを活用したIAMポリシー分析スクリプト
[589](#access-analyzerを活用したiamポリシー分析スクリプト)](#access-analyzerを活用したiamポリシー分析スクリプト)

[環境変数とタグを活用したマルチリージョン設定
[591](#環境変数とタグを活用したマルチリージョン設定)](#環境変数とタグを活用したマルチリージョン設定)

[両リージョンを並記したプロバイダー設定
[592](#両リージョンを並記したプロバイダー設定)](#両リージョンを並記したプロバイダー設定)

[環境変数を活用したマルチリージョンのAuroraクラスター設定
[594](#環境変数を活用したマルチリージョンのauroraクラスター設定)](#環境変数を活用したマルチリージョンのauroraクラスター設定)

[手動承認ステージを実装したAFTパイプライン設定
[596](#手動承認ステージを実装したaftパイプライン設定)](#手動承認ステージを実装したaftパイプライン設定)

[静的解析用ビルドスペック
[603](#静的解析用ビルドスペック)](#静的解析用ビルドスペック)

[IAM Access Analyzer用ビルドスペック
[605](#iam-access-analyzer用ビルドスペック)](#iam-access-analyzer用ビルドスペック)

[静的解析結果サマリー生成スクリプト
[606](#静的解析結果サマリー生成スクリプト)](#静的解析結果サマリー生成スクリプト)

[IAMポリシー検証スクリプト
[610](#iamポリシー検証スクリプト)](#iamポリシー検証スクリプト)

[マルチリージョン対応のECS Fargateクラスター設定
[613](#マルチリージョン対応のecs-fargateクラスター設定)](#マルチリージョン対応のecs-fargateクラスター設定)

[マルチリージョン対応のECRリポジトリ設定
[618](#マルチリージョン対応のecrリポジトリ設定)](#マルチリージョン対応のecrリポジトリ設定)

[東京-大阪間のDR設定とフェイルオーバー自動化
[624](#東京-大阪間のdr設定とフェイルオーバー自動化)](#東京-大阪間のdr設定とフェイルオーバー自動化)

[フェイルオーバー検知Lambdaの実装（コード例）
[630](#フェイルオーバー検知lambdaの実装コード例)](#フェイルオーバー検知lambdaの実装コード例)

[環境タグ付けとCI/CDパイプラインでの自動タグ付け
[632](#環境タグ付けとcicdパイプラインでの自動タグ付け)](#環境タグ付けとcicdパイプラインでの自動タグ付け)

[マルチリージョン対応のFlywayデータベースマイグレーション設定
[635](#マルチリージョン対応のflywayデータベースマイグレーション設定)](#マルチリージョン対応のflywayデータベースマイグレーション設定)

[Flyway用のビルドスペック例
[646](#flyway用のビルドスペック例)](#flyway用のビルドスペック例)

[マルチリージョン対応のAFTカスタムベースラインの例
[649](#マルチリージョン対応のaftカスタムベースラインの例)](#マルチリージョン対応のaftカスタムベースラインの例)

[AFTカスタムベースラインのCloudFormationテンプレート例
[659](#aftカスタムベースラインのcloudformationテンプレート例)](#aftカスタムベースラインのcloudformationテンプレート例)

[AFTアカウント申請JSONのサンプル（本番環境用のマルチリージョン対応）
[667](#aftアカウント申請jsonのサンプル本番環境用のマルチリージョン対応)](#aftアカウント申請jsonのサンプル本番環境用のマルチリージョン対応)

[開発環境用のAFTアカウント申請JSONサンプル
[668](#開発環境用のaftアカウント申請jsonサンプル)](#開発環境用のaftアカウント申請jsonサンプル)

[実用的なFlywayマイグレーションスクリプト例
[669](#実用的なflywayマイグレーションスクリプト例)](#実用的なflywayマイグレーションスクリプト例)

[まとめ [679](#まとめ)](#まとめ)

# **AWS AFT ハンズオン設計書作成プロンプト：TechNova社オンプレミス基幹システムのAWS移行・マイクロサービス化プロジェクト**

あなたはAWSソリューションアーキテクトとして、架空の企業「TechNova社」のオンプレミス基幹システムのAWS移行およびマイクロサービス化プロジェクトのために、AWS
AFT（AWS Control Tower Account Factory for
Terraform）を用いた大規模マルチアカウント環境の設計・実装を行うハンズオン形式の設計書を作成してください。

このハンズオンは、「オンプレミスからAWSへの移行の基本設計が終了し、構築方法としてAFTの導入が検討された」という、実際のプロジェクトでよくある状況をモデルにしています。TechNova社ではAWS移行の基本設計は完了しており、実際の構築手法としてAFTを活用することになりました。

この設計書は、実際の手順を追いながら設計思想や判断基準を学べる、コア設計書（約525ページ）と技術実装ガイド（約325ページ）の合計800ページ以上の包括的な2部構成とします。

## **プロジェクト背景と要件**

TechNova社は従業員5,000名のグローバル製造業企業で、主に産業機械の設計・製造・販売・保守を行っています。同社は創業60年の歴史を持ち、精密機械加工分野で国内シェア28%、アジア太平洋地域で18%を占める業界リーディングカンパニーです。近年は
Industry 4.0
の潮流に合わせ、IoT・AI技術を活用したスマートファクトリーソリューションの提供にも注力しています。

**現行システム構成の詳細**

同社では現在、以下の基幹業務システムをオンプレミスで運用しています：

- **生産管理システム**：工場での製造計画、在庫管理、生産工程追跡

  - **追加詳細**：3つの主力工場（本社工場、関西工場、九州工場）で稼働

  - **処理規模**：月間生産指示18,000件、管理部品点数45万SKU、同時接続ユーザー数最大500名

  - **技術課題**：レガシーJava EE（Java 8）、Oracle 11g、WebLogic 12c
    により保守性が低下

- **販売管理システム**：受注処理、出荷管理、請求管理

  - **追加詳細**：グローバル15拠点での受注・出荷業務を統合管理

  - **処理規模**：年間受注件数4,800件、顧客企業数2,800社、取引金額総額380億円

  - **技術課題**：.NET Framework 4.7、SQL Server
    2016による機能制約とライセンス費用高騰

- **保守サービス管理**：顧客機器の保守履歴、点検スケジュール、部品交換履歴

  - **追加詳細**：24時間365日体制での機器監視・保守対応

  - **処理規模**：管理対象機器14,500台、年間保守契約7,200件、技術者450名の稼働管理

  - **技術課題**：PHP 7.2、MySQL 5.7による性能限界とセキュリティリスク

- **機器IoTプラットフォーム**：販売済み機器からのテレメトリデータ収集・分析

  - **追加詳細**：リアルタイムデータ分析による予防保全・稼働最適化サービス

  - **処理規模**：接続機器7,800台、日次データ量1.8TB、月間アラート件数1,200件

  - **技術課題**：Python 3.7、MongoDB
    4.2、オンプレミスKafkaクラスターのスケーリング限界

- **顧客ポータル**：顧客向け情報提供、保守予約、部品注文

  - **追加詳細**：多言語対応（日本語、英語、中国語、ドイツ語）のWebプラットフォーム

  - **処理規模**：登録ユーザー11,200名、月間ログイン数25,000回、年間部品注文8,500件

  - **技術課題**：React 16、Node.js 14、PostgreSQL
    12による保守負荷とUX改善要求への対応遅延

## **プロジェクト状況と課題**

**プロジェクト進行状況の詳細**

- **既完了フェーズ：**

  - **現状分析・要件定義フェーズ（2023年10月～2024年3月）**

  - **アプリケーション棚卸し：**全32システムの詳細調査完了、依存関係マップ作成

  - **データ資産分析：**総データ量85TB、マスターデータ種別147種の洗い出し完了

  - **非機能要件策定：**可用性99.99%、RPO1時間、RTO4時間等の目標値確定

  - **移行優先度評価：**ビジネスクリティカリティとテクニカルデット指標による評価完了

- **AWS移行基本設計フェーズ（2024年4月～2024年8月）**

  - **アーキテクチャ設計：**マイクロサービス境界定義、API設計指針確定

  - **技術選定：**ECS Fargate + Aurora Serverless v2 + API
    Gateway構成決定

  - **セキュリティ設計：**IAM Identity
    Center、WAF/Shield統合、暗号化方針策定

  - **データ移行戦略：**段階的移行計画と並行運用期間（最大6ヶ月）の設計完了

- **概念実証（PoC）フェーズ（2024年6月～2024年9月）**

  - **マイクロサービス検証：**顧客ポータルの一部機能でコンテナ化・API化実証

  - **パフォーマンステスト：**ピーク負荷時の性能要件クリアを確認

  - **セキュリティ検証：**ペネトレーションテスト実施、脆弱性対策効果確認

  - **運用性検証：**CloudWatch統合監視、自動スケーリング動作確認

**現在のプロジェクト状況（2024年10月時点）**

- **進行中のフェーズ：**詳細設計・実装準備フェーズ

  - **進捗率：**全体計画の65%完了

  - **予算執行率：**計画予算15億円中、8.2億円執行済み（55%）

  - **要員稼働状況：**プロジェクトメンバー50名中、43名がフル稼働中

- **直近の成果物：**

  - **マイクロサービス詳細設計書：**15サービスの詳細仕様完成（全20サービス中）

  - **Infrastructure as
    Code：**Terraformモジュール85%完成、テスト環境での検証済み

  - **CI/CDパイプライン：**GitLab
    CI/CD基盤構築完了、デプロイ自動化テスト済み

  - **移行手順書：**データ移行スクリプト70%完成、テストデータでの検証進行中

**当初計画からの主要変更点**

- **技術アーキテクチャの見直し：**

  - **データベース戦略変更：**当初のAurora Serverless
    v1からv2への変更（コスト最適化）

  - **API Gateway選定見直し：**Application Load
    Balancer併用によるレイテンシ最適化

  - **監視戦略強化：**Grafana +
    Prometheus追加導入によるマイクロサービス監視強化

- **プロジェクトスコープの調整：**

  - **IoTプラットフォーム移行の前倒し：**ビジネス価値創出のため第1フェーズに移動

  - **レガシーシステム延命：**生産管理システムの一部機能を6ヶ月間並行運用継続

  - **多言語対応の段階化：**当初の4言語同時対応から、日英中の3言語先行対応に変更

**現在直面している主要課題**

- **技術的課題：**

1.  **大規模アカウント管理の複雑性**

    - **課題詳細：**事業部門×環境のマトリックスで必要なアカウント数が当初想定90から120に増加

    - **影響：**手動でのアカウント管理では膨大な工数が発生し、プロジェクト遅延リスクが顕在化

    - **現状対応：**暫定的に20アカウントを手動作成済みだが、設定の不整合が3件発生

<!-- -->

2.  **セキュリティ設定の標準化困難**

    - **課題詳細：**各事業部門からの独自セキュリティ要件により、統一的な設定適用が困難

    - **影響：**セキュリティポリシーの一貫性確保とコンプライアンス監査への対応に懸念

    - **現状対応：**セキュリティ設計書の改訂を3回実施、標準設定テンプレート策定中

<!-- -->

3.  **クロスアカウントアクセス管理**

    - **課題詳細：**マイクロサービス間のデータ連携で必要なクロスアカウントアクセスパターンが複雑化

    - **影響：**サービス間通信のセキュリティ境界設計とトラブルシューティングの複雑化

    - **現状対応：**PoC環境で10パターンのアクセスパターンを検証、最適解を模索中

**組織・運用課題：**

1.  **多部門間の調整負荷**

    - **課題詳細：**5事業部門それぞれの業務要件とシステム要件の調整に時間を要している

    - **影響：**意思決定の遅延により、詳細設計フェーズが当初計画より2週間遅延

    - **現状対応：**週次ステアリング会議の開催、課題エスカレーションフロー確立

<!-- -->

2.  **CI/CDパイプライン標準化の課題**

    - **課題詳細：**各マイクロサービスの特性に応じたCI/CDパイプラインの個別最適化が必要

    - **影響：**統一的な品質管理とデプロイプロセスの確立が困難

    - **現状対応：**テンプレート化できる部分と個別対応部分の仕分け作業を実施中

**AFT導入による課題解決の期待効果**

**直接的な解決効果：**

- **アカウント作成自動化：**手動2週間→自動2時間により、120アカウント作成の工数を95%削減

- **設定標準化：**AFTベースラインにより、セキュリティ設定の100%標準化実現

- **ガバナンス強化：**Control
  Towerとの統合により、組織全体のガバナンス自動化

**プロジェクト全体への波及効果：**

- **品質向上：**人的ミスの削減により、テスト工数を30%削減

- **納期リカバリ：**アカウント関連作業の効率化により、遅延2週間のうち1週間回復見込み

- **運用準備促進：**標準化されたアカウント構成により、運用手順書作成を2週間短縮

**今後のマイルストーンとリスク**

**直近の重要マイルストーン：**

- **2024年11月末：**AFT環境構築完了、初回アカウント自動作成テスト

- **2024年12月末：**全120アカウントの自動作成完了

- **2025年1月末：**第1フェーズ（顧客ポータル・IoTプラットフォーム）移行開始

- **2025年3月末：**データセンター契約満了に伴う完全移行完了

**主要リスクと対策：**

1.  **AFT習熟期間不足：**新技術導入による学習コストとトラブルシューティング時間

    - **対策：**AWS Professional Service連携、専門トレーニング実施

<!-- -->

2.  **大規模移行時の安定性：**120アカウント一斉移行時のシステム負荷

    - **対策：**段階的移行計画の策定、ロールバック手順の整備

<!-- -->

3.  **組織変革への抵抗：**新しい開発・運用プロセスへの適応遅延

    - **対策：**早期の現場巻き込み、成功事例の共有促進

**このような状況下で、AFTの導入は単なる技術的解決策ではなく、プロジェクト成功とTechNova社のDX推進における戦略的要素として位置づけられています。**

**AWSアカウント・権限設計（基本方針）**

**アカウント構造の詳細設計**

**組織階層とアカウント分類：**

1.  **管理アカウント階層**

    - **組織マスターアカウント：**AWS Organizations のルートアカウント

      - **用途：**請求統合、組織ポリシー管理、Control Tower管理

      - **アクセス制御：**最小限の管理者（経営層2名、IT部長1名）のみ

      - **セキュリティ要件：**MFA必須、CloudTrail全有効、Config記録

    - **セキュリティアカウント：**セキュリティログ・監視の集中管理

      - **用途：**Security Hub、GuardDuty、Config、CloudTrail ログ集約

      - **アクセス制御：**セキュリティ管理者3名、読み取り専用監査者5名

      - **セキュリティ要件：**ログの暗号化、90日間の保持、改ざん防止

    - **共有サービスアカウント：**共通インフラコンポーネント管理

      - **用途：**DNS（Route
        53）、証明書管理（ACM）、コンテナレジストリ（ECR）

      - **アクセス制御：**インフラ管理者5名、自動化サービス用ロール

      - **セキュリティ要件：**リソース共有ポリシー、アクセスログ監視

2.  **ネットワークアカウント：**ネットワークインフラ専用管理

    - **ネットワークハブアカウント**

      - **用途：**Transit Gateway、DirectConnect、Site-to-Site VPN管理

      - **アクセス制御：**ネットワーク管理者3名、緊急時対応者2名

      - **セキュリティ要件：**ネットワークフロー監視、VPC Flow Logs有効

## **事業部門別アカウント構成**

**アカウント命名規則：** {会社略称}-{事業部門}-{環境}-{サービス群}

**事業部門分類（5部門）：**

1.  **製造部門（mfg）：**生産管理、品質管理システム

2.  **営業部門（sales）：**販売管理、顧客管理システム

3.  **サービス部門（service）：**保守サービス管理システム

4.  **IoT部門（iot）：**機器IoTプラットフォーム

5.  **共通部門（common）：**認証、通知、マスターデータ、レポーティング

**環境分類（4環境）：**

1.  **開発環境（dev）：**開発・単体テスト用

2.  **テスト環境（test）：**結合テスト・性能テスト用

3.  **ステージング環境（staging）：**本番前検証用

4.  **本番環境（prod）：**商用サービス稼働用

**サービス群分類（6群）：**

1.  **アプリケーション群（app）：**マイクロサービス本体

2.  **データベース群（db）：**Aurora、DynamoDB

3.  **API群（api）：**API Gateway、Cognito

4.  **バッチ群（batch）：**Step Functions、Lambda

5.  **監視群（monitor）：**CloudWatch、X-Ray

6.  **ネットワーク群（network）：VPC、ALB、NLB**

**具体的アカウント一覧（120アカウント）**

**製造部門アカウント（24アカウント）：**

technova-mfg-dev-app \# 製造アプリケーション開発環境

technova-mfg-dev-db \# 製造データベース開発環境

technova-mfg-dev-api \# 製造API開発環境

technova-mfg-dev-batch \# 製造バッチ開発環境

technova-mfg-dev-monitor \# 製造監視開発環境

technova-mfg-dev-network \# 製造ネットワーク開発環境

> technova-mfg-test-app \# 製造アプリケーションテスト環境
>
> technova-mfg-test-db \# 製造データベーステスト環境
>
> technova-mfg-test-api \# 製造APIテスト環境
>
> technova-mfg-test-batch \# 製造バッチテスト環境
>
> technova-mfg-test-monitor \# 製造監視テスト環境
>
> technova-mfg-test-network \# 製造ネットワークテスト環境
>
> technova-mfg-staging-app \# 製造アプリケーションステージング環境
>
> technova-mfg-staging-db \# 製造データベースステージング環境
>
> technova-mfg-staging-api \# 製造APIステージング環境
>
> technova-mfg-staging-batch \# 製造バッチステージング環境
>
> technova-mfg-staging-monitor \# 製造監視ステージング環境
>
> technova-mfg-staging-network \# 製造ネットワークステージング環境
>
> technova-mfg-prod-app \# 製造アプリケーション本番環境
>
> technova-mfg-prod-db \# 製造データベース本番環境
>
> technova-mfg-prod-api \# 製造API本番環境
>
> technova-mfg-prod-batch \# 製造バッチ本番環境
>
> technova-mfg-prod-monitor \# 製造監視本番環境
>
> technova-mfg-prod-network \# 製造ネットワーク本番環境

**営業部門アカウント（24アカウント）：**

technova-sales-{env}-{service} \# 営業部門の全環境・サービス群

**サービス部門アカウント（24アカウント）：**

technova-service-{env}-{service} \# サービス部門の全環境・サービス群

**IoT部門アカウント（24アカウント）：**

technova-iot-{env}-{service} \# IoT部門の全環境・サービス群

**共通部門アカウント（24アカウント）：**

technova-common-{env}-{service} \# 共通部門の全環境・サービス群

**アカウント管理要件**

**アカウント作成・管理自動化要件：**

- **作成時間短縮：**手動2週間→AFT自動化2時間以内

- **設定一貫性：**100%の設定標準化、人的ミス0件

- **セキュリティベースライン：**全アカウントに統一セキュリティ設定自動適用

- **タグ管理：**コスト配分用タグの自動付与（部門、環境、プロジェクト、担当者）

**運用管理要件：**

- **アカウント棚卸し：**月次でのアカウント利用状況レビュー

- **コスト監視：**アカウント別予算設定とアラート通知

- **使用量監視：**未使用リソースの自動検出と通知

- **セキュリティ監査：**アカウント設定の定期的な監査とレポート

**災害対策要件：**

- **マルチリージョン：**本番環境は東京（ap-northeast-1）・大阪（ap-northeast-3）の両リージョン

- **データレプリケーション：**本番データベースの自動レプリケーション

- **フェイルオーバー：**RTOの4時間、RPO1時間の要件達成

**認証・認可設計**

**AWS IAM Identity Center（旧SSO）をID連携の中核に：**

- **社内Active
  Directoryとの連携：**既存のユーザー・グループ情報を自動同期

- **多要素認証（MFA）：**全ユーザーでMFA必須、緊急時のバックアップ認証方式

- **セッション管理：**業務時間帯は8時間、非業務時間帯は1時間のセッション有効期限

**Permission Set設計：**

1.  **管理者権限セット：**

    - **OrganizationAdmin：**組織全体の管理（経営層・IT管理責任者）

    - **SecurityAdmin：**セキュリティ管理（セキュリティ管理者）

    - **NetworkAdmin：**ネットワーク管理（ネットワーク管理者）

2.  **開発者権限セット：**

    - **DeveloperFull：**開発環境のフルアクセス（開発者）

    - **DeveloperRead：**開発環境の読み取りのみ（新人・インターン）

    - **QAEngineer：**テスト環境の必要最小限権限（QAエンジニア）

3.  **運用者権限セット：**

    - **OperationAdmin：**本番環境の運用権限（運用管理者）

    - **OperationReadOnly：**本番環境の監視専用権限（監視オペレーター）

    - **EmergencyAccess：**緊急時対応の特別権限（緊急時対応者）

4.  **監査者権限セット：**

    - **AuditorReadOnly：**全環境の読み取り専用権限（内部監査）

    - **ComplianceRead：**コンプライアンス監査用権限（外部監査）

**サービスロール設計：**

- **ECS Taskロール：**マイクロサービス実行時の最小権限

- **Aurora接続ロール：**IAMデータベース認証による接続

- **Lambda実行ロール：**バッチ処理用の必要最小限権限

- **CI/CDサービスロール：**デプロイパイプライン専用権限

**セキュリティ・コンプライアンス要件**

**最小権限の原則：**

- **時間制限アクセス：**特権アクセスは業務時間内のみ、緊急時は承認制

- **IP制限：**本社・各拠点のIPアドレスからのみアクセス許可

- **デバイス制限：**会社支給デバイスからのみアクセス許可

**監査・証跡要件：**

- **CloudTrail：**全アカウントで API 呼び出しを記録、3年間保持

- **Config：**リソース設定変更の記録、コンプライアンス違反の検出

- **Access Analyzer：**意図しないリソース共有の定期的な監査

**緊急時アクセス手順：**

- **ブレークグラス手順：**緊急時の特権アクセス手順を文書化

- **承認フロー：**緊急時アクセスの事前承認とログ監視

- **事後レビュー：**緊急時アクセス後の必須レビューと報告

この包括的なアカウント要件により、TechNova社は120のAWSアカウントを安全かつ効率的に管理し、マイクロサービス化されたシステムの運用基盤を確立できます。

## **業務マイクロサービス要件**

**マイクロサービス分割戦略と設計原則**

**ドメイン駆動設計（DDD）に基づくサービス境界定義：**

TechNova社では、既存のモノリシックシステムから、ビジネスドメインの境界を明確にしたマイクロサービスアーキテクチャへの移行を実施します。各マイクロサービスは独立したデータストア、デプロイサイクル、開発チームを持ち、疎結合でありながら事業価値を最大化する設計とします。

**マイクロサービス設計の基本原則：**

- **単一責任の原則**：各サービスは明確に定義された単一のビジネス機能を担当

- **データ所有権の原則**：各サービスが自身のデータを完全に所有・管理

- **API ファーストの原則**：サービス間通信は全てRESTful
  APIまたは非同期メッセージングで実装

- **独立デプロイの原則**：他のサービスに影響を与えることなく独立してデプロイ可能

- **障害隔離の原則**：一つのサービスの障害が他のサービスの機能を停止させない設計

**生産管理マイクロサービス群**

**1. 生産計画管理API（Production Planning Service）**

- **ビジネス責務**：

  - 月次・週次・日次生産計画の立案と最適化

  - 設備稼働計画と人員配置の最適化

  - 生産進捗の監視とリスケジューリング

  - 生産能力分析とボトルネック特定

- **データ所有範囲**：

  - 生産計画マスター（計画ID、期間、数量、優先度）

  - 工程定義マスター（工程順序、標準時間、設備要件）

  - 設備稼働予定（設備ID、予約時間、メンテナンス予定）

  - 生産実績データ（計画対実績の差異分析用）

- **技術要件**：

  - **想定リクエスト数**：平常時1,500件/日、月末計画策定時5,000件/日

  - **レスポンス要件**：計画照会90%ile \< 200ms、計画更新90%ile \< 500ms

  - **可用性要件**：99.9%（月間ダウンタイム43分以内）

  - **データ整合性**：強整合性（在庫引当との連携時）

- **外部連携**：

  - 在庫管理APIとの在庫残高照会・引当処理

  - 販売管理APIとの受注情報取得

  - 設備管理APIとの設備状態・メンテナンス情報連携

**2. 在庫管理API（Inventory Management Service）**

- **ビジネス責務**：

  - 原材料・仕掛品・完成品の在庫レベル監視

  - 発注点管理と自動発注アラート

  - ABC分析による在庫戦略最適化

  - 在庫回転率分析と不良在庫特定

- **データ所有範囲**：

  - 在庫トランザクション（入庫・出庫・移動・調整履歴）

  - 在庫マスター（品目別在庫ポリシー、安全在庫、発注点）

  - ロケーション管理（倉庫・棚・区画の在庫配置）

  - 在庫評価情報（単価、評価額、滞留日数）

- **技術要件**：

  - **想定リクエスト数**：平常時8,000件/日、棚卸時20,000件/日

  - **リアルタイム性**：在庫更新は5秒以内に全システム反映

  - **データ精度**：在庫差異率0.1%以内（月次棚卸基準）

  - **バッチ処理**：夜間バッチでの在庫分析・レポート生成

- **外部連携**：

  - 調達管理APIとの発注情報連携

  - 生産管理APIとの原材料消費・完成品入庫連携

  - 販売管理APIとの出荷指示・在庫引当連携

**3. 生産工程追跡API（Production Tracking Service）**

- **ビジネス責務**：

  - 製造工程別の進捗状況リアルタイム監視

  - 品質検査結果の記録と不良品トレーサビリティ

  - 作業実績収集と生産性分析

  - 工程遅延アラート配信

- **データ所有範囲**：

  - 作業実績（工程別開始・終了時刻、作業者、使用設备）

  - 品質データ（検査結果、不良内容、対策履歴）

  - 工程間仕掛品移動履歴

  - 生産指示書とその実行状況

- **技術要件**：

  - **想定リクエスト数**：平常時4,000件/日、ピーク時1,000件/時

  - **データ取込**：工場IoTセンサーからの自動データ取込対応

  - **アラート要件**：工程遅延検知から5分以内の通知

  - **分析処理**：リアルタイム統計処理とダッシュボード更新

- **外部連携**：

  - IoTプラットフォームとの設備稼働データ連携

  - 品質管理システムとの検査結果連携

  - 人事システムとの作業者情報連携

**4. 原材料管理API（Material Management Service）**

- **ビジネス責務**：

  - 調達計画策定と発注管理

  - サプライヤー評価と選定支援

  - 入荷検査と品質証明書管理

  - 原材料コスト分析と価格交渉支援

- **データ所有範囲**：

  - 調達履歴（発注・納期・価格・品質実績）

  - サプライヤーマスター（評価点数・認定状況・取引条件）

  - 品質基準・検査仕様書

  - 原材料仕様・図面・承認履歴

- **技術要件**：

  - **想定リクエスト数**：平常時1,200件/日、月末調達計画時3,000件/日

  - **文書管理**：仕様書・図面のバージョン管理とアクセス制御

  - **承認ワークフロー**：新規サプライヤー登録の多段階承認

  - **外部システム連携**：EDI経由での発注・納期回答処理

**販売管理マイクロサービス群**

**1. 受注管理API（Order Management Service）**

- **ビジネス責務**：

  - 注文受付とリアルタイム在庫確認

  - 納期自動算出と顧客回答

  - 受注承認ワークフローと与信管理

  - 注文変更・キャンセル処理

- **データ所有範囲**：

  - 受注情報（注文明細・顧客要望・特記事項）

  - 価格マスター（標準価格・顧客別価格・期間限定価格）

  - 受注承認履歴とワークフロー状態

  - 納期回答履歴と変更管理

- **技術要件**：

  - **想定リクエスト数**：平常時800件/日、展示会後2,000件/日

  - **レスポンス要件**：在庫確認・納期回答は3秒以内

  - **データ整合性**：重複受注防止とトランザクション保証

  - **外部API連携**：顧客ポータルからのリアルタイム受注

- **外部連携**：

  - 在庫管理APIとの在庫引当・確保処理

  - 顧客管理APIとの与信情報・取引条件照会

  - 生産計画APIとの製造スケジュール確認

**2. 顧客管理API（Customer Management Service）**

- **ビジネス責務**：

  - 顧客企業情報の統合管理

  - 取引履歴と売上分析

  - 営業活動支援と商談管理

  - 顧客満足度調査と分析

- **データ所有範囲**：

  - 顧客マスター（企業情報・担当者・連絡先）

  - 取引条件（支払条件・与信限度・特別価格）

  - 営業活動履歴（商談・提案・契約情報）

  - 顧客評価・満足度データ

- **技術要件**：

  - **想定リクエスト数**：平常時1,500件/日、営業活動ピーク時3,500件/日

  - **検索性能**：顧客検索90%ile \< 100ms

  - **データ品質**：重複顧客データの自動検出・統合

  - **個人情報保護**：GDPR・個人情報保護法対応

**3. 出荷管理API（Shipping Management Service）**

- **ビジネス責務**：

  - 出荷指示と配送計画最適化

  - 物流業者との連携と追跡情報管理

  - 梱包仕様と輸送条件管理

  - 配送状況の顧客通知

- **データ所有範囲**：

  - 出荷指示（出荷予定・実績・配送先情報）

  - 物流業者マスター（料金・サービスレベル・対応エリア）

  - 梱包・輸送履歴

  - 配送トラッキング情報

- **技術要件**：

  - **想定リクエスト数**：平常時600件/日、月末出荷集中時1,800件/日

  - **リアルタイム追跡**：配送状況の1時間ごと更新

  - **外部API連携**：物流業者の追跡APIとの自動連携

  - **通知機能**：配送完了の自動顧客通知

**4. 請求管理API（Billing Management Service）**

- **ビジネス責務**：

  - 売上計上と請求書発行

  - 入金消込と債権管理

  - 売上分析とレポート作成

  - 税務申告支援データ作成

- **データ所有範囲**：

  - 請求情報（請求書・入金予定・支払条件）

  - 売上実績（月次・四半期・年次売上）

  - 債権管理（未収金・滞留債権・回収状況）

  - 税務関連データ（消費税・源泉税・支払調書）

- **技術要件**：

  - **想定リクエスト数**：平常時400件/日、月末請求処理時2,000件/日

  - **正確性要件**：金額計算の100%正確性

  - **セキュリティ**：財務データの厳格なアクセス制御

  - **監査対応**：全取引の完全な監査証跡

**保守サービスマイクロサービス群**

**1. 機器管理API（Equipment Management Service）**

- **ビジネス責務**：

  - 販売済み機器の台帳管理

  - 機器仕様・設定情報の保管

  - ワランティ・保守契約管理

  - 機器ライフサイクル追跡

- **データ所有範囲**：

  - 機器台帳（シリアル番号・設置場所・設定情報）

  - 保守契約（契約期間・サービスレベル・料金）

  - 機器仕様・マニュアル・図面

  - 部品構成表（BOM）と交換履歴

- **技術要件**：

  - **想定リクエスト数**：平常時2,000件/日、新製品リリース時5,000件/日

  - **検索性能**：機器検索（型番・シリアル・顧客別）90%ile \< 150ms

  - **文書管理**：技術文書のバージョン管理と閲覧制御

  - **大容量対応**：機器図面・動画マニュアルの効率的配信

**2. 保守履歴API（Maintenance History Service）**

- **ビジネス責務**：

  - 点検・修理履歴の完全記録

  - 保守作業の標準化と品質向上

  - 故障傾向分析と予防保全計画

  - 技術者のスキル・経験管理

- **データ所有範囲**：

  - 保守作業履歴（作業内容・使用部品・作業時間）

  - 故障・不具合情報（原因・対策・再発防止）

  - 技術者情報（スキル・資格・担当エリア）

  - 作業標準書・手順書

- **技術要件**：

  - **想定リクエスト数**：平常時3,000件/日、繁忙期8,000件/日

  - **モバイル対応**：現場技術者のタブレット・スマートフォン対応

  - **オフライン対応**：通信不安定な現場でのローカル同期機能

  - **画像・動画**：作業前後の写真・動画アップロード機能

**3. 予約管理API（Appointment Management Service）**

- **ビジネス責務**：

  - 保守作業の予約受付と調整

  - 技術者スケジュール最適化

  - 緊急対応の優先制御

  - 顧客との予約確認・変更処理

- **データ所有範囲**：

  - 予約情報（日時・作業内容・担当者・顧客要望）

  - 技術者スケジュール（稼働予定・移動時間・休暇）

  - 緊急対応履歴とエスカレーション記録

  - SLA管理（応答時間・解決時間の実績）

- **技術要件**：

  - **想定リクエスト数**：平常時1,200件/日、設備トラブル多発時3,000件/日

  - **リアルタイム性**：予約変更の即座反映と関係者通知

  - **最適化アルゴリズム**：移動時間・スキルマッチを考慮した自動割当

  - **通知機能**：予約確認・リマインダーの自動配信

**4. 部品管理API（Spare Parts Service）**

- **ビジネス責務**：

  - 交換部品の在庫管理と調達

  - 部品需要予測と発注自動化

  - 廃版部品の代替品提案

  - 部品価格管理と見積対応

- **データ所有範囲**：

  - 部品マスター（仕様・互換性・調達情報）

  - 部品在庫（拠点別・技術者車載在庫）

  - 使用実績（部品別・機器別・故障パターン別）

  - 調達情報（供給業者・リードタイム・価格変動）

- **技術要件**：

  - **想定リクエスト数**：平常時800件/日、故障多発時2,500件/日

  - **在庫精度**：部品在庫差異率0.5%以内

  - **予測精度**：需要予測の月次精度85%以上

  - **供給継続性**：廃版部品の3ヶ月前アラート

**IoTマイクロサービス群**

**1. デバイス接続API（Device Connectivity Service）**

- **ビジネス責務**：

  - 産業機器のIoT接続管理

  - デバイス認証とセキュリティ管理

  - 通信プロトコル変換と標準化

  - 接続状態監視とアラート

- **データ所有範囲**：

  - デバイス登録情報（デバイスID・証明書・接続設定）

  - 接続履歴（接続・切断時刻・通信品質）

  - セキュリティ設定（暗号化・認証・アクセス制御）

  - 通信ログ（エラー・パフォーマンス・使用量）

- **技術要件**：

  - **接続デバイス数**：現在7,800台、年間20%成長予定

  - **同時接続**：最大8,000台の同時接続対応

  - **レイテンシ要件**：デバイス→クラウド間200ms以内

  - **可用性**：99.95%（IoT機器の24時間監視要件）

**2. テレメトリAPI（Telemetry Data Service）**

- **ビジネス責務**：

  - 機器稼働データのリアルタイム収集

  - 大容量時系列データの効率的保存

  - データ品質管理と異常値除去

  - リアルタイムストリーム処理

- **データ所有範囲**：

  - 稼働データ（温度・圧力・回転数・振動・電流値）

  - 生産実績（加工件数・稼働時間・停止理由）

  - エラーログ（警告・異常・故障履歴）

  - 環境データ（工場内温湿度・電力使用量）

- **技術要件**：

  - **データ量**：日次1.8TB、月次50TB規模

  - **取込頻度**：1秒間隔～1分間隔（センサー種別による）

  - **ストレージ要件**：3年間のデータ保持、段階的アーカイブ

  - **処理性能**：秒間10万件のデータポイント処理

**3. 分析API（Analytics Service）**

- **ビジネス責務**：

  - 機器性能分析と稼働率算出

  - 異常検知と予測分析

  - 生産性向上提案の自動生成

  - カスタム分析レポート作成

- **データ所有範囲**：

  - 分析結果（統計値・傾向・予測値）

  - 機械学習モデル（異常検知・寿命予測・最適化）

  - ベンチマーク データ（業界標準・同機種比較）

  - 分析設定（閾値・アルゴリズム・通知条件）

- **技術要件**：

  - **分析処理**：バッチ分析（夜間）+ リアルタイム分析

  - **機械学習**：月次でのモデル再学習と精度向上

  - **レポート生成**：月次レポート自動生成（PDF・Excel）

  - **API応答**：分析結果照会90%ile \< 300ms

**4. アラートAPI（Alert Service）**

- **ビジネス責務**：

  - 異常状態の即時検知と通知

  - 通知レベル管理と段階的エスカレーション

  - 通知履歴管理と対応追跡

  - 予防保全アラートの自動配信

- **データ所有範囲**：

  - アラート定義（条件・閾値・通知先・重要度）

  - 通知履歴（発報時刻・対応状況・解決時刻）

  - エスカレーション設定（未対応時の上位通知）

  - 通知先マスター（担当者・連絡先・役割・シフト）

- **技術要件**：

  - **検知速度**：異常検知から30秒以内の通知配信

  - **通知手段**：メール・SMS・Slack・専用アプリ

  - **可用性**：99.99%（24時間365日の監視要件）

  - **処理量**：月間12,000件のアラート処理

**共通マイクロサービス群**

**1. 認証API（Authentication Service）**

- **ビジネス責務**：

  - ユーザー認証とセッション管理

  - 多要素認証（MFA）の提供

  - シングルサインオン（SSO）基盤

  - 認証ログ監視とセキュリティ分析

- **データ所有範囲**：

  - ユーザー情報（ID・権限・プロファイル）

  - 認証履歴（ログイン・ログアウト・失敗試行）

  - セッション管理（有効期限・デバイス情報）

  - セキュリティ設定（パスワードポリシー・MFA設定）

- **技術要件**：

  - **想定ユーザー数**：社内5,000名、顧客12,000名

  - **同時セッション**：最大2,000セッション

  - **認証レスポンス**：90%ile \< 100ms

  - **セキュリティ**：OAuth 2.0 / OpenID Connect対応

**2. 通知API（Notification Service）**

- **ビジネス責務**：

  - 統一的な通知配信基盤

  - 多チャネル通知（メール・SMS・プッシュ・Slack）

  - 通知テンプレート管理と多言語対応

  - 通知履歴と配信結果追跡

- **データ所有範囲**：

  - 通知テンプレート（件名・本文・多言語版）

  - 配信設定（送信者・チャネル・優先度）

  - 配信履歴（送信結果・開封率・エラー情報）

  - 購読管理（通知設定・オプトアウト）

- **技術要件**：

  - **配信量**：日次20,000件、ピーク時5,000件/時

  - **配信速度**：緊急通知30秒以内、通常通知5分以内

  - **多言語対応**：日本語・英語・中国語・ドイツ語

  - **可用性**：99.9%（重要な業務通知のため）

**3. マスターデータAPI（Master Data Service）**

- **ビジネス責務**：

  - 企業全体のマスターデータ統合管理

  - データ品質管理と重複排除

  - マスターデータ変更の統制・承認

  - データ系譜とインパクト分析

- **データ所有範囲**：

  - 製品マスター（型番・仕様・価格・原価）

  - 組織マスター（部門・役職・承認権限）

  - 地域マスター（国・地域・通貨・税率）

  - 分類マスター（製品分類・顧客分類・勘定科目）

- **技術要件**：

  - **データ品質**：マスターデータ品質スコア95%以上

  - **整合性**：関連システム間の100%データ整合性

  - **変更管理**：マスターデータ変更の完全な監査証跡

  - **API性能**：マスターデータ照会90%ile \< 50ms

**4. レポーティングAPI（Reporting Service）**

- **ビジネス責務**：

  - 企業全体のデータ統合とBI基盤

  - 定型レポートの自動生成と配信

  - アドホック分析とセルフサービスBI

  - 経営ダッシュボードとKPI監視

- **データ所有範囲**：

  - レポート定義（項目・条件・レイアウト・配信設定）

  - 分析用データマート（各システムからのデータ統合）

  - ダッシュボード設定（KPI・グラフ・ドリルダウン）

  - 配信履歴（レポート生成・配信結果）

- **技術要件**：

  - **データ更新**：日次バッチ + リアルタイム更新（重要指標）

  - **レポート生成**：大容量レポート（100万行）30分以内

  - **同時利用**：最大500名の同時アクセス

  - **データ保持**：5年間の履歴データ保持

**マイクロサービス間連携アーキテクチャ**

**API設計標準：**

- **RESTful API**：同期通信での標準プロトコル

- **GraphQL**：複雑なデータ取得要件への対応

- **非同期メッセージング**：Amazon SQS/SNSによるイベント駆動

- **API Gateway**：統一エントリーポイントとトラフィック制御

**データ整合性戦略：**

- **Saga パターン**：分散トランザクション管理

- **イベント駆動アーキテクチャ**：データ変更の非同期通知

- **CQRS**：読み取り最適化とデータ投影

- **Eventually Consistent**：結果整合性による性能最適化

**サービス間セキュリティ：**

- **mTLS**：サービス間通信の相互認証

- **JWT トークン**：API認証と認可の標準化

- **Service Mesh**：通信の暗号化とトラフィック制御

- **Zero Trust**：すべての通信を検証・監視

この包括的なマイクロサービス要件により、TechNova社は既存のモノリシックシステムから、スケーラブルで保守性の高いマイクロサービスアーキテクチャへの移行を実現し、将来のビジネス成長に対応できる柔軟なシステム基盤を構築します。

## **インフラ要件**

**コンテナ基盤アーキテクチャ設計**

**Amazon ECS Fargate選定の背景と要件：**

TechNova社では、マイクロサービスの実行基盤として Amazon ECS Fargate
を採用します。この選択は、運用負荷の最小化、自動スケーリング、セキュリティ強化の観点から決定されました。

**ECS Fargate基盤要件：**

1.  **クラスター設計方針**

    - **環境別クラスター分離**：dev/test/staging/prod環境ごとに独立したクラスター

    - **マルチリージョン構成**：東京リージョン（primary）、大阪リージョン（DR）での冗長化

    - **サービス分離**：事業部門別のクラスター分離によるセキュリティ境界強化

    - **リソース最適化**：ワークロード特性に応じたタスクサイズの動的調整

2.  **コンテナリソース設計**

【生産管理マイクロサービス群】

生産計画管理API：

\- CPU: 2.0 vCPU, Memory: 4GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (月末計画策定時)

\- 想定同時タスク数: 2-8個

\- 理由: 複雑する計画最適化アルゴリズムで高CPU要求

在庫管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 3.0 vCPU, Memory: 6GB (リアルタイム更新ピーク時)

\- 想定同時タスク数: 5-15個

\- 理由: 高頻度アクセス(8,000件/日)、リアルタイム性要求

生産工程追跡API：

\- CPU: 1.5 vCPU, Memory: 3GB (通常時)

\- CPU: 3.0 vCPU, Memory: 6GB (IoTデータ大量取込時)

\- 想定同時タスク数: 3-10個

\- 理由: IoTセンサーデータのリアルタイム処理

原材料管理API：

\- CPU: 0.5 vCPU, Memory: 1GB (通常時)

\- CPU: 2.0 vCPU, Memory: 4GB (月末調達計画時)

\- 想定同時タスク数: 2-6個

\- 理由: 低頻度アクセス(1,200件/日)、文書管理メイン

【販売管理マイクロサービス群】

受注管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (展示会後受注ラッシュ時)

\- 想定同時タスク数: 3-12個

\- 理由: 3秒以内のレスポンス要件、在庫確認処理

顧客管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 2.5 vCPU, Memory: 5GB (営業活動ピーク時)

\- 想定同時タスク数: 4-10個

\- 理由: 検索性能要件(100ms以内)、GDPR対応処理

出荷管理API：

\- CPU: 0.5 vCPU, Memory: 1GB (通常時)

\- CPU: 2.0 vCPU, Memory: 4GB (月末出荷集中時)

\- 想定同時タスク数: 2-8個

\- 理由: 中程度アクセス(600件/日)、外部API連携

請求管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (月末請求処理時)

\- 想定同時タスク数: 2-10個

\- 理由: 高精度要求(金額計算)、大量バッチ処理

【保守サービスマイクロサービス群】

機器管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 3.0 vCPU, Memory: 6GB (新製品リリース時)

\- 想定同時タスク数: 3-12個

\- 理由: 文書管理(技術文書・動画)、検索性能要件

保守履歴API：

\- CPU: 1.5 vCPU, Memory: 3GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (繁忙期)

\- 想定同時タスク数: 5-20個

\- 理由: 高頻度アクセス(3,000-8,000件/日)、モバイル対応

予約管理API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 3.0 vCPU, Memory: 6GB (設備トラブル多発時)

\- 想定同時タスク数: 3-10個

\- 理由: リアルタイム性、最適化アルゴリズム

部品管理API：

\- CPU: 0.5 vCPU, Memory: 1GB (通常時)

\- CPU: 2.0 vCPU, Memory: 4GB (故障多発時)

\- 想定同時タスク数: 2-8個

\- 理由: 中程度アクセス(800件/日)、予測分析処理

【IoTマイクロサービス群】

デバイス接続API：

\- CPU: 2.0 vCPU, Memory: 4GB (固定)

\- 想定同時タスク数: 5-8個

\- 理由: 8,000台の同時接続管理、高可用性要求

テレメトリAPI：

\- CPU: 4.0 vCPU, Memory: 16GB (固定)

\- 想定同時タスク数: 8-15個

\- 理由: 大容量データ(1.8TB/日)、リアルタイム処理

分析API：

\- CPU: 8.0 vCPU, Memory: 32GB (バッチ処理時)

\- CPU: 2.0 vCPU, Memory: 8GB (通常時)

\- 想定同時タスク数: 3-10個

\- 理由: 機械学習処理、大量データ分析

アラートAPI：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (異常検知ピーク時)

\- 想定同時タスク数: 3-12個

\- 理由: 30秒以内の通知要件、高可用性(99.99%)

【共通マイクロサービス群】

認証API：

\- CPU: 2.0 vCPU, Memory: 4GB (通常時)

\- CPU: 6.0 vCPU, Memory: 12GB (ログインラッシュ時)

\- 想定同時タスク数: 5-20個

\- 理由: 全ユーザー(17,000名)の認証、100ms以内要件

通知API：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 4.0 vCPU, Memory: 8GB (大量通知時)

\- 想定同時タスク数: 3-15個

\- 理由: 20,000件/日の通知配信、多チャネル対応

マスターデータAPI：

\- CPU: 1.0 vCPU, Memory: 2GB (通常時)

\- CPU: 2.0 vCPU, Memory: 4GB (データ同期時)

\- 想定同時タスク数: 4-8個

\- 理由: 50ms以内のレスポンス、データ整合性要求

レポーティングAPI：

\- CPU: 4.0 vCPU, Memory: 16GB (レポート生成時)

\- CPU: 1.0 vCPU, Memory: 4GB (通常時)

\- 想定同時タスク数: 2-8個

\- 理由: 大容量レポート(100万行)、複雑なデータ統合

3.  **オートスケーリング設計**

    - **Target Tracking Scaling**：CPU利用率70%、メモリ利用率80%を目標値

    - **Step Scaling**：急激な負荷増加への段階的スケーリング

    - **Scheduled
      Scaling**：営業時間・月末処理等の予測可能な負荷への事前スケーリング

    - **カスタムメトリクス**：API
      レスポンス時間、キュー長に基づくスケーリング

4.  **ネットワーク・セキュリティ要件**

    - **VPC内実行**：すべてのタスクをプライベートサブネット内で実行

    - **サービスディスカバリ**：AWS Cloud Map による内部DNS解決

    - **Load Balancer統合**：ALB/NLB経由でのトラフィック分散

    - **セキュリティグループ**：マイクロサービス間の最小権限通信制御

**データベース基盤設計**

**Amazon Aurora採用の戦略的意義：**

Aurora Serverless
v2を中心としたデータベース基盤により、マイクロサービスごとのデータ独立性と運用効率性を両立します。

**Aurora設計要件：**

1.  **データベース分離戦略**

> 【生産管理系データベース群】
>
> aurora-prod-manufacturing-planning:
>
> \- 用途: 生産計画管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 150GB
>
> \- 接続数: 50 (計画最適化処理でCPU集約的)
>
> \- Read Replica: 1台 (レポート・分析用)
>
> aurora-prod-manufacturing-inventory:
>
> \- 用途: 在庫管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 200GB
>
> \- 接続数: 100 (高頻度アクセス8,000件/日)
>
> \- Read Replica: 2台 (リアルタイム参照・バックアップ用)
>
> aurora-prod-manufacturing-tracking:
>
> \- 用途: 生産工程追跡API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 300GB
>
> \- 接続数: 80 (IoTデータ大量書き込み)
>
> \- Read Replica: 1台 (工程分析用)
>
> aurora-prod-manufacturing-material:
>
> \- 用途: 原材料管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 100GB
>
> \- 接続数: 30 (低頻度アクセス、文書管理メイン)
>
> \- Read Replica: 1台 (調達分析用)
>
> 【販売管理系データベース群】
>
> aurora-prod-sales-order:
>
> \- 用途: 受注管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 120GB
>
> \- 接続数: 80 (3秒レスポンス要件、トランザクション重要)
>
> \- Read Replica: 1台 (売上分析用)
>
> aurora-prod-sales-customer:
>
> \- 用途: 顧客管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 80GB
>
> \- 接続数: 60 (検索性能要件100ms以内)
>
> \- Read Replica: 1台 (営業分析・GDPR対応用)
>
> aurora-prod-sales-shipping:
>
> \- 用途: 出荷管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 60GB
>
> \- 接続数: 40 (中程度アクセス、外部API連携)
>
> \- Read Replica: 1台 (物流分析用)
>
> aurora-prod-sales-billing:
>
> \- 用途: 請求管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 100GB
>
> \- 接続数: 50 (高精度要求、監査対応)
>
> \- Read Replica: 2台 (財務分析・監査用)
>
> 【保守サービス系データベース群】
>
> aurora-prod-service-equipment:
>
> \- 用途: 機器管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 250GB
>
> \- 接続数: 70 (技術文書・動画管理、14,500台の機器情報)
>
> \- Read Replica: 1台 (機器分析用)
>
> aurora-prod-service-maintenance:
>
> \- 用途: 保守履歴API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 400GB
>
> \- 接続数: 120 (高頻度アクセス8,000件/日、モバイル対応)
>
> \- Read Replica: 2台 (履歴分析・レポート用)
>
> aurora-prod-service-appointment:
>
> \- 用途: 予約管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 50GB
>
> \- 接続数: 60 (リアルタイム性、最適化処理)
>
> \- Read Replica: 1台 (スケジュール分析用)
>
> aurora-prod-service-parts:
>
> \- 用途: 部品管理API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 80GB
>
> \- 接続数: 40 (予測分析処理、在庫管理)
>
> \- Read Replica: 1台 (需要予測分析用)
>
> 【IoT系データベース群】
>
> aurora-prod-iot-connectivity:
>
> \- 用途: デバイス接続API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 30GB
>
> \- 接続数: 100 (8,000台デバイス管理、高可用性要求)
>
> \- Read Replica: 2台 (冗長性・分析用)
>
> aurora-prod-iot-telemetry:
>
> \- 用途: テレメトリAPI専用
>
> \- Aurora MySQL 8.0 + Amazon Timestream併用
>
> \- Aurora: メタデータ管理 30GB, 接続数: 150
>
> \- Timestream: 時系列データ 2TB/月
>
> \- Read Replica: 1台 (メタデータ分析用)
>
> aurora-prod-iot-analytics:
>
> \- 用途: 分析API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 200GB
>
> \- 接続数: 60 (機械学習結果、分析設定)
>
> \- Read Replica: 2台 (分析結果配信・バックアップ用)
>
> aurora-prod-iot-alert:
>
> \- 用途: アラートAPI専用
>
> \- Aurora MySQL 8.0, 想定データ量: 40GB
>
> \- 接続数: 80 (高可用性99.99%、30秒以内通知)
>
> \- Read Replica: 2台 (アラート分析・冗長性用)
>
> 【共通系データベース群】
>
> aurora-prod-common-auth:
>
> \- 用途: 認証API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 50GB
>
> \- 接続数: 200 (17,000ユーザー、100ms要件)
>
> \- Read Replica: 3台 (負荷分散・高可用性・監査用)
>
> aurora-prod-common-notification:
>
> \- 用途: 通知API専用
>
> \- Aurora MySQL 8.0, 想定データ量: 80GB
>
> \- 接続数: 80 (20,000件/日配信、履歴管理)
>
> \- Read Replica: 1台 (通知分析用)
>
> aurora-prod-common-master:
>
> \- 用途: マスターデータAPI専用
>
> \- Aurora MySQL 8.0, 想定データ量: 60GB
>
> \- 接続数: 150 (50ms要件、全システム参照)
>
> \- Read Replica: 3台 (負荷分散・データ整合性・バックアップ用)
>
> aurora-prod-common-reporting:
>
> \- 用途: レポーティングAPI専用
>
> \- Aurora MySQL 8.0, 想定データ量: 500GB
>
> \- 接続数: 100 (大容量レポート、複雑な統合処理)
>
> \- Read Replica: 2台 (レポート生成・分析用)
>
> **データベース設計サマリー**
>
> 総計：
>
> \- Auroraクラスター数: 20個 (各マイクロサービス1対1対応)
>
> \- Read Replica総数: 29台
>
> \- 総データ量: 約 2.9TB
>
> \- 総接続数: 約 1,500接続
>
> \- 月間推定コスト: \$15,000-20,000 (東京リージョン)
>
> リージョン別構成：
>
> 東京リージョン (Primary):
>
> \- 全20クラスター + Read Replica 29台
>
> 大阪リージョン (DR):
>
> \- 本番環境のみGlobal Database構成
>
> \- 自動フェイルオーバー対応
>
> **データベース間連携設計**
>
> クロスサービスデータアクセスパターン：
>
> 読み取り専用参照：
>
> \- 受注管理 → 在庫管理 (在庫確認)
>
> \- 生産計画 → 在庫管理 (材料確保)
>
> \- 保守履歴 → 機器管理 (機器情報参照)
>
> イベント駆動連携：
>
> \- 在庫管理 → 通知API (在庫アラート)
>
> \- 機器管理 → アラートAPI (異常通知)
>
> \- 受注管理 → レポーティング (売上データ連携)
>
> API経由連携：
>
> \- 認証API → 全サービス (認証情報検証)
>
> \- マスターデータAPI → 全サービス (マスター参照)

2.  **パフォーマンス・可用性要件**

    - **Aurora Serverless v2**：自動スケーリング（ACU 0.5-128の範囲）

    - **Multi-AZ配置**：可用性99.95%の要件達成

    - **自動バックアップ**：Point-in-Time Recovery 7日間保持

    - **暗号化**：保存データ・転送中データの完全暗号化

3.  **災害対策・マルチリージョン構成**

    - **Aurora Global
      Database**：東京→大阪リージョンへの自動レプリケーション

    - **RPO要件**：1時間以内のデータ復旧ポイント

    - **RTO要件**：4時間以内の業務復旧時間

    - **フェイルオーバー**：手動フェイルオーバー（本番運用安定後に自動化検討）

4.  **IAMデータベース認証実装**

認証方式の標準化：

\- ECSタスクロール → Aurora IAM認証

\- ユーザー/パスワード認証の段階的廃止

\- 接続プールの最適化（PgBouncer/ProxySQL活用）

\- 監査ログの完全取得（すべてのDB操作を記録）

**API管理基盤設計**

**API Gateway統合アーキテクチャ：**

マイクロサービス間通信とクライアントアクセスの統一的な管理により、セキュリティ・パフォーマンス・運用性を確保します。

**API Gateway要件：**

1.  **階層化API設計**

> 3層API構成：
>
> External API Gateway (Internet-facing):
>
> \- 顧客ポータル、モバイルアプリからのアクセス
>
> \- WAF統合、DDoS Protection、SSL/TLS終端
>
> \- レート制限: 1000req/min/APIキー
>
> Internal API Gateway (VPC内):
>
> \- マイクロサービス間の内部通信
>
> \- Service Mesh統合、mTLS認証
>
> \- レート制限: 10000req/min/サービス
>
> Management API Gateway (管理系):
>
> \- 監視、デプロイ、設定変更用API
>
> \- IP制限、強力な認証、監査ログ
>
> \- レート制限: 100req/min/管理者

2.  **BFF (Backend for Frontend) パターン実装**

    - **Web BFF**：Webアプリケーション最適化API

    - **Mobile BFF**：モバイルアプリ最適化API（データ軽量化）

    - **Partner BFF**：外部パートナー向けAPI（機能限定）

    - **Internal BFF**：社内システム向けAPI（フル機能）

3.  **API バージョニング・ライフサイクル管理**

    - **セマンティックバージョニング**：major.minor.patch形式

    - **後方互換性保証**：最低2バージョンの同時サポート

    - **段階的廃止**：6ヶ月の非推奨期間後に廃止

    - **API契約テスト**：スキーマ変更の自動検出・通知

4.  **パフォーマンス・スケーラビリティ要件**

    - **レスポンス時間**：90%ile \< 200ms（内部API）、\<
      500ms（外部API）

    - **スループット**：100,000 requests/minute（全体）

    - **キャッシング**：CloudFront統合による静的レスポンスキャッシュ

    - **圧縮**：gzip/brotli圧縮によるデータ転送最適化

**認証基盤設計**

**Amazon Cognito統合認証アーキテクチャ：**

企業全体の認証基盤として、社内外ユーザーの統一的な認証・認可機能を提供します。

**Cognito設計要件：**

1.  **ユーザープール設計**

> **複数ユーザープール構成：**
>
> **Employee User Pool (社員用):**
>
> \- Active Directory連携（SAML/OIDC）
>
> \- MFA必須（SMS + TOTP）
>
> \- パスワードポリシー: 12文字以上、複雑性要求
>
> \- セッション有効期限: 8時間（業務時間）

**Customer User Pool (顧客用):**

> \- メールアドレス認証
>
> \- MFA推奨（SMS）
>
> \- パスワードポリシー: 8文字以上
>
> \- セッション有効期限: 24時間
>
> **Partner User Pool (パートナー用):**
>
> \- 企業ドメイン検証
>
> \- MFA必須（TOTP）
>
> \- 招待制ユーザー登録
>
> \- セッション有効期限: 4時間

2.  **ID連携・フェデレーション**

> **Active Directory連携：ADFS経由でのSAML認証**
>
> **Google Workspace連携：OAuth 2.0によるSSO**
>
> **Microsoft 365連携：Azure AD経由の認証**
>
> **カスタムOIDCプロバイダー：将来の追加認証基盤対応**

3.  **認可・アクセス制御設計**

> **Role-Based Access Control (RBAC)：役割ベースの権限制御**
>
> **Attribute-Based Access Control (ABAC)：属性ベースのきめ細かい制御**
>
> **Dynamic
> Authorization：コンテキスト情報（場所・時間・デバイス）による動的制御**
>
> **Zero Trust Architecture：すべてのアクセスを検証・記録**

4.  **セキュリティ・コンプライアンス要件**

**不正アクセス対策：アカウントロックアウト、異常ログイン検知**

> **個人情報保護：GDPR/個人情報保護法準拠、データ暗号化**
>
> **監査証跡：全認証イベントの記録、改ざん防止**
>
> **定期レビュー：アクセス権限の月次レビュー、未使用アカウント削除**
>
> **IAMアプローチとアクセス管理戦略**

**IAMユーザー最小化とフェデレーションアクセス：**

TechNova社では、従来のIAMユーザーによる認証から、IAM Identity
Centerを中核としたフェデレーションアクセス基盤への移行を実施し、セキュリティ強化と運用効率化を実現します。

**5-1. IAMユーザー最小化戦略**

IAMユーザー利用の限定：

緊急時管理用のみ（最大10アカウント）：

\- 経営層用緊急アクセス: 3アカウント

\- CEO、CTO、CFO専用、年次ローテーション

\- 強力なパスワード + ハードウェアMFA必須

\- IT管理責任者用: 4アカウント

\- インフラ管理責任者、セキュリティ管理責任者

\- ネットワーク管理責任者、データベース管理責任者

\- 月次パスワード変更、使用履歴の厳格監査

\- 自動化用サービスアカウント: 3アカウント

\- バックアップ・災害復旧時の最終手段

\- Cross-Region フェイルオーバー用

\- AWS Secrets Manager での認証情報管理

段階的廃止計画：

\- 既存IAMユーザー（現在約360個：120アカウント×平均3個）の棚卸し

\- Identity Center移行による段階的無効化

\- 6ヶ月間での完全移行完了（緊急用10アカウント以外）

**5-2. IAM Identity Center統合設計**

フェデレーション基盤の設計：

Active Directory連携：

\- SAML 2.0 による SSO 統合

\- グループメンバーシップの自動同期

\- ユーザー属性（部門・役職・場所）の活用

Permission Set体系（前回AWSアカウント設計と整合）：

管理者権限セット（3種類）：

\- OrganizationAdmin：組織全体の管理（経営層・IT管理責任者）

\- SecurityAdmin：セキュリティ管理（セキュリティ管理者）

\- NetworkAdmin：ネットワーク管理（ネットワーク管理者）

開発者権限セット（3種類）：

\- DeveloperFull：開発環境のフルアクセス（開発者）

\- DeveloperRead：開発環境の読み取りのみ（新人・インターン）

\- QAEngineer：テスト環境の必要最小限権限（QAエンジニア）

運用者権限セット（3種類）：

\- OperationAdmin：本番環境の運用権限（運用管理者）

\- OperationReadOnly：本番環境の監視専用権限（監視オペレーター）

\- EmergencyAccess：緊急時対応の特別権限（緊急時対応者）

監査者権限セット（2種類）：

\- AuditorReadOnly：全環境の読み取り専用権限（内部監査）

\- ComplianceRead：コンプライアンス監査用権限（外部監査）

カスタム権限セット（4種類）：

\- PowerUserAccess-Custom：制限付きパワーユーザー権限

\- ReadOnlyAccess-Enhanced：拡張読み取り専用権限

\- SecurityAuditAccess：セキュリティ監査専用権限

\- ProductionSupport：本番サポート限定権限

アクセス割り当て自動化：

\- ADグループ → Permission Set の自動マッピング

\- 新入社員の自動プロビジョニング

\- 退職者の自動デプロビジョニング

**5-3. コンテナからAuroraへのIAMロール認証**

**20マイクロサービス別TaskRole設計：**

【生産管理系Taskロール】

\- task-role-manufacturing-planning

→ aurora-prod-manufacturing-planning への接続権限のみ

\- task-role-manufacturing-inventory

→ aurora-prod-manufacturing-inventory への接続権限のみ

\- task-role-manufacturing-tracking

→ aurora-prod-manufacturing-tracking への接続権限のみ

\- task-role-manufacturing-material

→ aurora-prod-manufacturing-material への接続権限のみ

【販売管理系Taskロール】

\- task-role-sales-order

→ aurora-prod-sales-order への接続権限のみ

\- task-role-sales-customer

→ aurora-prod-sales-customer への接続権限のみ

\- task-role-sales-shipping

→ aurora-prod-sales-shipping への接続権限のみ

\- task-role-sales-billing

→ aurora-prod-sales-billing への接続権限のみ

【保守サービス系Taskロール】

\- task-role-service-equipment

→ aurora-prod-service-equipment への接続権限のみ

\- task-role-service-maintenance

→ aurora-prod-service-maintenance への接続権限のみ

\- task-role-service-appointment

→ aurora-prod-service-appointment への接続権限のみ

\- task-role-service-parts

→ aurora-prod-service-parts への接続権限のみ

【IoT系Taskロール】

\- task-role-iot-connectivity

→ aurora-prod-iot-connectivity への接続権限のみ

\- task-role-iot-telemetry

→ aurora-prod-iot-telemetry + Timestream への接続権限

\- task-role-iot-analytics

→ aurora-prod-iot-analytics への接続権限のみ

\- task-role-iot-alert

→ aurora-prod-iot-alert への接続権限のみ

【共通系Taskロール】

\- task-role-common-auth

→ aurora-prod-common-auth への接続権限のみ

\- task-role-common-notification

→ aurora-prod-common-notification への接続権限のみ

\- task-role-common-master

→ aurora-prod-common-master への接続権限のみ

\- task-role-common-reporting

→ aurora-prod-common-reporting への接続権限のみ

クロスサービスアクセス制御：

読み取り専用クロスアクセス用ロール：

\- task-role-readonly-inventory (在庫参照専用)

→ 受注管理・生産計画から在庫確認用

\- task-role-readonly-customer (顧客情報参照専用)

→ 保守サービスから顧客情報参照用

\- task-role-readonly-equipment (機器情報参照専用)

→ IoTサービスから機器情報参照用

認証フローの設計：

1\. ECS Task起動時にTaskロールを自動取得

2\. IAMロールベースでAurora認証トークン生成（15分有効期限）

3\. トークンを使用してAurora接続

4\. 接続セッションの監査ログ記録（CloudTrail + VPC Flow Logs）

**5-4. サービスロール統合管理**

自動化・運用サービス用ロール（120アカウント対応）：

AFT管理用ロール：

\- aft-execution-role

\- 120アカウントの作成・設定権限

\- Control Tower Operations権限

\- Organizations管理権限

CI/CDパイプライン用ロール：

\- codebuild-service-role-aft

\- AFTパイプライン実行権限

\- 静的解析ツール実行権限（tfsec, TFLint, checkov）

\- IAM Access Analyzer統合権限

監視・運用自動化用ロール：

\- lambda-execution-role-monitoring

\- 120アカウント横断のCloudWatch メトリクス収集

\- クロスアカウントSNS通知送信権限

\- Systems Manager パラメータ読み取り

バックアップ・災害復旧用ロール：

\- backup-service-role-cross-region

\- 全Auroraクラスター（20個）のスナップショット作成

\- S3 クロスリージョンレプリケーション

\- 東京→大阪リージョンでの復旧実行権限

**5-5. セキュリティ強化と監査体制**

120アカウント対応の監視・制御：

リアルタイム監視：

\- 120アカウント横断の異常APIコール検知

\- Identity Center経由のアクセス異常検知

\- 時間外・地域外アクセスのアラート

\- 緊急用IAMユーザー使用時の即座通知

定期的なアクセスレビュー：

\- 月次：各Permission Set（15種類）の使用状況レビュー

\- 四半期：120アカウントのクロスアカウントロール必要性検証

\- 年次：全TaskRole（20個）の最小権限見直し

自動修復メカニズム：

\- 不審なアクセスの自動一時停止

\- 未使用Permission Setの自動提案・削除

\- 120アカウント横断のパスワードポリシー違反検知

**5-6. 移行・運用計画（120アカウント対応）**

段階的移行スケジュール：

Phase 1（1-2ヶ月目）：

\- IAM Identity Center環境構築

\- AD連携設定とテストユーザーでの検証

\- 15種類Permission Set作成・テスト

Phase 2（3-4ヶ月目）：

\- 開発環境（30アカウント）でのフェデレーションアクセス開始

\- 20個のECS TaskロールによるAurora接続テスト

\- 既存IAMユーザー（約360個）の段階的移行開始

Phase 3（5-6ヶ月目）：

\- 全120アカウントへの適用完了

\- 緊急時用10IAMユーザー以外の完全無効化

\- 運用監視体制の本格稼働

継続的改善：

\- 120アカウントのアクセスパターン分析

\- Permission Set最適化（四半期レビュー）

\- 新サービス追加時の権限設計標準化

**5-7. コンプライアンス・監査対応**

120アカウント対応の規制要件：

SOX法対応：

\- 財務関連アカウント（請求管理等）への厳格なアクセス制御

\- 職務分掌の120アカウント横断での確実な実装

\- 四半期ごとの全アカウント権限棚卸し

ISO 27001対応：

\- 120アカウントの情報資産分類とアクセス管理

\- リスクベースのアクセス制御実装

\- マルチアカウント環境でのインシデント対応

監査証跡の完全性：

\- 120アカウント横断の全アクセスイベント記録

\- CloudTrail Organizationsレベルでの集中管理

\- 監査人による独立検証の支援体制

**ストレージ・データ管理要件**

**階層化ストレージ戦略：**

データの特性・アクセスパターンに応じた最適なストレージ選択により、コスト効率と性能を両立します。

1.  **Amazon S3活用戦略**

用途別バケット構成（20マイクロサービス対応）：

マイクロサービス別アプリケーションデータ:

\- technova-manufacturing-data-prod (Standard)

\- technova-sales-data-prod (Standard)

\- technova-service-data-prod (Standard)

\- technova-iot-data-prod (Standard)

\- technova-common-data-prod (Standard)

各マイクロサービス群の設定ファイル、テンプレート、静的アセット

バージョニング有効、MFA Delete保護

統合バックアップデータ:

\- technova-backup-prod (Standard-IA → Glacier)

20個のAuroraクラスターのバックアップ統合管理

アプリケーションログアーカイブ（20サービス分）

ライフサイクルポリシー: 30日後IA、90日後Glacier

IoTデータレイク（拡張対応）:

\- technova-iot-datalake-prod (Standard → IA → Glacier)

テレメトリデータ（日次1.8TB→月次50TB）

デバイス接続ログ（8,000台分）

分析結果データ（機械学習モデル含む）

パーティション設計: service/year/month/day/hour

マイクロサービス別ドキュメント管理:

\- technova-documents-manufacturing-prod

\- technova-documents-sales-prod

\- technova-documents-service-prod

\- technova-documents-iot-prod

\- technova-documents-common-prod

技術文書、マニュアル、図面、API仕様書

CloudFront連携、CDN配信最適化

機密データ分離ストレージ:

\- technova-confidential-customer-prod (Standard, 強化暗号化)

\- technova-confidential-financial-prod (Standard, 強化暗号化)

顧客個人情報、財務データの分離保存

GDPR/個人情報保護法対応、法的保持期間管理

2.  データベース補完ストレージ（20サービス対応）

サービス別キャッシュ・補完ストレージ：

Amazon ElastiCache Redis:

\- redis-cluster-auth-prod (認証セッション管理)

\- redis-cluster-inventory-prod (在庫リアルタイムキャッシュ)

\- redis-cluster-iot-prod (IoTデータ高速アクセス)

\- redis-cluster-common-prod (マスターデータキャッシュ)

Amazon DynamoDB:

\- dynamodb-manufacturing-config-prod (生産設定情報)

\- dynamodb-sales-session-prod (販売セッション管理)

\- dynamodb-iot-metadata-prod (IoTデバイスメタデータ)

\- dynamodb-common-audit-prod (監査ログ高速検索)

Amazon OpenSearch:

\- opensearch-application-logs-prod (20サービスのログ統合検索)

\- opensearch-iot-analytics-prod (IoTデータ全文検索)

\- opensearch-customer-search-prod (顧客情報検索)

Amazon Timestream:

\- timestream-iot-telemetry-prod (IoTテレメトリデータ)

\- timestream-performance-metrics-prod (20サービスのパフォーマンス指標)

\- timestream-audit-events-prod (監査イベント時系列管理)

3.  データ保護・災害対策（20クラスター対応）

クロスリージョンレプリケーション:

重要データの大阪リージョン自動レプリケーション

S3バケット：

\- 全本番バケット（15個）の大阪リージョン自動レプリケーション

\- IoTデータレイクの選択的レプリケーション（直近3ヶ月分）

Aurora Global Database:

\- 20個のAuroraクラスター全てのGlobal Database設定

\- 東京（Primary）→ 大阪（Secondary）の自動レプリケーション

\- RPO: 1時間、RTO: 4時間の要件達成

統合バックアップ管理:

AWS Backup統合管理（20サービス対応）

\- 製造系DBの日次バックアップ（7日保持）

\- 販売系DBの日次バックアップ（30日保持）

\- IoT系DBの週次バックアップ（90日保持）

\- 共通系DBの日次バックアップ（365日保持）

データ暗号化:

\- 保存時・転送時の完全暗号化（KMS管理キー）

\- サービス別暗号化キー（20個のKMSキー）

\- クロスリージョン暗号化キーレプリケーション

アクセス監査:

\- CloudTrail による20アカウント×20サービスのデータアクセス記録

\- S3 Access Logging の全バケット有効化

\- VPC Flow Logs による通信監査

4.  データライフサイクル管理（20サービス統合）

階層化データライフサイクル:

Hot Data (頻繁アクセス):

\- 製造系：生産計画・在庫データ（Standard Storage）

\- 販売系：受注・顧客データ（Standard Storage）

\- IoT系：直近1週間のテレメトリデータ（Standard Storage）

Warm Data (定期アクセス):

\- 製造系：過去1年の生産実績（Standard-IA）

\- 販売系：過去2年の取引履歴（Standard-IA）

\- IoT系：過去1ヶ月の分析済みデータ（Standard-IA）

Cold Data (アーカイブ):

\- 全サービス：過去3年以上のデータ（Glacier）

\- 法的保持要件：7年保存データ（Glacier Deep Archive）

自動階層化設定:

\- 30日後: Standard → Standard-IA

\- 90日後: Standard-IA → Glacier

\- 365日後: Glacier → Deep Archive（法的要件対応）

データ削除・パージ:

\- GDPR準拠：個人データの自動削除（要求後30日以内）

\- 法的保持期間満了：自動削除（監査ログ保持）

5.  容量計画・コスト最適化（20サービス統合）

ストレージ容量見積もり:

S3総容量（月次増加）:

\- アプリケーションデータ: 500GB/月

\- バックアップデータ: 2TB/月（20個DB分）

\- IoTデータレイク: 50TB/月

\- ドキュメント管理: 200GB/月

\- 機密データ: 100GB/月

年間総増加量: 約640TB

データベース容量（20クラスター）:

\- 総データ量: 2.9TB（初期）

\- 月次増加率: 15%

\- 年間増加量: 約1.5TB

コスト最適化戦略:

\- S3 Intelligent-Tiering: 自動コスト最適化

\- Reserved Capacity: DynamoDB・ElastiCache予約容量

\- Data Transfer Optimization: CloudFront活用

\- 月次コスト分析: サービス別・アカウント別コスト可視化

推定月間ストレージコスト:

\- S3: \$8,000-12,000

\- Aurora: \$15,000-20,000

\- DynamoDB: \$2,000-3,000

\- ElastiCache: \$3,000-4,000

\- その他: \$2,000-3,000

総計: \$30,000-42,000/月

6.  データガバナンス・コンプライアンス（20サービス統合）

データ分類・管理:

機密レベル別管理:

\- Top Secret: 財務データ、個人情報（強化暗号化）

\- Secret: 顧客データ、取引情報（標準暗号化）

\- Internal: 製造データ、技術情報（標準暗号化）

\- Public: マニュアル、仕様書（基本暗号化）

データ所有権管理:

\- 製造系データ: 製造部門管理

\- 販売系データ: 営業部門管理

\- IoTデータ: 技術部門管理

\- 共通データ: IT部門管理

規制対応:

\- GDPR: 個人データの厳格管理・削除権対応

\- 個人情報保護法: 日本の個人情報保護規制対応

\- SOX法: 財務データの完全性・可用性確保

\- ISO 27001: 情報セキュリティ管理体系準拠

監査・レポーティング:

\- 月次データ利用レポート（20サービス別）

\- 四半期コンプライアンスレポート

\- 年次データ棚卸し・リテンションレビュー

クロスアカウントネットワークアーキテクチャ設計（120アカウント対応）

セキュアハイブリッド・クロスアカウントネットワーク構成：

TechNova社の120アカウント構成において、オンプレミス統合、20マイクロサービス間通信、グローバルDNS統合、パフォーマンス最適化、包括的監視を実現する完全なネットワーク基盤を構築します。

1.  アカウント・ネットワーク対応関係（120アカウント完全版）

> 【組織階層とネットワーク構成】
>
> Root Management Account (AWS Organizations Root)
>
> └── VPC: なし（請求・組織管理のみ）
>
> Security Account (セキュリティ統合管理)
>
> ├── VPC: 10.200.0.0/16 (Security Operations Center)
>
> ├── Subnets:
>
> │ ├── Public: 10.200.1.0/24, 10.200.2.0/24 (管理アクセス)
>
> │ ├── Private: 10.200.10.0/24, 10.200.11.0/24 (SIEM, SOC)
>
> │ └── Endpoints: 10.200.20.0/24, 10.200.21.0/24
>
> ├── Services: Security Hub, GuardDuty, Config統合
>
> └── Cross-Account Role: 全120アカウントからのログ・監査データ受信
>
> Shared Services Account (共通インフラ統合)
>
> ├── VPC: 10.100.0.0/16 (Shared Infrastructure Hub)
>
> ├── Subnets:
>
> │ ├── Public: 10.100.1.0/24, 10.100.2.0/24 (ALB, CloudFront Origin)
>
> │ ├── Private: 10.100.10.0/24, 10.100.11.0/24 (ECR, DNS)
>
> │ ├── Database: 10.100.20.0/24, 10.100.21.0/24 (共通DB)
>
> │ └── Endpoints: 10.100.30.0/24, 10.100.31.0/24
>
> ├── Services:
>
> │ ├── ECR: 全20サービス用コンテナレジストリ
>
> │ ├── Route 53: Public/Private Hosted Zones
>
> │ ├── Certificate Manager: SSL/TLS証明書統合管理
>
> │ └── Parameter Store: 設定情報統合管理
>
> └── RAM共有: VPC Endpoints, Route 53 Resolver Rules
>
> Network Hub Account (ネットワーク中央管理)
>
> ├── VPC: 10.150.0.0/16 (Network Operations Center)
>
> ├── Subnets:
>
> │ ├── Public: 10.150.1.0/24, 10.150.2.0/24 (NAT Gateway, VPN)
>
> │ ├── Transit GW: 10.150.10.0/24, 10.150.11.0/24 (TGW Attachments)
>
> │ ├── Resolver: 10.150.20.0/24, 10.150.21.0/24 (DNS Endpoints)
>
> │ └── DirectConnect: 10.150.30.0/24, 10.150.31.0/24 (DX接続)
>
> ├── Services:
>
> │ ├── Transit Gateway: 全120アカウント接続ハブ
>
> │ ├── DirectConnect Gateway: オンプレミス接続
>
> │ ├── Site-to-Site VPN: バックアップ接続
>
> │ └── Route 53 Resolver: ハイブリッドDNS統合
>
> └── Network Monitoring: 全アカウント通信監視
>
> 【事業部門別アカウント構成（96アカウント）】
>
> 製造部門（Manufacturing - 24アカウント）:
>
> ┌─ Development Environment (6アカウント) ─┐
>
> │ technova-mfg-dev-app → VPC: 10.0.0.0/16 │
>
> │ technova-mfg-dev-db → VPC: 10.0.1.0/16 │
>
> │ technova-mfg-dev-api → VPC: 10.0.2.0/16 │
>
> │ technova-mfg-dev-batch → VPC: 10.0.3.0/16 │
>
> │ technova-mfg-dev-monitor → VPC: 10.0.4.0/16 │
>
> │ technova-mfg-dev-network → VPC: 10.0.5.0/16 │
>
> └─────────────────────────────────────────────┘
>
> ┌─ Test Environment (6アカウント) ─┐
>
> │ technova-mfg-test-\* → VPC: 10.0.10-15.0/16 │
>
> └─────────────────────────────────────────────────┘
>
> ┌─ Staging Environment (6アカウント) ─┐
>
> │ technova-mfg-staging-\* → VPC: 10.0.20-25.0/16 │
>
> └─────────────────────────────────────────────────┘
>
> ┌─ Production Environment (6アカウント) ─┐
>
> │ technova-mfg-prod-\* → VPC: 10.0.30-35.0/16 │
>
> └─────────────────────────────────────────────────┘
>
> 販売部門（Sales - 24アカウント）:
>
> 同様の4環境 × 6アカウント構成 → VPC: 10.1.0.0-10.1.35.0/16
>
> 保守サービス部門（Service - 24アカウント）:
>
> 同様の4環境 × 6アカウント構成 → VPC: 10.2.0.0-10.2.35.0/16
>
> IoT部門（IoT - 24アカウント）:
>
> 同様の4環境 × 6アカウント構成 → VPC: 10.3.0.0-10.3.35.0/16

2.  Transit Gateway統合アーキテクチャ（RAM完全統合）

> 【Transit Gateway中央集権管理】
>
> Network Hub Account内のTransit Gateway:
>
> tgw-technova-main (ap-northeast-1)
>
> ├── 最大接続数: 5,000 VPC (120アカウント対応十分)
>
> ├── 帯域幅: 50Gbps (全アカウント対応)
>
> ├── BGP ASN: 64512 (プライベートASN)
>
> ├── Default Route Table: 無効化（セキュリティ強化）
>
> └── ECMP: 有効（冗長化・負荷分散）
>
> 【RAM (Resource Access Manager) 完全統合】
>
> 共有設定:
>
> ┌─ 共有リソース ─┐
>
> │ • Transit Gateway: tgw-technova-main │
>
> │ • Route 53 Resolver Rules (全20個) │
>
> │ • VPC Endpoints (S3, ECR, Secrets Manager等) │
>
> │ • Network ACL Templates │
>
> └─────────────────────────────────────────────┘
>
> ┌─ 共有戦略 ─┐
>
> │ Organizational Unit単位での共有: │
>
> │ • Root OU → Security, Shared Services, Network │
>
> │ • Manufacturing OU → 製造24アカウント │
>
> │ • Sales OU → 販売24アカウント │
>
> │ • Service OU → サービス24アカウント │
>
> │ • IoT OU → IoT24アカウント │
>
> └──────────────────────────────────────────────┘
>
> 【VPC Attachment完全マップ】
>
> 製造部門本番アプリアカウント:
>
> vpc-attachment-mfg-prod-app
>
> ├── Account ID: 123456789012 (technova-mfg-prod-app)
>
> ├── VPC ID: vpc-0abc123def456789a (10.0.30.0/16)
>
> ├── Attachment Subnets:
>
> │ ├── 10.0.30.200/28 (AZ-1a) - TGW専用
>
> │ └── 10.0.30.216/28 (AZ-1c) - TGW専用
>
> ├── Route Table Association: manufacturing-prod-rt
>
> ├── Route Propagation: 有効
>
> └── Tags: {"Department": "Manufacturing", "Environment": "prod"}
>
> (同様に120個のVPC Attachment設定)

3.  高度なRoute Table設計（セキュリティ分離）

> 【Route Table完全分離戦略】
>
> 製造部門本番用Route Table:
>
> manufacturing-prod-rt
>
> ├── Associated VPCs (6個):
>
> │ ├── 10.0.30.0/16 (mfg-prod-app)
>
> │ ├── 10.0.31.0/16 (mfg-prod-db)
>
> │ ├── 10.0.32.0/16 (mfg-prod-api)
>
> │ ├── 10.0.33.0/16 (mfg-prod-batch)
>
> │ ├── 10.0.34.0/16 (mfg-prod-monitor)
>
> │ └── 10.0.35.0/16 (mfg-prod-network)
>
> ├── Static Routes:
>
> │ ├── 10.100.0.0/16 → Shared Services (共通サービス)
>
> │ ├── 10.1.30.0/20 → Sales Prod APIs (制限的アクセス)
>
> │ ├── 10.200.0.0/16 → Security Account (監査)
>
> │ └── 192.168.0.0/16 → On-Premises (ハイブリッド)
>
> ├── Blackhole Routes (セキュリティ):
>
> │ ├── 10.0.0.0/20 → Dev環境への本番アクセス禁止
>
> │ ├── 10.0.10.0/20 → Test環境への本番アクセス禁止
>
> │ └── 10.0.20.0/20 → Staging以外の環境アクセス禁止
>
> └── Route Propagation Rules:
>
> ├── Accept: 同一部門・同一環境
>
> ├── Conditional: クロス部門API (ホワイトリスト)
>
> └── Deny: その他全て
>
> クロス部門API専用Route Table:
>
> cross-department-api-rt
>
> ├── Purpose: 部門間の制限的API通信
>
> ├── Associated VPCs:
>
> │ ├── API Accounts only (各部門のAPI account)
>
> │ └── 最小権限の原則適用
>
> ├── Allowed Routes:
>
> │ ├── manufacturing-api → sales-api (受注連携)
>
> │ ├── sales-api → manufacturing-api (在庫確認)
>
> │ ├── service-api → iot-api (保守データ連携)
>
> │ └── all-api → common-api (認証・通知)
>
> ├── Security Controls:
>
> │ ├── Time-based Access (営業時間のみ)
>
> │ ├── Rate Limiting (API Gateway統合)
>
> │ └── Audit Logging (全通信記録)
>
> └── Monitoring:
>
> ├── Real-time Traffic Analysis
>
> ├── Anomaly Detection
>
> └── Security Event Correlation
>
> 共通サービス用Route Table:
>
> common-services-rt
>
> ├── Associated VPCs:
>
> │ ├── 10.100.0.0/16 (Shared Services)
>
> │ ├── 10.200.0.0/16 (Security)
>
> │ └── 10.150.0.0/16 (Network Hub)
>
> ├── Inbound Access:
>
> │ ├── FROM: 全120アカウント
>
> │ ├── TO: 認証、DNS、ECR、監視サービス
>
> │ └── Protocol: HTTPS, gRPC, DNS
>
> ├── Security Enhancement:
>
> │ ├── WAF Integration
>
> │ ├── DDoS Protection
>
> │ └── API Rate Limiting
>
> └── High Availability:
>
> ├── Multi-AZ配置
>
> ├── Auto Scaling
>
> └── Health Check統合
>
> 管理・運用専用Route Table:
>
> management-rt
>
> ├── Associated VPCs:
>
> │ ├── Network Hub VPC
>
> │ ├── Security VPC
>
> │ └── Management Tool VPCs
>
> ├── Administrative Access:
>
> │ ├── SSH/RDP: 管理端末からのみ
>
> │ ├── SNMP: 監視システム用
>
> │ ├── Backup: バックアップシステム用
>
> │ └── Patch Management: Systems Manager
>
> ├── Outbound Rules:
>
> │ ├── 全120アカウントVPCへのアクセス
>
> │ ├── オンプレミス管理システム連携
>
> │ └── 外部監視サービス連携
>
> └── Audit & Compliance:
>
> ├── 全アクセスログ記録
>
> ├── Privileged Access Management
>
> └── Session Recording
>
> オンプレミス統合Route Table:
>
> onpremises-integration-rt
>
> ├── DirectConnect Associations:
>
> │ ├── dx-connection-primary (2Gbps)
>
> │ ├── dx-connection-secondary (2Gbps)
>
> │ └── Failover to Site-to-Site VPN
>
> ├── BGP Configuration:
>
> │ ├── Advertised Networks:
>
> │ │ ├── 10.0.0.0/8 (全AWS VPC)
>
> │ │ └── 169.254.169.253/32 (AWS DNS)
>
> │ ├── Received Networks:
>
> │ │ ├── 192.168.0.0/16 (On-premises)
>
> │ │ └── 172.16.0.0/12 (Legacy systems)
>
> ├── Traffic Engineering:
>
> │ ├── AS-PATH Prepending (トラフィック制御)
>
> │ ├── MED Attributes (コスト最適化)
>
> │ └── Community Tags (QoS制御)
>
> └── Hybrid Services:
>
> ├── DNS Resolution (Route 53 ↔ AD)
>
> ├── Directory Services (AD Connector)
>
> └── File Services (FSx連携)

4.  完全統合DNS設計（グローバル↔AWS↔オンプレミス）

> 【DNS統合アーキテクチャ完全版】
>
> Route 53 Public Hosted Zone (グローバルDNS):
>
> technova.com (Shared Services Account管理)
>
> ├── Authoritative Name Servers:
>
> │ ├── ns-1234.awsdns-56.com
>
> │ ├── ns-789.awsdns-01.net
>
> │ ├── ns-456.awsdns-78.org
>
> │ └── ns-123.awsdns-90.co.uk
>
> ├── DNSSEC: 有効化（改ざん防止）
>
> ├── Global DNS Records:
>
> │ ├── www.technova.com → CloudFront (d123456.cloudfront.net)
>
> │ ├── portal.technova.com → CloudFront (d789012.cloudfront.net)
>
> │ ├── api.technova.com → API Gateway
> (api-gw-12345.execute-api.ap-northeast-1.amazonaws.com)
>
> │ ├── admin.technova.com → ALB
> (admin-alb-67890.ap-northeast-1.elb.amazonaws.com)
>
> │ └── aws.technova.com → AWS専用サブドメイン委任
>
> ├── Geo-Location Routing:
>
> │ ├── Asia-Pacific → ap-northeast-1 (Tokyo)
>
> │ ├── North America → us-east-1 (Virginia)
>
> │ └── Europe → eu-west-1 (Ireland)
>
> ├── Health Checks:
>
> │ ├── Primary: Tokyo Region (30秒間隔)
>
> │ ├── Secondary: Osaka Region (DR)
>
> │ └── Failover: 3回失敗で自動切り替え
>
> └── Traffic Policies:
>
> ├── Weighted Routing (Blue/Green Deploy)
>
> ├── Latency-based Routing
>
> └── Geolocation Routing
>
> Route 53 Private Hosted Zone (AWS内部統合):
>
> technova.internal (Shared Services Account管理)
>
> ├── VPC Associations (120個):
>
> │ ├── Cross-Account Association権限設定
>
> │ ├── 各アカウントVPCとの関連付け
>
> │ └── 自動更新・同期機能
>
> ├── Service Discovery統合:
>
> │ ├── manufacturing.technova.internal
>
> │ │ ├── planning.manufacturing.technova.internal → 10.0.30.100
>
> │ │ ├── inventory.manufacturing.technova.internal → 10.0.30.101
>
> │ │ ├── tracking.manufacturing.technova.internal → 10.0.30.102
>
> │ │ └── material.manufacturing.technova.internal → 10.0.30.103
>
> │ ├── sales.technova.internal
>
> │ │ ├── order.sales.technova.internal → 10.1.30.100
>
> │ │ ├── customer.sales.technova.internal → 10.1.30.101
>
> │ │ ├── shipping.sales.technova.internal → 10.1.30.102
>
> │ │ └── billing.sales.technova.internal → 10.1.30.103
>
> │ ├── service.technova.internal (保守4サービス)
>
> │ ├── iot.technova.internal (IoT4サービス)
>
> │ └── common.technova.internal (共通4サービス)
>
> ├── Infrastructure Records:
>
> │ ├── infra.technova.internal
>
> │ │ ├── aurora-manufacturing-planning.infra.technova.internal
>
> │ │ ├── aurora-sales-order.infra.technova.internal
>
> │ │ └── (全20個のAuroraクラスターエンドポイント)
>
> │ ├── shared.technova.internal
>
> │ │ ├── ecr.shared.technova.internal
>
> │ │ ├── secrets.shared.technova.internal
>
> │ │ └── parameter-store.shared.technova.internal
>
> │ └── network.technova.internal
>
> │ ├── tgw.network.technova.internal
>
> │ ├── resolver.network.technova.internal
>
> │ └── dx-gateway.network.technova.internal
>
> └── Dynamic DNS Updates:
>
> ├── ECS Service Connect統合
>
> ├── Auto Scaling統合
>
> └── Lambda関数による自動更新
>
> Route 53 Resolver統合 (Network Hub Account):
>
> hybrid-dns-integration
>
> ├── Inbound Resolver Endpoints:
>
> │ ├── Primary: 10.150.20.10 (AZ-1a)
>
> │ ├── Secondary: 10.150.20.11 (AZ-1c)
>
> │ ├── Purpose: オンプレミス → AWS DNS解決
>
> │ └── Supported Queries:
>
> │ ├── \*.technova.internal → Private Hosted Zone
>
> │ ├── aws.technova.local → AWS統合ドメイン
>
> │ └── \*.amazonaws.com → VPC Endpoint Private DNS
>
> ├── Outbound Resolver Endpoints:
>
> │ ├── Primary: 10.150.20.20 (AZ-1a)
>
> │ ├── Secondary: 10.150.20.21 (AZ-1c)
>
> │ ├── Purpose: AWS → オンプレミス DNS解決
>
> │ └── Target DNS Servers:
>
> │ ├── dc01.technova.local: 192.168.1.10
>
> │ ├── dc02.technova.local: 192.168.1.11
>
> │ └── Backup DNS: 192.168.1.12
>
> ├── Resolver Rules (RAM共有):
>
> │ ├── technova.local → オンプレミスDC
>
> │ ├── \*.technova.local → オンプレミスDC
>
> │ ├── corp.technova.com → オンプレミスDC
>
> │ └── 適用対象: 全120アカウントVPC
>
> └── DNS Query Logging:
>
> ├── CloudWatch Logs統合
>
> ├── Query Pattern Analysis
>
> └── Anomaly Detection
>
> オンプレミスDNS統合:
>
> technova.local (Active Directory)
>
> ├── Domain Controllers:
>
> │ ├── dc01.technova.local (192.168.1.10)
>
> │ ├── dc02.technova.local (192.168.1.11)
>
> │ └── dc03.technova.local (192.168.1.12) - Backup
>
> ├── DNS Zones:
>
> │ ├── technova.local (AD統合ゾーン)
>
> │ ├── \_msdcs.technova.local (AD Services)
>
> │ ├── \_sites.technova.local (AD Sites)
>
> │ └── \_tcp.technova.local (SRV Records)
>
> ├── Conditional Forwarders:
>
> │ ├── aws.technova.local → 10.150.20.10, 10.150.20.11
>
> │ ├── technova.internal → 10.150.20.10, 10.150.20.11
>
> │ └── amazonaws.com → 10.150.20.10, 10.150.20.11
>
> ├── Hybrid Integration:
>
> │ ├── User Accounts: user.technova.local
>
> │ ├── Computer Accounts: computer.technova.local
>
> │ ├── Service Accounts: service.technova.local
>
> │ └── Application Services: app.technova.local
>
> └── Security Integration:
>
> ├── DNSSEC Validation
>
> ├── DNS Filtering (悪意ドメインブロック)
>
> └── Query Audit Logging
>
> 【Split-View DNS実装】
>
> 同一FQDN・環境別解決:
>
> api.technova.com の解決パターン:
>
> ├── External (Internet) Resolution:
>
> │ ├── Query Source: 外部ユーザー・パートナー
>
> │ ├── Resolution: CloudFront Distribution
>
> │ ├── Endpoint: d987654321.cloudfront.net
>
> │ ├── Features: WAF, DDoS Protection, Global CDN
>
> │ └── Authentication: API Key, OAuth 2.0
>
> ├── Internal (VPC) Resolution:
>
> │ ├── Query Source: 120アカウント内ECS Tasks
>
> │ ├── Resolution: Internal Application Load Balancer
>
> │ ├── Endpoint: internal-api-12345.ap-northeast-1.elb.amazonaws.com
>
> │ ├── Features: High Performance, Low Latency
>
> │ └── Authentication: IAM Roles, mTLS
>
> └── On-Premises Resolution:
>
> ├── Query Source: オンプレミスシステム
>
> ├── Resolution: VPN経由Internal ALB
>
> ├── Endpoint: 10.100.10.100 (Private IP)
>
> └── Authentication: AD統合, Kerberos
>
> portal.technova.com の最適化:
>
> ├── Hairpin Problem Resolution:
>
> │ ├── 問題: VPC内 → CloudFront → Origin (同じVPC)
>
> │ ├── 解決: VPC内Private Hosted Zone
>
> │ └── portal.technova.internal → Internal ALB
>
> ├── Cost & Performance Benefits:
>
> │ ├── Data Transfer Cost削減
>
> │ ├── Latency削減 (CloudFront Bypass)
>
> │ └── 内部最適化ルーティング
>
> └── Implementation:
>
> ├── Private Zone: portal.technova.internal → 10.100.10.200
>
> ├── Public Zone: portal.technova.com → CloudFront
>
> └── Conditional: VPC内は内部解決優先

5.  VPC Endpoint統合最適化（共有・パフォーマンス）

> 【VPC Endpoint共有戦略完全版】
>
> Shared Services Account内の中央集権Endpoint:
>
> central-vpc-endpoints
>
> ├── S3 Gateway Endpoint (無料):
>
> │ ├── 配置: 全120アカウントでローカル配置
>
> │ ├── Route Table統合: 自動プロパゲーション
>
> │ └── Policy: 最小権限（アカウント別制限）
>
> ├── ECR Interface Endpoints:
>
> │ ├── ECR API: api.ecr.ap-northeast-1.amazonaws.com
>
> │ ├── ECR DKR: \*.dkr.ecr.ap-northeast-1.amazonaws.com
>
> │ ├── Private DNS: 有効化
>
> │ ├── Security Group: sg-ecr-endpoint-shared
>
> │ └── RAM共有: 全120アカウント
>
> ├── Secrets Manager Interface Endpoint:
>
> │ ├── DNS: secretsmanager.ap-northeast-1.amazonaws.com
>
> │ ├── 用途: DB認証情報、API Keys
>
> │ ├── Security Group: sg-secrets-endpoint-shared
>
> │ └── Audit: 全アクセスログ記録
>
> ├── Systems Manager Interface Endpoints:
>
> │ ├── SSM: ssm.ap-northeast-1.amazonaws.com
>
> │ ├── SSM Messages: ssmmessages.ap-northeast-1.amazonaws.com
>
> │ ├── EC2 Messages: ec2messages.ap-northeast-1.amazonaws.com
>
> │ └── 用途: パッチ管理、設定管理
>
> └── CloudWatch Interface Endpoints:
>
> ├── Logs: logs.ap-northeast-1.amazonaws.com
>
> ├── Monitoring: monitoring.ap-northeast-1.amazonaws.com
>
> ├── Events: events.ap-northeast-1.amazonaws.com
>
> └── 用途: 統合監視・ログ管理
>
> アカウント別専用Endpoints:
>
> specialized-endpoints
>
> ├── 製造部門専用:
>
> │ ├── RDS Interface Endpoint
>
> │ │ ├── DNS: rds.ap-northeast-1.amazonaws.com
>
> │ │ ├── 用途: Aurora管理API
>
> │ │ └── Security: 製造DB accountのみアクセス
>
> │ └── SNS Interface Endpoint
>
> │ ├── DNS: sns.ap-northeast-1.amazonaws.com
>
> │ └── 用途: 生産アラート通知
>
> ├── IoT部門専用:
>
> │ ├── IoT Core Interface Endpoint
>
> │ │ ├── DNS: iot.ap-northeast-1.amazonaws.com
>
> │ │ └── 用途: デバイス接続・管理
>
> │ ├── Kinesis Interface Endpoint
>
> │ │ ├── DNS: kinesis.ap-northeast-1.amazonaws.com
>
> │ │ └── 用途: ストリーミングデータ処理
>
> │ └── Timestream Interface Endpoint
>
> │ ├── DNS: query.timestream.ap-northeast-1.amazonaws.com
>
> │ └── 用途: 時系列データ分析
>
> └── 共通サービス専用:
>
> ├── Lambda Interface Endpoint
>
> │ ├── DNS: lambda.ap-northeast-1.amazonaws.com
>
> │ └── 用途: サーバーレス処理
>
> └── STS Interface Endpoint
>
> ├── DNS: sts.ap-northeast-1.amazonaws.com
>
> └── 用途: IAM Role Assume
>
> 【VPC Endpoint DNS解決最適化】
>
> Private DNS統合:
>
> endpoint-dns-resolution
>
> ├── 解決優先順位:
>
> │ ├── 1. VPC内のPrivate DNS (VPC Endpoint)
>
> │ ├── 2. Route 53 Private Hosted Zone
>
> │ ├── 3. Route 53 Resolver Rules (オンプレミス)
>
> │ └── 4. Public DNS Resolution
>
> ├── カスタムDNS Routing:
>
> │ ├── \*.amazonaws.com → VPC Endpoint Private DNS
>
> │ ├── \*.technova.internal → Private Hosted Zone
>
> │ ├── \*.technova.local → オンプレミスDC
>
> │ └── その他 → Public DNS
>
> ├── Performance Optimization:
>
> │ ├── DNS Caching: 300秒TTL
>
> │ ├── Negative Caching: 60秒TTL
>
> │ └── Query Distribution: Round Robin
>
> └── Monitoring:
>
> ├── DNS Query Latency
>
> ├── Resolution Success Rate
>
> └── Endpoint Health Status
>
> 【クロスアカウントEndpoint利用フロー】
>
> technova-mfg-prod-app での S3アクセス例:
>
> step-by-step-flow
>
> ├── 1. Application Request:
>
> │ ├── ECS Task: aws s3 ls s3://technova-app-data-prod/
>
> │ └── DNS Query: s3.ap-northeast-1.amazonaws.com
>
> ├── 2. DNS Resolution:
>
> │ ├── VPC DNS Resolver: 169.254.169.253
>
> │ ├── Check: VPC Endpoint Private DNS
>
> │ └── Result: 10.0.30.200 (VPC Endpoint ENI)
>
> ├── 3. Network Routing:
>
> │ ├── Source: ECS Task (10.0.30.100)
>
> │ ├── Destination: VPC Endpoint (10.0.30.200)
>
> │ ├── Route: Local VPC routing
>
> │ └── Security Group: sg-s3-endpoint-access
>
> ├── 4. API Request Processing:
>
> │ ├── VPC Endpoint → S3 Service
>
> │ ├── IAM Role Validation
>
> │ ├── Bucket Policy Check
>
> │ └── Object Access Authorization
>
> ├── 5. Response Path:
>
> │ ├── S3 Service → VPC Endpoint
>
> │ ├── VPC Endpoint → ECS Task
>
> │ └── Data Transfer: Private network内
>
> └── 6. Audit & Logging:
>
> ├── VPC Flow Logs: 通信記録
>
> ├── S3 Access Logs: API操作記録
>
> └── CloudTrail: 管理操作記録

6.  マイクロサービス間通信設計（gRPC + Service Connect統合）

> 【ECS Service Connect + gRPC統合アーキテクチャ】
>
> Service Connect Namespace統合:
>
> microservices-communication
>
> ├── Manufacturing Namespace:
>
> │ ├── Namespace: manufacturing.technova.local
>
> │ ├── Services:
>
> │ │ ├── planning:9090 (生産計画gRPCサービス)
>
> │ │ ├── inventory:9091 (在庫管理gRPCサービス)
>
> │ │ ├── tracking:9092 (工程追跡gRPCサービス)
>
> │ │ └── material:9093 (原材料gRPCサービス)
>
> │ ├── Service Discovery:
>
> │ │ ├── 内部DNS: planning.manufacturing.technova.local
>
> │ │ ├── ヘルスチェック: gRPC Health Check Protocol
>
> │ │ └── Load Balancing: Round Robin
>
> │ └── Cross-Account Access:
>
> │ ├── sales.technova.local → inventory:9091
>
> │ └── common.technova.local → 認証サービス統合
>
> ├── Sales Namespace:
>
> │ ├── Namespace: sales.technova.local
>
> │ ├── Services:
>
> │ │ ├── order:9100 (受注管理gRPCサービス)
>
> │ │ ├── customer:9101 (顧客管理gRPCサービス)
>
> │ │ ├── shipping:9102 (出荷管理gRPCサービス)
>
> │ │ └── billing:9103 (請求管理gRPCサービス)
>
> │ ├── Service Discovery:
>
> │ │ ├── 内部DNS: order.sales.technova.local
>
> │ │ ├── ヘルスチェック: gRPC Health Check Protocol
>
> │ │ └── Load Balancing: Weighted Round Robin
>
> │ └── Cross-Account Access:
>
> │ ├── manufacturing.technova.local → order:9100
>
> │ └── service.technova.local → customer:9101
>
> ├── Service Namespace:
>
> │ ├── Namespace: service.technova.local
>
> │ ├── Services:
>
> │ │ ├── equipment:9110 (機器管理gRPCサービス)
>
> │ │ ├── maintenance:9111 (保守履歴gRPCサービス)
>
> │ │ ├── appointment:9112 (予約管理gRPCサービス)
>
> │ │ └── parts:9113 (部品管理gRPCサービス)
>
> │ └── Cross-Account Access:
>
> │ ├── iot.technova.local → equipment:9110
>
> │ └── manufacturing.technova.local → parts:9113
>
> ├── IoT Namespace:
>
> │ ├── Namespace: iot.technova.local
>
> │ ├── Services:
>
> │ │ ├── connectivity:9120 (デバイス接続gRPCサービス)
>
> │ │ ├── telemetry:9121 (テレメトリgRPCサービス)
>
> │ │ ├── analytics:9122 (分析gRPCサービス)
>
> │ │ └── alert:9123 (アラートgRPCサービス)
>
> │ └── High-Throughput Configuration:
>
> │ ├── telemetry:9121 → NLB経由（大容量データ）
>
> │ └── analytics:9122 → 機械学習処理用最適化
>
> └── Common Namespace:
>
> ├── Namespace: common.technova.local
>
> ├── Services:
>
> │ ├── auth:9130 (認証gRPCサービス)
>
> │ ├── notification:9131 (通知gRPCサービス)
>
> │ ├── master:9132 (マスターデータgRPCサービス)
>
> │ └── reporting:9133 (レポーティングgRPCサービス)
>
> └── Global Access:
>
> └── 全事業部門からのアクセス許可
>
> 【クロスアカウントgRPC通信フロー】
>
> technova-sales-prod-app → technova-mfg-prod-app 通信例:
>
> step-by-step-grpc-flow
>
> ├── 1. Service Discovery:
>
> │├── Source: order.sales.technova.local (10.1.30.100)
>
> │ ├── Target: inventory.manufacturing.technova.local
>
> │ ├── DNS Resolution: Route 53 Private Hosted Zone
>
> │ └── Result: 10.0.30.101:9091
>
> ├── 2. Network Routing:
>
> │ ├── Sales VPC → Transit Gateway
>
> │ ├── Route Table: cross-department-api-rt
>
> │ ├── Security Group: sg-cross-dept-grpc
>
> │ └── Destination: Manufacturing VPC
>
> ├── 3. gRPC Connection Establishment:
>
> │ ├── TLS Handshake: mTLS証明書検証
>
> │ ├── Service Connect Proxy経由
>
> │ ├── Load Balancing: Target Instance選択
>
> │ └── Connection Pool: 再利用設定
>
> ├── 4. gRPC Request Processing:
>
> │ ├── Method: /inventory.InventoryService/CheckStock
>
> │ ├── Metadata: Authentication Headers
>
> │ ├── Payload: Product IDs and Quantities
>
> │ └── Timeout: 5秒
>
> ├── 5. Response Handling:
>
> │ ├── gRPC Response: Stock Availability
>
> │ ├── Service Connect Metrics収集
>
> │ ├── Circuit Breaker状態更新
>
> │ └── Connection Return to Pool
>
> └── 6. Monitoring & Observability:
>
> ├── CloudWatch Metrics: レイテンシ、成功率
>
> ├── X-Ray Tracing: End-to-End追跡
>
> ├── Service Connect Insights: 通信パターン
>
> └── Custom Metrics: ビジネスKPI
>
> 【gRPC通信セキュリティ】
>
> mTLS (Mutual TLS) 設定:
>
> cross-account-mtls-config
>
> ├── Certificate Authority:
>
> │ ├── AWS Private CA統合
>
> │ ├── アカウント別証明書発行
>
> │ └── 自動更新・ローテーション
>
> ├── Service Certificates:
>
> │ ├── manufacturing-planning.crt
>
> │ ├── sales-order.crt
>
> │ ├── 有効期限: 90日
>
> │ └── 自動更新: AWS Certificate Manager
>
> ├── Authentication Flow:
>
> │ ├── Client Certificate Verification
>
> │ ├── Server Certificate Verification
>
> │ ├── Common Name Validation
>
> │ └── Certificate Revocation Check
>
> └── Security Groups:
>
> ├── Source: sg-sales-grpc
>
> ├── Target: sg-manufacturing-grpc
>
> ├── Port: 9090-9093 (gRPCサービス)
>
> └── Protocol: TCP (TLS encrypted)

7.  ハイブリッド接続設計（完全統合）

【AWS Direct Connect拡張構成】

DirectConnect統合設計:

hybrid-connectivity-architecture

├── Primary Connection (東京):

│ ├── 専用線: 2Gbps × 2本 (冗長化)

│ ├── Virtual Gateway: vgw-technova-primary

│ ├── BGP ASN: 65000 (オンプレミス)

│ └── Advertised Routes: 10.0.0.0/8 (全AWS VPC)

├── Secondary Connection (大阪):

│ ├── 専用線: 1Gbps × 2本 (DR用)

│ ├── Virtual Gateway: vgw-technova-secondary

│ ├── BGP ASN: 65001 (DR)

│ └── Standby Configuration

├── Virtual Interfaces:

│ ├── Private VIF 1: Manufacturing系アカウント

│ ├── Private VIF 2: Sales系アカウント

│ ├── Private VIF 3: Service系アカウント

│ ├── Private VIF 4: IoT系アカウント

│ └── Transit VIF: 全アカウント統合接続

└── Traffic Engineering:

├── AS-PATH Prepending: トラフィック制御

├── Local Preference: 優先経路設定

└── MED Attributes: コスト最適化

【Site-to-Site VPN統合】

VPN冗長化設計: vpn-backup-architecture

├── Primary VPN Connections:

│ ├── Tunnel 1: 東京AZ-1a → オンプレミス

│ ├── Tunnel 2: 東京AZ-1c → オンプレミス

│ ├── BGP Routing: 動的経路制御

│ └── Bandwidth: 1.25Gbps per tunnel

├── Secondary VPN Connections:

│ ├── Tunnel 3: 大阪AZ-3a → オンプレミス

│ ├── Tunnel 4: 大阪AZ-3b → オンプレミス

│ ├── Standby Mode: DirectConnect障害時

│ └── Automatic Failover: 180秒以内

├── Routing Priority:

│ ├── 1st: DirectConnect (Primary)

│ ├── 2nd: DirectConnect (Secondary)

│ ├── 3rd: VPN (Primary)

│ └── 4th: VPN (Secondary)

└── Monitoring:

├── Tunnel Status: リアルタイム監視

├── Latency Monitoring: 品質監視

├── Bandwidth Utilization: 使用率監視

└── Failover Testing: 月次テスト

【オンプレミス統合設計】

ハイブリッドサービス統合:

onpremises-integration

├── Active Directory統合:

│ ├── AD Connector: aws.technova.local

│ ├── User Authentication: SSO統合

│ ├── Computer Accounts: AWS EC2統合

│ └── Group Policy: ハイブリッド適用

├── File Services統合:

│ ├── FSx for Windows: ファイルサーバー移行

│ ├── DFS Namespace: 統合名前空間

│ ├── Backup Integration: AWS Backup

│ └── Access Permissions: AD統合

├── Database統合:

│ ├── AWS DMS: データ移行・同期

│ ├── VPN Tunnel: 専用DB接続

│ ├── Read Replica: オンプレ → Aurora

│ └── Cutover Plan: 段階的移行

└── Monitoring統合:

├── SCOM Integration: 既存監視連携

├── CloudWatch Agent: メトリクス送信

├── Hybrid Dashboard: 統合表示

└── Alert Correlation: アラート統合

8.  **パフォーマンス最適化（全面強化）**

【ネットワーク最適化戦略】

レイテンシ最適化: network-performance-optimization

├── Enhanced Networking:

│ ├── SR-IOV: 全ECSインスタンスで有効化

│ ├── DPDK: 高性能パケット処理

│ ├── CPU Affinity: ネットワーク処理最適化

│ └── Interrupt Coalescing: CPU負荷軽減

├── Placement Groups:

│ ├── Cluster PG: 関連サービス群配置

│ │ └── manufacturing-planning + aurora-manufacturing

│ ├── Partition PG: 可用性重視サービス

│ └── Spread PG: 独立性重視サービス

├── Instance Optimization:

│ ├── c6gn.xlarge: ネットワーク最適化インスタンス

│ ├── 25Gbps Enhanced Networking

│ ├── 低レイテンシ要件: \<1ms (同一AZ内)

│ └── 高スループット: \>10Gbps

└── Connection Optimization:

├── Keep-Alive: 長時間接続維持

├── Connection Pooling: gRPC接続プール

├── Multiplexing: HTTP/2活用

└── Compression: gRPC圧縮有効化

【帯域最適化】

Traffic Engineering: bandwidth-optimization

├── QoS (Quality of Service):

│ ├── Critical: 認証・決済系 (最高優先度)

│ ├── High: リアルタイム通信 (高優先度)

│ ├── Medium: バッチ処理 (中優先度)

│ └── Low: ログ・バックアップ (低優先度)

├── Traffic Shaping:

│ ├── Rate Limiting: API別帯域制限

│ ├── Burst Handling: 一時的スパイク対応

│ ├── Fair Queuing: サービス間公平性

│ └── Congestion Control: 輻輳制御

├── Load Distribution:

│ ├── ECMP: 複数経路負荷分散

│ ├── Weighted Routing: 能力別重み付け

│ ├── Geographic Load Balancing

│ └── Time-based Routing: 時間帯別最適化

└── Caching Strategy:

├── CloudFront: 静的コンテンツ

├── ElastiCache: データベースキャッシュ

├── API Gateway Caching: API応答キャッシュ

└── Application-level: アプリケーション内キャッシュ

【データベース接続最適化】

Aurora Connection Optimization: database-connection-optimization

├── Aurora Proxy統合:

│ ├── Connection Pooling: 効率的接続管理

│ ├── 20個Aurora Cluster対応

│ ├── Read/Write分離: 負荷分散

│ └── Failover: 透明な障害対応

├── Connection Management:

│ ├── Pool Size: アプリケーション別最適化

│ ├── Idle Time: 接続タイムアウト設定

│ ├── Health Check: 接続ヘルスチェック

│ └── Retry Logic: 接続失敗時のリトライ

├── Query Optimization:

│ ├── Prepared Statements: 実行計画再利用

│ ├── Batch Processing: バッチクエリ最適化

│ ├── Index Strategy: インデックス最適化

│ └── Query Cache: クエリ結果キャッシュ

└── Monitoring:

├── Performance Insights: クエリ性能分析

├── Slow Query Log: 低速クエリ特定

├── Connection Metrics: 接続状態監視

└── Resource Utilization: リソース使用率

9.  **統合ネットワーク監視・可視化（完全版）**

【VPC Flow Logs統合分析】

Flow Logs統合監視: vpc-flow-logs-integration

├── ログ収集範囲:

│ ├── 120アカウント全VPC

│ ├── Transit Gateway Flow Logs

│ ├── VPC Endpoint Flow Logs

│ └── DirectConnect/VPN Flow Logs

├── ストレージ戦略:

│ ├── S3 Storage: s3://technova-network-logs-prod/

│ ├── Partition: account-id/vpc-id/year/month/day/hour

│ ├── Compression: Gzip圧縮

│ └── Lifecycle: 90日後Glacier移行

├── 分析基盤:

│ ├── Amazon OpenSearch: リアルタイム検索

│ ├── Amazon Athena: SQL分析

│ ├── Amazon QuickSight: 可視化ダッシュボード

│ └── Custom Analytics: Lambda関数処理

└── 異常検知:

├── ML-based Detection: 異常通信パターン

├── Threshold Alerts: 帯域・接続数アラート

├── Security Anomalies: セキュリティ異常

└── Performance Degradation: 性能劣化検知

【gRPC通信監視（Service Connect統合）】

Service Connect監視統合: grpc-monitoring-integration

├── メトリクス収集:

│ ├── Request Rate: リクエスト/秒

│ ├── Response Time: P50, P90, P99レイテンシ

│ ├── Error Rate: エラー率

│ └── Throughput: スループット

├── Service Map自動生成:

│ ├── サービス間依存関係

│ ├── 通信フロー可視化

│ ├── 障害影響範囲特定

│ └── パフォーマンスボトルネック特定

├── Health Check統合:

│ ├── gRPC Health Check Protocol

│ ├── Custom Health Endpoints

│ ├── Circuit Breaker状態監視

│ └── Failover Detection

└── Alerting:

├── SLA Breach: SLA違反アラート

├── High Error Rate: エラー率上昇

├── Circuit Breaker Open: 回路断検知

└── Performance Degradation: 性能劣化

【X-Ray分散トレーシング】

End-to-End Tracing: distributed-tracing-xray

├── Trace Coverage:

│ ├── 全20マイクロサービス

│ ├── クロスアカウント通信

│ ├── Aurora Database Calls

│ └── 外部API呼び出し

├── Service Map:

│ ├── Visual Service Dependencies

│ ├── Response Time Distribution

│ ├── Error Propagation Analysis

│ └── Performance Bottleneck Identification

├── Trace Analysis:

│ ├── Request Flow Visualization

│ ├── Latency Breakdown Analysis

│ ├── Error Root Cause Analysis

│ └── Performance Regression Detection

└── Integration:

├── CloudWatch Metrics連携

├── Service Connect統合

├── Custom Application Metrics

└── Business KPI Correlation

【統合監視ダッシュボード】

Unified Monitoring Dashboard: unified-monitoring-dashboard

├── Network Overview:

│ ├── 120アカウント接続状況

│ ├── Transit Gateway通信量

│ ├── DirectConnect/VPN状態

│ └── DNS解決状況

├── Service Health:

│ ├── 20マイクロサービス状態

│ ├── gRPC通信品質

│ ├── Database接続状況

│ └── API応答性能

├── Security Status:

│ ├── セキュリティイベント

│ ├── 異常通信検知

│ ├── アクセス制御状況

│ └── コンプライアンス状況

├── Performance Metrics:

│ ├── End-to-End Latency

│ ├── Throughput Trends

│ ├── Resource Utilization

│ └── Cost Analysis

└── Business KPIs:

├── Transaction Success Rate

├── User Experience Metrics

├── Service Availability

└── Business Impact Analysis

10. **災害対策・マルチリージョン（完全統合）**

【東京-大阪リージョン間DR設計】

Multi-Region DR Architecture: disaster-recovery-architecture

├── Primary Region (東京):

│ ├── 全120アカウント本番環境

│ ├── Transit Gateway: tgw-technova-tokyo

│ ├── DirectConnect: 2Gbps × 2

│ └── Full Service Deployment

├── DR Region (大阪):

│ ├── Critical Services DR環境

│ ├── Transit Gateway: tgw-technova-osaka

│ ├── DirectConnect: 1Gbps × 2

│ └── Standby Configuration

├── Cross-Region Connectivity:

│ ├── VPC Peering: 東京 ↔ 大阪

│ ├── Transit Gateway Peering

│ ├── Data Replication Channels

│ └── DNS Failover Configuration

└── Failover Automation:

├── Health Check Monitoring

├── Automatic DNS Switching

├── Service Startup Automation

└── Data Consistency Verification

【Aurora Global Database DR】

Database DR Configuration: aurora-global-dr

├── Global Database Setup:

│ ├── Primary Cluster: 東京リージョン

│ ├── Secondary Cluster: 大阪リージョン

│ ├── Replication Lag: \<1秒

│ └── Read Replica: 両リージョン配置

├── Failover Process:

│ ├── Detection: Health Check失敗

│ ├── Decision: 自動/手動切り替え

│ ├── Promotion: Secondary→Primary昇格

│ └── DNS Update: エンドポイント切り替え

├── Data Consistency:

│ ├── Transaction Log同期

│ ├── Point-in-Time Recovery

│ ├── Backup Verification

│ └── Integrity Check

└── Recovery Testing:

├── Monthly DR Drill

├── RTO/RPO Verification

├── Application Compatibility

└── Performance Validation

【Route 53 DNS Failover】

DNS-based Failover: route53-failover

├── Health Check Configuration:

│ ├── Primary Endpoints: 東京リージョン

│ ├── Check Interval: 30秒

│ ├── Failure Threshold: 3回連続失敗

│ └── Recovery Threshold: 2回連続成功

├── Failover Records:

│ ├── Primary: technova.com → 東京ALB

│ ├── Secondary: technova.com → 大阪ALB

│ ├── TTL: 60秒（高速切り替え）

│ └── Health Check Association

├── Application-Level Failover:

│ ├── api.technova.com → API Gateway

│ ├── portal.technova.com → CloudFront

│ ├── \*.technova.internal → Internal Services

│ └── Database Endpoints → Aurora Global

└── Monitoring & Alerting:

├── Health Check Status

├── DNS Resolution Monitoring

├── Failover Event Notification

└── Recovery Status Tracking

**この完全統合版により、TechNova社は120アカウント構成での包括的なネットワーク基盤を実現できます。**

**可用性・信頼性要件（完全統合版）**

**TechNova社120アカウント構成における包括的可用性・信頼性設計**

1.  **全体可用性目標とSLA定義**

**ビジネス影響度別可用性要件**

**Critical（重要業務）- 99.99%可用性**

- 対象システム：

  - 認証サービス（technova-common-prod-auth）

  - 受注管理API（technova-sales-prod-app）

  - 在庫管理API（technova-mfg-prod-app）

  - 顧客ポータル（外部アクセス）

- 許容ダウンタイム：年間52.6分以内

- RTO：15分以内

- RPO：5分以内

**High（高重要業務）- 99.95%可用性**

- 対象システム：

  - 生産計画API、工程追跡API

  - 保守管理システム全般

  - IoTテレメトリ・分析API

  - マスターデータAPI

- 許容ダウンタイム：年間4.38時間以内

- RTO：30分以内

- RPO：15分以内

**Medium（標準業務）- 99.9%可用性**

- 対象システム：

  - バッチ処理系、レポーティングAPI

  - 非本番環境（dev/test/staging）

  - 管理・監視システム

- 許容ダウンタイム：年間8.77時間以内

- RTO：1時間以内

- RPO：30分以内

2.  **アカウントレベル可用性設計**

**120アカウント可用性戦略**

**管理アカウント階層の冗長化**

- Root Management Account:

  - Single Point of Failure回避のため最小機能のみ

  - AWS Organizations設定のバックアップとIaC管理

- Security Account:

  - Multi-AZ配置（ap-northeast-1a, 1c, 3a）

  - ログ収集の中断防止：複数S3バケット、クロスリージョンレプリケーション

- Shared Services Account:

  - 99.99%可用性要件（全サービスの依存関係）

  - Route 53：複数ネームサーバー、ヘルスチェック統合

  - ECR：クロスリージョンレプリケーション（東京→大阪）

- Network Hub Account:

  - Transit Gateway: 50Gbps帯域、自動フェイルオーバー

  - DirectConnect: 2Gbps×2回線冗長化

  - VPN Backup: 4トンネル冗長構成

**事業部門アカウントの可用性設計**

- 本番環境（prod）：

  - 各事業部門24アカウント中、appアカウントは99.99%

  - dbアカウントはAurora Multi-AZ、Global Database

- 非本番環境：

  - 99.9%要件、コスト最適化優先

  - 障害時は本番影響を最小化

**アカウント間依存関係の可用性管理**

**依存関係マップ**

- 全appアカウント → common-prod-auth（認証依存）

- 全appアカウント → shared-services（ECR、DNS依存）

- 全アカウント → network-hub（通信依存）

- 部門間連携：sales-prod-app ↔ mfg-prod-app（業務依存）

**依存関係障害対策**

- Circuit Breaker Pattern: 依存サービス障害時の自動迂回

- Graceful Degradation: 部分機能停止での継続運用

- Retry with Exponential Backoff: 一時的障害への対応

- Bulkhead Pattern: 障害の分離と拡散防止

3.  **ECS Fargate可用性設計（20サービス対応）**

**コンテナレベル可用性**

**ECS Service設定（サービス別）**

**Critical Services（99.99%要件）**

- technova-common-prod-auth:

  - Task数: 最小3, 希望6, 最大20

  - Multi-AZ配置: 各AZに最低1タスク

  - Health Check: /health エンドポイント、10秒間隔

  - Auto Scaling: CPU 50%, Memory 70%でスケール

- technova-sales-prod-app（受注管理）:

  - Task数: 最小2, 希望4, 最大15

  - Placement Strategy: AZ分散必須

  - Health Check: gRPC Health Check Protocol

**High Services（99.95%要件）**

- 製造系4サービス（planning, inventory, tracking, material）:

  - Task数: 最小2, 希望3, 最大10

  - Service Connect: Namespace内冗長化

- IoT系4サービス:

  - telemetry: 最小3タスク（大容量処理のため）

  - connectivity: 最小2タスク（8,000台デバイス対応）

**ECS Cluster可用性**

**Cluster配置戦略**

- 各事業部門VPC内に独立クラスター

- Multi-AZ配置：ap-northeast-1a, 1c（東京）

- DR環境：ap-northeast-3a, 3b（大阪）

- Fargate Spot併用：コスト最適化（非Critical）

**Service Connect可用性**

- Namespace冗長化：各AZにService Connect Proxy

- DNS Failover：Service Discovery自動更新

- Load Balancing：Round Robin + Health Check

- Circuit Breaker：サービス間通信の障害分離

**コンテナイメージ可用性**

**ECR高可用性設計**

- Shared Services Account内の中央ECR

- Multi-Region Replication：東京→大阪自動同期

- Image Scanning：脆弱性自動検出・アラート

- Lifecycle Policy：古いイメージの自動削除

- Pull Through Cache：外部レジストリの高速化

**イメージデプロイ戦略**

- Blue/Green Deployment：ゼロダウンタイム

- Canary Release：段階的リリース（10%→50%→100%）

- Rollback機能：30秒以内の自動ロールバック

- Health Check統合：異常検知時の自動停止

4.  **Aurora可用性設計（20クラスター対応）**

**Aurora Cluster可用性**

**高可用性構成（20クラスター）**

**Critical Database Clusters（99.99%）**

- aurora-common-auth:

  - Multi-AZ（3AZ分散）

  - Read Replica: 3台（負荷分散・冗長化）

  - Backup: 7日保持、PITRポイントインタイムリカバリ

- aurora-sales-order:

  - Multi-AZ、Read Replica: 2台

  - Global Database（東京→大阪レプリケーション）

**High Database Clusters（99.95%）**

- 製造系4クラスター、IoT系4クラスター:

  - Multi-AZ配置

  - Read Replica: 1-2台（負荷に応じて）

  - Automated Backup: 5日保持

**Aurora Serverless v2スケーリング**

- ACU（Aurora Capacity Unit）設定:

  - Critical: 0.5-64 ACU（高速スケーリング）

  - High: 0.5-32 ACU

  - Medium: 0.5-16 ACU

- Auto Pause：非Critical環境で15分非活動後

- Cold Start最適化：Warmed Capacity Pool

**Aurora Global Database（DR対応）**

**東京-大阪間レプリケーション**

- Primary Cluster：東京リージョン（ap-northeast-1）

- Secondary Cluster：大阪リージョン（ap-northeast-3）

- Replication Lag：通常\<1秒、最大5秒

- RPO Target：1時間以内

**Failover設計**

- 手動Failover：15分以内（初期運用）

- 自動Failover：検討（安定運用後）

- DNS切り替え：Route 53 Health Check連動

- Application対応：Connection String自動更新

**Database接続可用性**

**Connection Pool最適化**

- Aurora Proxy活用：

  - Connection Pooling：効率的接続管理

  - Failover透明化：アプリケーション無変更

  - Read/Write分離：負荷分散

- IAM Database Authentication：

  - Token自動更新：15分間隔

  - 認証失敗時のRetry Logic

  - 接続エラー時のCircuit Breaker

5.  **ネットワーク可用性設計（120アカウント対応）**

**Transit Gateway可用性**

**TGW冗長化設計**

- 帯域幅：50Gbps（120アカウント対応）

- ECMP：複数経路負荷分散

- Route Table冗長化：部門別分離

- Cross-Region Peering：東京-大阪TGW間接続

**VPC Attachment可用性**

- Multi-AZ Attachment：各VPCで2AZ

- 帯域監視：利用率80%でアラート

- Health Check：VPC間通信の死活監視

**ハイブリッド接続可用性**

**DirectConnect冗長化**

- Primary：2Gbps × 2回線（東京）

- Secondary：1Gbps × 2回線（大阪）

- BGP設定：AS-PATH Prepending

- Automatic Failover：180秒以内

**VPN Backup**

- 4トンネル冗長構成

- IPSec設定：Dead Peer Detection

- Bandwidth：各1.25Gbps

- Health Check：10秒間隔

**DNS可用性設計**

**Route 53高可用性**

- Public Hosted Zone：

  - 4つのネームサーバー

  - DNSSEC有効化

  - Health Check：30秒間隔、3回失敗でFailover

- Private Hosted Zone：

  - 120アカウントVPC Association

  - Cross-Account権限管理

  - 動的DNS更新：ECS Service Connect連動

**Route 53 Resolver**

- Inbound/Outbound Endpoints：各2台冗長化

- Resolver Rules：RAM共有、全VPC適用

- DNS Query Logging：障害分析用

- Cache Optimization：TTL最適化

6.  **セキュリティ可用性統合**

**セキュリティサービス可用性**

**AWS Security Services**

- Security Hub：Multi-Region集約

- GuardDuty：全120アカウント有効化

- Config：継続的コンプライアンス監視

- CloudTrail：Organization-wide証跡、S3冗長保存

**WAF/Shield/Firewall Manager**

- WAF：API Gateway、ALB、CloudFront統合

- Shield Standard：全リソース自動適用

- Network Firewall：Multi-AZ配置

- Firewall Manager：中央集権ポリシー管理

**セキュリティ監視可用性**

**SIEM統合**

- OpenSearch：Multi-AZ配置

- ログ取り込み：Kinesis Data Firehose

- Real-time分析：Lambda関数処理

- Alert：SNS→PagerDuty→24時間監視

7.  **監視・アラート統合可用性**

**CloudWatch統合監視**

**Cross-Account監視**

- 120アカウント統合ダッシュボード

- カスタムメトリクス：ビジネスKPI

- Composite Alarm：複数条件組み合わせ

- Anomaly Detection：ML-based異常検知

**アラート階層化**

- Critical：即座PagerDuty→電話

- High：Slack通知→15分以内対応

- Medium：Email通知→4時間以内対応

- Low：Daily Report

**X-Ray分散トレーシング**

**End-to-End可視化**

- 全20マイクロサービス統合

- クロスアカウント通信追跡

- Service Map自動生成

- Performance異常の自動検知

8.  **災害対策・事業継続性**

**マルチリージョンDR**

**東京-大阪DR設計**

- Primary：東京（Full Active）

- Secondary：大阪（Warm Standby）

- RTO：4時間以内

- RPO：1時間以内

**DR切り替え手順**

1.  障害検知：Health Check 3分連続失敗

2.  判断：自動/手動切り替え判定

3.  DNS切り替え：Route 53 Failover

4.  Service起動：大阪リージョンサービス開始

5.  確認：疎通・性能・データ整合性確認

**バックアップ・リストア戦略**

**データバックアップ**

- Aurora：自動バックアップ7日、手動スナップショット月次

- ECS設定：AWS Config設定履歴

- 設定情報：Parameter Store、Secrets Manager

**設定バックアップ**

- Terraform State：S3バージョニング、Cross-Region複製

- Infrastructure as Code：Git管理、タグ付け

- Account設定：AWS Config Rules記録

9.  **可用性テスト・検証**

**定期的な可用性テスト**

**Chaos Engineering**

- 月次：単一AZ障害シミュレーション

- 四半期：リージョン障害シミュレーション

- 年次：完全DR切り替え訓練

**Game Day実施**

- シナリオ：本番同等環境での障害注入

- 参加者：開発・運用・ビジネス部門

- 評価：RTO/RPO達成状況、改善点抽出

**可用性メトリクス監視**

**SLA監視**

- Uptime計算：月次・年次レポート

- Mean Time to Detect（MTTD）：障害検知時間

- Mean Time to Repair（MTTR）：復旧時間

- Customer Impact：ビジネス影響分析

この包括的な可用性・信頼性設計により、TechNova社の120アカウント構成において、各システムの重要度に応じた適切な可用性レベルを確保し、ビジネス継続性を実現します。

## **セキュリティ要件**

**セキュリティ要件（完全統合版）**

**TechNova社120アカウント構成における包括的セキュリティアーキテクチャ**

1.  **全体セキュリティ戦略とコンプライアンス要件**

**セキュリティ設計原則**

**Zero Trust アーキテクチャの採用**

- すべてのネットワークトラフィック、ユーザーアクセス、デバイス接続を検証

- 「信頼せず、常に検証する」原則の徹底適用

- 最小権限の原則（Principle of Least Privilege）の厳格な実装

**多層防御（Defense in Depth）戦略**

- ネットワーク層、アプリケーション層、データ層の複数レイヤーでのセキュリティ制御

- 単一障害点の排除と冗長性の確保

- 各層での独立したセキュリティ監視と制御

**セキュリティ・バイ・デザイン（Security by Design）**

- 設計段階からのセキュリティ考慮

- 脅威モデリングに基づくリスク評価

- セキュリティ要件の明確化と実装

**コンプライアンス要件**

**法的・規制要件**

- **個人情報保護法**：顧客データの適切な取り扱いと保護

- **GDPR**：EU域内データの処理に関する厳格な規制対応

- **SOX法**：財務データの完全性と内部統制

- **ISO 27001**：情報セキュリティ管理システムの国際標準準拠

**業界標準準拠**

- **NIST Cybersecurity Framework**：セキュリティ管理の標準化

- **CIS Controls**：重要セキュリティ制御の実装

- **AWS Well-Architected
  Framework**：クラウドセキュリティベストプラクティス

2.  **アカウントレベルセキュリティ（120アカウント対応）**

**アカウント分離とセキュリティ境界**

**アカウント階層とセキュリティ境界設計**

**Root管理アカウント**

- **最小権限アクセス**：経営層3名のみアクセス可能

- **強力な認証**：ハードウェアMFA必須

- **監査証跡**：全アクションの完全記録

- **アクセス制限**：IP制限、時間制限の実装

**セキュリティ専用アカウント**

- **集中監視機能**：全120アカウントのセキュリティログ集約

- **独立性確保**：他アカウントからの影響を受けない独立運用

- **権限分離**：セキュリティ管理者とシステム管理者の役割分離

**アカウント間セキュリティ通信**

セキュリティ通信フロー：

各アカウント → Security Account → 集中監視

├── CloudTrail ログ

├── GuardDuty 検知情報

├── Config 設定変更履歴

├── Security Hub 統合レポート

└── VPC Flow Logs

クロスアカウント通信制御：

├── 最小権限によるAssumeRole設定

├── 時間制限付きアクセス（業務時間のみ）

├── 特定IPからのアクセス制限

└── 全通信の監査ログ記録

**アカウント別セキュリティ設定**

**本番環境アカウント（24アカウント）**

- **厳格なアクセス制御**：本番環境への変更は承認制

- **データ暗号化**：保存時・転送時の完全暗号化

- **監査ログ**：全操作の完全記録と長期保存（7年）

- **変更管理**：全変更の事前承認と影響評価

**開発・テスト環境アカウント（96アカウント）**

- **開発者権限**：必要最小限の権限付与

- **データマスキング**：本番データの機密性保護

- **アクセス時間制限**：業務時間外のアクセス制限

- **定期的なリソース削除**：不要リソースの自動削除

- 

3.  **Identity and Access Management（IAM）統合セキュリティ**

**IAM Identity Center統合認証**

**フェデレーション認証基盤**

認証フロー：

Active Directory → IAM Identity Center → 120アカウント

├── SAML 2.0 認証

├── グループベースの権限付与

├── 条件付きアクセス（時間・場所・デバイス）

└── セッション管理（自動タイムアウト）

**Permission Set設計とセキュリティ制御**

**管理者権限セット（厳格な制御）**

> {
>
> "OrganizationAdmin": {
>
> "AccessLevel": "Full",
>
> "MFA": "Required",
>
> "SessionDuration": "4時間",
>
> "IPRestriction": "本社IPのみ",
>
> "TimeRestriction": "業務時間のみ",
>
> "ApprovalRequired": "Yes"
>
> },
>
> "SecurityAdmin": {
>
> "AccessLevel": "SecurityServices",
>
> "MFA": "Required",
>
> "SessionDuration": "8時間",
>
> "IPRestriction": "セキュリティチームIPのみ",
>
> "AuditLogging": "Enhanced"
>
> }
>
> }

**開発者権限セット（環境別制御）**

> {
>
> "DeveloperFull": {
>
> "AccessLevel": "DevelopmentEnvironment",
>
> "MFA": "Required",
>
> "SessionDuration": "8時間",
>
> "ResourceLimits": "開発環境のみ",
>
> "CostControl": "月次予算制限"
>
> },
>
> "DeveloperRead": {
>
> "AccessLevel": "ReadOnly",
>
> "MFA": "Optional",
>
> "SessionDuration": "8時間",
>
> "ResourceScope": "開発環境のみ"
>
> }
>
> }

**サービスロールセキュリティ設計**

**ECS Task Role最小権限設計**

> {
>
> "20マイクロサービス別TaskRole": {
>
> "manufacturing-planning": {
>
> "DatabaseAccess": "aurora-prod-manufacturing-planning のみ",
>
> "S3Access": "専用バケットのみ",
>
> "SecretsManager": "専用シークレットのみ",
>
> "CloudWatchLogs": "専用ロググループのみ"
>
> },
>
> "sales-order": {
>
> "DatabaseAccess": "aurora-prod-sales-order のみ",
>
> "CrossServiceAPI": "inventory-check API のみ",
>
> "S3Access": "専用バケットのみ",
>
> "SecretsManager": "専用シークレットのみ"
>
> }
>
> }
>
> }

**IAM Database認証セキュリティ**

> Aurora IAM認証フロー：
>
> ECS Task → IAM Role → Database Token (15分有効)
>
> ├── トークン自動ローテーション
>
> ├── 接続時間制限
>
> ├── 接続数制限
>
> └── 全接続の監査ログ記録

4.  **ネットワークセキュリティ（多層防御）**

**VPC セキュリティ設計**

**ネットワーク分離とセキュリティ境界**

VPC分離戦略（120アカウント）：

管理系VPC (10.200.0.0/16)

├── Security Account VPC

├── Shared Services VPC

└── Network Hub VPC

事業部門VPC (10.0.0.0/8)

├── 製造部門 (10.0.0.0/14)

├── 販売部門 (10.1.0.0/14)

├── サービス部門 (10.2.0.0/14)

└── IoT部門 (10.3.0.0/14)

セキュリティ制御：

├── プライベートサブネット中心の設計

├── NATゲートウェイ経由の外部通信

├── VPC Endpoint による AWS サービスアクセス

└── Transit Gateway による制御された相互接続

セキュリティグループ設計

> {
>
> "セキュリティグループ階層": {
>
> "web-tier-sg": {
>
> "InboundRules": \[
>
> {
>
> "Protocol": "HTTPS",
>
> "Port": 443,
>
> "Source": "ALB Security Group",
>
> "Description": "ALB からのHTTPS通信のみ"
>
> }
>
> \]
>
> },
>
> "app-tier-sg": {
>
> "InboundRules": \[
>
> {
>
> "Protocol": "HTTP",
>
> "Port": 8080,
>
> "Source": "web-tier-sg",
>
> "Description": "Web層からのHTTP通信のみ"
>
> }
>
> \]
>
> },
>
> "db-tier-sg": {
>
> "InboundRules": \[
>
> {
>
> "Protocol": "MySQL",
>
> "Port": 3306,
>
> "Source": "app-tier-sg",
>
> "Description": "App層からのMySQL通信のみ"
>
> }
>
> \]
>
> }
>
> }
>
> }

**Network Firewall実装**

**ステートフルファイアウォール設定**

> \# Network Firewall Rule Groups
>
> StatefulRuleGroups:
>
> \- Name: "malware-protection"
>
> Rules:
>
> \- Action: "DROP"
>
> Header:
>
> Protocol: "TCP"
>
> Source: "ANY"
>
> Destination: "ANY"
>
> RuleOptions:
>
> \- Keyword: "content"
>
> Values: \["malware-signature-patterns"\]
>
> \- Name: "intrusion-detection"
>
> Rules:
>
> \- Action: "ALERT"
>
> Header:
>
> Protocol: "TCP"
>
> Source: "ANY"
>
> Destination: "ANY"
>
> RuleOptions:
>
> \- Keyword: "sid"
>
> Values: \["1001"\]
>
> \- Keyword: "msg"
>
> Values: \["Suspicious network activity detected"\]
>
> ドメインフィルタリング設定
>
> {
>
> "DomainFiltering": {
>
> "AllowedDomains": \[
>
> "\*.amazonaws.com",
>
> "\*.technova.com",
>
> "github.com",
>
> "registry.npmjs.org"
>
> \],
>
> "BlockedCategories": \[
>
> "malware",
>
> "phishing",
>
> "gambling",
>
> "adult-content"
>
> \],
>
> "CustomBlockList": \[
>
> "known-malicious-domains.txt",
>
> "cryptocurrency-mining-sites.txt"
>
> \]
>
> }
>
> }

5.  **Web Application Firewall（WAF）統合保護**

> **WAF設定とルール管理**
>
> **多層WAF配置**
>
> WAF配置戦略：
>
> CloudFront → WAF (Global)
>
> ├── DDoS Protection
>
> ├── Geo-blocking
>
> ├── Rate Limiting
>
> └── Bot Management
>
> ALB → WAF (Regional)
>
> ├── Application-specific Rules
>
> ├── Custom Rules
>
> ├── Managed Rule Groups
>
> └── IP Reputation Lists
>
> API Gateway → WAF (API Protection)
>
> ├── API-specific Rules
>
> ├── Request Validation
>
> ├── Rate Limiting per API Key
>
> └── Payload Inspection
>
> WAF ルール設定
>
> {
>
> "WAFRuleGroups": {
>
> "AWSManagedRules": {
>
> "CommonRuleSet": {
>
> "Enabled": true,
>
> "Priority": 1,
>
> "OverrideAction": "None"
>
> },
>
> "KnownBadInputsRuleSet": {
>
> "Enabled": true,
>
> "Priority": 2,
>
> "OverrideAction": "None"
>
> },
>
> "SQLiRuleSet": {
>
> "Enabled": true,
>
> "Priority": 3,
>
> "OverrideAction": "None"
>
> },
>
> "XSSRuleSet": {
>
> "Enabled": true,
>
> "Priority": 4,
>
> "OverrideAction": "None"
>
> }
>
> },
>
> "CustomRules": {
>
> "RateLimitRule": {
>
> "Priority": 10,
>
> "Action": "Block",
>
> "Statement": {
>
> "RateBasedStatement": {
>
> "Limit": 1000,
>
> "AggregateKeyType": "IP"
>
> }
>
> }
>
> },
>
> "GeoBlockRule": {
>
> "Priority": 11,
>
> "Action": "Block",
>
> "Statement": {
>
> "GeoMatchStatement": {
>
> "CountryCodes": \["CN", "KP", "IR"\]
>
> }
>
> }
>
> }
>
> }
>
> }
>
> }
>
> **DDoS Protection統合**
>
> **AWS Shield Standard + Advanced設定**
>
> \# Shield Protection Configuration
>
> ShieldProtection:
>
> Resources:
>
> \- CloudFront Distributions
>
> \- Route 53 Hosted Zones
>
> \- Application Load Balancers
>
> \- Network Load Balancers
>
> \- Elastic IP Addresses
>
> DDoSResponseTeam:
>
> \- 24/7 Support Access
>
> \- Incident Response Automation
>
> \- Emergency Escalation Procedures
>
> AdvancedProtection:
>
> \- Application Layer DDoS Protection
>
> \- Attack Analytics and Reporting
>
> \- Cost Protection Guarantee
>
> **通信暗号化とTLS管理**
>
> **エンドツーエンド暗号化戦略**
>
> {
>
> "CommunicationEncryption": {
>
> "TLS暗号化基準": {
>
> "MinimumTLSVersion": "1.2",
>
> "PreferredTLSVersion": "1.3",
>
> "CipherSuites": \[
>
> "TLS_AES_256_GCM_SHA384",
>
> "TLS_CHACHA20_POLY1305_SHA256",
>
> "TLS_AES_128_GCM_SHA256"
>
> \],
>
> "CertificateAuthority": "AWS Certificate Manager",
>
> "CertificateValidation": "DNS validation",
>
> "AutomaticRenewal": "有効"
>
> },
>
> "通信フロー別暗号化": {
>
> "External_to_AWS": {
>
> "ClientToCloudFront": "TLS 1.3",
>
> "CloudFrontToOrigin": "TLS 1.2以上",
>
> "CustomHeaders": "暗号化必須"
>
> },
>
> "Internal_AWS_Services": {
>
> "ALBToECS": "TLS 1.2以上",
>
> "ECSToAurora": "TLS 1.2 + IAM認証",
>
> "ServiceToService": "mTLS (相互認証)",
>
> "VPCEndpoint": "TLS 1.2以上"
>
> },
>
> "Hybrid_OnPremises": {
>
> "DirectConnect": "MACsec暗号化",
>
> "VPN": "IPSec AES-256",
>
> "ApplicationLayer": "TLS 1.3"
>
> }
>
> }
>
> }
>
> }
>
> **マイクロサービス間通信暗号化**
>
> **Service-to-Service暗号化**
>
> \# Microservice Communication Encryption
>
> ServiceToServiceEncryption:
>
> ECS_Service_Connect:
>
> Encryption: "TLS 1.3"
>
> CertificateManagement: "AWS Certificate Manager"
>
> MutualTLS:
>
> ClientCertificate: "Service-specific certificates"
>
> ServerCertificate: "Service-specific certificates"
>
> CertificateRotation: "Automatic (90 days)"
>
> API_Gateway_Integration:
>
> UpstreamTLS: "TLS 1.2 minimum"
>
> DownstreamTLS: "TLS 1.3 preferred"
>
> CertificatePinning: "Enabled for critical services"
>
> Database_Connections:
>
> Aurora_MySQL:
>
> SSL_Mode: "REQUIRED"
>
> SSL_Cipher: "AES256-SHA256"
>
> CertificateVerification: "VERIFY_IDENTITY"
>
> Message_Queues:
>
> SQS: "Server-side encryption with KMS"
>
> SNS: "Message encryption in transit and at rest"
>
> **証明書管理とローテーション**
>
> **AWS Certificate Manager統合**
>
> {
>
> "CertificateManagement": {
>
> "ドメイン別証明書戦略": {
>
> "PublicCertificates": {
>
> "\*.technova.com": {
>
> "Type": "Wildcard SSL/TLS Certificate",
>
> "ValidationMethod": "DNS",
>
> "AutoRenewal": true,
>
> "UsedBy": \["CloudFront", "ALB", "API Gateway"\]
>
> },
>
> "api.technova.com": {
>
> "Type": "Single Domain Certificate",
>
> "ValidationMethod": "DNS",
>
> "AutoRenewal": true,
>
> "UsedBy": \["API Gateway", "ECS Services"\]
>
> }
>
> },
>
> "PrivateCertificates": {
>
> "internal.technova.local": {
>
> "Type": "Private CA Certificate",
>
> "IssuingCA": "AWS Private Certificate Authority",
>
> "UsedBy": \["Internal Service Communication"\],
>
> "ValidityPeriod": "1 year"
>
> }
>
> }
>
> },
>
> "マイクロサービス別証明書": {
>
> "manufacturing-planning.internal": "Service-specific certificate",
>
> "sales-order.internal": "Service-specific certificate",
>
> "inventory-management.internal": "Service-specific certificate"
>
> }
>
> }
>
> }
>
> **VPN・DirectConnect暗号化**
>
> **ハイブリッド接続暗号化**
>
> \# Hybrid Connection Encryption
>
> HybridEncryption:
>
> DirectConnect:
>
> MACsec:
>
> Enabled: true
>
> CipherSuite: "GCM-AES-256"
>
> KeyAgreement: "SAK (Secure Association Key)"
>
> ConnectivityAssociation: "Pre-shared key"
>
> VirtualInterface:
>
> BGP_MD5: "Enabled"
>
> BGP_Password: "Complex 32-character password"
>
> VLAN_Encryption: "802.1AE MACsec"
>
> Site_to_Site_VPN:
>
> IKE_Version: "IKEv2"
>
> Encryption_Algorithm: "AES-256"
>
> Integrity_Algorithm: "SHA-256"
>
> DH_Group: "Group 14 (2048-bit MODP)"
>
> PFS: "Perfect Forward Secrecy enabled"
>
> Tunnel_Configuration:
>
> Phase1_Lifetime: "28800 seconds"
>
> Phase2_Lifetime: "3600 seconds"
>
> Dead_Peer_Detection: "Enabled"
>
> Client_VPN:
>
> Protocol: "OpenVPN"
>
> Cipher: "AES-256-GCM"
>
> Auth: "SHA-256"
>
> Certificate_Authentication: "Mutual authentication"
>
> **アプリケーション層暗号化**
>
> **データフロー暗号化**
>
> {
>
> "ApplicationLayerEncryption": {
>
> "API通信": {
>
> "REST_APIs": {
>
> "Protocol": "HTTPS only",
>
> "TLS_Version": "1.3",
>
> "HSTS": "Enabled",
>
> "Certificate_Transparency": "Enabled"
>
> },
>
> "GraphQL_APIs": {
>
> "Transport": "HTTPS/WSS",
>
> "Query_Encryption": "Field-level encryption for sensitive data",
>
> "Response_Encryption": "Conditional based on data classification"
>
> },
>
> "gRPC_Services": {
>
> "Transport": "HTTP/2 over TLS",
>
> "Application_Layer_Protocol_Negotiation": "Enabled",
>
> "Connection_Multiplexing": "Encrypted streams"
>
> }
>
> },
>
> "WebSocket通信": {
>
> "Protocol": "WSS (WebSocket Secure)",
>
> "TLS_Version": "1.3",
>
> "Message_Level_Encryption": "Additional AES-256 for sensitive
> payloads"
>
> },
>
> "ファイル転送": {
>
> "S3_Upload": "TLS 1.2 + Server-side encryption",
>
> "Direct_Upload": "Multipart upload with encryption",
>
> "Pre_signed_URLs": "Short expiration + HTTPS only"
>
> }
>
> }
>
> }
>
> **暗号化監視・検証**
>
> **TLS監視とコンプライアンス**
>
> \# TLS Monitoring and Compliance
>
> TLSMonitoring:
>
> Certificate_Monitoring:
>
> \- Expiration_Alerts: "30, 14, 7 days before expiration"
>
> Certificate_Health_Checks: "Daily SSL Labs scans"
>
> Weak_Cipher_Detection: "Automated scanning"
>
> Mixed_Content_Detection: "HTTP resources on HTTPS pages"
>
> TLS_Configuration_Compliance:
>
> \- Config_Rules:
>
> \- "alb-tls-1-2-required"
>
> \- "cloudfront-tls-1-2-required"
>
> \- "api-gateway-tls-1-2-required"
>
> \- Custom_Checks:
>
> \- "Verify cipher suite compliance"
>
> \- "Check certificate chain validity"
>
> \- "Validate OCSP stapling"
>
> Traffic_Analysis:
>
> \- Encrypted_Traffic_Percentage: "Target: 100%"
>
> Unencrypted_Detection: "Immediate alerts"
>
> TLS_Handshake_Failures: "Trending analysis"
>
> Performance_Impact: "Latency monitoring"
>
> **暗号化キー管理統合**
>
> **KMS統合暗号化**
>
> {
>
> "EncryptionKeyManagement": {
>
> "通信暗号化キー階層": {
>
> "TLS_Certificates": {
>
> "KeyType": "RSA-2048 or EC P-256",
>
> "Management": "AWS Certificate Manager",
>
> "Rotation": "Automatic"
>
> },
>
> "Application_Level_Keys": {
>
> "KeyType": "AES-256",
>
> "Management": "AWS KMS",
>
> "Usage": "Field-level encryption",
>
> "Rotation": "Annual"
>
> },
>
> "Service_Communication_Keys": {
>
> "KeyType": "EC P-256",
>
> "Management": "AWS Private CA",
>
> "Usage": "mTLS certificates",
>
> "Rotation": "Quarterly"
>
> }
>
> },
>
> "キーガバナンス": {
>
> "KeyAccess": "Role-based with least privilege",
>
> "KeyAuditing": "All key usage logged in CloudTrail",
>
> "KeyRotation": "Automated with business approval",
>
> "KeyRecovery": "Secure backup and recovery procedures"
>
> }
>
> }
>
> }
>
> **暗号化パフォーマンス最適化**
>
> **暗号化オーバーヘッド管理**
>
> \# Encryption Performance Optimization
>
> EncryptionPerformance:
>
> TLS_Optimization:
>
> \- Session_Resumption: "TLS session tickets enabled"
>
> OCSP_Stapling: "Enabled to reduce handshake latency"
>
> Hardware_Acceleration: "AWS Nitro System utilization"
>
> Connection_Reuse: "HTTP/2 connection multiplexing"
>
> Cipher_Suite_Optimization:
>
> \- AEAD_Ciphers: "Preferred for authenticated encryption"
>
> ECDHE_Key_Exchange: "Perfect Forward Secrecy"
>
> Hardware_AES: "AES-NI instruction utilization"
>
> Load_Distribution:
>
> \- SSL_Termination: "Load balancer level"
>
> Connection_Pooling: "Backend SSL connection reuse"
>
> Regional_Distribution: "Edge location SSL termination"
>
> **暗号化コンプライアンス**
>
> **規制要件対応**
>
> {
>
> "EncryptionCompliance": {
>
> "FIPS_140_2": {
>
> "Level": "Level 2 validated modules",
>
> "Scope": "All cryptographic operations",
>
> "Implementation": "AWS FIPS endpoints"
>
> },
>
> "Common_Criteria": {
>
> "EAL_Level": "EAL4+",
>
> "Validated_Components": "AWS KMS, CloudHSM"
>
> },
>
> "Industry_Standards": {
>
> "PCI_DSS": "Strong cryptography for cardholder data",
>
> "GDPR": "Appropriate technical measures",
>
> "HIPAA": "Encryption of PHI in transit"
>
> },
>
> "国内規制": {
>
> "個人情報保護法": "個人データの安全管理措置",
>
> "サイバーセキュリティ基本法": "重要インフラの保護"
>
> }
>
> }
>
> }

6.  **コンテナセキュリティ（ECS/ECR）**

> **ECR セキュリティ設定**
>
> **コンテナイメージセキュリティ**
>
> {
>
> "ECRSecurityConfiguration": {
>
> "ImageScanning": {
>
> "ScanOnPush": true,
>
> "ScanningFrequency": "CONTINUOUS",
>
> "VulnerabilityThreshold": {
>
> "Critical": "Block",
>
> "High": "Alert",
>
> "Medium": "Log",
>
> "Low": "Log"
>
> }
>
> },
>
> "ImageImmutability": true,
>
> "Encryption": {
>
> "Type": "KMS",
>
> "KMSKey": "service-specific-key"
>
> },
>
> "LifecyclePolicy": {
>
> "UntaggedImages": "Delete after 7 days",
>
> "TaggedImages": "Keep latest 10 versions"
>
> }
>
> }
>
> }
>
> 脆弱性管理自動化
>
> \# Container Security Automation
>
> VulnerabilityManagement:
>
> Detection:
>
> \- Continuous Image Scanning
>
> \- Runtime Vulnerability Assessment
>
> \- Third-party Security Integration
>
> Response:
>
> \- Automated Patch Deployment
>
> \- Image Rebuild Triggers
>
> \- Security Alert Notifications
>
> Compliance:
>
> \- CIS Benchmark Compliance
>
> \- NIST Container Security Guidelines
>
> \- Industry Best Practices
>
> **ECS Runtime セキュリティ**
>
> **コンテナランタイム保護**
>
> {
>
> "ECSSecurityConfiguration": {
>
> "TaskDefinitionSecurity": {
>
> "Privileged": false,
>
> "ReadOnlyRootFilesystem": true,
>
> "User": "non-root",
>
> "NetworkMode": "awsvpc",
>
> "RequireCompatibilities": \["FARGATE"\]
>
> },
>
> "SecretsManagement": {
>
> "SecretProvider": "AWS Secrets Manager",
>
> "AutoRotation": true,
>
> "EncryptionInTransit": true
>
> },
>
> "LogConfiguration": {
>
> "LogDriver": "awslogs",
>
> "LogGroup": "/ecs/security-enhanced",
>
> "LogRetention": "30 days"
>
> }
>
> }
>
> }
>
> Service Connect セキュリティ
>
> \# Service Connect Security Configuration
>
> ServiceConnectSecurity:
>
> Encryption:
>
> \- TLS 1.3 for Service Communication
>
> \- Certificate Management via ACM
>
> \- Automatic Certificate Rotation
>
> Authentication:
>
> \- mTLS for Service-to-Service Communication
>
> \- IAM Roles for Service Identity
>
> \- Service Mesh Integration
>
> Monitoring:
>
> \- Traffic Flow Analysis
>
> \- Anomaly Detection
>
> \- Security Event Correlation

7.  **データベースセキュリティ（Aurora）**

> **Aurora セキュリティ設定**
>
> **データベース暗号化とアクセス制御**
>
> {
>
> "AuroraSecurityConfiguration": {
>
> "Encryption": {
>
> "EncryptionAtRest": {
>
> "Enabled": true,
>
> "KMSKey": "service-specific-key",
>
> "AlgorithmSuite": "AES-256"
>
> },
>
> "EncryptionInTransit": {
>
> "Enabled": true,
>
> "TLSVersion": "1.2",
>
> "CertificateValidation": true
>
> }
>
> },
>
> "AccessControl": {
>
> "IAMAuthentication": true,
>
> "DatabaseUserManagement": "IAM-based",
>
> "PasswordPolicy": {
>
> "Disabled": true,
>
> "Reason": "IAM authentication only"
>
> },
>
> "NetworkAccess": {
>
> "VPCOnly": true,
>
> "SecurityGroups": \["db-tier-sg"\],
>
> "SubnetGroups": \["private-subnets-only"\]
>
> }
>
> }
>
> }
>
> }
>
> データベース監査とモニタリング
>
> \# Database Security Monitoring
>
> DatabaseAuditing:
>
> AuditLogging:
>
> \- All Connection Attempts
>
> \- Query Execution Logs
>
> \- Schema Changes
>
> \- Privilege Escalations
>
> PerformanceInsights:
>
> \- Query Performance Monitoring
>
> \- Resource Utilization Tracking
>
> \- Anomaly Detection
>
> Alerting:
>
> \- Suspicious Query Patterns
>
> \- Unusual Connection Attempts
>
> \- Performance Degradation
>
> \- Security Policy Violations
>
> **データ分類と保護**
>
> **データ分類フレームワーク**
>
> {
>
> "DataClassification": {
>
> "Confidential": {
>
> "Examples": \["customer_personal_data", "financial_records"\],
>
> "EncryptionRequired": true,
>
> "AccessRestrictions": "Need-to-know basis",
>
> "AuditLogging": "Enhanced",
>
> "DataRetention": "Legal requirements"
>
> },
>
> "Internal": {
>
> "Examples": \["business_processes", "internal_reports"\],
>
> "EncryptionRequired": true,
>
> "AccessRestrictions": "Employee access only",
>
> "AuditLogging": "Standard",
>
> "DataRetention": "7 years"
>
> },
>
> "Public": {
>
> "Examples": \["product_specifications", "marketing_materials"\],
>
> "EncryptionRequired": false,
>
> "AccessRestrictions": "Public access allowed",
>
> "AuditLogging": "Basic",
>
> "DataRetention": "As needed"
>
> }
>
> }
>
> }

8.  **S3セキュリティ・アクセス制御**

> **S3バケットセキュリティ設計**
>
> **バケット別セキュリティ戦略**
>
> {
>
> "S3SecurityArchitecture": {
>
> "バケット分類とセキュリティレベル": {
>
> "機密データバケット": {
>
> "Examples": \[
>
> "technova-customer-data-prod",
>
> "technova-financial-records-prod",
>
> "technova-employee-data-prod"
>
> \],
>
> "SecurityLevel": "最高",
>
> "PublicAccessBlock": "全て有効",
>
> "BucketPolicy": "最小権限の原則",
>
> "Encryption": "Customer Managed KMS",
>
> "Versioning": "有効",
>
> "MFADelete": "必須",
>
> "AccessLogging": "完全",
>
> "EventNotifications": "全操作"
>
> },
>
> "アプリケーションデータバケット": {
>
> "Examples": \[
>
> "technova-manufacturing-data-prod",
>
> "technova-sales-data-prod",
>
> "technova-service-data-prod",
>
> "technova-iot-data-prod"
>
> \],
>
> "SecurityLevel": "高",
>
> "PublicAccessBlock": "全て有効",
>
> "BucketPolicy": "サービス別制限",
>
> "Encryption": "SSE-S3",
>
> "Versioning": "有効",
>
> "AccessLogging": "標準",
>
> "LifecyclePolicy": "自動階層化"
>
> },
>
> "ログ・監査バケット": {
>
> "Examples": \[
>
> "technova-cloudtrail-logs-prod",
>
> "technova-access-logs-prod",
>
> "technova-security-logs-prod"
>
> \],
>
> "SecurityLevel": "高",
>
> "PublicAccessBlock": "全て有効",
>
> "BucketPolicy": "読み取り専用（監査用）",
>
> "Encryption": "SSE-S3",
>
> "ObjectLock": "Governance Mode",
>
> "RetentionPeriod": "7年",
>
> "ImmutableAccess": "有効"
>
> }
>
> }
>
> }
>
> }
>
> **IAMポリシーとバケットポリシーの組み合わせ**
>
> **階層的アクセス制御**
>
> {
>
> "S3AccessControl": {
>
> "サービス別IAMポリシー": {
>
> "manufacturing-service-s3-policy": {
>
> "Version": "2012-10-17",
>
> "Statement": \[
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "s3:GetObject",
>
> "s3:PutObject",
>
> "s3:DeleteObject"
>
> \],
>
> "Resource": \[
>
> "arn:aws:s3:::technova-manufacturing-data-prod/\*",
>
> "arn:aws:s3:::technova-manufacturing-backup-prod/\*"
>
> \],
>
> "Condition": {
>
> "StringEquals": {
>
> "s3:x-amz-server-side-encryption": "AES256"
>
> },
>
> "Bool": {
>
> "aws:SecureTransport": "true"
>
> }
>
> }
>
> },
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "s3:ListBucket"
>
> \],
>
> "Resource": \[
>
> "arn:aws:s3:::technova-manufacturing-data-prod",
>
> "arn:aws:s3:::technova-manufacturing-backup-prod"
>
> \],
>
> "Condition": {
>
> "StringLike": {
>
> "s3:prefix": \[
>
> "production-orders/\*",
>
> "materials/\*",
>
> "workflows/\*"
>
> \]
>
> }
>
> }
>
> }
>
> \]
>
> }
>
> }
>
> }
>
> }
>
> バケットポリシー例（機密データ用）
>
> {
>
> "CustomerDataBucketPolicy": {
>
> "Version": "2012-10-17",
>
> "Statement": \[
>
> {
>
> "Sid": "DenyInsecureConnections",
>
> "Effect": "Deny",
>
> "Principal": "\*",
>
> "Action": "s3:\*",
>
> "Resource": \[
>
> "arn:aws:s3:::technova-customer-data-prod",
>
> "arn:aws:s3:::technova-customer-data-prod/\*"
>
> \],
>
> "Condition": {
>
> "Bool": {
>
> "aws:SecureTransport": "false"
>
> }
>
> }
>
> },
>
> {
>
> "Sid": "DenyUnEncryptedObjectUploads",
>
> "Effect": "Deny",
>
> "Principal": "\*",
>
> "Action": "s3:PutObject",
>
> "Resource": "arn:aws:s3:::technova-customer-data-prod/\*",
>
> "Condition": {
>
> "StringNotEquals": {
>
> "s3:x-amz-server-side-encryption": "aws:kms"
>
> }
>
> }
>
> },
>
> {
>
> "Sid": "AllowOnlySpecificKMSKey",
>
> "Effect": "Deny",
>
> "Principal": "\*",
>
> "Action": "s3:PutObject",
>
> "Resource": "arn:aws:s3:::technova-customer-data-prod/\*",
>
> "Condition": {
>
> "StringNotEquals": {
>
> "s3:x-amz-server-side-encryption-aws-kms-key-id":
> "arn:aws:kms:ap-northeast-1:123456789012:key/customer-data-key-id"
>
> }
>
> }
>
> },
>
> {
>
> "Sid": "AllowSpecificRolesOnly",
>
> "Effect": "Allow",
>
> "Principal": {
>
> "AWS": \[
>
> "arn:aws:iam::123456789012:role/sales-customer-access-role",
>
> "arn:aws:iam::123456789012:role/service-customer-access-role"
>
> \]
>
> },
>
> "Action": \[
>
> "s3:GetObject",
>
> "s3:PutObject"
>
> \],
>
> "Resource": "arn:aws:s3:::technova-customer-data-prod/\*",
>
> "Condition": {
>
> "StringEquals": {
>
> "s3:x-amz-server-side-encryption": "aws:kms"
>
> },
>
> "DateGreaterThan": {
>
> "aws:CurrentTime": "2024-01-01T00:00:00Z"
>
> }
>
> }
>
> }
>
> \]
>
> }
>
> }
>
> **S3 Access Points とマルチリージョンアクセス制御**
>
> **Access Points設計**
>
> \# S3 Access Points Configuration
>
> S3AccessPoints:
>
> manufacturing-data-ap:
>
> Bucket: "technova-manufacturing-data-prod"
>
> VPCConfiguration:
>
> VPCId: "vpc-manufacturing-prod"
>
> Policy:
>
> Version: "2012-10-17"
>
> Statement:
>
> \- Effect: Allow
>
> Principal:
>
> AWS: "arn:aws:iam::123456789012:role/manufacturing-\*"
>
> Action:
>
> \- "s3:GetObject"
>
> \- "s3:PutObject"
>
> Resource:
> "arn:aws:s3:ap-northeast-1:123456789012:accesspoint/manufacturing-data-ap/object/\*"
>
> Condition:
>
> StringEquals:
>
> "s3:DataAccessPointAccount": "123456789012"
>
> sales-customer-data-ap:
>
> Bucket: "technova-customer-data-prod"
>
> VPCConfiguration:
>
> VPCId: "vpc-sales-prod"
>
> Policy:
>
> Version: "2012-10-17"
>
> Statement:
>
> \- Effect: Allow
>
> Principal:
>
> AWS: "arn:aws:iam::123456789012:role/sales-customer-\*"
>
> Action:
>
> \- "s3:GetObject"
>
> Resource:
> "arn:aws:s3:ap-northeast-1:123456789012:accesspoint/sales-customer-data-ap/object/\*"
>
> Condition:
>
> StringEquals:
>
> "s3:DataAccessPointAccount": "123456789012"
>
> IpAddress:
>
> "aws:SourceIp": \["10.1.0.0/16"\] \# Sales VPC CIDR
>
> **クロスリージョンレプリケーションセキュリティ**
>
> **レプリケーション設定とアクセス制御**
>
> {
>
> "CrossRegionReplication": {
>
> "ReplicationConfiguration": {
>
> "Role": "arn:aws:iam::123456789012:role/s3-replication-role",
>
> "Rules": \[
>
> {
>
> "ID": "ReplicateCustomerDataToDR",
>
> "Status": "Enabled",
>
> "Priority": 1,
>
> "Filter": {
>
> "Prefix": "customer-data/"
>
> },
>
> "Destination": {
>
> "Bucket": "arn:aws:s3:::technova-customer-data-dr-osaka",
>
> "StorageClass": "STANDARD_IA",
>
> "EncryptionConfiguration": {
>
> "ReplicaKmsKeyID":
> "arn:aws:kms:ap-northeast-3:123456789012:key/dr-customer-data-key"
>
> },
>
> "AccessControlTranslation": {
>
> "Owner": "Destination"
>
> }
>
> }
>
> }
>
> \]
>
> },
>
> "ReplicationRolePolicy": {
>
> "Version": "2012-10-17",
>
> "Statement": \[
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "s3:GetObjectVersionForReplication",
>
> "s3:GetObjectVersionAcl"
>
> \],
>
> "Resource": "arn:aws:s3:::technova-customer-data-prod/\*"
>
> },
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "s3:ReplicateObject",
>
> "s3:ReplicateDelete"
>
> \],
>
> "Resource": "arn:aws:s3:::technova-customer-data-dr-osaka/\*"
>
> },
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "kms:Decrypt"
>
> \],
>
> "Resource":
> "arn:aws:kms:ap-northeast-1:123456789012:key/customer-data-key-id"
>
> },
>
> {
>
> "Effect": "Allow",
>
> "Action": \[
>
> "kms:GenerateDataKey"
>
> \],
>
> "Resource":
> "arn:aws:kms:ap-northeast-3:123456789012:key/dr-customer-data-key"
>
> }
>
> \]
>
> }
>
> }
>
> }
>
> **S3監査・ログ・アラート設定**
>
> **包括的S3監視**
>
> {
>
> "S3SecurityMonitoring": {
>
> "CloudTrailS3Events": {
>
> "DataEvents": \[
>
> {
>
> "ReadWriteType": "All",
>
> "IncludeManagementEvents": true,
>
> "DataResources": \[
>
> {
>
> "Type": "AWS::S3::Object",
>
> "Values": \[
>
> "arn:aws:s3:::technova-customer-data-prod/\*",
>
> "arn:aws:s3:::technova-financial-records-prod/\*"
>
> \]
>
> }
>
> \]
>
> }
>
> \]
>
> },
>
> "S3AccessLogging": {
>
> "TargetBucket": "technova-s3-access-logs-prod",
>
> "TargetPrefix": "access-logs/",
>
> "LogObjectKeyFormat": "SimplePrefix"
>
> },
>
> "EventNotifications": {
>
> "CloudWatchEvents": \[
>
> {
>
> "EventName": "ObjectCreated",
>
> "EventDestination": "SNS Topic",
>
> "FilterRules": \[
>
> {
>
> "Name": "prefix",
>
> "Value": "sensitive-data/"
>
> }
>
> \]
>
> },
>
> {
>
> "EventName": "ObjectRemoved",
>
> "EventDestination": "Lambda Function",
>
> "Function": "s3-delete-alert-handler"
>
> }
>
> \]
>
> }
>
> }
>
> }
>
> **S3セキュリティ自動化**
>
> **自動修復・対応**
>
> \# S3 Security Automation
>
> S3SecurityAutomation:
>
> ComplianceMonitoring:
>
> \- PolicyViolationDetection:
>
> Trigger: "Config Rule違反"
>
> Response: "自動アラート + 手動修復"
>
> \- PublicAccessDetection:
>
> Trigger: "Public Read/Write検出"
>
> Response: "即座にブロック + セキュリティチーム通知"
>
> \- UnencryptedObjectDetection:
>
> Trigger: "暗号化されていないオブジェクト検出"
>
> Response: "アップロードブロック + 自動暗号化"
>
> AccessAnomalyDetection:
>
> \- UnusualAccessPatterns:
>
> Detection: "GuardDuty Malicious IP"
>
> Response: "IP自動ブロック + インシデント作成"
>
> \- MassDownloadDetection:
>
> Detection: "大量ダウンロード (\>1GB/hour)"
>
> Response: "一時的アクセス制限 + 調査開始"
>
> \- CrossRegionAccessAnomaly:
>
> Detection: "通常と異なるリージョンからのアクセス"
>
> Response: "MFA再認証要求 + ログ強化"
>
> AutomatedRemediation:
>
> \- S3-Bucket-Public-Access-Prohibited:
>
> RemediationAction: "aws-s3-bucket-public-access-block"
>
> Parameters:
>
> BlockPublicAcls: true
>
> BlockPublicPolicy: true
>
> IgnorePublicAcls: true
>
> RestrictPublicBuckets: true
>
> \- S3-Bucket-SSL-Requests-Only:
>
> RemediationAction: "aws-s3-bucket-ssl-requests-only"
>
> Parameters:
>
> BucketPolicy: "DenyInsecureConnections"
>
> **GDPR・データ保護法対応のS3設定**
>
> **個人データ保護特別設定**
>
> {
>
> "GDPRComplianceS3": {
>
> "PersonalDataBuckets": {
>
> "technova-customer-personal-data-prod": {
>
> "ObjectLockConfiguration": {
>
> "ObjectLockEnabled": "Enabled",
>
> "Rule": {
>
> "DefaultRetention": {
>
> "Mode": "GOVERNANCE",
>
> "Years": 7
>
> }
>
> }
>
> },
>
> "NotificationConfiguration": {
>
> "CloudWatchConfiguration": {
>
> "Events": \["s3:ObjectCreated:\*", "s3:ObjectRemoved:\*"\],
>
> "CloudWatchConfiguration": {
>
> "LogGroupName": "/aws/s3/gdpr-compliance"
>
> }
>
> }
>
> },
>
> "Tags": \[
>
> {
>
> "Key": "DataClassification",
>
> "Value": "PersonalData"
>
> },
>
> {
>
> "Key": "GDPRScope",
>
> "Value": "true"
>
> },
>
> {
>
> "Key": "RetentionPeriod",
>
> "Value": "7years"
>
> }
>
> \]
>
> }
>
> },
>
> "DataSubjectRightsSupport": {
>
> "RightToErasure": {
>
> "AutomatedDeletion": "Lambda function triggered by API",
>
> "VerificationProcess": "Multi-step approval",
>
> "AuditTrail": "Complete deletion record in CloudTrail"
>
> },
>
> "RightToAccess": {
>
> "DataInventory": "S3 Inventory + Lambda processing",
>
> "ResponseTime": "30 days maximum",
>
> "DeliveryMethod": "Secure download link"
>
> }
>
> }
>
> }
>
> }
>
> **マイクロサービス別S3アクセスパターン**
>
> **20マイクロサービス用の個別S3アクセス制御**
>
> \# Microservice-specific S3 Access Patterns
>
> MicroserviceS3Access:
>
> Manufacturing:
>
> ProductionPlanningService:
>
> AllowedBuckets:
>
> \- "technova-production-plans-prod"
>
> \- "technova-manufacturing-reports-prod"
>
> AllowedActions: \["s3:GetObject", "s3:PutObject", "s3:ListBucket"\]
>
> PathRestrictions: \["production-plans/\*", "planning-reports/\*"\]
>
> InventoryManagementService:
>
> AllowedBuckets:
>
> \- "technova-inventory-data-prod"
>
> \- "technova-manufacturing-shared-prod"
>
> AllowedActions: \["s3:GetObject", "s3:PutObject", "s3:DeleteObject"\]
>
> CrossServiceAccess:
>
> \- Service: "SalesOrderService"
>
> BucketPath: "technova-inventory-data-prod/stock-levels/\*"
>
> Permission: "ReadOnly"
>
> Sales:
>
> CustomerManagementService:
>
> AllowedBuckets:
>
> \- "technova-customer-data-prod"
>
> AllowedActions: \["s3:GetObject", "s3:PutObject"\]
>
> DataClassification: "Confidential"
>
> EncryptionRequired: "Customer-managed KMS"
>
> AccessLogging: "Enhanced"
>
> IoT:
>
> TelemetryService:
>
> AllowedBuckets:
>
> \- "technova-iot-telemetry-prod"
>
> \- "technova-iot-processed-data-prod"
>
> AllowedActions: \["s3:PutObject", "s3:GetObject"\]
>
> VolumeRestrictions:
>
> MaxObjectSize: "100MB"
>
> DailyUploadLimit: "10GB"
>
> LifecycleManagement:
>
> TransitionToIA: "30 days"
>
> TransitionToGlacier: "90 days"

9.  **API セキュリティ（Gateway/Cognito）**

> **API Gateway セキュリティ設定**
>
> **API認証と認可**
>
> {
>
> "APIGatewaySecurity": {
>
> "Authentication": {
>
> "CognitoUserPools": {
>
> "AuthType": "JWT",
>
> "TokenValidation": true,
>
> "ScopeValidation": true
>
> },
>
> "IAMRoles": {
>
> "ServiceToService": true,
>
> "CrossAccountAccess": "Restricted"
>
> }
>
> },
>
> "Authorization": {
>
> "ScopeBasedAccess": true,
>
> "ResourceBasedPolicies": true,
>
> "ContextualAccess": "IP, Time, Device"
>
> },
>
> "Throttling": {
>
> "BurstLimit": 1000,
>
> "RateLimit": 500,
>
> "QuotaLimit": "10000/day"
>
> }
>
> }
>
> }
>
> API Gateway WAF統合
>
> \# API Gateway WAF Configuration
>
> APIGatewayWAF:
>
> CustomRules:
>
> \- Name: "API-specific-rate-limit"
>
> Priority: 1
>
> Action: "Block"
>
> Statement:
>
> RateBasedStatement:
>
> Limit: 100
>
> AggregateKeyType: "IP"
>
> \- Name: "API-payload-validation"
>
> Priority: 2
>
> Action: "Block"
>
> Statement:
>
> SizeConstraintStatement:
>
> FieldToMatch:
>
> Body: {}
>
> ComparisonOperator: "GT"
>
> Size: 1048576 \# 1MB limit
>
> **Cognito セキュリティ強化**
>
> **ユーザープールセキュリティ設定**
>
> {
>
> "CognitoSecurity": {
>
> "PasswordPolicy": {
>
> "MinimumLength": 12,
>
> "RequireUppercase": true,
>
> "RequireLowercase": true,
>
> "RequireNumbers": true,
>
> "RequireSymbols": true,
>
> "TemporaryPasswordValidityDays": 1
>
> },
>
> "MFAConfiguration": {
>
> "MFARequired": true,
>
> "AllowedMFATypes": \["SMS", "TOTP"\],
>
> "PreferredMFA": "TOTP"
>
> },
>
> "AccountSecurity": {
>
> "AccountRecovery": "Email and Phone",
>
> "PreventUserExistenceErrors": true,
>
> "AdvancedSecurityMode": "ENFORCED"
>
> },
>
> "DeviceTracking": {
>
> "ChallengeRequiredOnNewDevice": true,
>
> "DeviceOnlyRememberedOnUserPrompt": true
>
> }
>
> }
>
> }

10. **Secrets Management と Key Management**

> **AWS Secrets Manager統合**
>
> **シークレット管理戦略**
>
> {
>
> "SecretsManagement": {
>
> "SecretCategories": {
>
> "DatabaseCredentials": {
>
> "Scope": "Per-microservice",
>
> "RotationEnabled": true,
>
> "RotationInterval": "30 days",
>
> "EncryptionKey": "service-specific-kms-key"
>
> },
>
> "APIKeys": {
>
> "Scope": "Per-integration",
>
> "RotationEnabled": true,
>
> "RotationInterval": "90 days",
>
> "AccessLogging": "Enhanced"
>
> },
>
> "CertificateKeys": {
>
> "Scope": "Per-domain",
>
> "RotationEnabled": true,
>
> "RotationInterval": "365 days",
>
> "CertificateAuthority": "AWS ACM"
>
> }
>
> },
>
> "AccessControl": {
>
> "ResourceBasedPolicies": true,
>
> "IAMRoleBasedAccess": true,
>
> "VPCEndpointAccess": true,
>
> "CrossAccountAccess": "Restricted"
>
> }
>
> }
>
> }
>
> **KMS Key Management**
>
> **暗号化キー階層**
>
> \# KMS Key Management Strategy
>
> KMSKeyHierarchy:
>
> CustomerMasterKeys:
>
> \- Purpose: "Root Encryption"
>
> Type: "AWS Managed"
>
> Usage: "Organization Level"
>
> \- Purpose: "Service Encryption"
>
> Type: "Customer Managed"
>
> Usage: "Per-microservice"
>
> KeyRotation: "Annual"
>
> \- Purpose: "Data Encryption"
>
> Type: "Customer Managed"
>
> Usage: "Per-data-classification"
>
> KeyRotation: "Annual"
>
> KeyPolicies:
>
> \- Principal: "Service Roles"
>
> Actions: \["kms:Decrypt", "kms:GenerateDataKey"\]
>
> Conditions:
>
> \- StringEquals:
>
> "kms:ViaService": "service-name.region.amazonaws.com"

11. **監視・ログ・インシデント対応**

> **統合セキュリティ監視**
>
> **Security Hub統合**
>
> {
>
> "SecurityHubConfiguration": {
>
> "EnabledStandards": \[
>
> "AWS Foundational Security Standard",
>
> "CIS AWS Foundations Benchmark",
>
> "PCI DSS Standard"
>
> \],
>
> "CustomInsights": \[
>
> {
>
> "Name": "High-Severity-Findings",
>
> "Filters": {
>
> "SeverityLabel": \["HIGH", "CRITICAL"\],
>
> "WorkflowStatus": \["NEW", "NOTIFIED"\]
>
> }
>
> },
>
> {
>
> "Name": "Compliance-Failures",
>
> "Filters": {
>
> "ComplianceStatus": \["FAILED"\],
>
> "RecordState": \["ACTIVE"\]
>
> }
>
> }
>
> \],
>
> "Automation": {
>
> "AutomatedRemediationEnabled": true,
>
> "NotificationTargets": \["security-team-sns-topic"\],
>
> "EscalationProcedures": "security-incident-response-playbook"
>
> }
>
> }
>
> }
>
> CloudTrail統合監査
>
> \# CloudTrail Security Configuration
>
> CloudTrailSecurity:
>
> OrganizationTrail:
>
> \- MultiRegionTrail: true
>
> IncludeGlobalServiceEvents: true
>
> LogFileValidation: true
>
> KMSEncryption: true
>
> S3BucketPolicy: "Restrictive"
>
> DataEvents:
>
> \- S3ObjectLevelLogging: true
>
> LambdaFunctionLogging: true
>
> DynamoDBTableLogging: true
>
> InsightSelectors:
>
> \- ApiCallRateInsight: true
>
> ApiErrorRateInsight: true
>
> LogAnalysis:
>
> \- RealTimeProcessing: true
>
> AnomalyDetection: true
>
> ThreatIntelligence: true
>
> **インシデント対応フレームワーク**
>
> **自動インシデント対応**
>
> {
>
> "IncidentResponse": {
>
> "DetectionSources": \[
>
> "GuardDuty",
>
> "Security Hub",
>
> "CloudWatch Alarms",
>
> "VPC Flow Logs",
>
> "WAF Logs"
>
> \],
>
> "ResponseAutomation": {
>
> "IsolationProcedures": {
>
> "NetworkIsolation": "Auto-quarantine suspicious instances",
>
> "AccessRevocation": "Disable compromised credentials",
>
> "TrafficBlocking": "WAF rule updates"
>
> },
>
> "NotificationProcedures": {
>
> "SecurityTeam": "Immediate alert via PagerDuty",
>
> "Management": "Executive summary within 1 hour",
>
> "Legal": "Data breach notification procedures"
>
> },
>
> "EvidenceCollection": {
>
> "MemoryDumps": "Automated collection",
>
> "LogPreservation": "Extended retention",
>
> "ForensicImages": "Automated snapshots"
>
> }
>
> }
>
> }
>
> }

12. **災害復旧・事業継続のセキュリティ**

> **DR環境セキュリティ**
>
> **大阪リージョンDRセキュリティ**
>
> \# DR Security Configuration
>
> DRSecurity:
>
> SecurityReplication:
>
> \- SecurityGroups: "Synchronized"
>
> NACLs: "Synchronized"
>
> WAFRules: "Synchronized"
>
> KMSKeys: "Cross-region replicated"
>
> AccessControl:
>
> \- EmergencyAccess: "Break-glass procedures"
>
> DRActivation: "Multi-person authorization"
>
> SecurityValidation: "Pre-activation security checks"
>
> DataProtection:
>
> \- EncryptionInTransit: "TLS 1.3"
>
> EncryptionAtRest: "Customer managed KMS"
>
> DataIntegrity: "Continuous validation"
>
> Monitoring:
>
> \- SecurityEventReplication: "Real-time"
>
> CrossRegionAlerting: "Enabled"
>
> ComplianceValidation: "Automated"

13. **コンプライアンス・ガバナンス**

> **継続的コンプライアンス監視**
>
> **AWS Config統合**
>
> {
>
> "ConfigCompliance": {
>
> "ConfigRules": \[
>
> {
>
> "RuleName": "encrypted-volumes",
>
> "Source": "AWS Config Managed Rule",
>
> "Scope": "All EBS volumes",
>
> "ComplianceType": "NON_COMPLIANT if not encrypted"
>
> },
>
> {
>
> "RuleName": "mfa-enabled-for-root",
>
> "Source": "AWS Config Managed Rule",
>
> "Scope": "Root account",
>
> "ComplianceType": "NON_COMPLIANT if MFA not enabled"
>
> },
>
> {
>
> "RuleName": "security-group-ssh-restricted",
>
> "Source": "AWS Config Managed Rule",
>
> "Scope": "All security groups",
>
> "ComplianceType": "NON_COMPLIANT if SSH open to 0.0.0.0/0"
>
> }
>
> \],
>
> "RemediationConfigurations": \[
>
> {
>
> "ConfigRuleName": "encrypted-volumes",
>
> "TargetType": "SSM_DOCUMENT",
>
> "TargetId": "AWS-EncryptEBSVolume",
>
> "AutomationAssumeRole": "config-remediation-role"
>
> }
>
> \]
>
> }
>
> }
>
> **定期的セキュリティ評価**
>
> **セキュリティ評価フレームワーク**
>
> \# Security Assessment Framework
>
> SecurityAssessment:
>
> VulnerabilityAssessment:
>
> \- Frequency: "Monthly"
>
> Scope: "All production systems"
>
> Tools: \["AWS Inspector", "Third-party scanners"\]
>
> Reporting: "Executive dashboard"
>
> PenetrationTesting:
>
> \- Frequency: "Quarterly"
>
> Scope: "External-facing systems"
>
> Authorization: "AWS penetration testing approval"
>
> Reporting: "Detailed technical report"
>
> ComplianceAudit:
>
> \- Frequency: "Annual"
>
> Standards: \["ISO 27001", "SOC 2", "PCI DSS"\]
>
> Auditor: "Third-party certified"
>
> Remediation: "Action plan with timelines"
>
> SecurityMetrics:
>
> \- MeanTimeToDetection: "\< 5 minutes"
>
> MeanTimeToResponse: "\< 30 minutes"
>
> SecurityIncidents: "Trend analysis"
>
> ComplianceScore: "99.5% target"

14. **セキュリティ運用・管理**

> **実装対象サービス**

- **AWS Security Hub（セキュリティ統合管理）**

- **Amazon GuardDuty（脅威検知）**

- **AWS Config（コンプライアンス監視）**

- **Amazon CloudWatch（メトリクス・アラート）**

- **AWS Systems Manager（運用自動化）**

> Terraform実装コード
>
> hcl
>
> *\# Security Hub の組織レベル設定*
>
> resource "aws_securityhub_account" "main" {
>
> enable_default_standards = true
>
> }
>
> resource "aws_securityhub_standards_subscription" "aws_foundational" {
>
> standards_arn =
> "arn:aws:securityhub:::ruleset/finding-format/aws-foundational-security-standard"
>
> depends_on = \[aws_securityhub_account.main\]
>
> }
>
> resource "aws_securityhub_standards_subscription" "cis" {
>
> standards_arn =
> "arn:aws:securityhub:::ruleset/finding-format/cis-aws-foundations-benchmark"
>
> depends_on = \[aws_securityhub_account.main\]
>
> }
>
> *\# GuardDuty 設定（全機能有効化）*
>
> resource "aws_guardduty_detector" "main" {
>
> enable = true
>
> datasources {
>
> s3_logs {
>
> enable = true
>
> }
>
> kubernetes {
>
> audit_logs {
>
> enable = true
>
> }
>
> }
>
> malware_protection {
>
> scan_ec2_instance_with_findings {
>
> ebs_volumes {
>
> enable = true
>
> }
>
> }
>
> }
>
> }
>
> finding_publishing_frequency = "FIFTEEN_MINUTES"
>
> tags = {
>
> Name = "Primary GuardDuty Detector"
>
> Environment = var.environment
>
> }
>
> }
>
> *\# セキュリティメトリクス用 CloudWatch カスタムメトリクス*
>
> resource "aws_cloudwatch_metric_alarm" "critical_security_findings" {
>
> alarm_name = "critical-security-findings"
>
> comparison_operator = "GreaterThanThreshold"
>
> evaluation_periods = "1"
>
> metric_name = "Findings"
>
> namespace = "AWS/SecurityHub"
>
> period = "300"
>
> statistic = "Sum"
>
> threshold = "0"
>
> alarm_description = "Critical security findings detected"
>
> dimensions = {
>
> ComplianceType = "FAILED"
>
> SeverityLabel = "CRITICAL"
>
> }
>
> alarm_actions = \[aws_sns_topic.security_alerts.arn\]
>
> tags = {
>
> SecurityKPI = "CriticalFindings"
>
> }
>
> }
>
> *\# MTTR (Mean Time To Recovery) 計測用 Lambda*
>
> resource "aws_lambda_function" "security_metrics_collector" {
>
> filename = "security_metrics.zip"
>
> function_name = "security-metrics-collector"
>
> role = aws_iam_role.security_metrics_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 300
>
> environment {
>
> variables = {
>
> CLOUDWATCH_NAMESPACE = "TechNova/Security"
>
> SECURITY_HUB_REGION = var.aws_region
>
> }
>
> }
>
> tags = {
>
> Purpose = "Security KPI Collection"
>
> }
>
> }
>
> *\# セキュリティKPI計測用 EventBridge*
>
> resource "aws_cloudwatch_event_rule" "security_metrics_schedule" {
>
> name = "security-metrics-collection"
>
> description = "Collect security KPIs every 5 minutes"
>
> schedule_expression = "rate(5 minutes)"
>
> }
>
> resource "aws_cloudwatch_event_target" "security_metrics_target" {
>
> rule = aws_cloudwatch_event_rule.security_metrics_schedule.name
>
> target_id = "SecurityMetricsLambda"
>
> arn = aws_lambda_function.security_metrics_collector.arn
>
> }
>
> **15. 新技術・脅威への対応**
>
> **実装対象サービス**

- **Amazon GuardDuty（脅威インテリジェンス）**

- **AWS Lambda（脅威分析・自動対応）**

- **Amazon S3（脅威インテリジェンスデータ保存）**

- **Amazon EventBridge（イベント処理）**

- **Amazon Comprehend（AI分析）**

> Terraform実装コード
>
> hcl
>
> *\# 脅威インテリジェンス用 S3 バケット*
>
> resource "aws_s3_bucket" "threat_intelligence" {
>
> bucket = "technova-threat-intel-\${random_id.bucket_suffix.hex}"
>
> tags = {
>
> Purpose = "Threat Intelligence Storage"
>
> DataClassification = "Confidential"
>
> }
>
> }
>
> resource "aws_s3_bucket_server_side_encryption_configuration"
> "threat_intel_encryption" {
>
> bucket = aws_s3_bucket.threat_intelligence.id
>
> rule {
>
> apply_server_side_encryption_by_default {
>
> kms_master_key_id = aws_kms_key.security_key.arn
>
> sse_algorithm = "aws:kms"
>
> }
>
> }
>
> }
>
> *\# GuardDuty カスタム脅威インテリジェンス*
>
> resource "aws_guardduty_threatintelset" "custom_iocs" {
>
> activate = true
>
> detector_id = aws_guardduty_detector.main.id
>
> format = "TXT"
>
> location =
> "s3://\${aws_s3_bucket.threat_intelligence.id}/iocs/malicious-ips.txt"
>
> name = "CustomMaliciousIPs"
>
> tags = {
>
> Source = "Internal Threat Intelligence"
>
> }
>
> }
>
> resource "aws_guardduty_ipset" "known_safe_ips" {
>
> activate = true
>
> detector_id = aws_guardduty_detector.main.id
>
> format = "TXT"
>
> location =
> "s3://\${aws_s3_bucket.threat_intelligence.id}/allowlist/safe-ips.txt"
>
> name = "KnownSafeIPs"
>
> }
>
> *\# 脅威インテリジェンス更新用 Lambda*
>
> resource "aws_lambda_function" "threat_intel_updater" {
>
> filename = "threat_intel_updater.zip"
>
> function_name = "threat-intelligence-updater"
>
> role = aws_iam_role.threat_intel_lambda_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 512
>
> environment {
>
> variables = {
>
> THREAT_INTEL_BUCKET = aws_s3_bucket.threat_intelligence.id
>
> GUARDDUTY_DETECTOR_ID = aws_guardduty_detector.main.id
>
> EXTERNAL_FEED_URLS = "https://api.threatintel.com/v1/indicators"
>
> MITRE_ATTACK_API = "https://attack.mitre.org/api/v2/"
>
> }
>
> }
>
> tags = {
>
> Purpose = "Threat Intelligence Automation"
>
> }
>
> }
>
> *\# AI異常検知用 Lambda（Amazon Comprehend使用）*
>
> resource "aws_lambda_function" "ai_anomaly_detector" {
>
> filename = "ai_anomaly_detector.zip"
>
> function_name = "ai-anomaly-detector"
>
> role = aws_iam_role.ai_detection_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 300
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> COMPREHEND_MODEL_ARN =
> aws_comprehend_document_classifier.security_classifier.arn
>
> ANOMALY_THRESHOLD = "0.8"
>
> ALERT_SNS_TOPIC = aws_sns_topic.ai_security_alerts.arn
>
> }
>
> }
>
> }
>
> *\# Amazon Comprehend セキュリティ分類モデル*
>
> resource "aws_comprehend_document_classifier" "security_classifier" {
>
> name = "security-event-classifier"
>
> data_access_role_arn = aws_iam_role.comprehend_role.arn
>
> language_code = "en"
>
> input_data_config {
>
> s3_uri =
> "s3://\${aws_s3_bucket.ml_training_data.id}/security-training-data/"
>
> }
>
> tags = {
>
> Purpose = "Security Event Classification"
>
> ModelType = "DocumentClassifier"
>
> }
>
> }
>
> *\# 脅威ハンティング用 EventBridge ルール*
>
> resource "aws_cloudwatch_event_rule" "threat_hunting_schedule" {
>
> name = "automated-threat-hunting"
>
> description = "Automated threat hunting every 6 hours"
>
> schedule_expression = "rate(6 hours)"
>
> }
>
> resource "aws_cloudwatch_event_target" "threat_hunting_target" {
>
> rule = aws_cloudwatch_event_rule.threat_hunting_schedule.name
>
> target_id = "ThreatHuntingLambda"
>
> arn = aws_lambda_function.threat_hunter.arn
>
> }
>
> **16. セキュリティ教育・トレーニング**
>
> **実装対象サービス**

- **Amazon DynamoDB（教育記録・結果保存）**

- **Amazon SES（フィッシングシミュレーション）**

- **AWS Lambda（教育システム制御）**

- **Amazon CloudWatch（教育メトリクス）**

- **Amazon S3（教育コンテンツ保存）**

> Terraform実装コード
>
> hcl
>
> *\# 従業員セキュリティ教育記録用 DynamoDB*
>
> resource "aws_dynamodb_table" "security_training_records" {
>
> name = "security-training-records"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "employee_id"
>
> range_key = "training_date"
>
> attribute {
>
> name = "employee_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "training_date"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "training_type"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "TrainingTypeIndex"
>
> hash_key = "training_type"
>
> range_key = "training_date"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Security Training Management"
>
> DataRetention = "7years"
>
> }
>
> }
>
> *\# フィッシングシミュレーション結果用 DynamoDB*
>
> resource "aws_dynamodb_table" "phishing_simulation_results" {
>
> name = "phishing-simulation-results"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "employee_id"
>
> range_key = "simulation_id"
>
> attribute {
>
> name = "employee_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "simulation_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "result_status"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "ResultStatusIndex"
>
> hash_key = "result_status"
>
> range_key = "simulation_id"
>
> projection_type = "ALL"
>
> }
>
> ttl {
>
> attribute_name = "expiry_time"
>
> enabled = true
>
> }
>
> tags = {
>
> Purpose = "Phishing Simulation Analytics"
>
> }
>
> }
>
> *\# フィッシングシミュレーション用 SES 設定*
>
> resource "aws_ses_email_identity" "phishing_simulation" {
>
> email = "security-training@technova.com"
>
> tags = {
>
> Purpose = "Phishing Simulation"
>
> }
>
> }
>
> resource "aws_ses_configuration_set" "phishing_tracking" {
>
> name = "phishing-simulation-tracking"
>
> event_destination {
>
> name = "cloudwatch-event-destination"
>
> enabled = true
>
> matching_types = \["send", "bounce", "complaint", "delivery", "open",
> "click"\]
>
> cloudwatch_destination {
>
> default_value = "0"
>
> dimension_name = "MessageTag"
>
> value_source = "messageTag"
>
> }
>
> }
>
> }
>
> *\# フィッシングシミュレーション実行用 Lambda*
>
> resource "aws_lambda_function" "phishing_simulation" {
>
> filename = "phishing_simulation.zip"
>
> function_name = "phishing-simulation-executor"
>
> role = aws_iam_role.phishing_simulation_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 300
>
> memory_size = 512
>
> environment {
>
> variables = {
>
> SES_IDENTITY = aws_ses_email_identity.phishing_simulation.email
>
> RESULTS_TABLE = aws_dynamodb_table.phishing_simulation_results.name
>
> EMPLOYEE_DATABASE = aws_dynamodb_table.employee_directory.name
>
> SIMULATION_TEMPLATES =
> "s3://\${aws_s3_bucket.training_content.id}/phishing-templates/"
>
> SUCCESS_THRESHOLD = "95"
>
> }
>
> }
>
> tags = {
>
> Purpose = "Security Training Automation"
>
> }
>
> }
>
> *\# セキュリティ教育コンテンツ用 S3*
>
> resource "aws_s3_bucket" "training_content" {
>
> bucket = "technova-security-training-\${random_id.bucket_suffix.hex}"
>
> tags = {
>
> Purpose = "Security Training Content"
>
> }
>
> }
>
> resource "aws_s3_bucket_policy" "training_content_policy" {
>
> bucket = aws_s3_bucket.training_content.id
>
> policy = jsonencode({
>
> Version = "2012-10-17"
>
> Statement = \[
>
> {
>
> Sid = "RestrictToVPCEndpoint"
>
> Effect = "Allow"
>
> Principal = "\*"
>
> Action = \[
>
> "s3:GetObject",
>
> "s3:GetObjectVersion"
>
> \]
>
> Resource = "\${aws_s3_bucket.training_content.arn}/\*"
>
> Condition = {
>
> StringEquals = {
>
> "aws:sourceVpce" = aws_vpc_endpoint.s3_endpoint.id
>
> }
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> *\# 教育メトリクス用 CloudWatch ダッシュボード*
>
> resource "aws_cloudwatch_dashboard" "security_training_dashboard" {
>
> dashboard_name = "security-training-metrics"
>
> dashboard_body = jsonencode({
>
> widgets = \[
>
> {
>
> type = "metric"
>
> x = 0
>
> y = 0
>
> width = 12
>
> height = 6
>
> properties = {
>
> metrics = \[
>
> \["AWS/DynamoDB", "ConsumedReadCapacityUnits", "TableName",
> aws_dynamodb_table.security_training_records.name\],
>
> \["AWS/DynamoDB", "ConsumedWriteCapacityUnits", "TableName",
> aws_dynamodb_table.security_training_records.name\],
>
> \["AWS/SES", "Send", "ConfigurationSet",
> aws_ses_configuration_set.phishing_tracking.name\],
>
> \["AWS/SES", "Open", "ConfigurationSet",
> aws_ses_configuration_set.phishing_tracking.name\]
>
> \]
>
> period = 300
>
> stat = "Sum"
>
> region = var.aws_region
>
> title = "Security Training Activity"
>
> }
>
> },
>
> {
>
> type = "log"
>
> x = 0
>
> y = 6
>
> width = 12
>
> height = 6
>
> properties = {
>
> query = "SOURCE '/aws/lambda/phishing-simulation-executor' \| fields
> @timestamp, @message \| filter @message like /SUCCESS/ \| stats
> count() by bin(5m)"
>
> region = var.aws_region
>
> title = "Phishing Simulation Success Rate"
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> **17. サプライチェーンセキュリティ**
>
> **実装対象サービス**

- **AWS Systems Manager（ベンダー評価管理）**

- **Amazon Inspector（コンテナ・依存関係スキャン）**

- **AWS CodeBuild（セキュアビルドパイプライン）**

- **Amazon ECR（コンテナイメージセキュリティ）**

- **AWS Config（サプライチェーンコンプライアンス）**

> Terraform実装コード
>
> hcl
>
> *\# Inspector V2 有効化（コンテナ・EC2脆弱性スキャン）*
>
> resource "aws_inspector2_enabler" "organization" {
>
> account_ids = \[data.aws_caller_identity.current.account_id\]
>
> resource_types = \["ECR", "EC2"\]
>
> }
>
> *\# ECR レポジトリセキュリティ設定*
>
> resource "aws_ecr_repository" "secure_apps" {
>
> count = length(var.application_names)
>
> name = var.application_names\[count.index\]
>
> image_tag_mutability = "IMMUTABLE"
>
> image_scanning_configuration {
>
> scan_on_push = true
>
> }
>
> encryption_configuration {
>
> encryption_type = "KMS"
>
> kms_key = aws_kms_key.ecr_key.arn
>
> }
>
> tags = {
>
> Purpose = "Secure Container Registry"
>
> SecurityScanning = "Enabled"
>
> }
>
> }
>
> *\# ECR ライフサイクルポリシー（古い脆弱性のあるイメージ削除）*
>
> resource "aws_ecr_lifecycle_policy" "security_policy" {
>
> count = length(aws_ecr_repository.secure_apps)
>
> repository = aws_ecr_repository.secure_apps\[count.index\].name
>
> policy = jsonencode({
>
> rules = \[
>
> {
>
> rulePriority = 1
>
> description = "Delete images with HIGH or CRITICAL vulnerabilities
> older than 7 days"
>
> selection = {
>
> tagStatus = "any"
>
> imageCreatedSince = 7
>
> countType = "sinceImagePushed"
>
> countUnit = "days"
>
> }
>
> action = {
>
> type = "expire"
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> *\# CodeBuild セキュアビルドプロジェクト*
>
> resource "aws_codebuild_project" "secure_build" {
>
> name = "secure-build-pipeline"
>
> description = "Secure build pipeline with security scanning"
>
> service_role = aws_iam_role.codebuild_role.arn
>
> artifacts {
>
> type = "CODEPIPELINE"
>
> }
>
> environment {
>
> compute_type = "BUILD_GENERAL1_MEDIUM"
>
> image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"
>
> type = "LINUX_CONTAINER"
>
> image_pull_credentials_type = "CODEBUILD"
>
> privileged_mode = true
>
> environment_variable {
>
> name = "SNYK_TOKEN"
>
> value = aws_ssm_parameter.snyk_token.name
>
> type = "PARAMETER_STORE"
>
> }
>
> environment_variable {
>
> name = "SECURITY_SCAN_THRESHOLD"
>
> value = "HIGH"
>
> }
>
> }
>
> source {
>
> type = "CODEPIPELINE"
>
> buildspec = "buildspec-security.yml"
>
> }
>
> tags = {
>
> Purpose = "Secure Software Supply Chain"
>
> }
>
> }
>
> *\# ベンダー評価結果保存用 DynamoDB*
>
> resource "aws_dynamodb_table" "vendor_assessments" {
>
> name = "vendor-security-assessments"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "vendor_id"
>
> range_key = "assessment_date"
>
> attribute {
>
> name = "vendor_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "assessment_date"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "risk_level"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "RiskLevelIndex"
>
> hash_key = "risk_level"
>
> range_key = "assessment_date"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Vendor Risk Management"
>
> DataRetention = "7years"
>
> }
>
> }
>
> *\# 依存関係チェック用 Lambda*
>
> resource "aws_lambda_function" "dependency_checker" {
>
> filename = "dependency_checker.zip"
>
> function_name = "dependency-security-checker"
>
> role = aws_iam_role.dependency_checker_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> VULNERABILITY_DATABASE = "https://api.osv.dev/v1/query"
>
> SNYK_API_URL = "https://api.snyk.io/v1/"
>
> RESULTS_TABLE = aws_dynamodb_table.dependency_scan_results.name
>
> SEVERITY_THRESHOLD = "HIGH"
>
> }
>
> }
>
> tags = {
>
> Purpose = "Software Supply Chain Security"
>
> }
>
> }
>
> *\# SBOM (Software Bill of Materials) 保存用 S3*
>
> resource "aws_s3_bucket" "sbom_storage" {
>
> bucket = "technova-sbom-\${random_id.bucket_suffix.hex}"
>
> tags = {
>
> Purpose = "SBOM Storage"
>
> DataClassification = "Internal"
>
> }
>
> }
>
> resource "aws_s3_bucket_lifecycle_configuration" "sbom_lifecycle" {
>
> bucket = aws_s3_bucket.sbom_storage.id
>
> rule {
>
> id = "sbom_retention"
>
> status = "Enabled"
>
> expiration {
>
> days = 2555 *\# 7 years retention*
>
> }
>
> noncurrent_version_expiration {
>
> noncurrent_days = 90
>
> }
>
> }
>
> }
>
> **18. プライバシー・データ保護**
>
> **実装対象サービス**

- **Amazon Macie（個人情報自動検出）**

- **AWS KMS（暗号化キー管理）**

- **Amazon S3（データローカライゼーション）**

- **AWS CloudTrail（データアクセス監査）**

- **AWS Config（プライバシー設定監視）**

> Terraform実装コード
>
> hcl
>
> *\# Amazon Macie 有効化（個人情報検出）*
>
> resource "aws_macie2_account" "main" {
>
> finding_publishing_frequency = "FIFTEEN_MINUTES"
>
> status = "ENABLED"
>
> }
>
> *\# Macie カスタム分類ジョブ*
>
> resource "aws_macie2_classification_job" "pii_discovery" {
>
> job_type = "SCHEDULED"
>
> name = "pii-discovery-job"
>
> s3_job_definition {
>
> bucket_definitions {
>
> account_id = data.aws_caller_identity.current.account_id
>
> buckets = \[aws_s3_bucket.data_lake.arn\]
>
> }
>
> scoping {
>
> excludes {
>
> and {
>
> simple_scope_term {
>
> comparator = "STARTS_WITH"
>
> key = "OBJECT_KEY"
>
> values = \["logs/", "temp/"\]
>
> }
>
> }
>
> }
>
> }
>
> }
>
> schedule_frequency = "DAILY"
>
> tags = {
>
> Purpose = "PII Discovery and Classification"
>
> }
>
> }
>
> *\# 地域別データ分離用 S3 バケット（日本）*
>
> resource "aws_s3_bucket" "japan_data" {
>
> bucket = "technova-japan-data-\${random_id.bucket_suffix.hex}"
>
> tags = {
>
> DataResidency = "Japan"
>
> GDPRScope = "false"
>
> Purpose = "Japan Personal Data Storage"
>
> }
>
> }
>
> resource "aws_s3_bucket_policy" "japan_data_policy" {
>
> bucket = aws_s3_bucket.japan_data.id
>
> policy = jsonencode({
>
> Version = "2012-10-17"
>
> Statement = \[
>
> {
>
> Sid = "RestrictToJapanOnly"
>
> Effect = "Deny"
>
> Principal = "\*"
>
> Action = "s3:\*"
>
> Resource = \[
>
> aws_s3_bucket.japan_data.arn,
>
> "\${aws_s3_bucket.japan_data.arn}/\*"
>
> \]
>
> Condition = {
>
> StringNotEquals = {
>
> "aws:RequestedRegion" = "ap-northeast-1"
>
> }
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> *\# EU データ用 S3 バケット（GDPR対応）*
>
> resource "aws_s3_bucket" "eu_data" {
>
> bucket = "technova-eu-data-\${random_id.bucket_suffix.hex}"
>
> tags = {
>
> DataResidency = "EU"
>
> GDPRScope = "true"
>
> Purpose = "EU Personal Data Storage"
>
> }
>
> }
>
> *\# GDPR データ主体権利対応用 Lambda*
>
> resource "aws_lambda_function" "gdpr_rights_handler" {
>
> filename = "gdpr_rights_handler.zip"
>
> function_name = "gdpr-data-subject-rights"
>
> role = aws_iam_role.gdpr_lambda_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> EU_DATA_BUCKET = aws_s3_bucket.eu_data.id
>
> JAPAN_DATA_BUCKET = aws_s3_bucket.japan_data.id
>
> MACIE_FINDINGS_TABLE = aws_dynamodb_table.macie_findings.name
>
> DATA_CATALOG_TABLE = aws_dynamodb_table.data_catalog.name
>
> RESPONSE_DEADLINE = "30" *\# days*
>
> }
>
> }
>
> tags = {
>
> Purpose = "GDPR Compliance Automation"
>
> }
>
> }
>
> *\# 個人データカタログ用 DynamoDB*
>
> resource "aws_dynamodb_table" "data_catalog" {
>
> name = "personal-data-catalog"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "data_subject_id"
>
> range_key = "data_location"
>
> attribute {
>
> name = "data_subject_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "data_location"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "data_type"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "retention_date"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "DataTypeIndex"
>
> hash_key = "data_type"
>
> range_key = "retention_date"
>
> projection_type = "ALL"
>
> }
>
> ttl {
>
> attribute_name = "expiry_timestamp"
>
> enabled = true
>
> }
>
> tags = {
>
> Purpose = "Personal Data Inventory"
>
> GDPRCompliance = "Required"
>
> }
>
> }
>
> *\# 忘れられる権利対応用 Lambda*
>
> resource "aws_lambda_function" "right_to_erasure" {
>
> filename = "right_to_erasure.zip"
>
> function_name = "gdpr-right-to-erasure"
>
> role = aws_iam_role.erasure_lambda_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> environment {
>
> variables = {
>
> DATA_CATALOG_TABLE = aws_dynamodb_table.data_catalog.name
>
> BACKUP_BUCKET = aws_s3_bucket.gdpr_backup.id
>
> LOG_GROUP = aws_cloudwatch_log_group.gdpr_operations.name
>
> }
>
> }
>
> tags = {
>
> Purpose = "GDPR Right to Erasure"
>
> }
>
> }
>
> *\# データポータビリティ用 Lambda*
>
> resource "aws_lambda_function" "data_portability" {
>
> filename = "data_portability.zip"
>
> function_name = "gdpr-data-portability"
>
> role = aws_iam_role.portability_lambda_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> environment {
>
> variables = {
>
> DATA_CATALOG_TABLE = aws_dynamodb_table.data_catalog.name
>
> EXPORT_BUCKET = aws_s3_bucket.data_export.id
>
> ENCRYPTION_KEY = aws_kms_key.gdpr_key.arn
>
> }
>
> }
>
> tags = {
>
> Purpose = "GDPR Data Portability"
>
> }
>
> }
>
> *\# GDPR 監査ログ用 CloudWatch Log Group*
>
> resource "aws_cloudwatch_log_group" "gdpr_operations" {
>
> name = "/aws/gdpr/operations"
>
> retention_in_days = 2555 *\# 7 years*
>
> kms_key_id = aws_kms_key.gdpr_key.arn
>
> tags = {
>
> Purpose = "GDPR Operations Audit Log"
>
> }
>
> }
>
> **19. セキュリティコスト最適化**
>
> **実装対象サービス**

- **AWS Cost Explorer（セキュリティコスト分析）**

- **AWS Budgets（セキュリティ予算管理）**

- **AWS Trusted Advisor（コスト最適化推奨）**

- **Amazon CloudWatch（リソース使用率監視）**

- **AWS Lambda（自動コスト最適化）**

> Terraform実装コード
>
> hcl
>
> *\# セキュリティコスト監視用 Cost Budget*
>
> resource "aws_budgets_budget" "security_services_budget" {
>
> name = "security-services-budget"
>
> budget_type = "COST"
>
> limit_amount = "10000"
>
> limit_unit = "USD"
>
> time_unit = "MONTHLY"
>
> cost_filters {
>
> service = \[
>
> "Amazon GuardDuty",
>
> "AWS Security Hub",
>
> "Amazon Macie",
>
> "Amazon Inspector",
>
> "AWS Config",
>
> "AWS CloudTrail",
>
> "AWS Key Management Service"
>
> \]
>
> }
>
> notification {
>
> comparison_operator = "GREATER_THAN"
>
> threshold = 80
>
> threshold_type = "PERCENTAGE"
>
> notification_type = "ACTUAL"
>
> subscriber_email_addresses = \["security-team@technova.com"\]
>
> }
>
> notification {
>
> comparison_operator = "GREATER_THAN"
>
> threshold = 100
>
> threshold_type = "PERCENTAGE"
>
> notification_type = "FORECASTED"
>
> subscriber_email_addresses = \["ciso@technova.com"\]
>
> }
>
> }
>
> *\# セキュリティツール使用率分析用 Lambda*
>
> resource "aws_lambda_function" "security_cost_analyzer" {
>
> filename = "security_cost_analyzer.zip"
>
> function_name = "security-cost-analyzer"
>
> role = aws_iam_role.cost_analyzer_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 600
>
> memory_size = 512
>
> environment {
>
> variables = {
>
> COST_EXPLORER_REGION = "us-east-1"
>
> SECURITY_SERVICES = "GuardDuty,SecurityHub,Macie,Inspector,Config"
>
> UTILIZATION_THRESHOLD = "70"
>
> REPORT_BUCKET = aws_s3_bucket.cost_reports.id
>
> }
>
> }
>
> tags = {
>
> Purpose = "Security Cost Optimization"
>
> }
>
> }
>
> *\# コスト最適化推奨事項保存用 DynamoDB*
>
> resource "aws_dynamodb_table" "cost_optimization_recommendations" {
>
> name = "security-cost-optimization"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "service_name"
>
> range_key = "recommendation_date"
>
> attribute {
>
> name = "service_name"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "recommendation_date"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "potential_savings"
>
> type = "N"
>
> }
>
> global_secondary_index {
>
> name = "SavingsIndex"
>
> hash_key = "potential_savings"
>
> range_key = "recommendation_date"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Cost Optimization Tracking"
>
> }
>
> }
>
> *\# 未使用セキュリティリソース検出用 Lambda*
>
> resource "aws_lambda_function" "unused_security_resources" {
>
> filename = "unused_resources_detector.zip"
>
> function_name = "unused-security-resources-detector"
>
> role = aws_iam_role.resource_optimizer_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> UNUSED_THRESHOLD_DAYS = "30"
>
> AUTO_CLEANUP_ENABLED = "false"
>
> NOTIFICATION_TOPIC = aws_sns_topic.cost_optimization_alerts.arn
>
> }
>
> }
>
> tags = {
>
> Purpose = "Resource Optimization"
>
> }
>
> }
>
> *\# セキュリティツール ROI 分析用 CloudWatch ダッシュボード*
>
> resource "aws_cloudwatch_dashboard" "security_roi_dashboard" {
>
> dashboard_name = "security-investment-roi"
>
> dashboard_body = jsonencode({
>
> widgets = \[
>
> {
>
> type = "metric"
>
> x = 0
>
> y = 0
>
> width = 12
>
> height = 6
>
> properties = {
>
> metrics = \[
>
> \["AWS/GuardDuty", "FindingCount", "DetectorId",
> aws_guardduty_detector.main.id\],
>
> \["AWS/SecurityHub", "Findings", "ComplianceType", "FAILED"\],
>
> \["AWS/Config", "NonCompliantRules"\]
>
> \]
>
> period = 3600
>
> stat = "Sum"
>
> region = var.aws_region
>
> title = "Security Tools Effectiveness"
>
> }
>
> },
>
> {
>
> type = "metric"
>
> x = 0
>
> y = 6
>
> width = 12
>
> height = 6
>
> properties = {
>
> metrics = \[
>
> \["AWS/Billing", "EstimatedCharges", "ServiceName", "Amazon
> GuardDuty"\],
>
> \["AWS/Billing", "EstimatedCharges", "ServiceName", "AWS Security
> Hub"\],
>
> \["AWS/Billing", "EstimatedCharges", "ServiceName", "Amazon Macie"\]
>
> \]
>
> period = 86400
>
> stat = "Maximum"
>
> region = "us-east-1"
>
> title = "Security Services Cost Trend"
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> **20. 継続的改善・成熟度向上**
>
> **実装対象サービス**

- **AWS Well-Architected Tool（セキュリティ評価）**

- **AWS Systems Manager（運用成熟度管理）**

- **Amazon QuickSight（セキュリティメトリクス可視化）**

- **AWS Config（設定管理成熟度）**

- **AWS Lambda（成熟度評価自動化）**

> Terraform実装コード
>
> hcl
>
> *\# セキュリティ成熟度評価用 DynamoDB*
>
> resource "aws_dynamodb_table" "security_maturity_assessments" {
>
> name = "security-maturity-assessments"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "assessment_id"
>
> range_key = "assessment_date"
>
> attribute {
>
> name = "assessment_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "assessment_date"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "maturity_level"
>
> type = "N"
>
> }
>
> global_secondary_index {
>
> name = "MaturityLevelIndex"
>
> hash_key = "maturity_level"
>
> range_key = "assessment_date"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Security Maturity Tracking"
>
> }
>
> }
>
> *\# セキュリティメトリクス集約用 Lambda*
>
> resource "aws_lambda_function" "security_metrics_aggregator" {
>
> filename = "security_metrics_aggregator.zip"
>
> function_name = "security-metrics-aggregator"
>
> role = aws_iam_role.metrics_aggregator_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> SECURITY_HUB_REGION = var.aws_region
>
> GUARDDUTY_DETECTOR_ID = aws_guardduty_detector.main.id
>
> CONFIG_RECORDER_NAME = aws_config_configuration_recorder.recorder.name
>
> MATURITY_TABLE = aws_dynamodb_table.security_maturity_assessments.name
>
> CLOUDWATCH_NAMESPACE = "TechNova/SecurityMaturity"
>
> }
>
> }
>
> tags = {
>
> Purpose = "Security Maturity Measurement"
>
> }
>
> }
>
> *\# セキュリティベンチマーク用 Systems Manager パラメータ*
>
> resource "aws_ssm_parameter" "security_benchmarks" {
>
> name = "/security/benchmarks/current"
>
> type = "String"
>
> value = jsonencode({
>
> detection_time_target = 300 *\# 5 minutes*
>
> containment_time_target = 1800 *\# 30 minutes*
>
> recovery_time_target = 14400 *\# 4 hours*
>
> false_positive_threshold = 5 *\# 5%*
>
> compliance_score_target = 99.5 *\# 99.5%*
>
> vulnerability_remediation = {
>
> critical = 2880 *\# 48 hours in minutes*
>
> high = 10080 *\# 7 days in minutes*
>
> }
>
> })
>
> tags = {
>
> Purpose = "Security Performance Benchmarks"
>
> }
>
> }
>
> *\# PDCA サイクル実行用 Step Functions*
>
> resource "aws_sfn_state_machine" "security_pdca_cycle" {
>
> name = "security-pdca-cycle"
>
> role_arn = aws_iam_role.step_functions_role.arn
>
> definition = jsonencode({
>
> Comment = "Security PDCA Cycle Automation"
>
> StartAt = "Plan"
>
> States = {
>
> Plan = {
>
> Type = "Task"
>
> Resource = aws_lambda_function.security_planning.arn
>
> Next = "Do"
>
> Retry = \[{
>
> ErrorEquals = \["Lambda.ServiceException",
> "Lambda.AWSLambdaException"\]
>
> IntervalSeconds = 2
>
> MaxAttempts = 3
>
> BackoffRate = 2.0
>
> }\]
>
> }
>
> Do = {
>
> Type = "Task"
>
> Resource = aws_lambda_function.security_implementation.arn
>
> Next = "Check"
>
> Retry = \[{
>
> ErrorEquals = \["Lambda.ServiceException",
> "Lambda.AWSLambdaException"\]
>
> IntervalSeconds = 2
>
> MaxAttempts = 3
>
> BackoffRate = 2.0
>
> }\]
>
> }
>
> Check = {
>
> Type = "Task"
>
> Resource = aws_lambda_function.security_assessment.arn
>
> Next = "Act"
>
> Retry = \[{
>
> ErrorEquals = \["Lambda.ServiceException",
> "Lambda.AWSLambdaException"\]
>
> IntervalSeconds = 2
>
> MaxAttempts = 3
>
> BackoffRate = 2.0
>
> }\]
>
> }
>
> Act = {
>
> Type = "Task"
>
> Resource = aws_lambda_function.security_improvement.arn
>
> End = true
>
> Retry = \[{
>
> ErrorEquals = \["Lambda.ServiceException",
> "Lambda.AWSLambdaException"\]
>
> IntervalSeconds = 2
>
> MaxAttempts = 3
>
> BackoffRate = 2.0
>
> }\]
>
> }
>
> }
>
> })
>
> tags = {
>
> Purpose = "Security Continuous Improvement"
>
> }
>
> }
>
> *\# セキュリティKPI可視化用 QuickSight データセット*
>
> resource "aws_quicksight_data_set" "security_kpis" {
>
> data_set_id = "security-kpis-dataset"
>
> name = "Security KPIs Dataset"
>
> physical_table_map {
>
> physical_table_id = "security-metrics-table"
>
> s3_source {
>
> data_source_arn = aws_quicksight_data_source.security_metrics_s3.arn
>
> input_columns {
>
> name = "metric_name"
>
> type = "STRING"
>
> }
>
> input_columns {
>
> name = "metric_value"
>
> type = "DECIMAL"
>
> }
>
> input_columns {
>
> name = "timestamp"
>
> type = "DATETIME"
>
> }
>
> input_columns {
>
> name = "target_value"
>
> type = "DECIMAL"
>
> }
>
> }
>
> }
>
> tags = {
>
> Purpose = "Security KPI Visualization"
>
> }
>
> }
>
> *\# セキュリティ成熟度レポート生成用 EventBridge スケジュール*
>
> resource "aws_cloudwatch_event_rule" "monthly_maturity_assessment" {
>
> name = "monthly-security-maturity-assessment"
>
> description = "Monthly security maturity assessment"
>
> schedule_expression = "cron(0 9 1 \* ? \*)" *\# 毎月1日 9:00 JST*
>
> }
>
> resource "aws_cloudwatch_event_target" "maturity_assessment_target" {
>
> rule = aws_cloudwatch_event_rule.monthly_maturity_assessment.name
>
> target_id = "MaturityAssessmentLambda"
>
> arn = aws_lambda_function.security_metrics_aggregator.arn
>
> }
>
> **2１. セキュリティ実装ロードマップ**
>
> **実装対象サービス**

- **AWS Systems Manager（実装進捗管理）**

- **AWS CodePipeline（段階的デプロイメント）**

- **Amazon EventBridge（フェーズ管理）**

- **AWS Lambda（実装自動化）**

- **Amazon CloudWatch（実装監視）**

> Terraform実装コード
>
> hcl
>
> *\# 実装フェーズ管理用 DynamoDB*
>
> resource "aws_dynamodb_table" "implementation_roadmap" {
>
> name = "security-implementation-roadmap"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "phase_id"
>
> range_key = "task_id"
>
> attribute {
>
> name = "phase_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "task_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "status"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "priority"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "StatusIndex"
>
> hash_key = "status"
>
> range_key = "priority"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Implementation Progress Tracking"
>
> }
>
> }
>
> *\# フェーズ1実装用 CodePipeline*
>
> resource "aws_codepipeline" "phase1_foundation" {
>
> name = "security-phase1-foundation"
>
> role_arn = aws_iam_role.codepipeline_role.arn
>
> artifact_store {
>
> location = aws_s3_bucket.pipeline_artifacts.bucket
>
> type = "S3"
>
> encryption_key {
>
> id = aws_kms_key.pipeline_key.arn
>
> type = "KMS"
>
> }
>
> }
>
> stage {
>
> name = "Source"
>
> action {
>
> name = "Source"
>
> category = "Source"
>
> owner = "AWS"
>
> provider = "S3"
>
> version = "1"
>
> output_artifacts = \["source_output"\]
>
> configuration = {
>
> S3Bucket = aws_s3_bucket.terraform_source.bucket
>
> S3ObjectKey = "phase1-foundation.zip"
>
> }
>
> }
>
> }
>
> stage {
>
> name = "SecurityValidation"
>
> action {
>
> name = "SecurityScan"
>
> category = "Build"
>
> owner = "AWS"
>
> provider = "CodeBuild"
>
> version = "1"
>
> input_artifacts = \["source_output"\]
>
> configuration = {
>
> ProjectName = aws_codebuild_project.security_validation.name
>
> }
>
> }
>
> }
>
> stage {
>
> name = "Deploy"
>
> action {
>
> name = "DeployFoundation"
>
> category = "Build"
>
> owner = "AWS"
>
> provider = "CodeBuild"
>
> version = "1"
>
> input_artifacts = \["source_output"\]
>
> configuration = {
>
> ProjectName = aws_codebuild_project.phase1_deploy.name
>
> }
>
> }
>
> }
>
> tags = {
>
> Phase = "Foundation"
>
> Priority = "Critical"
>
> }
>
> }
>
> *\# 実装進捗監視用 Lambda*
>
> resource "aws_lambda_function" "implementation_monitor" {
>
> filename = "implementation_monitor.zip"
>
> function_name = "security-implementation-monitor"
>
> role = aws_iam_role.implementation_monitor_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 300
>
> environment {
>
> variables = {
>
> ROADMAP_TABLE = aws_dynamodb_table.implementation_roadmap.name
>
> CODEPIPELINE_NAMES =
> "security-phase1-foundation,security-phase2-enhancement"
>
> SLACK_WEBHOOK_URL = aws_ssm_parameter.slack_webhook.name
>
> SUCCESS_CRITERIA_TABLE = aws_dynamodb_table.success_criteria.name
>
> }
>
> }
>
> tags = {
>
> Purpose = "Implementation Progress Monitoring"
>
> }
>
> }
>
> *\# 成功基準管理用 DynamoDB*
>
> resource "aws_dynamodb_table" "success_criteria" {
>
> name = "implementation-success-criteria"
>
> billing_mode = "PAY_PER_REQUEST"
>
> hash_key = "phase_id"
>
> range_key = "criterion_id"
>
> attribute {
>
> name = "phase_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "criterion_id"
>
> type = "S"
>
> }
>
> attribute {
>
> name = "achievement_status"
>
> type = "S"
>
> }
>
> global_secondary_index {
>
> name = "AchievementIndex"
>
> hash_key = "achievement_status"
>
> range_key = "phase_id"
>
> projection_type = "ALL"
>
> }
>
> tags = {
>
> Purpose = "Success Criteria Tracking"
>
> }
>
> }
>
> *\# フェーズゲート検証用 Lambda*
>
> resource "aws_lambda_function" "phase_gate_validator" {
>
> filename = "phase_gate_validator.zip"
>
> function_name = "security-phase-gate-validator"
>
> role = aws_iam_role.phase_gate_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 600
>
> environment {
>
> variables = {
>
> SUCCESS_CRITERIA_TABLE = aws_dynamodb_table.success_criteria.name
>
> SECURITY_HUB_REGION = var.aws_region
>
> COMPLIANCE_THRESHOLD = "95"
>
> APPROVAL_SNS_TOPIC = aws_sns_topic.phase_gate_approvals.arn
>
> }
>
> }
>
> tags = {
>
> Purpose = "Phase Gate Validation"
>
> }
>
> }
>
> *\# 実装進捗ダッシュボード*
>
> resource "aws_cloudwatch_dashboard" "implementation_progress" {
>
> dashboard_name = "security-implementation-progress"
>
> dashboard_body = jsonencode({
>
> widgets = \[
>
> {
>
> type = "metric"
>
> x = 0
>
> y = 0
>
> width = 12
>
> height = 6
>
> properties = {
>
> metrics = \[
>
> \["AWS/CodePipeline", "PipelineExecutionSuccess", "PipelineName",
> aws_codepipeline.phase1_foundation.name\],
>
> \["AWS/CodeBuild", "SucceededBuilds", "ProjectName",
> aws_codebuild_project.phase1_deploy.name\]
>
> \]
>
> period = 3600
>
> stat = "Sum"
>
> region = var.aws_region
>
> title = "Implementation Pipeline Success Rate"
>
> }
>
> },
>
> {
>
> type = "log"
>
> x = 0
>
> y = 6
>
> width = 12
>
> height = 6
>
> properties = {
>
> query = "SOURCE '/aws/lambda/security-implementation-monitor' \|
> fields @timestamp, phase_id, completion_percentage \| filter
> completion_percentage \> 0 \| stats max(completion_percentage) by
> phase_id"
>
> region = var.aws_region
>
> title = "Phase Completion Progress"
>
> }
>
> }
>
> \]
>
> })
>
> }
>
> *\# 自動ロールバック機能用 Lambda*
>
> resource "aws_lambda_function" "implementation_rollback" {
>
> filename = "implementation_rollback.zip"
>
> function_name = "security-implementation-rollback"
>
> role = aws_iam_role.rollback_role.arn
>
> handler = "index.handler"
>
> runtime = "python3.9"
>
> timeout = 900
>
> memory_size = 1024
>
> environment {
>
> variables = {
>
> TERRAFORM_STATE_BUCKET = aws_s3_bucket.terraform_state.id
>
> BACKUP_RETENTION_DAYS = "30"
>
> ROLLBACK_APPROVAL_TOPIC = aws_sns_topic.rollback_approvals.arn
>
> }
>
> }
>
> tags = {
>
> Purpose = "Implementation Rollback Automation"
>
> }
>
> }
>
> *\# 実装完了通知用 EventBridge ルール*
>
> resource "aws_cloudwatch_event_rule" "implementation_milestones" {
>
> name = "security-implementation-milestones"
>
> description = "Security implementation milestone notifications"
>
> event_pattern = jsonencode({
>
> source = \["custom.security.implementation"\]
>
> detail-type = \["Phase Completion", "Milestone Achievement"\]
>
> detail = {
>
> status = \["COMPLETED", "ACHIEVED"\]
>
> }
>
> })
>
> }
>
> resource "aws_cloudwatch_event_target" "milestone_notification" {
>
> rule = aws_cloudwatch_event_rule.implementation_milestones.name
>
> target_id = "MilestoneNotificationLambda"
>
> arn = aws_lambda_function.milestone_notifier.arn
>
> }
>
> **まとめ**
>
> **この実装コードにより、以下のAWSサービスを使用して包括的なセキュリティ体制を構築できます：**
>
> **主要サービス対応表**

<span id="_Toc199105014" class="anchor"></span>**主要サービス対応表**

| **セクション** | **主要AWSサービス** | **具体的な設定内容** |
|:---|:---|:---|
| **セキュリティ運用・管理** | Security Hub, GuardDuty, CloudWatch | 統合セキュリティ監視、メトリクス収集、アラート設定 |
| **脅威対応** | GuardDuty, Lambda, S3, EventBridge | 脅威インテリジェンス統合、AI分析、自動対応 |
| **セキュリティ教育** | DynamoDB, SES, Lambda, CloudWatch | フィッシングシミュレーション、教育記録管理 |
| **サプライチェーン** | Inspector, ECR, CodeBuild, Config | 脆弱性スキャン、セキュアビルド、SBOM管理 |
| **プライバシー保護** | Macie, KMS, S3, Lambda | 個人情報検出、暗号化、GDPR対応 |
| **コスト最適化** | Cost Explorer, Budgets, Lambda | セキュリティコスト監視、ROI分析 |
| **継続的改善** | Systems Manager, QuickSight, Step Functions | 成熟度評価、PDCA自動化、KPI可視化 |
| **実装管理** | CodePipeline, DynamoDB, EventBridge | 段階的実装、進捗監視、フェーズゲート |

> **重要な設定ポイント**

1.  **自動化の実現: Lambda関数による運用タスクの自動化**

2.  **統合監視: CloudWatchダッシュボードによる一元的な可視化**

3.  **コンプライアンス: Config Rules、Security Hub標準による継続的監査**

4.  **データ保護: KMS暗号化、Macie個人情報検出の組み合わせ**

5.  **コスト管理: Budgets、Cost Explorerによる費用対効果の監視**

**これらの具体的な実装により、TechNova社の120アカウント環境において、実用的で効果的なセキュリティ体制を段階的に構築できます。**

## **IaC & CI/CD要件**

**IaC & CI/CD 統合要件 - 包括的セキュリティ分析パイプライン**

**目次**

1.  [概要](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#%E6%A6%82%E8%A6%81)

2.  [パイプライン全体構成](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#1-%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3%E5%85%A8%E4%BD%93%E6%A7%8B%E6%88%90)

3.  [静的解析の詳細実装](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#2-%E9%9D%99%E7%9A%84%E8%A7%A3%E6%9E%90%E3%81%AE%E8%A9%B3%E7%B4%B0%E5%AE%9F%E8%A3%85)

4.  [IAM
    アクセス分析の詳細実装](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#3-iam-%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E5%88%86%E6%9E%90%E3%81%AE%E8%A9%B3%E7%B4%B0%E5%AE%9F%E8%A3%85)

5.  [動的解析の詳細実装](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#4-%E5%8B%95%E7%9A%84%E8%A7%A3%E6%9E%90%E3%81%AE%E8%A9%B3%E7%B4%B0%E5%AE%9F%E8%A3%85)

6.  [エラーハンドリング Lambda
    関数](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#5-%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0-lambda-%E9%96%A2%E6%95%B0%E8%A9%B3%E7%B4%B0%E5%AE%9F%E8%A3%85)

7.  [監視とレポーティングシステム](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#6-%E7%9B%A3%E8%A6%96%E3%81%A8%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0)

8.  [実装まとめ](https://claude.ai/chat/16c88446-c69f-4115-9456-55d2d27864d0#7-%E5%AE%9F%E8%A3%85%E3%81%BE%E3%81%A8%E3%82%81)

**概要**

**プロジェクト背景**

TechNova社は現在、従来のモノリシックアーキテクチャから120アカウント構成のマイクロサービス環境への移行を進めています。このプロセスにおいて、Infrastructure
as Code (IaC)
とCI/CDパイプラインの統合により、セキュリティ品質を担保しながら開発効率を最大化する包括的なセキュリティ分析システムが必要となりました。

**要件の目的**

本要件書は、静的解析、IAM権限分析、動的脆弱性検証を統合した多層防御型のDevSecOpsパイプラインを定義します。これにより、デプロイ前の段階で潜在的なセキュリティリスクを確実に検出・修正し、120アカウント環境全体のセキュリティガバナンスを実現します。

**パイプライン実行順序**

ソース取得 → 静的解析 → IAM分析 → 動的解析 → 承認 → デプロイ

↓ ↓ ↓ ↓ ↓ ↓

Git取得 構文チェック 権限分析 脆弱性検証 人間判断 実行

↓ ↓ ↓ ↓ ↓ ↓

1-2分 10-20分 5-10分 45-60分 可変 10-20分

**実装対象サービス**

- **AWS CodePipeline**: メインパイプライン制御・ワークフロー管理

- **AWS CodeBuild**: ステージ別実行環境・分析ツール実行

- **AWS CodeCommit**: ソースコード管理・バージョン管理

- **AWS S3**: アーティファクト保存・ログ管理・レポート保存

- **AWS SNS**: エラー通知・承認要求・アラート配信

- **AWS Lambda**: エラーハンドリング・自動化処理・レポート生成

- **AWS IAM Access Analyzer**: 権限分析・外部アクセス検出

- **AWS DynamoDB**: 結果保存・メトリクス追跡・エラー記録

- **Amazon CloudWatch**: 監視・メトリクス・ダッシュボード

- **AWS Systems Manager**: 設定管理・パラメータストア

- **Amazon EventBridge**: イベント処理・スケジューリング

**セキュリティ分析の3層構造**

**第1層: 静的解析 (10-20分)**

- **Terraform Validate**: 構文検証・参照整合性

- **TFLint**: コード品質・ベストプラクティス

- **Checkov**: セキュリティ設定・コンプライアンス

**第2層: IAM分析 (5-10分)**

- **組織レベル分析**: 120アカウント横断の権限関係

- **外部アクセス検出**: 予期しない外部からのアクセス

- **未使用権限特定**: 過剰権限・不要権限の洗い出し

**第3層: 動的解析 (45-60分・並列実行)**

- **インフラ脆弱性スキャン**: ネットワーク・OS・ミドルウェア

- **アプリ脆弱性スキャン**: OWASP Top 10・Webアプリケーション

- **ペネトレーションテスト**: 実悪用可能性・侵入経路検証

**1. パイプライン全体構成**

**1.1 基本アーキテクチャ**

resource "aws_codepipeline" "security_integrated_pipeline" {

name = "security-integrated-deployment-pipeline"

role_arn = aws_iam_role.codepipeline_role.arn

artifact_store {

location = aws_s3_bucket.pipeline_artifacts.bucket

type = "S3"

encryption_key {

id = aws_kms_key.pipeline_key.arn

type = "KMS"

}

}

\# ========================================

\# ソース取得

\# ========================================

stage {

name = "Source"

action {

name = "SourceAction"

category = "Source"

owner = "AWS"

provider = "CodeCommit"

version = "1"

output_artifacts = \["source_output"\]

configuration = {

RepositoryName = aws_codecommit_repository.iac_repo.repository_name

BranchName = "main"

}

}

}

\# ========================================

\# 静的解析（3つのステージに分割）

\# ========================================

stage {

name = "TerraformValidate"

action {

name = "ValidateAction"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_validate.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "ERROR_HANDLING_MODE"

value = var.error_handling_mode

type = "PLAINTEXT"

}

\])

}

on_failure {

action_type_id {

category = "Invoke"

owner = "AWS"

provider = "Lambda"

version = "1"

}

configuration = {

FunctionName = aws_lambda_function.pipeline_error_handler.function_name

UserParameters = jsonencode({

stage_name = "TerraformValidate"

error_type = "VALIDATION_ERROR"

pipeline_name = "security-integrated-deployment-pipeline"

})

}

}

}

}

\# 手動承認ステージ（Validateエラー時）

stage {

name = "ValidateErrorApproval"

action {

name = "ManualApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.pipeline_approvals.arn

CustomData = "Terraform Validate failed. Review errors and approve to
continue or reject to stop pipeline."

}

}

}

stage {

name = "TFLint"

action {

name = "LintAction"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.tflint.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "ERROR_HANDLING_MODE"

value = var.error_handling_mode

type = "PLAINTEXT"

}

\])

}

on_failure {

action_type_id {

category = "Invoke"

owner = "AWS"

provider = "Lambda"

version = "1"

}

configuration = {

FunctionName = aws_lambda_function.pipeline_error_handler.function_name

UserParameters = jsonencode({

stage_name = "TFLint"

error_type = "LINTING_ERROR"

pipeline_name = "security-integrated-deployment-pipeline"

})

}

}

}

}

\# 手動承認ステージ（TFLintエラー時）

stage {

name = "TFLintErrorApproval"

action {

name = "ManualApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.pipeline_approvals.arn

CustomData = "TFLint analysis failed. Review linting errors and approve
to continue."

}

}

}

stage {

name = "Checkov"

action {

name = "CheckovAction"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.checkov.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "ERROR_HANDLING_MODE"

value = var.error_handling_mode

type = "PLAINTEXT"

}

\])

}

on_failure {

action_type_id {

category = "Invoke"

owner = "AWS"

provider = "Lambda"

version = "1"

}

configuration = {

FunctionName = aws_lambda_function.pipeline_error_handler.function_name

UserParameters = jsonencode({

stage_name = "Checkov"

error_type = "SECURITY_VIOLATION"

pipeline_name = "security-integrated-deployment-pipeline"

})

}

}

}

}

\# セキュリティ承認ステージ（静的解析完了後）

stage {

name = "StaticAnalysisApproval"

action {

name = "StaticAnalysisApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.security_approvals.arn

CustomData = "Static security analysis complete. Review all findings
before proceeding to IAM analysis."

}

}

}

\# ========================================

\# IAM アクセス分析

\# ========================================

stage {

name = "IAMAccessAnalysis"

action {

name = "AnalyzeIAMAccess"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.iam_access_analysis.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "TARGET_ENVIRONMENT"

value = "staging"

type = "PLAINTEXT"

},

{

name = "ANALYZER_ARN"

value = aws_accessanalyzer_analyzer.organization_analyzer.arn

type = "PLAINTEXT"

},

{

name = "ERROR_HANDLING_MODE"

value = var.error_handling_mode

type = "PLAINTEXT"

}

\])

}

on_failure {

action_type_id {

category = "Invoke"

owner = "AWS"

provider = "Lambda"

version = "1"

}

configuration = {

FunctionName = aws_lambda_function.pipeline_error_handler.function_name

UserParameters = jsonencode({

stage_name = "IAMAccessAnalysis"

error_type = "IAM_SECURITY_VIOLATION"

pipeline_name = "security-integrated-deployment-pipeline"

})

}

}

}

}

\# IAM分析結果承認ステージ

stage {

name = "IAMAnalysisApproval"

action {

name = "IAMAnalysisApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.iam_analysis_approvals.arn

CustomData = "IAM Access Analysis complete. Review external access
findings and unused permissions before proceeding to dynamic analysis."

}

}

}

\# ========================================

\# 動的解析（並列実行）

\# ========================================

stage {

name = "DynamicSecurityAnalysis"

action {

name = "InfraVulnScan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.dynamic_vuln_scan.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "TARGET_ENVIRONMENT"

value = "staging"

type = "PLAINTEXT"

},

{

name = "ERROR_HANDLING_MODE"

value = var.error_handling_mode

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

action {

name = "AppVulnScan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.dynamic_app_scan.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "TARGET_ENVIRONMENT"

value = "staging"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

action {

name = "PenTest"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.penetration_test.name

EnvironmentVariables = jsonencode(\[

{

name = "PIPELINE_EXECUTION_ID"

value = "#{codepipeline.PipelineExecutionId}"

type = "PLAINTEXT"

},

{

name = "TARGET_ENVIRONMENT"

value = "staging"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

\# 動的解析結果承認ステージ

stage {

name = "DynamicAnalysisApproval"

action {

name = "DynamicAnalysisApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.security_approvals.arn

CustomData = "Dynamic security analysis complete. Review vulnerability
scan results and penetration test findings."

}

}

}

\# ========================================

\# デプロイステージ（開発環境）

\# ========================================

stage {

name = "DeployDev"

action {

name = "DeployToDev"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_deploy_dev.name

EnvironmentVariables = jsonencode(\[

{

name = "TARGET_ENVIRONMENT"

value = "development"

type = "PLAINTEXT"

},

{

name = "TERRAFORM_WORKSPACE"

value = "dev"

type = "PLAINTEXT"

}

\])

}

}

}

\# 本番承認ステージ

stage {

name = "ProductionApproval"

action {

name = "ProductionDeploymentApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.production_approvals.arn

CustomData = "Development deployment successful. Approve for production
deployment."

}

}

}

\# デプロイステージ（本番環境）

stage {

name = "DeployProd"

action {

name = "DeployToProd"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_deploy_prod.name

EnvironmentVariables = jsonencode(\[

{

name = "TARGET_ENVIRONMENT"

value = "production"

type = "PLAINTEXT"

},

{

name = "TERRAFORM_WORKSPACE"

value = "prod"

type = "PLAINTEXT"

}

\])

}

}

}

tags = {

Purpose = "Integrated Security Pipeline"

Environment = "Multi-Account"

Owner = "SecurityTeam"

Project = "TechNova-DevSecOps"

}

}

**1.2 必要なIAMロール**

\# CodePipeline サービスロール

resource "aws_iam_role" "codepipeline_role" {

name = "codepipeline-security-pipeline-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codepipeline.amazonaws.com"

}

}

\]

})

tags = {

Purpose = "CodePipeline Service Role"

Environment = "Multi-Account"

}

}

resource "aws_iam_role_policy" "codepipeline_policy" {

name = "codepipeline-security-pipeline-policy"

role = aws_iam_role.codepipeline_role.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"s3:GetBucketVersioning",

"s3:PutObject",

"s3:GetObject",

"s3:GetObjectVersion"

\]

Resource = \[

aws_s3_bucket.pipeline_artifacts.arn,

"\${aws_s3_bucket.pipeline_artifacts.arn}/\*"

\]

},

{

Effect = "Allow"

Action = \[

"codebuild:BatchGetBuilds",

"codebuild:StartBuild"

\]

Resource = "\*"

},

{

Effect = "Allow"

Action = \[

"lambda:InvokeFunction"

\]

Resource = \[

aws_lambda_function.pipeline_error_handler.arn

\]

},

{

Effect = "Allow"

Action = \[

"sns:Publish"

\]

Resource = \[

aws_sns_topic.pipeline_approvals.arn,

aws_sns_topic.security_approvals.arn,

aws_sns_topic.production_approvals.arn

\]

}

\]

})

}

\# CodeBuild サービスロール

resource "aws_iam_role" "codebuild_role" {

name = "codebuild-security-analysis-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codebuild.amazonaws.com"

}

}

\]

})

tags = {

Purpose = "CodeBuild Service Role"

Environment = "Multi-Account"

}

}

resource "aws_iam_role_policy" "codebuild_policy" {

name = "codebuild-security-analysis-policy"

role = aws_iam_role.codebuild_role.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\]

Resource = "arn:aws:logs:\*:\*:\*"

},

{

Effect = "Allow"

Action = \[

"s3:GetObject",

"s3:GetObjectVersion",

"s3:PutObject"

\]

Resource = \[

"\${aws_s3_bucket.pipeline_artifacts.arn}/\*",

"\${aws_s3_bucket.build_logs.arn}/\*"

\]

},

{

Effect = "Allow"

Action = \[

"sns:Publish"

\]

Resource = \[

aws_sns_topic.pipeline_errors.arn,

aws_sns_topic.critical_security_alerts.arn

\]

},

{

Effect = "Allow"

Action = \[

"ec2:DescribeInstances",

"ec2:DescribeSecurityGroups",

"ec2:DescribeVpcs",

"ec2:DescribeSubnets",

"ec2:DescribeNetworkAcls"

\]

Resource = "\*"

},

{

Effect = "Allow"

Action = \[

"cloudwatch:PutMetricData"

\]

Resource = "\*"

Condition = {

StringEquals = {

"cloudwatch:namespace" = \[

"TechNova/SecurityAnalysis",

"TechNova/IAMSecurity",

"TechNova/PenetrationTesting"

\]

}

}

}

\]

})

}

**2. 静的解析の詳細実装**

**2.1 Terraform Validate**

resource "aws_codebuild_project" "terraform_validate" {

name = "terraform-validate-with-error-handling"

description = "Terraform validation with enhanced error handling"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "S3_LOG_BUCKET"

value = aws_s3_bucket.build_logs.id

}

environment_variable {

name = "ERROR_HANDLER_FUNCTION"

value = aws_lambda_function.build_error_handler.function_name

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/validate.yml"

}

tags = {

Stage = "StaticAnalysis"

Tool = "TerraformValidate"

ErrorHandling = "Enabled"

}

}

**2.2 validate.yml（詳細エラーハンドリング）**

version: 0.2

env:

variables:

LOG_FILE: "terraform-validate-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

TERRAFORM_VERSION: "1.5.0"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up environment..." \| tee logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# Terraform インストール

wget
https://releases.hashicorp.com/terraform/\${TERRAFORM_VERSION}/terraform\_\${TERRAFORM_VERSION}\_linux_amd64.zip

unzip terraform\_\${TERRAFORM_VERSION}\_linux_amd64.zip

sudo mv terraform /usr/local/bin/

terraform version \| tee -a logs/\$LOG_FILE

pre_build:

commands:

\- echo "\[PRE_BUILD\] Initializing Terraform..." \| tee -a
logs/\$LOG_FILE

\- \|

\# Backend設定なしでinit（validation用）

terraform init -backend=false \>\> logs/\$LOG_FILE 2\>&1

INIT_EXIT_CODE=\$?

if \[ \$INIT_EXIT_CODE -ne 0 \]; then

echo "\[ERROR\] Terraform init failed with exit code \$INIT_EXIT_CODE"
\| tee -a logs/\$LOG_FILE

export BUILD_ERROR="TERRAFORM_INIT_FAILED"

export BUILD_EXIT_CODE=\$INIT_EXIT_CODE

fi

build:

commands:

\- echo "\[BUILD\] Running terraform validate..." \| tee -a
logs/\$LOG_FILE

\- \|

\# Terraform validate実行

terraform validate \>\> logs/\$LOG_FILE 2\>&1

VALIDATE_EXIT_CODE=\$?

if \[ \$VALIDATE_EXIT_CODE -ne 0 \]; then

echo "\[ERROR\] Terraform validate failed with exit code
\$VALIDATE_EXIT_CODE" \| tee -a logs/\$LOG_FILE

\# エラー詳細の解析

if grep -q "Invalid reference" logs/\$LOG_FILE; then

export SPECIFIC_ERROR="INVALID_REFERENCE"

elif grep -q "Missing required argument" logs/\$LOG_FILE; then

export SPECIFIC_ERROR="MISSING_ARGUMENT"

elif grep -q "Duplicate resource" logs/\$LOG_FILE; then

export SPECIFIC_ERROR="DUPLICATE_RESOURCE"

elif grep -q "Invalid provider configuration" logs/\$LOG_FILE; then

export SPECIFIC_ERROR="INVALID_PROVIDER_CONFIG"

elif grep -q "Module not found" logs/\$LOG_FILE; then

export SPECIFIC_ERROR="MODULE_NOT_FOUND"

else

export SPECIFIC_ERROR="GENERIC_VALIDATION_ERROR"

fi

export BUILD_ERROR="TERRAFORM_VALIDATE_FAILED"

export BUILD_EXIT_CODE=\$VALIDATE_EXIT_CODE

\# エラーハンドリング Lambda を呼び出し

aws lambda invoke \\

--function-name \$ERROR_HANDLER_FUNCTION \\

--payload '{

"stage": "TerraformValidate",

"error_type": "'\$SPECIFIC_ERROR'",

"exit_code": '\$VALIDATE_EXIT_CODE',

"pipeline_execution_id": "'\$PIPELINE_EXECUTION_ID'",

"log_file": "'\$LOG_FILE'",

"error_handling_mode": "'\$ERROR_HANDLING_MODE'"

}' \\

/tmp/error_response.json

else

echo "\[SUCCESS\] Terraform validate completed successfully" \| tee -a
logs/\$LOG_FILE

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Uploading logs and handling errors..." \| tee -a
logs/\$LOG_FILE

\- \|

\# ログをS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "S3 upload failed"

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Error handling mode is STOP. Failing build." \| tee
-a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Error handling mode is CONTINUE. Build continues
despite errors." \| tee -a logs/\$LOG_FILE

exit 0

elif \[ "\$ERROR_HANDLING_MODE" = "MANUAL_APPROVAL" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Error handling mode is MANUAL_APPROVAL. Human
intervention required." \| tee -a logs/\$LOG_FILE

\# 手動承認待ちのマーカーファイル作成

echo "\$BUILD_ERROR" \> /tmp/manual_approval_required.txt

aws s3 cp /tmp/manual_approval_required.txt
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/manual_approval_required.txt

exit 0

else

echo "\[POST_BUILD\] No errors or successful completion" \| tee -a
logs/\$LOG_FILE exit 0 fi

artifacts: files: - logs/\* - /tmp/manual_approval_required.txt name:
terraform-validate-results

\### 2.3 TFLint解析

\`\`\`hcl

resource "aws_codebuild_project" "tflint" {

name = "tflint-security-analysis"

description = "TFLint code quality and best practices analysis"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "TFLINT_CONFIG_BUCKET"

value = aws_s3_bucket.security_configs.id

}

environment_variable {

name = "TFLINT_RULES_SEVERITY"

value = "HIGH"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/tflint.yml"

}

tags = {

Stage = "StaticAnalysis"

Tool = "TFLint"

Severity = "High"

}

}

2.4 tflint.yml（包括的品質分析）

version: 0.2

env:

variables:

LOG_FILE: "tflint-analysis-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

TFLINT_VERSION: "0.47.0"

RESULTS_FILE: "tflint-results.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up TFLint environment..." \| tee
logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# TFLint インストール

curl -s
https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh
\| bash

tflint --version \| tee -a logs/\$LOG_FILE

\# AWS ruleset プラグインのセットアップ

mkdir -p ~/.tflint.d/plugins

tflint --init \| tee -a logs/\$LOG_FILE

pre_build:

commands:

\- echo "\[PRE_BUILD\] Downloading TFLint configuration..." \| tee -a
logs/\$LOG_FILE

\- \|

\# カスタム設定をS3からダウンロード

aws s3 cp s3://\$TFLINT_CONFIG_BUCKET/tflint-config/.tflint.hcl
.tflint.hcl \|\| echo "Using default config"

\# ルールセット設定確認

if \[ -f .tflint.hcl \]; then

echo "\[PRE_BUILD\] Using custom TFLint configuration:" \| tee -a
logs/\$LOG_FILE

cat .tflint.hcl \| tee -a logs/\$LOG_FILE

else

echo "\[PRE_BUILD\] Creating default TFLint configuration" \| tee -a
logs/\$LOG_FILE

cat \> .tflint.hcl \<\< 'EOF'

plugin "aws" {

enabled = true

version = "0.24.1"

source = "github.com/terraform-linters/tflint-ruleset-aws"

}

rule "terraform_deprecated_interpolation" {

enabled = true

}

rule "terraform_unused_declarations" {

enabled = true

}

rule "terraform_comment_syntax" {

enabled = true

}

rule "terraform_documented_outputs" {

enabled = true

}

rule "terraform_documented_variables" {

enabled = true

}

rule "terraform_typed_variables" {

enabled = true

}

rule "terraform_module_pinned_source" {

enabled = true

style = "semver"

}

rule "terraform_naming_convention" {

enabled = true

format = "snake_case"

}

rule "terraform_standard_module_structure" {

enabled = true

}

rule "aws_instance_invalid_type" {

enabled = true

}

rule "aws_security_group_rule_invalid_protocol" {

enabled = true

}

rule "aws_db_instance_invalid_type" {

enabled = true

}

rule "aws_elasticache_cluster_invalid_type" {

enabled = true

}

rule "aws_alb_invalid_security_group" {

enabled = true

}

rule "aws_elb_invalid_security_group" {

enabled = true

}

rule "aws_instance_invalid_ami" {

enabled = true

}

rule "aws_launch_configuration_invalid_image_id" {

enabled = true

}

rule "aws_route_invalid_route_table" {

enabled = true

}

EOF

fi

build:

commands:

\- echo "\[BUILD\] Running TFLint analysis..." \| tee -a logs/\$LOG_FILE

\- \|

\# TFLint実行（JSON形式で結果出力）

tflint --format=json --force \> logs/\$RESULTS_FILE 2\>&1

TFLINT_EXIT_CODE=\$?

\# 結果をログにも出力（人間が読みやすい形式）

echo "\[BUILD\] TFLint Results Summary:" \| tee -a logs/\$LOG_FILE

tflint --format=compact \| tee -a logs/\$LOG_FILE

\# JSONから重要度別の問題数を集計

ERROR_COUNT=\$(jq '\[.issues\[\] \| select(.rule.severity == "error")\]
\| length' logs/\$RESULTS_FILE 2\>/dev/null \|\| echo "0")

WARNING_COUNT=\$(jq '\[.issues\[\] \| select(.rule.severity ==
"warning")\] \| length' logs/\$RESULTS_FILE 2\>/dev/null \|\| echo "0")

NOTICE_COUNT=\$(jq '\[.issues\[\] \| select(.rule.severity ==
"notice")\] \| length' logs/\$RESULTS_FILE 2\>/dev/null \|\| echo "0")

echo "\[BUILD\] Issues Summary:" \| tee -a logs/\$LOG_FILE

echo " - Errors: \$ERROR_COUNT" \| tee -a logs/\$LOG_FILE

echo " - Warnings: \$WARNING_COUNT" \| tee -a logs/\$LOG_FILE

echo " - Notices: \$NOTICE_COUNT" \| tee -a logs/\$LOG_FILE

\# 重要度に基づく判定

if \[ "\$TFLINT_RULES_SEVERITY" = "HIGH" \] && \[ "\$ERROR_COUNT" -gt 0
\]; then

echo "\[ERROR\] High severity mode: Found \$ERROR_COUNT error(s)" \| tee
-a logs/\$LOG_FILE

export BUILD_ERROR="TFLINT_HIGH_SEVERITY_VIOLATIONS"

export BUILD_EXIT_CODE=1

elif \[ "\$TFLINT_RULES_SEVERITY" = "MEDIUM" \] && \[ \$((ERROR_COUNT +
WARNING_COUNT)) -gt 0 \]; then

echo "\[ERROR\] Medium severity mode: Found \$((ERROR_COUNT +
WARNING_COUNT)) error(s)/warning(s)" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="TFLINT_MEDIUM_SEVERITY_VIOLATIONS"

export BUILD_EXIT_CODE=1

elif \[ "\$TFLINT_RULES_SEVERITY" = "LOW" \] && \[ \$((ERROR_COUNT +
WARNING_COUNT + NOTICE_COUNT)) -gt 0 \]; then

echo "\[ERROR\] Low severity mode: Found \$((ERROR_COUNT +
WARNING_COUNT + NOTICE_COUNT)) issue(s)" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="TFLINT_LOW_SEVERITY_VIOLATIONS"

export BUILD_EXIT_CODE=1

else

echo "\[SUCCESS\] TFLint analysis passed for severity level:
\$TFLINT_RULES_SEVERITY" \| tee -a logs/\$LOG_FILE

fi

\# 詳細な違反分析

if \[ ! -z "\$BUILD_ERROR" \]; then

echo "\[BUILD\] Detailed violation analysis:" \| tee -a logs/\$LOG_FILE

jq -r '.issues\[\] \| "Rule: \\.rule.name) \| Severity:
\\.rule.severity) \| File: \\.range.filename):\\.range.start.line) \|
Message: \\.message)"' logs/\$RESULTS_FILE \| tee -a logs/\$LOG_FILE

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Processing results and uploading artifacts..."
\| tee -a logs/\$LOG_FILE

\- \|

\# CloudWatchメトリクス送信

aws cloudwatch put-metric-data \\

--namespace "TechNova/SecurityAnalysis" \\

--metric-data \\

MetricName=TFLintErrors,Value=\$ERROR_COUNT,Unit=Count \\

MetricName=TFLintWarnings,Value=\$WARNING_COUNT,Unit=Count \\

MetricName=TFLintNotices,Value=\$NOTICE_COUNT,Unit=Count \\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

\# 結果をS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

aws s3 cp logs/\$RESULTS_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$RESULTS_FILE \|\| echo "Results
upload failed"

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to TFLint violations" \| tee
-a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite TFLint violations" \|
tee -a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts:

files:

\- logs/\*

name: tflint-analysis-results

2.5 Checkov セキュリティ解析

resource "aws_codebuild_project" "checkov" {

name = "checkov-security-compliance"

description = "Checkov security and compliance analysis"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "CHECKOV_CONFIG_BUCKET"

value = aws_s3_bucket.security_configs.id

}

environment_variable {

name = "SECURITY_FRAMEWORK"

value = "CIS,NIST,SOC2"

}

environment_variable {

name = "COMPLIANCE_THRESHOLD"

value = "80"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/checkov.yml"

}

tags = {

Stage = "StaticAnalysis"

Tool = "Checkov"

Compliance = "CIS-NIST-SOC2"

}

}

2.6 checkov.yml（包括的セキュリティ検証）

version: 0.2

env:

variables:

LOG_FILE: "checkov-analysis-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

RESULTS_FILE: "checkov-results.json"

SUMMARY_FILE: "checkov-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up Checkov environment..." \| tee
logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# Python環境とCheckovのインストール

python3 -m pip install --upgrade pip

pip3 install checkov==2.3.228

checkov --version \| tee -a logs/\$LOG_FILE

\# 必要なPythonライブラリ

pip3 install jq boto3 requests

pre_build:

commands:

\- echo "\[PRE_BUILD\] Configuring Checkov security policies..." \| tee
-a logs/\$LOG_FILE

\- \|

\# カスタム設定をS3からダウンロード

aws s3 cp s3://\$CHECKOV_CONFIG_BUCKET/checkov-config/checkov.yaml
checkov.yaml \|\| echo "Using default config"

\# カスタムポリシーファイルをダウンロード

mkdir -p custom-policies

aws s3 sync s3://\$CHECKOV_CONFIG_BUCKET/custom-policies/
custom-policies/ \|\| echo "No custom policies found"

\# デフォルト設定の作成

if \[ ! -f checkov.yaml \]; then

echo "\[PRE_BUILD\] Creating default Checkov configuration" \| tee -a
logs/\$LOG_FILE

cat \> checkov.yaml \<\< 'EOF'

branch: main

check:

\- CKV_AWS_1 \# Root access key check

\- CKV_AWS_2 \# ALB listener security

\- CKV_AWS_3 \# EBS encryption

\- CKV_AWS_7 \# KMS key rotation

\- CKV_AWS_8 \# Launch config public IP

\- CKV_AWS_9 \# ElastiCache Redis AUTH

\- CKV_AWS_10 \# RDS backup retention

\- CKV_AWS_14 \# Ensure all data stored in the Launch configuration or
Auto Scaling Group EBS is securely encrypted at rest

\- CKV_AWS_17 \# RDS encryption

\- CKV_AWS_18 \# S3 server side encryption

\- CKV_AWS_19 \# S3 encryption with customer key

\- CKV_AWS_20 \# S3 public access block

\- CKV_AWS_21 \# S3 versioning

\- CKV_AWS_23 \# ECR image scanning

\- CKV_AWS_24 \# Security group description

\- CKV_AWS_25 \# Security group rule description

\- CKV_AWS_27 \# SQS encryption

\- CKV_AWS_28 \# DynamoDB point in time recovery

\- CKV_AWS_33 \# ECR image tag immutability

\- CKV_AWS_34 \# CloudFront WAF

\- CKV_AWS_35 \# CloudTrail encryption

\- CKV_AWS_36 \# ElastiCache encryption transit

\- CKV_AWS_37 \# ElastiCache encryption rest

\- CKV_AWS_38 \# RDS public access

\- CKV_AWS_39 \# Lambda environment encryption

\- CKV_AWS_40 \# IAM policy attached to users

\- CKV_AWS_41 \# IAM policy attached to groups

\- CKV_AWS_42 \# IAM policy attached to roles

\- CKV_AWS_43 \# Lambda function X-Ray tracing

\- CKV_AWS_45 \# Lambda environment credentials

\- CKV_AWS_46 \# API Gateway X-Ray tracing

\- CKV_AWS_47 \# API Gateway request validation

\- CKV_AWS_48 \# API Gateway SSL certificate

\- CKV_AWS_49 \# API Gateway execution logging

\- CKV_AWS_50 \# Lambda function dead letter queue

\- CKV_AWS_51 \# ECR repository policy

\- CKV_AWS_54 \# S3 bucket public read

\- CKV_AWS_55 \# S3 bucket public write

\- CKV_AWS_56 \# S3 bucket public read ACP

\- CKV_AWS_57 \# S3 bucket public write ACP

\- CKV_AWS_58 \# S3 bucket logging

\- CKV_AWS_59 \# API Gateway cache encryption

\- CKV_AWS_60 \# IAM policy allows root access

\- CKV_AWS_61 \# IAM policy allows full admin access

\- CKV_AWS_62 \# IAM policy allows trust

\- CKV_AWS_63 \# IAM policy allows manage

\- CKV_AWS_64 \# Redshift encryption

\- CKV_AWS_65 \# Redshift SSL

\- CKV_AWS_66 \# CloudTrail log validation

\- CKV_AWS_67 \# CloudTrail encryption

\- CKV_AWS_68 \# CloudFront default root object

\- CKV_AWS_69 \# S3 bucket encryption

\- CKV_AWS_70 \# RDS deletion protection

\- CKV_AWS_71 \# Redshift public access

\- CKV_AWS_72 \# RDS encryption key

\- CKV_AWS_73 \# API Gateway X-Ray tracing

\- CKV_AWS_74 \# Lambda function code signing

\- CKV_AWS_75 \# DocDB encryption

\- CKV_AWS_76 \# API Gateway access logging

\- CKV_AWS_77 \# Neptune encryption

\- CKV_AWS_78 \# CodeBuild image pull credentials

\- CKV_AWS_79 \# Lambda function reserved concurrency

\- CKV_AWS_80 \# MSK cluster logging

\- CKV_AWS_81 \# ElastiCache replication group encryption

\- CKV_AWS_82 \# ElastiCache replication group auth token

\- CKV_AWS_83 \# ElastiCache replication group backup

\- CKV_AWS_84 \# ElastiCache replication group multi AZ

\- CKV_AWS_85 \# DocDB backup retention

\- CKV_AWS_86 \# CloudFront default root object

\- CKV_AWS_87 \# Redshift enhanced VPC routing

\- CKV_AWS_88 \# EC2 public IP

\- CKV_AWS_89 \# DMS replication instance public access

\- CKV_AWS_90 \# DocDB logging

\- CKV_AWS_91 \# EKS endpoint private access

\- CKV_AWS_92 \# EKS endpoint public access

skip_check:

\# 環境固有でスキップするチェック

framework:

\- cis

\- nist_cybersecurity_framework_1.1

\- soc2

output: json

quiet: false

external_checks_dir: ./custom-policies

EOF

fi

build:

commands:

\- echo "\[BUILD\] Running Checkov security analysis..." \| tee -a
logs/\$LOG_FILE

\- \|

\# Checkov実行（複数フレームワークでの検証）

echo "\[BUILD\] Starting comprehensive security analysis with multiple
frameworks" \| tee -a logs/\$LOG_FILE

\# 基本的なCheckov実行

checkov -d . \\

--config-file checkov.yaml \\

--output json \\

--output-file logs/\$RESULTS_FILE \\

--framework terraform \\

--download-external-modules True \\

--evaluate-variables True \>\> logs/\$LOG_FILE 2\>&1

CHECKOV_EXIT_CODE=\$?

\# 結果の詳細分析

if \[ -f logs/\$RESULTS_FILE \]; then

echo "\[BUILD\] Analyzing Checkov results..." \| tee -a logs/\$LOG_FILE

\# 統計情報の抽出

TOTAL_CHECKS=\$(jq '.summary.parsing_errors + .summary.passed_checks +
.summary.failed_checks + .summary.skipped_checks' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

PASSED_CHECKS=\$(jq '.summary.passed_checks' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

FAILED_CHECKS=\$(jq '.summary.failed_checks' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

SKIPPED_CHECKS=\$(jq '.summary.skipped_checks' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

PARSING_ERRORS=\$(jq '.summary.parsing_errors' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

\# コンプライアンススコア計算

if \[ \$TOTAL_CHECKS -gt 0 \]; then

COMPLIANCE_SCORE=\$(echo "scale=2; \$PASSED_CHECKS \* 100 /
(\$PASSED_CHECKS + \$FAILED_CHECKS)" \| bc -l 2\>/dev/null \|\| echo
"0")

else

COMPLIANCE_SCORE="0"

fi

echo "\[BUILD\] Security Analysis Summary:" \| tee -a logs/\$LOG_FILE

echo " - Total Checks: \$TOTAL_CHECKS" \| tee -a logs/\$LOG_FILE

echo " - Passed: \$PASSED_CHECKS" \| tee -a logs/\$LOG_FILE

echo " - Failed: \$FAILED_CHECKS" \| tee -a logs/\$LOG_FILE

echo " - Skipped: \$SKIPPED_CHECKS" \| tee -a logs/\$LOG_FILE

echo " - Parsing Errors: \$PARSING_ERRORS" \| tee -a logs/\$LOG_FILE

echo " - Compliance Score: \${COMPLIANCE_SCORE}%" \| tee -a
logs/\$LOG_FILE

\# 重要度別の失敗分析

HIGH_SEVERITY_FAILS=\$(jq '\[.results.failed_checks\[\] \|
select(.severity == "HIGH")\] \| length' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

MEDIUM_SEVERITY_FAILS=\$(jq '\[.results.failed_checks\[\] \|
select(.severity == "MEDIUM")\] \| length' logs/\$RESULTS_FILE
2\>/dev/null \|\| echo "0")

LOW_SEVERITY_FAILS=\$(jq '\[.results.failed_checks\[\] \|
select(.severity == "LOW")\] \| length' logs/\$RESULTS_FILE 2\>/dev/null
\|\| echo "0")

echo " - High Severity Failures: \$HIGH_SEVERITY_FAILS" \| tee -a
logs/\$LOG_FILE

echo " - Medium Severity Failures: \$MEDIUM_SEVERITY_FAILS" \| tee -a
logs/\$LOG_FILE

echo " - Low Severity Failures: \$LOW_SEVERITY_FAILS" \| tee -a
logs/\$LOG_FILE

\# サマリーJSONファイル作成

cat \> logs/\$SUMMARY_FILE \<\< EOF

{

"pipeline_execution_id": "\$PIPELINE_EXECUTION_ID",

"timestamp": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",

"total_checks": \$TOTAL_CHECKS,

"passed_checks": \$PASSED_CHECKS,

"failed_checks": \$FAILED_CHECKS,

"skipped_checks": \$SKIPPED_CHECKS,

"parsing_errors": \$PARSING_ERRORS,

"compliance_score": \$COMPLIANCE_SCORE,

"severity_breakdown": {

"high": \$HIGH_SEVERITY_FAILS,

"medium": \$MEDIUM_SEVERITY_FAILS,

"low": \$LOW_SEVERITY_FAILS

},

"compliance_threshold": \$COMPLIANCE_THRESHOLD,

"threshold_met": \$(echo "\$COMPLIANCE_SCORE \>= \$COMPLIANCE_THRESHOLD"
\| bc -l)

}

EOF

\# コンプライアンス閾値の判定

THRESHOLD_MET=\$(echo "\$COMPLIANCE_SCORE \>= \$COMPLIANCE_THRESHOLD" \|
bc -l)

if \[ "\$THRESHOLD_MET" = "0" \]; then

echo "\[ERROR\] Compliance score \${COMPLIANCE_SCORE}% is below
threshold \${COMPLIANCE_THRESHOLD}%" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="COMPLIANCE_THRESHOLD_NOT_MET"

export BUILD_EXIT_CODE=1

elif \[ \$HIGH_SEVERITY_FAILS -gt 0 \]; then

echo "\[ERROR\] Found \$HIGH_SEVERITY_FAILS high severity security
violations" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="HIGH_SEVERITY_SECURITY_VIOLATIONS"

export BUILD_EXIT_CODE=1

elif \[ \$PARSING_ERRORS -gt 0 \]; then

echo "\[ERROR\] Found \$PARSING_ERRORS parsing errors" \| tee -a
logs/\$LOG_FILE

export BUILD_ERROR="PARSING_ERRORS"

export BUILD_EXIT_CODE=1

else

echo "\[SUCCESS\] Security analysis passed all requirements" \| tee -a
logs/\$LOG_FILE

fi

\# 失敗したチェックの詳細表示

if \[ \$FAILED_CHECKS -gt 0 \]; then

echo "\[BUILD\] Failed Security Checks Details:" \| tee -a
logs/\$LOG_FILE

jq -r '.results.failed_checks\[\] \| "Check: \\.check_id) \| File:
\\.file_path):\\.file_line_range\[0\]) \| Message: \\.check_name)"'
logs/\$RESULTS_FILE \| head -20 \| tee -a logs/\$LOG_FILE

if \[ \$FAILED_CHECKS -gt 20 \]; then

echo "... and \$((FAILED_CHECKS - 20)) more failures. See full report
for details." \| tee -a logs/\$LOG_FILE

fi

fi

else

echo "\[ERROR\] Checkov results file not found" \| tee -a
logs/\$LOG_FILE

export BUILD_ERROR="CHECKOV_EXECUTION_FAILED"

export BUILD_EXIT_CODE=1

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Processing results and generating reports..." \|
tee -a logs/\$LOG_FILE

\- \|

\# CloudWatchメトリクス送信

if \[ -f logs/\$SUMMARY_FILE \]; then

aws cloudwatch put-metric-data \\

--namespace "TechNova/SecurityAnalysis" \\

--metric-data \\

MetricName=CheckovTotalChecks,Value=\$TOTAL_CHECKS,Unit=Count \\

MetricName=CheckovPassedChecks,Value=\$PASSED_CHECKS,Unit=Count \\

MetricName=CheckovFailedChecks,Value=\$FAILED_CHECKS,Unit=Count \\

MetricName=CheckovComplianceScore,Value=\$COMPLIANCE_SCORE,Unit=Percent
\\

MetricName=CheckovHighSeverityFails,Value=\$HIGH_SEVERITY_FAILS,Unit=Count
\\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

fi

\# 重要な場合はSNS通知送信

if \[ ! -z "\$BUILD_ERROR" \] && \[ "\$BUILD_ERROR" =
"HIGH_SEVERITY_SECURITY_VIOLATIONS" \]; then

aws sns publish \\

--topic-arn \$CRITICAL_SECURITY_ALERTS_TOPIC \\

--subject "CRITICAL: High Severity Security Violations Detected" \\

--message "Pipeline: \$PIPELINE_EXECUTION_ID\nHigh Severity Failures:
\$HIGH_SEVERITY_FAILS\nCompliance Score: \${COMPLIANCE_SCORE}%\nReview
required immediately." \\

--region \$AWS_DEFAULT_REGION \|\| echo "SNS notification failed"

fi

\# 結果をS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

aws s3 cp logs/\$RESULTS_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$RESULTS_FILE \|\| echo "Results
upload failed"

aws s3 cp logs/\$SUMMARY_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$SUMMARY_FILE \|\| echo "Summary
upload failed"

\# HTMLレポート生成

if command -v checkov \>/dev/null 2\>&1; then

checkov -d . \\

--config-file checkov.yaml \\

--output cli \\

--framework terraform \> logs/checkov-report.txt 2\>&1 \|\| echo "HTML
report generation failed"

aws s3 cp logs/checkov-report.txt
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/checkov-report.txt \|\| echo "Report
upload failed"

fi

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to security violations" \|
tee -a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite security violations" \|
tee -a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts:

files:

\- logs/\*

name: checkov-security-analysis-results

**3. IAM アクセス分析の詳細実装**

**3.1 IAM Access Analyzer設定**

\# 組織レベルのAccess Analyzer

resource "aws_accessanalyzer_analyzer" "organization_analyzer" {

analyzer_name = "technova-organization-analyzer"

type = "ORGANIZATION"

tags = {

Purpose = "Organization-wide IAM Access Analysis"

Environment = "Multi-Account"

Project = "TechNova-DevSecOps"

}

}

\# アカウントレベルのAccess Analyzer（各アカウント用）

resource "aws_accessanalyzer_analyzer" "account_analyzer" {

analyzer_name = "technova-account-analyzer"

type = "ACCOUNT"

tags = {

Purpose = "Account-level IAM Access Analysis"

Environment = "Multi-Account"

Project = "TechNova-DevSecOps"

}

}

3.2 IAM分析CodeBuildプロジェクト

resource "aws_codebuild_project" "iam_access_analysis" {

name = "iam-access-comprehensive-analysis"

description = "Comprehensive IAM access rights and security analysis"

service_role = aws_iam_role.codebuild_iam_analysis_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "ORGANIZATION_ID"

value = data.aws_organizations_organization.current.id

}

environment_variable {

name = "ACCOUNT_LIST_BUCKET"

value = aws_s3_bucket.security_configs.id

}

environment_variable {

name = "IAM_ANALYSIS_DEPTH"

value = "COMPREHENSIVE"

}

}

source { type = "CODEPIPELINE" buildspec = "buildspecs/iam_analysis.yml"
}

tags = { Stage = "IAMAnalysis" Tool = "AccessAnalyzer" Scope =
"Organization" } }

**IAM分析用の拡張ロール**

resource "aws_iam_role" "codebuild_iam_analysis_role" { name =
"codebuild-iam-analysis-role"

assume_role_policy = jsonencode({ Version = "2012-10-17" Statement = \[
{ Action = "sts:AssumeRole" Effect = "Allow" Principal = { Service =
"codebuild.amazonaws.com" } } \] })

tags = { Purpose = "IAM Analysis CodeBuild Role" Environment =
"Multi-Account" } }

resource "aws_iam_role_policy" "codebuild_iam_analysis_policy" { name =
"codebuild-iam-analysis-policy" role =
aws_iam_role.codebuild_iam_analysis_role.id

policy = jsonencode({ Version = "2012-10-17" Statement = \[ { Effect =
"Allow" Action = \[ "logs:CreateLogGroup", "logs:CreateLogStream",
"logs:PutLogEvents" \] Resource = "arn:aws:logs:*:*:*" }, { Effect =
"Allow" Action = \[ "s3:GetObject", "s3:GetObjectVersion",
"s3:PutObject" \] Resource = \[
"\${aws_s3_bucket.pipeline_artifacts.arn}/*",
"\${aws_s3_bucket.build_logs.arn}/*",
"\${aws_s3_bucket.security_configs.arn}/*" \] }, { Effect = "Allow"
Action = \[ "access-analyzer:ListAnalyzers",
"access-analyzer:ListFindings", "access-analyzer:GetFinding",
"access-analyzer:GetAnalyzer", "access-analyzer:ListArchiveRules" \]
Resource = "*" }, { Effect = "Allow" Action = \[ "iam:ListRoles",
"iam:ListUsers", "iam:ListGroups", "iam:ListPolicies", "iam:GetRole",
"iam:GetUser", "iam:GetGroup", "iam:GetPolicy", "iam:GetPolicyVersion",
"iam:ListRolePolicies", "iam:ListUserPolicies", "iam:ListGroupPolicies",
"iam:ListAttachedRolePolicies", "iam:ListAttachedUserPolicies",
"iam:ListAttachedGroupPolicies", "iam:GetRolePolicy",
"iam:GetUserPolicy", "iam:GetGroupPolicy",
"iam:SimulatePrincipalPolicy", "iam:GetAccountSummary" \] Resource = "*"
}, { Effect = "Allow" Action = \[ "organizations:ListAccounts",
"organizations:DescribeOrganization", "organizations:ListRoots",
"organizations:ListOrganizationalUnitsForParent",
"organizations:ListAccountsForParent" \] Resource = "*" }, { Effect =
"Allow" Action = \[ "sts:AssumeRole" \] Resource =
"arn:aws:iam::*:role/TechNova-CrossAccount-SecurityAnalysis-Role" }, {
Effect = "Allow" Action = \[ "cloudwatch:PutMetricData" \] Resource =
"\*" Condition = { StringEquals = { "cloudwatch:namespace" =
"TechNova/IAMSecurity" } } } \] }) }

\### 3.3 iam_analysis.yml（包括的IAM分析）

\`\`\`yaml

version: 0.2

env:

variables:

LOG_FILE: "iam-analysis-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

FINDINGS_FILE: "iam-findings.json"

CROSS_ACCOUNT_FINDINGS_FILE: "cross-account-findings.json"

UNUSED_PERMISSIONS_FILE: "unused-permissions.json"

EXTERNAL_ACCESS_FILE: "external-access-findings.json"

SUMMARY_FILE: "iam-analysis-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up IAM analysis environment..." \| tee
logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# 必要なツールのインストール

yum update -y

yum install -y jq bc python3-pip

pip3 install boto3 botocore awscli

\# カスタムIAM分析スクリプトの準備

aws s3 cp s3://\$ACCOUNT_LIST_BUCKET/scripts/iam-analyzer.py
iam-analyzer.py \|\| echo "Using default analysis script"

if \[ ! -f iam-analyzer.py \]; then

echo "\[INSTALL\] Creating default IAM analysis script" \| tee -a
logs/\$LOG_FILE

cat \> iam-analyzer.py \<\< 'EOF'

\#!/usr/bin/env python3

import boto3

import json

import sys

from datetime import datetime, timedelta

from botocore.exceptions import ClientError

class IAMSecurityAnalyzer:

def \_\_init\_\_(self):

self.session = boto3.Session()

self.iam = self.session.client('iam')

self.access_analyzer = self.session.client('accessanalyzer')

self.organizations = self.session.client('organizations')

self.sts = self.session.client('sts')

def analyze_organization_accounts(self):

"""120アカウント全体のIAM分析"""

try:

response = self.organizations.list_accounts()

accounts = response\['Accounts'\]

print(f"Found {len(accounts)} accounts in organization")

return accounts

except ClientError as e:

print(f"Error listing accounts: {e}")

return \[\]

def analyze_external_access(self, analyzer_arn):

"""外部アクセス分析"""

findings = \[\]

try:

paginator = self.access_analyzer.get_paginator('list_findings')

for page in paginator.paginate(analyzerArn=analyzer_arn):

findings.extend(page\['findings'\])

external_findings = \[\]

for finding in findings:

if finding\['status'\] == 'ACTIVE':

external_findings.append({

'id': finding\['id'\],

'resource_type': finding\['resourceType'\],

'resource': finding\['resource'\],

'principal': finding.get('principal', {}),

'action': finding.get('action', \[\]),

'condition': finding.get('condition', {}),

'created_at': finding\['createdAt'\].isoformat(),

'updated_at': finding\['updatedAt'\].isoformat(),

'status': finding\['status'\]

})

return external_findings

except ClientError as e:

print(f"Error analyzing external access: {e}")

return \[\]

def analyze_unused_permissions(self):

"""未使用権限の分析"""

unused_permissions = \[\]

try:

\# ロール一覧取得

paginator = self.iam.get_paginator('list_roles')

for page in paginator.paginate():

for role in page\['Roles'\]:

role_name = role\['RoleName'\]

last_used = role.get('RoleLastUsed', {})

\# 90日以上未使用のロールを特定

if 'LastUsedDate' in last_used:

last_used_date = last_used\['LastUsedDate'\]

if datetime.now(last_used_date.tzinfo) - last_used_date \>
timedelta(days=90):

unused_permissions.append({

'type': 'role',

'name': role_name,

'arn': role\['Arn'\],

'last_used': last_used_date.isoformat(),

'days_unused': (datetime.now(last_used_date.tzinfo) -
last_used_date).days,

'created_date': role\['CreateDate'\].isoformat()

})

else:

\# 未使用（使用履歴なし）

created_date = role\['CreateDate'\]

days_since_creation = (datetime.now(created_date.tzinfo) -
created_date).days

if days_since_creation \> 30: \# 作成から30日以上経過

unused_permissions.append({

'type': 'role',

'name': role_name,

'arn': role\['Arn'\],

'last_used': 'never',

'days_unused': days_since_creation,

'created_date': created_date.isoformat()

})

\# ユーザー分析

paginator = self.iam.get_paginator('list_users')

for page in paginator.paginate():

for user in page\['Users'\]:

user_name = user\['UserName'\]

\# アクセスキーの最終使用日確認

try:

access_keys = self.iam.list_access_keys(UserName=user_name)

for key in access_keys\['AccessKeyMetadata'\]:

key_id = key\['AccessKeyId'\]

last_used_response =
self.iam.get_access_key_last_used(AccessKeyId=key_id)

last_used_info = last_used_response\['AccessKeyLastUsed'\]

if 'LastUsedDate' in last_used_info:

last_used_date = last_used_info\['LastUsedDate'\]

if datetime.now(last_used_date.tzinfo) - last_used_date \>
timedelta(days=90):

unused_permissions.append({

'type': 'user_access_key',

'name': user_name,

'access_key_id': key_id,

'last_used': last_used_date.isoformat(),

'days_unused': (datetime.now(last_used_date.tzinfo) -
last_used_date).days,

'created_date': key\['CreateDate'\].isoformat()

})

else:

created_date = key\['CreateDate'\]

days_since_creation = (datetime.now(created_date.tzinfo) -
created_date).days

if days_since_creation \> 30:

unused_permissions.append({

'type': 'user_access_key',

'name': user_name,

'access_key_id': key_id,

'last_used': 'never',

'days_unused': days_since_creation,

'created_date': created_date.isoformat()

})

except ClientError as e:

print(f"Error analyzing user {user_name}: {e}")

continue

return unused_permissions

except ClientError as e:

print(f"Error analyzing unused permissions: {e}")

return \[\]

def analyze_cross_account_access(self):

"""クロスアカウントアクセス分析"""

cross_account_findings = \[\]

try:

\# 現在のアカウントID取得

current_account = self.sts.get_caller_identity()\['Account'\]

\# ロール一覧取得してクロスアカウント信頼関係を分析

paginator = self.iam.get_paginator('list_roles')

for page in paginator.paginate():

for role in page\['Roles'\]:

assume_role_policy = role\['AssumeRolePolicyDocument'\]

\# URLエンコードされたポリシーをデコード

import urllib.parse

policy_doc = json.loads(urllib.parse.unquote(assume_role_policy))

for statement in policy_doc.get('Statement', \[\]):

principal = statement.get('Principal', {})

\# AWS principalの分析

if isinstance(principal, dict) and 'AWS' in principal:

aws_principals = principal\['AWS'\]

if isinstance(aws_principals, str):

aws_principals = \[aws_principals\]

for aws_principal in aws_principals:

if ':' in aws_principal and aws_principal.split(':')\[4\] !=
current_account:

cross_account_findings.append({

'role_name': role\['RoleName'\],

'role_arn': role\['Arn'\],

'trusted_principal': aws_principal,

'trusted_account': aws_principal.split(':')\[4\] if ':' in aws_principal
else 'unknown',

'statement_effect': statement.get('Effect', 'Allow'),

'conditions': statement.get('Condition', {}),

'created_date': role\['CreateDate'\].isoformat()

})

return cross_account_findings

except ClientError as e:

print(f"Error analyzing cross-account access: {e}")

return \[\]

if \_\_name\_\_ == "\_\_main\_\_":

analyzer = IAMSecurityAnalyzer()

\# 分析実行

print("Starting comprehensive IAM security analysis...")

accounts = analyzer.analyze_organization_accounts()

print(f"Organization analysis: {len(accounts)} accounts")

analyzer_arn = sys.argv\[1\] if len(sys.argv) \> 1 else None

if analyzer_arn:

external_access = analyzer.analyze_external_access(analyzer_arn)

print(f"External access analysis: {len(external_access)} findings")

with open('logs/external-access-findings.json', 'w') as f:

json.dump(external_access, f, indent=2, default=str)

unused_permissions = analyzer.analyze_unused_permissions()

print(f"Unused permissions analysis: {len(unused_permissions)}
findings")

with open('logs/unused-permissions.json', 'w') as f:

json.dump(unused_permissions, f, indent=2, default=str)

cross_account_access = analyzer.analyze_cross_account_access()

print(f"Cross-account access analysis: {len(cross_account_access)}
findings")

with open('logs/cross-account-findings.json', 'w') as f:

json.dump(cross_account_access, f, indent=2, default=str)

\# サマリー作成

summary = {

'timestamp': datetime.now().isoformat(),

'organization_accounts': len(accounts),

'external_access_findings': len(external_access) if analyzer_arn else 0,

'unused_permissions': len(unused_permissions),

'cross_account_trusts': len(cross_account_access),

'total_security_findings': len(external_access) +
len(unused_permissions) + len(cross_account_access) if analyzer_arn else
len(unused_permissions) + len(cross_account_access)

}

with open('logs/iam-analysis-summary.json', 'w') as f:

json.dump(summary, f, indent=2)

print("IAM security analysis completed")

EOF

chmod +x iam-analyzer.py

fi

pre_build:

commands:

\- echo "\[PRE_BUILD\] Preparing IAM analysis configuration..." \| tee
-a logs/\$LOG_FILE

\- \|

\# Access Analyzerの状態確認

if \[ ! -z "\$ANALYZER_ARN" \]; then

aws accessanalyzer get-analyzer --analyzer-arn \$ANALYZER_ARN \>\>
logs/\$LOG_FILE 2\>&1

ANALYZER_STATUS=\$?

if \[ \$ANALYZER_STATUS -ne 0 \]; then

echo "\[PRE_BUILD\] Warning: Access Analyzer not accessible, skipping
external access analysis" \| tee -a logs/\$LOG_FILE

export ANALYZER_ARN=""

fi

fi

\# 組織アカウント一覧の取得

aws organizations list-accounts \> logs/organization-accounts.json
2\>/dev/null \|\| echo "\[\]" \> logs/organization-accounts.json

ACCOUNT_COUNT=\$(jq length logs/organization-accounts.json)

echo "\[PRE_BUILD\] Found \$ACCOUNT_COUNT accounts in organization" \|
tee -a logs/\$LOG_FILE

build:

commands:

\- echo "\[BUILD\] Starting comprehensive IAM security analysis..." \|
tee -a logs/\$LOG_FILE

\- \|

\# Python分析スクリプト実行

python3 iam-analyzer.py "\$ANALYZER_ARN" \>\> logs/\$LOG_FILE 2\>&1

ANALYSIS_EXIT_CODE=\$?

if \[ \$ANALYSIS_EXIT_CODE -ne 0 \]; then

echo "\[ERROR\] IAM analysis script failed with exit code
\$ANALYSIS_EXIT_CODE" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="IAM_ANALYSIS_SCRIPT_FAILED"

export BUILD_EXIT_CODE=\$ANALYSIS_EXIT_CODE

fi

\# 分析結果の検証と統計

if \[ -f logs/\$SUMMARY_FILE \]; then

echo "\[BUILD\] Processing analysis results..." \| tee -a
logs/\$LOG_FILE

\# サマリー情報の抽出

TOTAL_ACCOUNTS=\$(jq '.organization_accounts' logs/\$SUMMARY_FILE)

EXTERNAL_FINDINGS=\$(jq '.external_access_findings' logs/\$SUMMARY_FILE)

UNUSED_PERMISSIONS=\$(jq '.unused_permissions' logs/\$SUMMARY_FILE)

CROSS_ACCOUNT_TRUSTS=\$(jq '.cross_account_trusts' logs/\$SUMMARY_FILE)

TOTAL_FINDINGS=\$(jq '.total_security_findings' logs/\$SUMMARY_FILE)

echo "\[BUILD\] IAM Security Analysis Results:" \| tee -a
logs/\$LOG_FILE

echo " - Organization Accounts: \$TOTAL_ACCOUNTS" \| tee -a
logs/\$LOG_FILE

echo " - External Access Findings: \$EXTERNAL_FINDINGS" \| tee -a
logs/\$LOG_FILE

echo " - Unused Permissions: \$UNUSED_PERMISSIONS" \| tee -a
logs/\$LOG_FILE

echo " - Cross-Account Trusts: \$CROSS_ACCOUNT_TRUSTS" \| tee -a
logs/\$LOG_FILE

echo " - Total Security Findings: \$TOTAL_FINDINGS" \| tee -a
logs/\$LOG_FILE

\# リスクレベルの判定

HIGH_RISK_THRESHOLD=50

MEDIUM_RISK_THRESHOLD=20

if \[ \$TOTAL_FINDINGS -gt \$HIGH_RISK_THRESHOLD \]; then

echo "\[ERROR\] High risk: \$TOTAL_FINDINGS security findings exceed
threshold (\$HIGH_RISK_THRESHOLD)" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="HIGH_RISK_IAM_FINDINGS"

export BUILD_EXIT_CODE=1

export RISK_LEVEL="HIGH"

elif \[ \$TOTAL_FINDINGS -gt \$MEDIUM_RISK_THRESHOLD \]; then

echo "\[WARNING\] Medium risk: \$TOTAL_FINDINGS security findings exceed
threshold (\$MEDIUM_RISK_THRESHOLD)" \| tee -a logs/\$LOG_FILE

export BUILD_ERROR="MEDIUM_RISK_IAM_FINDINGS"

export BUILD_EXIT_CODE=1

export RISK_LEVEL="MEDIUM"

else

echo "\[SUCCESS\] Low risk: \$TOTAL_FINDINGS security findings within
acceptable limits" \| tee -a logs/\$LOG_FILE

export RISK_LEVEL="LOW"

fi

\# 重要な外部アクセス検出の詳細分析

if \[ -f logs/\$EXTERNAL_ACCESS_FILE \] && \[ \$EXTERNAL_FINDINGS -gt 0
\]; then

echo "\[BUILD\] Analyzing external access details..." \| tee -a
logs/\$LOG_FILE

\# 重要度の高い外部アクセスを特定

CRITICAL_EXTERNAL=\$(jq '\[.\[\] \| select(.resource_type ==
"AWS::S3::Bucket" or .resource_type == "AWS::IAM::Role")\] \| length'
logs/\$EXTERNAL_ACCESS_FILE)

if \[ \$CRITICAL_EXTERNAL -gt 0 \]; then

echo "\[ERROR\] Found \$CRITICAL_EXTERNAL critical external access
findings" \| tee -a logs/\$LOG_FILE

echo "\[BUILD\] Critical External Access Details:" \| tee -a
logs/\$LOG_FILE

jq -r '.\[\] \| select(.resource_type == "AWS::S3::Bucket" or
.resource_type == "AWS::IAM::Role") \| "Resource: \\.resource) \| Type:
\\.resource_type) \| Principal: \\.principal)"'
logs/\$EXTERNAL_ACCESS_FILE \| head -10 \| tee -a logs/\$LOG_FILE

if \[ -z "\$BUILD_ERROR" \]; then

export BUILD_ERROR="CRITICAL_EXTERNAL_ACCESS_DETECTED"

export BUILD_EXIT_CODE=1

fi

fi

fi

\# 未使用権限の詳細分析

if \[ -f logs/\$UNUSED_PERMISSIONS_FILE \] && \[ \$UNUSED_PERMISSIONS
-gt 0 \]; then

echo "\[BUILD\] Analyzing unused permissions details..." \| tee -a
logs/\$LOG_FILE

\# 長期間未使用の権限を特定

LONG_UNUSED=\$(jq '\[.\[\] \| select(.days_unused \> 180)\] \| length'
logs/\$UNUSED_PERMISSIONS_FILE)

NEVER_USED=\$(jq '\[.\[\] \| select(.last_used == "never")\] \| length'
logs/\$UNUSED_PERMISSIONS_FILE)

echo " - Long-term unused (\>180 days): \$LONG_UNUSED" \| tee -a
logs/\$LOG_FILE

echo " - Never used: \$NEVER_USED" \| tee -a logs/\$LOG_FILE

if \[ \$LONG_UNUSED -gt 10 \]; then

echo "\[WARNING\] Excessive long-term unused permissions detected" \|
tee -a logs/\$LOG_FILE

fi

fi

\# クロスアカウントアクセスの分析

if \[ -f logs/\$CROSS_ACCOUNT_FINDINGS_FILE \] && \[
\$CROSS_ACCOUNT_TRUSTS -gt 0 \]; then

echo "\[BUILD\] Analyzing cross-account access details..." \| tee -a
logs/\$LOG_FILE

\# 外部アカウントからの信頼関係を特定

EXTERNAL_TRUSTS=\$(jq '\[.\[\] \| select(.trusted_account !=
"'\$AWS_ACCOUNT_ID'")\] \| length' logs/\$CROSS_ACCOUNT_FINDINGS_FILE
2\>/dev/null \|\| echo "0")

if \[ \$EXTERNAL_TRUSTS -gt 0 \]; then

echo "\[WARNING\] Found \$EXTERNAL_TRUSTS external account trust
relationships" \| tee -a logs/\$LOG_FILE

echo "\[BUILD\] External Trust Details:" \| tee -a logs/\$LOG_FILE

jq -r '.\[\] \| select(.trusted_account != "'\$AWS_ACCOUNT_ID'") \|
"Role: \\.role_name) \| Trusted Account: \\.trusted_account) \|
Principal: \\.trusted_principal)"' logs/\$CROSS_ACCOUNT_FINDINGS_FILE \|
head -5 \| tee -a logs/\$LOG_FILE

fi

fi

else

echo "\[ERROR\] IAM analysis summary not found" \| tee -a
logs/\$LOG_FILE

export BUILD_ERROR="IAM_ANALYSIS_INCOMPLETE"

export BUILD_EXIT_CODE=1

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Processing IAM analysis results and generating
reports..." \| tee -a logs/\$LOG_FILE

\- \|

\# CloudWatchメトリクス送信

if \[ -f logs/\$SUMMARY_FILE \]; then

aws cloudwatch put-metric-data \\

--namespace "TechNova/IAMSecurity" \\

--metric-data \\

MetricName=OrganizationAccounts,Value=\$TOTAL_ACCOUNTS,Unit=Count \\

MetricName=ExternalAccessFindings,Value=\$EXTERNAL_FINDINGS,Unit=Count
\\

MetricName=UnusedPermissions,Value=\$UNUSED_PERMISSIONS,Unit=Count \\

MetricName=CrossAccountTrusts,Value=\$CROSS_ACCOUNT_TRUSTS,Unit=Count \\

MetricName=TotalSecurityFindings,Value=\$TOTAL_FINDINGS,Unit=Count \\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

fi

\# 高リスクの場合はSNS通知

if \[ "\$RISK_LEVEL" = "HIGH" \] \|\| \[ ! -z "\$BUILD_ERROR" \] && \[\[
"\$BUILD_ERROR" == \*"CRITICAL"\* \]\]; then

aws sns publish \\

--topic-arn \$CRITICAL_SECURITY_ALERTS_TOPIC \\

--subject "CRITICAL: High-Risk IAM Security Findings Detected" \\

--message "Pipeline: \$PIPELINE_EXECUTION_ID\nRisk Level:
\$RISK_LEVEL\nTotal Findings: \$TOTAL_FINDINGS\nExternal Access:
\$EXTERNAL_FINDINGS\nUnused Permissions:
\$UNUSED_PERMISSIONS\nCross-Account Trusts:
\$CROSS_ACCOUNT_TRUSTS\nImmediate review required." \\

--region \$AWS_DEFAULT_REGION \|\| echo "SNS notification failed"

fi

\# 結果ファイルをS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

for file in \$SUMMARY_FILE \$EXTERNAL_ACCESS_FILE
\$UNUSED_PERMISSIONS_FILE \$CROSS_ACCOUNT_FINDINGS_FILE; do

if \[ -f logs/\$file \]; then

aws s3 cp logs/\$file s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$file \|\| echo
"\$file upload failed"

fi

done

\# 組織アカウント情報もアップロード

if \[ -f logs/organization-accounts.json \]; then

aws s3 cp logs/organization-accounts.json
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/organization-accounts.json \|\| echo
"Organization accounts upload failed"

fi

\# HTMLレポート生成

if \[ -f logs/\$SUMMARY_FILE \]; then

cat \> logs/iam-security-report.html \<\< EOF

\<!DOCTYPE html\>

\<html\>

\<head\>

\<title\>IAM Security Analysis Report - Pipeline
\$PIPELINE_EXECUTION_ID\</title\>

\<style\>

body { font-family: Arial, sans-serif; margin: 40px; }

.header { background: \#f0f0f0; padding: 20px; border-radius: 5px; }

.section { margin: 20px 0; padding: 15px; border-left: 4px solid
\#007cba; }

.high-risk { border-left-color: \#d32f2f; background: \#ffebee; }

.medium-risk { border-left-color: \#f57c00; background: \#fff3e0; }

.low-risk { border-left-color: \#388e3c; background: \#e8f5e8; }

.metric { display: inline-block; margin: 10px; padding: 10px;
background: \#f5f5f5; border-radius: 3px; }

\</style\>

\</head\>

\<body\>

\<div class="header"\>

\<h1\>IAM Security Analysis Report\</h1\>

\<p\>Pipeline Execution: \$PIPELINE_EXECUTION_ID\</p\>

\<p\>Analysis Date: \$(date)\</p\>

\<p\>Risk Level: \<strong\>\$RISK_LEVEL\</strong\>\</p\>

\</div\>

\<div class="section \${RISK_LEVEL,,}-risk"\>

\<h2\>Summary Metrics\</h2\>

\<div class="metric"\>Organization Accounts:
\<strong\>\$TOTAL_ACCOUNTS\</strong\>\</div\>

\<div class="metric"\>External Access Findings:
\<strong\>\$EXTERNAL_FINDINGS\</strong\>\</div\>

\<div class="metric"\>Unused Permissions:
\<strong\>\$UNUSED_PERMISSIONS\</strong\>\</div\>

\<div class="metric"\>Cross-Account Trusts:
\<strong\>\$CROSS_ACCOUNT_TRUSTS\</strong\>\</div\>

\<div class="metric"\>Total Security Findings:
\<strong\>\$TOTAL_FINDINGS\</strong\>\</div\>

\</div\>

\<div class="section"\>

\<h2\>Detailed Analysis\</h2\>

\<p\>Complete analysis results are available in the pipeline artifacts
and S3 logs.\</p\>

\<ul\>

\<li\>External Access Details: external-access-findings.json\</li\>

\<li\>Unused Permissions: unused-permissions.json\</li\>

\<li\>Cross-Account Findings: cross-account-findings.json\</li\>

\<li\>Full Log: \$LOG_FILE\</li\>

\</ul\>

\</div\>

\</body\>

\</html\>

EOF

aws s3 cp logs/iam-security-report.html
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/iam-security-report.html \|\| echo
"HTML report upload failed"

fi

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to IAM security violations"
\| tee -a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite IAM security
violations" \| tee -a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts:

files:

\- logs/\*

name: iam-security-analysis-results

**4. 動的解析の詳細実装**

**4.1 動的脆弱性スキャン（インフラ）**

resource "aws_codebuild_project" "dynamic_vuln_scan" {

name = "dynamic-infrastructure-vulnerability-scan"

description = "Dynamic infrastructure vulnerability scanning using
multiple tools"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials\_

image_pull_credentials_type = "CODEBUILD"

privileged_mode = true

environment_variable {

name = "SCAN_TARGET_ENVIRONMENT"

value = "staging"

}

environment_variable {

name = "VULNERABILITY_TOOLS"

value = "nmap,nuclei,testssl"

}

environment_variable {

name = "SCAN_INTENSITY"

value = "COMPREHENSIVE"

}

environment_variable {

name = "MAX_SCAN_DURATION"

value = "3600" \# 1時間

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/dynamic_vuln_scan.yml"

}

timeout_in_minutes = 90

tags = {

Stage = "DynamicAnalysis"

Tool = "VulnerabilityScanner"

Target = "Infrastructure"

}

}

4.2 dynamic_vuln_scan.yml（包括的インフラ脆弱性スキャン）

version: 0.2

env:

variables:

LOG_FILE: "dynamic-vuln-scan-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

NMAP_RESULTS: "nmap-scan-results.xml"

NUCLEI_RESULTS: "nuclei-scan-results.json"

TESTSSL_RESULTS: "testssl-scan-results.json"

CONSOLIDATED_RESULTS: "vulnerability-scan-results.json"

SUMMARY_FILE: "vulnerability-scan-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up vulnerability scanning environment..."
\| tee logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# システム更新

yum update -y

yum install -y docker jq bc nmap git golang

\# Docker起動

service docker start

usermod -a -G docker codebuild

\# Nucleiインストール

GO111MODULE=on go install -v
github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest

export PATH=\$PATH:/root/go/bin

nuclei -version \| tee -a logs/\$LOG_FILE

\# Nucleiテンプレート更新

nuclei -update-templates

\# testssl.shインストール

git clone --depth 1 https://github.com/drwetter/testssl.sh.git

chmod +x testssl.sh/testssl.sh

\# カスタムスキャン設定の取得

aws s3 cp
s3://\$SECURITY_CONFIGS_BUCKET/vuln-scan-config/scan-targets.json
scan-targets.json \|\| echo '{"targets": \[\]}' \> scan-targets.json

aws s3 cp s3://\$SECURITY_CONFIGS_BUCKET/vuln-scan-config/exclusions.txt
exclusions.txt \|\| touch exclusions.txt

pre_build:

commands:

\- echo "\[PRE_BUILD\] Preparing vulnerability scan targets..." \| tee
-a logs/\$LOG_FILE

\- \|

\# ターゲット環境のリソース検出

echo "\[PRE_BUILD\] Discovering scan targets in \$TARGET_ENVIRONMENT
environment" \| tee -a logs/\$LOG_FILE

\# ALB/ELBエンドポイント取得

aws elbv2 describe-load-balancers --query
'LoadBalancers\[?State.Code==\`active\`\].\[DNSName,Type\]' --output
text \| while read dns_name type; do

echo "ALB/NLB: \$dns_name (\$type)" \| tee -a logs/\$LOG_FILE

echo "\$dns_name" \>\> scan-targets-discovered.txt

done

\# CloudFrontディストリビューション取得

aws cloudfront list-distributions --query
'DistributionList.Items\[?Status==\`Deployed\`\].DomainName' --output
text \| tr '\t' '\n' \| while read domain; do

if \[ ! -z "\$domain" \]; then

echo "CloudFront: \$domain" \| tee -a logs/\$LOG_FILE

echo "\$domain" \>\> scan-targets-discovered.txt

fi

done

\# API Gatewayエンドポイント取得

aws apigateway get-rest-apis --query
'items\[?endpointConfiguration.types\[0\]==\`REGIONAL\`\].\[id,name\]'
--output text \| while read api_id name; do

api_endpoint="\${api_id}.execute-api.\${AWS_DEFAULT_REGION}.amazonaws.com"

echo "API Gateway: \$api_endpoint (\$name)" \| tee -a logs/\$LOG_FILE

echo "\$api_endpoint" \>\> scan-targets-discovered.txt

done

\# EC2インスタンスのパブリックIP取得（注意深く）

aws ec2 describe-instances \\

--filters "Name=instance-state-name,Values=running"
"Name=tag:Environment,Values=\$TARGET_ENVIRONMENT" \\

--query
'Reservations\[\].Instances\[?PublicIpAddress\].\[PublicIpAddress,Tags\[?Key==\`Name\`\].Value\|\[0\]\]'
\\

--output text \| while read ip name; do

if \[ ! -z "\$ip" \] && \[ "\$ip" != "None" \]; then

echo "EC2 Instance: \$ip (\$name)" \| tee -a logs/\$LOG_FILE

echo "\$ip" \>\> scan-targets-discovered.txt

fi

done

\# 重複除去とソート

if \[ -f scan-targets-discovered.txt \]; then

sort -u scan-targets-discovered.txt \> scan-targets-final.txt

TARGET_COUNT=\$(wc -l \< scan-targets-final.txt)

echo "\[PRE_BUILD\] Found \$TARGET_COUNT scan targets" \| tee -a
logs/\$LOG_FILE

else

echo "\[PRE_BUILD\] No scan targets discovered" \| tee -a
logs/\$LOG_FILE

touch scan-targets-final.txt

fi

\# カスタム設定からのターゲット追加

if \[ -f scan-targets.json \]; then

jq -r '.targets\[\]' scan-targets.json \>\> scan-targets-final.txt

sort -u scan-targets-final.txt \> scan-targets-temp.txt

mv scan-targets-temp.txt scan-targets-final.txt

fi

build:

commands:

\- echo "\[BUILD\] Starting comprehensive vulnerability scanning..." \|
tee -a logs/\$LOG_FILE

\- \|

SCAN_START_TIME=\$(date +%s)

MAX_DURATION=\${MAX_SCAN_DURATION:-3600}

\# 結果ファイル初期化

echo '{"nmap_results": \[\], "nuclei_results": \[\], "testssl_results":
\[\], "summary": {}}' \> logs/\$CONSOLIDATED_RESULTS

\# スキャン対象がない場合の処理

if \[ ! -s scan-targets-final.txt \]; then

echo "\[BUILD\] No targets to scan, creating empty results" \| tee -a
logs/\$LOG_FILE

echo '{"targets_scanned": 0, "vulnerabilities_found": 0,
"scan_duration": 0}' \> logs/\$SUMMARY_FILE

else

echo "\[BUILD\] Starting scans on \$(wc -l \< scan-targets-final.txt)
targets" \| tee -a logs/\$LOG_FILE

\# 並列スキャン実行

while IFS= read -r target; do

CURRENT_TIME=\$(date +%s)

ELAPSED_TIME=\$((CURRENT_TIME - SCAN_START_TIME))

if \[ \$ELAPSED_TIME -gt \$MAX_DURATION \]; then

echo "\[BUILD\] Maximum scan duration reached, stopping scans" \| tee -a
logs/\$LOG_FILE

break

fi

if \[ -z "\$target" \]; then

continue

fi

echo "\[BUILD\] Scanning target: \$target" \| tee -a logs/\$LOG_FILE

\# Nmapスキャン（ポートスキャン・サービス検出）

if \[\[ "\$VULNERABILITY_TOOLS" == \*"nmap"\* \]\]; then

echo "\[BUILD\] Running Nmap scan on \$target" \| tee -a logs/\$LOG_FILE

nmap -sS -sV -O -A --script=vuln,safe,discovery \\

-oX logs/nmap-\${target//\[^a-zA-Z0-9\]/\_}.xml \\

-oN logs/nmap-\${target//\[^a-zA-Z0-9\]/\_}.txt \\

--max-retries 2 --host-timeout 10m \\

\$target \>\> logs/\$LOG_FILE 2\>&1 &

NMAP_PID=\$!

echo "Nmap PID: \$NMAP_PID for target \$target" \| tee -a
logs/\$LOG_FILE

fi

\# Nucleiスキャン（脆弱性テンプレート）

if \[\[ "\$VULNERABILITY_TOOLS" == \*"nuclei"\* \]\]; then

echo "\[BUILD\] Running Nuclei scan on \$target" \| tee -a
logs/\$LOG_FILE

nuclei -u "http://\$target" -u "https://\$target" \\

-severity critical,high,medium \\

-json -o logs/nuclei-\${target//\[^a-zA-Z0-9\]/\_}.json \\

-timeout 30 \\

-retries 2 \\

-rate-limit 10 \>\> logs/\$LOG_FILE 2\>&1 &

NUCLEI_PID=\$!

echo "Nuclei PID: \$NUCLEI_PID for target \$target" \| tee -a
logs/\$LOG_FILE

fi

\# testssl.shスキャン（SSL/TLS設定）

if \[\[ "\$VULNERABILITY_TOOLS" == \*"testssl"\* \]\]; then

echo "\[BUILD\] Running testssl.sh scan on \$target" \| tee -a
logs/\$LOG_FILE

./testssl.sh/testssl.sh --jsonfile
logs/testssl-\${target//\[^a-zA-Z0-9\]/\_}.json \\

--logfile logs/testssl-\${target//\[^a-zA-Z0-9\]/\_}.log \\

--severity HIGH \\

--fast \\

\$target \>\> logs/\$LOG_FILE 2\>&1 &

TESTSSL_PID=\$!

echo "testssl PID: \$TESTSSL_PID for target \$target" \| tee -a
logs/\$LOG_FILE

fi

\# 同時実行数制限（最大5並列）

RUNNING_JOBS=\$(jobs -r \| wc -l)

if \[ \$RUNNING_JOBS -ge 15 \]; then

echo "\[BUILD\] Waiting for scan slots to free up..." \| tee -a
logs/\$LOG_FILE

wait -n \# 任意のジョブ完了まで待機

fi

done \< scan-targets-final.txt

\# 全スキャン完了待機

echo "\[BUILD\] Waiting for all scans to complete..." \| tee -a
logs/\$LOG_FILE

wait

\# 結果の統合と分析

echo "\[BUILD\] Consolidating scan results..." \| tee -a logs/\$LOG_FILE

TOTAL_VULNERABILITIES=0

HIGH_SEVERITY_VULNS=0

MEDIUM_SEVERITY_VULNS=0

LOW_SEVERITY_VULNS=0

\# Nmapの結果解析

for nmap_file in logs/nmap-\*.xml; do

if \[ -f "\$nmap_file" \]; then

\# XMLから脆弱性情報を抽出

NMAP_VULNS=\$(grep -c "VULNERABLE" "\$nmap_file" 2\>/dev/null \|\| echo
"0")

TOTAL_VULNERABILITIES=\$((TOTAL_VULNERABILITIES + NMAP_VULNS))

echo "\[BUILD\] Nmap found \$NMAP_VULNS vulnerabilities in \$nmap_file"
\| tee -a logs/\$LOG_FILE

fi

done

\# Nucleiの結果解析

for nuclei_file in logs/nuclei-\*.json; do

if \[ -f "\$nuclei_file" \] && \[ -s "\$nuclei_file" \]; then

CRITICAL_NUCLEI=\$(jq '\[.\[\] \| select(.info.severity == "critical")\]
\| length' "\$nuclei_file" 2\>/dev/null \|\| echo "0")

HIGH_NUCLEI=\$(jq '\[.\[\] \| select(.info.severity == "high")\] \|
length' "\$nuclei_file" 2\>/dev/null \|\| echo "0")

MEDIUM_NUCLEI=\$(jq '\[.\[\] \| select(.info.severity == "medium")\] \|
length' "\$nuclei_file" 2\>/dev/null \|\| echo "0")

HIGH_SEVERITY_VULNS=\$((HIGH_SEVERITY_VULNS + CRITICAL_NUCLEI +
HIGH_NUCLEI))

MEDIUM_SEVERITY_VULNS=\$((MEDIUM_SEVERITY_VULNS + MEDIUM_NUCLEI))

TOTAL_VULNERABILITIES=\$((TOTAL_VULNERABILITIES + CRITICAL_NUCLEI +
HIGH_NUCLEI + MEDIUM_NUCLEI))

echo "\[BUILD\] Nuclei found Critical:\$CRITICAL_NUCLEI
High:\$HIGH_NUCLEI Medium:\$MEDIUM_NUCLEI in \$nuclei_file" \| tee -a
logs/\$LOG_FILE

fi

done

\# testssl.shの結果解析

for testssl_file in logs/testssl-\*.json; do

if \[ -f "\$testssl_file" \] && \[ -s "\$testssl_file" \]; then

SSL_HIGH=\$(jq '\[.\[\] \| select(.severity == "HIGH")\] \| length'
"\$testssl_file" 2\>/dev/null \|\| echo "0")

SSL_MEDIUM=\$(jq '\[.\[\] \| select(.severity == "MEDIUM")\] \| length'
"\$testssl_file" 2\>/dev/null \|\| echo "0")

SSL_LOW=\$(jq '\[.\[\] \| select(.severity == "LOW")\] \| length'
"\$testssl_file" 2\>/dev/null \|\| echo "0")

HIGH_SEVERITY_VULNS=\$((HIGH_SEVERITY_VULNS + SSL_HIGH))

MEDIUM_SEVERITY_VULNS=\$((MEDIUM_SEVERITY_VULNS + SSL_MEDIUM))

LOW_SEVERITY_VULNS=\$((LOW_SEVERITY_VULNS + SSL_LOW))

TOTAL_VULNERABILITIES=\$((TOTAL_VULNERABILITIES + SSL_HIGH +
SSL_MEDIUM + SSL_LOW))

echo "\[BUILD\] testssl found High:\$SSL_HIGH Medium:\$SSL_MEDIUM
Low:\$SSL_LOW in \$testssl_file" \| tee -a logs/\$LOG_FILE

fi

done

SCAN_END_TIME=\$(date +%s)

SCAN_DURATION=\$((SCAN_END_TIME - SCAN_START_TIME))

echo "\[BUILD\] Vulnerability Scan Summary:" \| tee -a logs/\$LOG_FILE

echo " - Total Vulnerabilities: \$TOTAL_VULNERABILITIES" \| tee -a
logs/\$LOG_FILE

echo " - High Severity: \$HIGH_SEVERITY_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Medium Severity: \$MEDIUM_SEVERITY_VULNS" \| tee -a
logs/\$LOG_FILE

echo " - Low Severity: \$LOW_SEVERITY_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Scan Duration: \${SCAN_DURATION}s" \| tee -a logs/\$LOG_FILE

\# サマリーJSON作成

cat \> logs/\$SUMMARY_FILE \<\< EOF

{

"pipeline_execution_id": "\$PIPELINE_EXECUTION_ID",

"timestamp": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",

"targets_scanned": \$(wc -l \< scan-targets-final.txt),

"scan_duration_seconds": \$SCAN_DURATION,

"vulnerabilities_found": \$TOTAL_VULNERABILITIES,

"severity_breakdown": {

"high": \$HIGH_SEVERITY_VULNS,

"medium": \$MEDIUM_SEVERITY_VULNS,

"low": \$LOW_SEVERITY_VULNS

},

"tools_used": "\$VULNERABILITY_TOOLS",

"scan_intensity": "\$SCAN_INTENSITY"

}

EOF

\# リスク判定

CRITICAL_THRESHOLD=10

HIGH_THRESHOLD=25

if \[ \$HIGH_SEVERITY_VULNS -gt \$CRITICAL_THRESHOLD \]; then

echo "\[ERROR\] Critical risk: \$HIGH_SEVERITY_VULNS high severity
vulnerabilities exceed threshold (\$CRITICAL_THRESHOLD)" \| tee -a
logs/\$LOG_FILE

export BUILD_ERROR="CRITICAL_VULNERABILITIES_DETECTED"

export BUILD_EXIT_CODE=1

export RISK_LEVEL="CRITICAL"

elif \[ \$TOTAL_VULNERABILITIES -gt \$HIGH_THRESHOLD \]; then

echo "\[WARNING\] High risk: \$TOTAL_VULNERABILITIES total
vulnerabilities exceed threshold (\$HIGH_THRESHOLD)" \| tee -a
logs/\$LOG_FILE

export BUILD_ERROR="HIGH_RISK_VULNERABILITIES_DETECTED"

export BUILD_EXIT_CODE=1

export RISK_LEVEL="HIGH"

else

echo "\[SUCCESS\] Acceptable risk: \$TOTAL_VULNERABILITIES
vulnerabilities within limits" \| tee -a logs/\$LOG_FILE

export RISK_LEVEL="LOW"

fi

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Processing vulnerability scan results..." \| tee
-a logs/\$LOG_FILE

\- \|

\# CloudWatchメトリクス送信

if \[ -f logs/\$SUMMARY_FILE \]; then

TARGETS_SCANNED=\$(jq '.targets_scanned' logs/\$SUMMARY_FILE)

VULNERABILITIES_FOUND=\$(jq '.vulnerabilities_found'
logs/\$SUMMARY_FILE)

HIGH_SEVERITY=\$(jq '.severity_breakdown.high' logs/\$SUMMARY_FILE)

MEDIUM_SEVERITY=\$(jq '.severity_breakdown.medium' logs/\$SUMMARY_FILE)

aws cloudwatch put-metric-data \\

--namespace "TechNova/VulnerabilityScanning" \\

--metric-data \\

MetricName=TargetsScanned,Value=\$TARGETS_SCANNED,Unit=Count \\

MetricName=VulnerabilitiesFound,Value=\$VULNERABILITIES_FOUND,Unit=Count
\\

MetricName=HighSeverityVulns,Value=\$HIGH_SEVERITY,Unit=Count \\

MetricName=MediumSeverityVulns,Value=\$MEDIUM_SEVERITY,Unit=Count \\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

fi

\# 重要な脆弱性発見時のSNS通知

if \[ "\$RISK_LEVEL" = "CRITICAL" \] \|\| \[ ! -z "\$BUILD_ERROR" \] &&
\[\[ "\$BUILD_ERROR" == \*"CRITICAL"\* \]\]; then

aws sns publish \\

--topic-arn \$CRITICAL_SECURITY_ALERTS_TOPIC \\

--subject "CRITICAL: High-Risk Vulnerabilities Detected" \\

--message "Pipeline: \$PIPELINE_EXECUTION_ID\nRisk Level:
\$RISK_LEVEL\nHigh Severity Vulnerabilities:
\$HIGH_SEVERITY_VULNS\nTotal Vulnerabilities:
\$TOTAL_VULNERABILITIES\nImmediate remediation required." \\

--region \$AWS_DEFAULT_REGION \|\| echo "SNS notification failed"

fi

\# 全結果ファイルをS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

if \[ -f logs/\$SUMMARY_FILE \]; then

aws s3 cp logs/\$SUMMARY_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$SUMMARY_FILE \|\| echo "Summary
upload failed"

fi

\# スキャン結果ファイルのアップロード

for result_file in logs/nmap-\*.xml logs/nmap-\*.txt logs/nuclei-\*.json
logs/testssl-\*.json logs/testssl-\*.log; do

if \[ -f "\$result_file" \]; then

aws s3 cp "\$result_file" s3://\$S3_LOG_BUCKET/\$S3_PREFIX/ \|\| echo
"\$(basename \$result_file) upload failed"

fi

done

\# 統合レポート生成

if \[ -f logs/\$SUMMARY_FILE \]; then

cat \> logs/vulnerability-scan-report.html \<\< EOF

\<!DOCTYPE html\>

\<html\>

\<head\>

\<title\>Vulnerability Scan Report - Pipeline
\$PIPELINE_EXECUTION_ID\</title\>

\<style\>

body { font-family: Arial, sans-serif; margin: 40px; }

.header { background: \#f0f0f0; padding: 20px; border-radius: 5px; }

.section { margin: 20px 0; padding: 15px; border-left: 4px solid
\#007cba; }

.critical { border-left-color: \#d32f2f; background: \#ffebee; }

.high { border-left-color: \#f57c00; background: \#fff3e0; }

.low { border-left-color: \#388e3c; background: \#e8f5e8; }

.metric { display: inline-block; margin: 10px; padding: 10px;
background: \#f5f5f5; border-radius: 3px; }

.vuln-list { max-height: 300px; overflow-y: auto; background: \#fafafa;
padding: 10px; border-radius: 3px; }

\</style\>

\</head\>

\<body\>

\<div class="header"\>

\<h1\>Infrastructure Vulnerability Scan Report\</h1\>

\<p\>Pipeline Execution: \$PIPELINE_EXECUTION_ID\</p\>

\<p\>Scan Date: \$(date)\</p\>

\<p\>Risk Level: \<strong\>\$RISK_LEVEL\</strong\>\</p\>

\</div\>

\<div class="section \${RISK_LEVEL,,}"\>

\<h2\>Scan Summary\</h2\>

\<div class="metric"\>Targets Scanned:
\<strong\>\$TARGETS_SCANNED\</strong\>\</div\>

\<div class="metric"\>Total Vulnerabilities:
\<strong\>\$VULNERABILITIES_FOUND\</strong\>\</div\>

\<div class="metric"\>High Severity:
\<strong\>\$HIGH_SEVERITY_VULNS\</strong\>\</div\>

\<div class="metric"\>Medium Severity:
\<strong\>\$MEDIUM_SEVERITY_VULNS\</strong\>\</div\>

\<div class="metric"\>Low Severity:
\<strong\>\$LOW_SEVERITY_VULNS\</strong\>\</div\>

\<div class="metric"\>Scan Duration:
\<strong\>\${SCAN_DURATION}s\</strong\>\</div\>

\</div\>

\<div class="section"\>

\<h2\>Tools Used\</h2\>

\<p\>\$VULNERABILITY_TOOLS\</p\>

\</div\>

\<div class="section"\>

\<h2\>Detailed Results\</h2\>

\<p\>Complete scan results are available in the pipeline
artifacts:\</p\>

\<ul\>

\<li\>Nmap Results: nmap-\*.xml, nmap-\*.txt\</li\>

\<li\>Nuclei Results: nuclei-\*.json\</li\>

\<li\>testssl Results: testssl-\*.json\</li\>

\<li\>Full Log: \$LOG_FILE\</li\>

\</ul\>

\</div\>

\</body\>

\</html\>

EOF

aws s3 cp logs/vulnerability-scan-report.html
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/vulnerability-scan-report.html \|\|
echo "HTML report upload failed"

fi

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to critical vulnerabilities"
\| tee -a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite vulnerabilities" \| tee
-a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts:

files:

\- logs/\*

\- scan-targets-final.txt

name: vulnerability-scan-results

4.3 動的アプリケーション脆弱性スキャン

resource "aws_codebuild_project" "dynamic_app_scan" {

name = "dynamic-application-security-scan"

description = "Dynamic application security testing using OWASP ZAP and
custom tools"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

privileged_mode = true

environment_variable {

name = "ZAP_SCAN_TYPE"

value = "FULL"

}

environment_variable {

name = "OWASP_TOP10_FOCUS"

value = "true"

}

environment_variable {

name = "CUSTOM_PAYLOADS_BUCKET"

value = aws_s3_bucket.security_configs.id

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/dynamic_app_scan.yml"

}

timeout_in_minutes = 120

tags = {

Stage = "DynamicAnalysis"

Tool = "OWASP-ZAP"

Target = "WebApplications"

}

}

4.4 dynamic_app_scan.yml（OWASP ZAP包括的スキャン）

version: 0.2

env:

variables:

LOG_FILE: "dynamic-app-scan-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

ZAP_REPORT_HTML: "zap-report.html"

ZAP_REPORT_JSON: "zap-report.json"

ZAP_REPORT_XML: "zap-report.xml"

SUMMARY_FILE: "app-scan-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up OWASP ZAP and application scanning
environment..." \| tee logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# Dockerインストールと起動

yum update -y

yum install -y docker jq bc wget

service docker start

usermod -a -G docker codebuild

\# OWASP ZAP Dockerイメージの取得

docker pull owasp/zap2docker-stable:latest

\# カスタムペイロードとスキャン設定の取得

aws s3 cp s3://\$CUSTOM_PAYLOADS_BUCKET/app-scan-config/scan-config.json
scan-config.json \|\| echo '{"applications": \[\]}' \> scan-config.json

aws s3 cp s3://\$CUSTOM_PAYLOADS_BUCKET/app-scan-config/custom-payloads/
custom-payloads/ --recursive \|\| mkdir -p custom-payloads

\# ZAPのカスタム設定

mkdir -p zap-config

cat \> zap-config/options.prop \<\< 'EOF'

\# ZAP Configuration

scanner.attackOnStart=true

scanner.delayInMs=200

scanner.threadPerHost=10

scanner.hostPerScan=5

spider.maxDuration=30

spider.postForm=true

spider.processForm=true

passivescan.autoTagScanners=true

EOF

pre_build:

commands:

\- echo "\[PRE_BUILD\] Discovering web application targets..." \| tee -a
logs/\$LOG_FILE

\- \|

\# Webアプリケーションターゲットの自動検出

echo '\[\]' \> app-targets.json

\# ALB/ELBのHTTP/HTTPSエンドポイント

aws elbv2 describe-load-balancers --query
'LoadBalancers\[?State.Code==\`active\`\].\[DNSName,Type\]' --output
text \| while read dns_name type; do

\# HTTPSエンドポイントを優先

https_url="https://\$dns_name"

http_url="http://\$dns_name"

\# 接続テスト

if curl -k -s --connect-timeout 10 "\$https_url" \>/dev/null 2\>&1; then

echo "Found HTTPS endpoint: \$https_url" \| tee -a logs/\$LOG_FILE

jq --arg url "\$https_url" '. += \[{"url": \$url, "type":
"load_balancer", "protocol": "https"}\]' app-targets.json \>
app-targets-temp.json

mv app-targets-temp.json app-targets.json

elif curl -s --connect-timeout 10 "\$http_url" \>/dev/null 2\>&1; then

echo "Found HTTP endpoint: \$http_url" \| tee -a logs/\$LOG_FILE

jq --arg url "\$http_url" '. += \[{"url": \$url, "type":
"load_balancer", "protocol": "http"}\]' app-targets.json \>
app-targets-temp.json

mv app-targets-temp.json app-targets.json

fi

done

\# CloudFrontディストリビューション

aws cloudfront list-distributions --query
'DistributionList.Items\[?Status==\`Deployed\`\].DomainName' --output
text \| tr '\t' '\n' \| while read domain; do

if \[ ! -z "\$domain" \]; then

https_url="https://\$domain"

if curl -k -s --connect-timeout 10 "\$https_url" \>/dev/null 2\>&1; then

echo "Found CloudFront endpoint: \$https_url" \| tee -a logs/\$LOG_FILE

jq --arg url "\$https_url" '. += \[{"url": \$url, "type": "cloudfront",
"protocol": "https"}\]' app-targets.json \> app-targets-temp.json

mv app-targets-temp.json app-targets.json

fi

fi

done

\# API Gateway REST APIs

aws apigateway get-rest-apis --query 'items\[\].\[id,name\]' --output
text \| while read api_id name; do

api_url="https://\${api_id}.execute-api.\${AWS_DEFAULT_REGION}.amazonaws.com/prod"

if curl -k -s --connect-timeout 10 "\$api_url" \>/dev/null 2\>&1; then

echo "Found API Gateway endpoint: \$api_url" \| tee -a logs/\$LOG_FILE

jq --arg url "\$api_url

jq --arg url "apiurl"−−argname"api_url" --arg name "
apiu​rl"−−argname"name" '. += \[{"url": \$url, "type": "api_gateway",
"protocol": "https", "name": \$name}\]' app-targets.json \>
app-targets-temp.json mv app-targets-temp.json app-targets.json fi done

\# カスタム設定からの追加ターゲット

if \[ -f scan-config.json \]; then

jq -r '.applications\[\].url' scan-config.json \| while read custom_url;
do

if \[ ! -z "\$custom_url" \]; then

echo "Adding custom target: \$custom_url" \| tee -a logs/\$LOG_FILE

jq --arg url "\$custom_url" '. += \[{"url": \$url, "type": "custom",
"protocol": "https"}\]' app-targets.json \> app-targets-temp.json

mv app-targets-temp.json app-targets.json

fi

done

fi

TARGET_COUNT=\$(jq length app-targets.json)

echo "\[PRE_BUILD\] Found \$TARGET_COUNT web application targets" \| tee
-a logs/\$LOG_FILE

if \[ \$TARGET_COUNT -eq 0 \]; then

echo "\[PRE_BUILD\] No web application targets found for scanning" \|
tee -a logs/\$LOG_FILE

echo '{"message": "No targets found"}' \> logs/\$SUMMARY_FILE

fi

build: commands: - echo "\[BUILD\] Starting dynamic application security
scanning..." \| tee -a logs/\$LOG_FILE - \| SCAN_START_TIME=\$(date +%s)

\# スキャン対象がない場合の処理 TARGET_COUNT=\$(jq length
app-targets.json) if \[ \$TARGET_COUNT -eq 0 \]; then echo "\[BUILD\] No
targets to scan, creating empty results" \| tee -a logs/\$LOG_FILE cat
\> logs/\$SUMMARY_FILE \<\< EOF

\# 結果集計用変数

TOTAL_VULNERABILITIES=0

HIGH_RISK_VULNS=0

MEDIUM_RISK_VULNS=0

LOW_RISK_VULNS=0

INFO_VULNS=0

declare -A OWASP_TOP10_COUNTS

OWASP_TOP10_COUNTS\[A01\]=0 \# Broken Access Control

OWASP_TOP10_COUNTS\[A02\]=0 \# Cryptographic Failures

OWASP_TOP10_COUNTS\[A03\]=0 \# Injection

OWASP_TOP10_COUNTS\[A04\]=0 \# Insecure Design

OWASP_TOP10_COUNTS\[A05\]=0 \# Security Misconfiguration

OWASP_TOP10_COUNTS\[A06\]=0 \# Vulnerable Components

OWASP_TOP10_COUNTS\[A07\]=0 \# Authentication Failures

OWASP_TOP10_COUNTS\[A08\]=0 \# Software Integrity Failures

OWASP_TOP10_COUNTS\[A09\]=0 \# Logging Monitoring Failures

OWASP_TOP10_COUNTS\[A10\]=0 \# Server-Side Request Forgery

\# 各ターゲットに対してZAPスキャン実行

jq -c '.\[\]' app-targets.json \| while read -r target; do

TARGET_URL=\$(echo "\$target" \| jq -r '.url')

TARGET_TYPE=\$(echo "\$target" \| jq -r '.type')

echo "\[BUILD\] Scanning \$TARGET_URL (\$TARGET_TYPE)" \| tee -a
logs/\$LOG_FILE

\# URLから安全なファイル名を生成

TARGET_SAFE_NAME=\$(echo "\$TARGET_URL" \| sed 's\|https\\://\|\|g' \|
sed 's\|\[^a-zA-Z0-9\]\|\_\|g')

\# ZAP基本スキャン（スパイダー + パッシブスキャン + アクティブスキャン）

if \[ "\$ZAP_SCAN_TYPE" = "FULL" \]; then

echo "\[BUILD\] Running full ZAP scan on \$TARGET_URL" \| tee -a
logs/\$LOG_FILE

\# フルスキャン（時間制限付き）

timeout 45m docker run --rm \\

-v \$(pwd)/logs:/zap/wrk/:rw \\

-v \$(pwd)/zap-config:/zap/config/:ro \\

owasp/zap2docker-stable:latest \\

zap-full-scan.py \\

-t "\$TARGET_URL" \\

-g gen.conf \\

-J "zap-\${TARGET_SAFE_NAME}.json" \\

-H "zap-\${TARGET_SAFE_NAME}.html" \\

-X "zap-\${TARGET_SAFE_NAME}.xml" \\

-r "zap-\${TARGET_SAFE_NAME}-report.html" \\

-x "zap-\${TARGET_SAFE_NAME}-xml-report.xml" \\

-m 30 \\

-T 45 \\

-z "-config scanner.attackOnStart=true -config scanner.delayInMs=200" \\

\>\> logs/\$LOG_FILE 2\>&1

ZAP_EXIT_CODE=\$?

echo "\[BUILD\] ZAP full scan completed with exit code \$ZAP_EXIT_CODE
for \$TARGET_URL" \| tee -a logs/\$LOG_FILE

else

echo "\[BUILD\] Running baseline ZAP scan on \$TARGET_URL" \| tee -a
logs/\$LOG_FILE

\# ベースラインスキャン（軽量・高速）

timeout 20m docker run --rm \\

-v \$(pwd)/logs:/zap/wrk/:rw \\

owasp/zap2docker-stable:latest \\

zap-baseline.py \\

-t "\$TARGET_URL" \\

-J "zap-\${TARGET_SAFE_NAME}.json" \\

-H "zap-\${TARGET_SAFE_NAME}.html" \\

-x "zap-\${TARGET_SAFE_NAME}-xml-report.xml" \\

-T 20 \\

\>\> logs/\$LOG_FILE 2\>&1

ZAP_EXIT_CODE=\$?

echo "\[BUILD\] ZAP baseline scan completed with exit code
\$ZAP_EXIT_CODE for \$TARGET_URL" \| tee -a logs/\$LOG_FILE

fi

\# ZAP結果の解析

if \[ -f "logs/zap-\${TARGET_SAFE_NAME}.json" \]; then

echo "\[BUILD\] Analyzing ZAP results for \$TARGET_URL" \| tee -a
logs/\$LOG_FILE

\# 脆弱性カウント

HIGH_COUNT=\$(jq '\[.site\[\].alerts\[\] \| select(.riskdesc \|
startswith("High"))\] \| length' "logs/zap-\${TARGET_SAFE_NAME}.json"
2\>/dev/null \|\| echo "0")

MEDIUM_COUNT=\$(jq '\[.site\[\].alerts\[\] \| select(.riskdesc \|
startswith("Medium"))\] \| length' "logs/zap-\${TARGET_SAFE_NAME}.json"
2\>/dev/null \|\| echo "0")

LOW_COUNT=\$(jq '\[.site\[\].alerts\[\] \| select(.riskdesc \|
startswith("Low"))\] \| length' "logs/zap-\${TARGET_SAFE_NAME}.json"
2\>/dev/null \|\| echo "0")

INFO_COUNT=\$(jq '\[.site\[\].alerts\[\] \| select(.riskdesc \|
startswith("Informational"))\] \| length'
"logs/zap-\${TARGET_SAFE_NAME}.json" 2\>/dev/null \|\| echo "0")

HIGH_RISK_VULNS=\$((HIGH_RISK_VULNS + HIGH_COUNT))

MEDIUM_RISK_VULNS=\$((MEDIUM_RISK_VULNS + MEDIUM_COUNT))

LOW_RISK_VULNS=\$((LOW_RISK_VULNS + LOW_COUNT))

INFO_VULNS=\$((INFO_VULNS + INFO_COUNT))

TOTAL_VULNERABILITIES=\$((TOTAL_VULNERABILITIES + HIGH_COUNT +
MEDIUM_COUNT + LOW_COUNT + INFO_COUNT))

echo "\[BUILD\] \$TARGET_URL vulnerabilities - High:\$HIGH_COUNT
Medium:\$MEDIUM_COUNT Low:\$LOW_COUNT Info:\$INFO_COUNT" \| tee -a
logs/\$LOG_FILE

\# OWASP Top 10 分類

if \[ "\$OWASP_TOP10_FOCUS" = "true" \]; then

\# 各OWASP Top 10カテゴリの検出

jq -r '.site\[\].alerts\[\].name' "logs/zap-\${TARGET_SAFE_NAME}.json"
2\>/dev/null \| while read alert_name; do

case "\$alert_name" in

\*"Access Control"\*\|\*"Authorization"\*\|\*"Privilege"\*)

OWASP_TOP10_COUNTS\[A01\]=\$((\${OWASP_TOP10_COUNTS\[A01\]} + 1))

;;

\*"Crypto"\*\|\*"Encryption"\*\|\*"Hash"\*\|\*"SSL"\*\|\*"TLS"\*)

OWASP_TOP10_COUNTS\[A02\]=\$((\${OWASP_TOP10_COUNTS\[A02\]} + 1))

;;

\*"Injection"\*\|\*"SQL"\*\|\*"XSS"\*\|\*"Script"\*\|\*"Command"\*)

OWASP_TOP10_COUNTS\[A03\]=\$((\${OWASP_TOP10_COUNTS\[A03\]} + 1))

;;

\*"Configuration"\*\|\*"Default"\*\|\*"Misconfiguration"\*)

OWASP_TOP10_COUNTS\[A05\]=\$((\${OWASP_TOP10_COUNTS\[A05\]} + 1))

;;

\*"Component"\*\|\*"Library"\*\|\*"Dependency"\*\|\*"Version"\*)

OWASP_TOP10_COUNTS\[A06\]=\$((\${OWASP_TOP10_COUNTS\[A06\]} + 1))

;;

\*"Authentication"\*\|\*"Session"\*\|\*"Login"\*)

OWASP_TOP10_COUNTS\[A07\]=\$((\${OWASP_TOP10_COUNTS\[A07\]} + 1))

;;

\*"Integrity"\*\|\*"Tamper"\*\|\*"Signature"\*)

OWASP_TOP10_COUNTS\[A08\]=\$((\${OWASP_TOP10_COUNTS\[A08\]} + 1))

;;

\*"Log"\*\|\*"Monitor"\*\|\*"Audit"\*)

OWASP_TOP10_COUNTS\[A09\]=\$((\${OWASP_TOP10_COUNTS\[A09\]} + 1))

;;

\*"SSRF"\*\|\*"Request Forgery"\*)

OWASP_TOP10_COUNTS\[A10\]=\$((\${OWASP_TOP10_COUNTS\[A10\]} + 1))

;;

esac

done

fi

else

echo "\[BUILD\] ZAP results file not found for \$TARGET_URL" \| tee -a
logs/\$LOG_FILE

fi

done

SCAN_END_TIME=\$(date +%s)

SCAN_DURATION=\$((SCAN_END_TIME - SCAN_START_TIME))

echo "\[BUILD\] Application Security Scan Summary:" \| tee -a
logs/\$LOG_FILE

echo " - Total Vulnerabilities: \$TOTAL_VULNERABILITIES" \| tee -a
logs/\$LOG_FILE

echo " - High Risk: \$HIGH_RISK_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Medium Risk: \$MEDIUM_RISK_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Low Risk: \$LOW_RISK_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Informational: \$INFO_VULNS" \| tee -a logs/\$LOG_FILE

echo " - Scan Duration: \${SCAN_DURATION}s" \| tee -a logs/\$LOG_FILE

\# リスクレベル判定

if \[ \$HIGH_RISK_VULNS -gt 5 \]; then

RISK_LEVEL="CRITICAL"

export BUILD_ERROR="CRITICAL_APP_VULNERABILITIES"

export BUILD_EXIT_CODE=1

elif \[ \$HIGH_RISK_VULNS -gt 0 \] \|\| \[ \$MEDIUM_RISK_VULNS -gt 10
\]; then

RISK_LEVEL="HIGH"

export BUILD_ERROR="HIGH_RISK_APP_VULNERABILITIES"

export BUILD_EXIT_CODE=1

elif \[ \$MEDIUM_RISK_VULNS -gt 0 \] \|\| \[ \$LOW_RISK_VULNS -gt 20 \];
then

RISK_LEVEL="MEDIUM"

else

RISK_LEVEL="LOW"

fi

echo " - Risk Level: \$RISK_LEVEL" \| tee -a logs/\$LOG_FILE

\# サマリーJSON作成

cat \> logs/\$SUMMARY_FILE \<\< EOF

{ "pipeline_execution_id": "\$PIPELINE_EXECUTION_ID", "timestamp":
"\$(date -u +%Y-%m-%dT%H:%M:%SZ)", "targets_scanned": \$TARGET_COUNT,
"scan_duration_seconds": \$SCAN_DURATION, "vulnerabilities_found":
\$TOTAL_VULNERABILITIES, "severity_breakdown": { "high":
\$HIGH_RISK_VULNS, "medium": \$MEDIUM_RISK_VULNS, "low":
\$LOW_RISK_VULNS, "informational": \$INFO_VULNS },
"owasp_top10_findings": { "A01_broken_access_control":
\${OWASP_TOP10_COUNTS\[A01\]}, "A02_cryptographic_failures":
\${OWASP_TOP10_COUNTS\[A02\]}, "A03_injection":
\${OWASP_TOP10_COUNTS\[A03\]}, "A04_insecure_design":
\${OWASP_TOP10_COUNTS\[A04\]}, "A05_security_misconfiguration":
\${OWASP_TOP10_COUNTS\[A05\]}, "A06_vulnerable_components":
\${OWASP_TOP10_COUNTS\[A06\]}, "A07_authentication_failures":
\${OWASP_TOP10_COUNTS\[A07\]}, "A08_software_integrity_failures":
\${OWASP_TOP10_COUNTS\[A08\]}, "A09_logging_monitoring_failures":
\${OWASP_TOP10_COUNTS\[A09\]}, "A10_ssrf": \${OWASP_TOP10_COUNTS\[A10\]}
}, "scan_type": "\$ZAP_SCAN_TYPE", "risk_level": "\$RISK_LEVEL" } EOF fi

post_build: commands: - echo "\[POST_BUILD\] Processing application
security scan results..." \| tee -a logs/\$LOG_FILE - \| \#
CloudWatchメトリクス送信 if \[ -f logs/\$SUMMARY_FILE \]; then
TARGETS_SCANNED=(jq′.targetsscanned′logs/(jq '.targets_scanned' logs/
(jq′.targetss​canned′logs/SUMMARY_FILE)
VULNERABILITIES_FOUND=(jq′.vulnerabilitiesfound′logs/(jq
'.vulnerabilities_found' logs/
(jq′.vulnerabilitiesf​ound′logs/SUMMARY_FILE)
HIGH_SEVERITY=(jq′.severitybreakdown.high′logs/(jq
'.severity_breakdown.high' logs/
(jq′.severityb​reakdown.high′logs/SUMMARY_FILE)
MEDIUM_SEVERITY=(jq′.severitybreakdown.medium′logs/(jq
'.severity_breakdown.medium' logs/
(jq′.severityb​reakdown.medium′logs/SUMMARY_FILE)
OWASP_A03_INJECTION=(jq′.owasptop10findings.A03injection′logs/(jq
'.owasp_top10_findings.A03_injection' logs/
(jq′.owaspt​op10f​indings.A03i​njection′logs/SUMMARY_FILE)

aws cloudwatch put-metric-data \\

--namespace "TechNova/ApplicationSecurity" \\

--metric-data \\

MetricName=AppTargetsScanned,Value=\$TARGETS_SCANNED,Unit=Count \\

MetricName=AppVulnerabilitiesFound,Value=\$VULNERABILITIES_FOUND,Unit=Count
\\

MetricName=AppHighSeverityVulns,Value=\$HIGH_SEVERITY,Unit=Count \\

MetricName=AppMediumSeverityVulns,Value=\$MEDIUM_SEVERITY,Unit=Count \\

MetricName=InjectionVulnerabilities,Value=\$OWASP_A03_INJECTION,Unit=Count
\\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

fi

\# 重要な脆弱性発見時のSNS通知

if \[ "\$RISK_LEVEL" = "CRITICAL" \] \|\| \[ ! -z "\$BUILD_ERROR" \] &&
\[\[ "\$BUILD_ERROR" == \*"CRITICAL"\* \]\]; then

aws sns publish \\

--topic-arn \$CRITICAL_SECURITY_ALERTS_TOPIC \\

--subject "CRITICAL: High-Risk Application Vulnerabilities Detected" \\

--message "Pipeline: \$PIPELINE_EXECUTION_ID\nRisk Level:
\$RISK_LEVEL\nHigh Risk Vulnerabilities: \$HIGH_RISK_VULNS\nMEDIUM Risk
Vulnerabilities: \$MEDIUM_RISK_VULNS\nTotal Vulnerabilities:
\$TOTAL_VULNERABILITIES\nImmediate remediation required." \\

--region \$AWS_DEFAULT_REGION \|\| echo "SNS notification failed"

fi

\# 結果ファイルをS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

if \[ -f logs/\$SUMMARY_FILE \]; then

aws s3 cp logs/\$SUMMARY_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$SUMMARY_FILE \|\| echo "Summary
upload failed"

fi

\# ZAP結果ファイルのアップロード

for zap_file in logs/zap-\*.json logs/zap-\*.html logs/zap-\*.xml; do

if \[ -f "\$zap_file" \]; then

aws s3 cp "\$zap_file" s3://\$S3_LOG_BUCKET/\$S3_PREFIX/ \|\| echo
"\$(basename \$zap_file) upload failed"

fi

done

\# ターゲット情報もアップロード

if \[ -f app-targets.json \]; then

aws s3 cp app-targets.json
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/app-targets.json \|\| echo "App targets
upload failed"

fi

\# 統合レポート生成

if \[ -f logs/\$SUMMARY_FILE \]; then

cat \> logs/application-security-report.html \<\< EOF

\<!DOCTYPE html\> \<html\> \<head\> \<title\>Application Security Scan
Report - Pipeline \$PIPELINE_EXECUTION_ID\</title\> \<style\> body {
font-family: Arial, sans-serif; margin: 40px; } .header { background:
\#f0f0f0; padding: 20px; border-radius: 5px; } .section { margin: 20px
0; padding: 15px; border-left: 4px solid \#007cba; } .critical {
border-left-color: \#d32f2f; background: \#ffebee; } .high {
border-left-color: \#f57c00; background: \#fff3e0; } .medium {
border-left-color: \#fbc02d; background: \#fffde7; } .low {
border-left-color: \#388e3c; background: \#e8f5e8; } .metric { display:
inline-block; margin: 10px; padding: 10px; background: \#f5f5f5;
border-radius: 3px; } .owasp-grid { display: grid;
grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 10px;
margin: 20px 0; } .owasp-item { padding: 15px; background: \#f9f9f9;
border-radius: 5px; border-left: 4px solid \#007cba; } .owasp-count {
font-size: 24px; font-weight: bold; color: \#d32f2f; } \</style\>
\</head\> \<body\> \<div class="header"\> \<h1\>Application Security
Scan Report\</h1\> \<p\>Pipeline Execution:
\$PIPELINE_EXECUTION_ID\</p\> \<p\>Scan Date: \$(date)\</p\> \<p\>Risk
Level: \<strong\>\$RISK_LEVEL\</strong\>\</p\> \<p\>Tool: OWASP ZAP
(\$ZAP_SCAN_TYPE scan)\</p\> \</div\>

\<div class="section \${RISK_LEVEL,,}"\>

\<h2\>Scan Summary\</h2\>

\<div class="metric"\>Targets Scanned:
\<strong\>\$TARGETS_SCANNED\</strong\>\</div\>

\<div class="metric"\>Total Vulnerabilities:
\<strong\>\$TOTAL_VULNERABILITIES\</strong\>\</div\>

\<div class="metric"\>High Risk:
\<strong\>\$HIGH_RISK_VULNS\</strong\>\</div\>

\<div class="metric"\>Medium Risk:
\<strong\>\$MEDIUM_RISK_VULNS\</strong\>\</div\>

\<div class="metric"\>Low Risk:
\<strong\>\$LOW_RISK_VULNS\</strong\>\</div\>

\<div class="metric"\>Informational:
\<strong\>\$INFO_VULNS\</strong\>\</div\>

\<div class="metric"\>Scan Duration:
\<strong\>\${SCAN_DURATION}s\</strong\>\</div\>

\</div\>

\<div class="section"\>

\<h2\>OWASP Top 10 Findings\</h2\>

\<div class="owasp-grid"\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A01\]}\</div\>

\<div\>A01: Broken Access Control\</div\>

\</div\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A02\]}\</div\>

\<div\>A02: Cryptographic Failures\</div\>

\</div\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A03\]}\</div\>

\<div\>A03: Injection\</div\>

\</div\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A05\]}\</div\>

\<div\>A05: Security Misconfiguration\</div\>

\</div\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A06\]}\</div\>

\<div\>A06: Vulnerable Components\</div\>

\</div\>

\<div class="owasp-item"\>

\<div class="owasp-count"\>\${OWASP_TOP10_COUNTS\[A07\]}\</div\>

\<div\>A07: Authentication Failures\</div\>

\</div\>

\</div\>

\</div\>

\<div class="section"\>

\<h2\>Detailed Reports\</h2\>

\<p\>Complete ZAP scan results are available in the pipeline
artifacts:\</p\>

\<ul\>

\<li\>JSON Reports: zap-\*.json\</li\>

\<li\>HTML Reports: zap-\*.html\</li\>

\<li\>XML Reports: zap-\*.xml\</li\>

\<li\>Full Log: \$LOG_FILE\</li\>

\</ul\>

\</div\>

\</body\> \</html\> EOF

aws s3 cp logs/application-security-report.html
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/application-security-report.html \|\|
echo "HTML report upload failed"

fi

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to critical application
vulnerabilities" \| tee -a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite application
vulnerabilities" \| tee -a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts: files: - logs/\* - app-targets.json name:
application-security-scan-results

\### 4.5 ペネトレーションテスト

\`\`\`hcl

resource "aws_codebuild_project" "penetration_test" {

name = "automated-penetration-testing"

description = "Automated penetration testing using multiple frameworks"

service_role = aws_iam_role.codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:latest"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

privileged_mode = true

environment_variable {

name = "PENTEST_SCOPE"

value = "EXTERNAL_ONLY"

}

environment_variable {

name = "PENTEST_INTENSITY"

value = "MODERATE"

}

environment_variable {

name = "MAX_PENTEST_DURATION"

value = "2700" \# 45分

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/penetration_test.yml"

}

timeout_in_minutes = 60

tags = {

Stage = "DynamicAnalysis"

Tool = "PenetrationTest"

Scope = "Automated"

}

}

**4.6 penetration_test.yml（自動ペネトレーションテスト）**

yaml

version: 0.2

env:

variables:

LOG_FILE: "penetration-test-\$PIPELINE_EXECUTION_ID.log"

S3_PREFIX: "logs/\$PIPELINE_EXECUTION_ID"

PENTEST_RESULTS: "pentest-results.json"

METASPLOIT_RESULTS: "metasploit-results.json"

SUMMARY_FILE: "pentest-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Setting up penetration testing environment..." \|
tee logs/\$LOG_FILE

\- mkdir -p logs

\- \|

\# システム更新とツールインストール

yum update -y

yum install -y docker jq bc git python3-pip

*\# Docker起動*

service docker start

usermod -a -G docker codebuild

*\# Kali Linux Dockerイメージの取得（ペネトレーションテスト用）*

docker pull kalilinux/kali-rolling:latest

*\# セキュリティテスト用Pythonライブラリ*

pip3 install requests beautifulsoup4 paramiko

*\# カスタムペネトレーションテスト設定*

aws s3 cp s3://\$SECURITY_CONFIGS_BUCKET/pentest-config/ pentest-config/
--recursive \|\| mkdir -p pentest-config

*\# 許可されたターゲット設定の確認*

cat \> pentest-config/allowed-targets.json \<\< 'EOF'

{

"allowed_networks": \[

"10.0.0.0/8",

"172.16.0.0/12",

"192.168.0.0/16"

\],

"allowed_domains": \[

"\*.technova-staging.com",

"\*.technova-dev.com"

\],

"prohibited_targets": \[

"production",

"prod",

"live"

\]

}

EOF

pre_build:

commands:

\- echo "\[PRE_BUILD\] Preparing penetration test targets and scope..."
\| tee -a logs/\$LOG_FILE

\- \|

\# ペネトレーションテスト用の安全なターゲット検出

echo '\[\]' \> pentest-targets.json

*\# ステージング環境のリソースのみを対象とする*

if \[ "\$TARGET_ENVIRONMENT" = "staging" \] \|\| \[
"\$TARGET_ENVIRONMENT" = "development" \]; then

echo "\[PRE_BUILD\] Scanning for \$TARGET_ENVIRONMENT environment
targets" \| tee -a logs/\$LOG_FILE

*\# ステージング環境のALB/ELB*

aws elbv2 describe-load-balancers \\

--query
'LoadBalancers\[?State.Code==\`active\`\].\[DNSName,LoadBalancerName\]'
\\

--output text \| while read dns_name lb_name; do

*\# ステージング環境の識別*

if echo "\$lb_name" \| grep -E "(staging\|dev\|test)" \>/dev/null 2\>&1;
then

echo "Found staging load balancer: \$dns_name (\$lb_name)" \| tee -a
logs/\$LOG_FILE

jq --arg url "\$dns_name" --arg name "\$lb_name" '. += \[{"target":
\$url, "type": "load_balancer", "name": \$name, "environment":
"staging"}\]' pentest-targets.json \> pentest-targets-temp.json

mv pentest-targets-temp.json pentest-targets.json

fi

done

*\# ステージング環境のEC2インスタンス（タグベース）*

aws ec2 describe-instances \\

--filters "Name=instance-state-name,Values=running"
"Name=tag:Environment,Values=\$TARGET_ENVIRONMENT" \\

--query
'Reservations\[\].Instances\[?PublicIpAddress\].\[PublicIpAddress,Tags\[?Key==\`Name\`\].Value\|\[0\],InstanceId\]'
\\

--output text \| while read ip name instance_id; do

if \[ ! -z "\$ip" \] && \[ "\$ip" != "None" \]; then

echo "Found staging EC2 instance: \$ip (\$name)" \| tee -a
logs/\$LOG_FILE

jq --arg ip "\$ip" --arg name "\$name" --arg id "\$instance_id" '. +=
\[{"target": \$ip, "type": "ec2_instance", "name": \$name,
"instance_id": \$id, "environment": "staging"}\]' pentest-targets.json

再試行

C

続ける

編集

jq --arg ip "ip"−−argname"ip" --arg name " ip"−−argname"name" --arg id
"\$instance_id" '. += \[{"target": \$ip, "type": "ec2_instance", "name":
\$name, "instance_id": \$id, "environment": "staging"}\]'
pentest-targets.json \> pentest-targets-temp.json mv
pentest-targets-temp.json pentest-targets.json fi done

else

echo "\[PRE_BUILD\] Production environment detected - penetration
testing disabled for safety" \| tee -a logs/\$LOG_FILE

echo '{"error": "Production environment penetration testing
prohibited"}' \> logs/\$SUMMARY_FILE

fi

\# ターゲット数と安全性確認

TARGET_COUNT=\$(jq length pentest-targets.json)

echo "\[PRE_BUILD\] Found \$TARGET_COUNT penetration test targets" \|
tee -a logs/\$LOG_FILE

\# 安全性チェック

if \[ \$TARGET_COUNT -eq 0 \]; then

echo "\[PRE_BUILD\] No safe targets identified for penetration testing"
\| tee -a logs/\$LOG_FILE

else

echo "\[PRE_BUILD\] Verifying target safety..." \| tee -a
logs/\$LOG_FILE

\# 本番環境の誤検出防止

jq -c '.\[\]' pentest-targets.json \| while read -r target; do

TARGET_NAME=\$(echo "\$target" \| jq -r '.name // .target')

if echo "\$TARGET_NAME" \| grep -E "(prod\|production\|live)"
\>/dev/null 2\>&1; then

echo "\[ERROR\] Production target detected in penetration test scope:
\$TARGET_NAME" \| tee -a logs/\$LOG_FILE

export PENTEST_SAFETY_ERROR="PRODUCTION_TARGET_DETECTED"

fi

done

fi

build: commands: - echo "\[BUILD\] Starting automated penetration
testing..." \| tee -a logs/\$LOG_FILE - \| PENTEST_START_TIME=\$(date
+%s) MAX_DURATION=\${MAX_PENTEST_DURATION:-2700}

\# 安全性エラーがある場合は中止

if \[ ! -z "\$PENTEST_SAFETY_ERROR" \]; then

echo "\[BUILD\] Penetration testing aborted due to safety concerns" \|
tee -a logs/\$LOG_FILE

cat \> logs/\$SUMMARY_FILE \<\< EOF

{ "pipeline_execution_id": "\$PIPELINE_EXECUTION_ID", "timestamp":
"\$(date -u +%Y-%m-%dT%H:%M:%SZ)", "status": "ABORTED", "reason":
"\$PENTEST_SAFETY_ERROR", "targets_tested": 0,
"vulnerabilities_exploited": 0, "risk_level": "NONE" } EOF exit 0 fi

TARGET_COUNT=\$(jq length pentest-targets.json)

if \[ \$TARGET_COUNT -eq 0 \]; then

echo "\[BUILD\] No targets available for penetration testing" \| tee -a
logs/\$LOG_FILE

cat \> logs/\$SUMMARY_FILE \<\< EOF

{ "pipeline_execution_id": "\$PIPELINE_EXECUTION_ID", "timestamp":
"\$(date -u +%Y-%m-%dT%H:%M:%SZ)", "status": "COMPLETED",
"targets_tested": 0, "vulnerabilities_exploited": 0,
"attack_vectors_tested": 0, "pentest_duration_seconds": 0, "risk_level":
"NONE" } EOF else echo "\[BUILD\] Starting penetration tests on
TARGETCOUNTtargets"∣tee−alogs/TARGET_COUNT targets" \| tee -a logs/
TARGETC​OUNTtargets"∣tee−alogs/LOG_FILE

\# 結果集計用変数

TOTAL_EXPLOITS_ATTEMPTED=0

SUCCESSFUL_EXPLOITS=0

FAILED_EXPLOITS=0

CRITICAL_FINDINGS=0

HIGH_FINDINGS=0

MEDIUM_FINDINGS=0

\# ペネトレーションテスト結果配列

echo '{"pentest_results": \[\], "summary": {}}' \>
logs/\$PENTEST_RESULTS

\# 各ターゲットに対するペネトレーションテスト

jq -c '.\[\]' pentest-targets.json \| while read -r target; do

CURRENT_TIME=\$(date +%s)

ELAPSED_TIME=\$((CURRENT_TIME - PENTEST_START_TIME))

if \[ \$ELAPSED_TIME -gt \$MAX_DURATION \]; then

echo "\[BUILD\] Maximum penetration test duration reached" \| tee -a
logs/\$LOG_FILE

break

fi

TARGET_IP=\$(echo "\$target" \| jq -r '.target')

TARGET_TYPE=\$(echo "\$target" \| jq -r '.type')

TARGET_NAME=\$(echo "\$target" \| jq -r '.name // .target')

echo "\[BUILD\] Penetration testing \$TARGET_IP (\$TARGET_NAME)" \| tee
-a logs/\$LOG_FILE

\# 基本的なポートスキャンと脆弱性検証

echo "\[BUILD\] Phase 1: Reconnaissance and enumeration" \| tee -a
logs/\$LOG_FILE

\# Nmapによる詳細ポートスキャン

nmap -sS -sV -A --script=vuln,exploit,auth \\

-oX logs/pentest-nmap-\${TARGET_IP//\[^0-9\]/\_}.xml \\

--max-retries 1 --host-timeout 5m \\

\$TARGET_IP \>\> logs/\$LOG_FILE 2\>&1 &

NMAP_PID=\$!

\# 基本的なHTTP/HTTPS脆弱性テスト

echo "\[BUILD\] Phase 2: Web application testing" \| tee -a
logs/\$LOG_FILE

\# HTTPサービス検出とテスト

for port in 80 443 8080 8443; do

if nc -z -w3 \$TARGET_IP \$port 2\>/dev/null; then

protocol="http"

\[ \$port -eq 443 \] \|\| \[ \$port -eq 8443 \] && protocol="https"

target_url="\${protocol}://\${TARGET_IP}:\${port}"

echo "\[BUILD\] Testing web service: \$target_url" \| tee -a
logs/\$LOG_FILE

\# 基本的なWebアプリケーション脆弱性テスト

timeout 300 docker run --rm \\

-v \$(pwd)/logs:/tmp/results \\

kalilinux/kali-rolling:latest \\

bash -c "

apt-get update -qq && apt-get install -y -qq curl nikto dirb
2\>/dev/null

echo 'Testing \$target_url' \>
/tmp/results/pentest-web-\${TARGET_IP//\[^0-9\]/\_}-\${port}.log

\# Basic HTTP enumeration

curl -k -s -I '\$target_url' \>\>
/tmp/results/pentest-web-\${TARGET_IP//\[^0-9\]/\_}-\${port}.log 2\>&1

\# Directory enumeration (limited)

timeout 180 dirb '\$target_url' -w -S -r \>\>
/tmp/results/pentest-web-\${TARGET_IP//\[^0-9\]/\_}-\${port}.log 2\>&1

\# Nikto scan (basic)

timeout 180 nikto -h '\$target_url' -Format txt \>\>
/tmp/results/pentest-web-\${TARGET_IP//\[^0-9\]/\_}-\${port}.log 2\>&1

" \>\> logs/\$LOG_FILE 2\>&1 &

WEB_TEST_PID=\$!

echo "Web test PID: \$WEB_TEST_PID for \$target_url" \| tee -a
logs/\$LOG_FILE

fi

done

\# SSH接続テスト（認証脆弱性）

echo "\[BUILD\] Phase 3: SSH security testing" \| tee -a logs/\$LOG_FILE

if nc -z -w3 \$TARGET_IP 22 2\>/dev/null; then

echo "\[BUILD\] SSH service detected on \$TARGET_IP" \| tee -a
logs/\$LOG_FILE

\# SSH設定の脆弱性チェック

timeout 60 docker run --rm \\

kalilinux/kali-rolling:latest \\

bash -c "

apt-get update -qq && apt-get install -y -qq ssh-audit 2\>/dev/null

ssh-audit \$TARGET_IP 2\>&1

" \> logs/pentest-ssh-\${TARGET_IP//\[^0-9\]/\_}.log 2\>&1 &

SSH_TEST_PID=\$!

fi

wait \$NMAP_PID 2\>/dev/null

wait \$WEB_TEST_PID 2\>/dev/null

wait \$SSH_TEST_PID 2\>/dev/null

\# 結果の分析

echo "\[BUILD\] Analyzing penetration test results for \$TARGET_IP" \|
tee -a logs/\$LOG_FILE

\# Nmapの脆弱性結果解析

if \[ -f "logs/pentest-nmap-\${TARGET_IP//\[^0-9\]/\_}.xml" \]; then

NMAP_VULNS=\$(grep -c "VULNERABLE\\EXPLOIT"
"logs/pentest-nmap-\${TARGET_IP//\[^0-9\]/\_}.xml" 2\>/dev/null \|\|
echo "0")

TOTAL_EXPLOITS_ATTEMPTED=\$((TOTAL_EXPLOITS_ATTEMPTED + NMAP_VULNS))

if \[ \$NMAP_VULNS -gt 0 \]; then

SUCCESSFUL_EXPLOITS=\$((SUCCESSFUL_EXPLOITS + NMAP_VULNS))

HIGH_FINDINGS=\$((HIGH_FINDINGS + NMAP_VULNS))

echo "\[BUILD\] Found \$NMAP_VULNS exploitable vulnerabilities via Nmap"
\| tee -a logs/\$LOG_FILE

fi

fi

\# Webアプリケーション脆弱性結果解析

for web_log in logs/pentest-web-\${TARGET_IP//\[^0-9\]/\_}-\*.log; do

if \[ -f "\$web_log" \]; then

WEB_VULNS=\$(grep -c -E "(OSVDB\|CVE-\|High\|Critical)" "\$web_log"
2\>/dev/null \|\| echo "0")

if \[ \$WEB_VULNS -gt 0 \]; then

MEDIUM_FINDINGS=\$((MEDIUM_FINDINGS + WEB_VULNS))

echo "\[BUILD\] Found \$WEB_VULNS web vulnerabilities on \$TARGET_IP" \|
tee -a logs/\$LOG_FILE

fi

fi

done

\# SSH脆弱性結果解析

if \[ -f "logs/pentest-ssh-\${TARGET_IP//\[^0-9\]/\_}.log" \]; then

SSH_ISSUES=\$(grep -c -E "(FAIL\|WARN)"
"logs/pentest-ssh-\${TARGET_IP//\[^0-9\]/\_}.log" 2\>/dev/null \|\| echo
"0")

if \[ \$SSH_ISSUES -gt 0 \]; then

MEDIUM_FINDINGS=\$((MEDIUM_FINDINGS + SSH_ISSUES))

echo "\[BUILD\] Found \$SSH_ISSUES SSH security issues on \$TARGET_IP"
\| tee -a logs/\$LOG_FILE

fi

fi

done

PENTEST_END_TIME=\$(date +%s)

PENTEST_DURATION=\$((PENTEST_END_TIME - PENTEST_START_TIME))

echo "\[BUILD\] Penetration Test Summary:" \| tee -a logs/\$LOG_FILE

echo " - Targets Tested: \$TARGET_COUNT" \| tee -a logs/\$LOG_FILE

echo " - Exploits Attempted: \$TOTAL_EXPLOITS_ATTEMPTED" \| tee -a
logs/\$LOG_FILE

echo " - Successful Exploits: \$SUCCESSFUL_EXPLOITS" \| tee -a
logs/\$LOG_FILE

echo " - Critical Findings: \$CRITICAL_FINDINGS" \| tee -a
logs/\$LOG_FILE

echo " - High Findings: \$HIGH_FINDINGS" \| tee -a logs/\$LOG_FILE

echo " - Medium Findings: \$MEDIUM_FINDINGS" \| tee -a logs/\$LOG_FILE

echo " - Test Duration: \${PENTEST_DURATION}s" \| tee -a logs/\$LOG_FILE

\# リスク判定

TOTAL_FINDINGS=\$((CRITICAL_FINDINGS + HIGH_FINDINGS + MEDIUM_FINDINGS))

if \[ \$CRITICAL_FINDINGS -gt 0 \] \|\| \[ \$SUCCESSFUL_EXPLOITS -gt 3
\]; then

RISK_LEVEL="CRITICAL"

export BUILD_ERROR="CRITICAL_PENTEST_FINDINGS"

export BUILD_EXIT_CODE=1

elif \[ \$HIGH_FINDINGS -gt 0 \] \|\| \[ \$SUCCESSFUL_EXPLOITS -gt 0 \];
then

RISK_LEVEL="HIGH"

export BUILD_ERROR="HIGH_RISK_PENTEST_FINDINGS"

export BUILD_EXIT_CODE=1

elif \[ \$MEDIUM_FINDINGS -gt 5 \]; then

RISK_LEVEL="MEDIUM"

else

RISK_LEVEL="LOW"

fi

echo " - Risk Level: \$RISK_LEVEL" \| tee -a logs/\$LOG_FILE

\# サマリーJSON作成

cat \> logs/\$SUMMARY_FILE \<\< EOF

{ "pipeline_execution_id": "\$PIPELINE_EXECUTION_ID", "timestamp":
"\$(date -u +%Y-%m-%dT%H:%M:%SZ)", "status": "COMPLETED",
"targets_tested": \$TARGET_COUNT, "pentest_duration_seconds":
\$PENTEST_DURATION, "attack_vectors_tested": \$TOTAL_EXPLOITS_ATTEMPTED,
"vulnerabilities_exploited": \$SUCCESSFUL_EXPLOITS,
"findings_breakdown": { "critical": \$CRITICAL_FINDINGS, "high":
\$HIGH_FINDINGS, "medium": \$MEDIUM_FINDINGS, "total": \$TOTAL_FINDINGS
}, "pentest_scope": "\$PENTEST_SCOPE", "pentest_intensity":
"\$PENTEST_INTENSITY", "risk_level": "\$RISK_LEVEL" } EOF fi

post_build: commands: - echo "\[POST_BUILD\] Processing penetration test
results..." \| tee -a logs/\$LOG_FILE - \| \# CloudWatchメトリクス送信
if \[ -f logs/SUMMARY_FILE \] && \[ " (jq -r '.status'
logs/\$SUMMARY_FILE)" = "COMPLETED" \]; then
TARGETS_TESTED=(jq′.targetstested′logs/(jq '.targets_tested' logs/
(jq′.targetst​ested′logs/SUMMARY_FILE)
VULNS_EXPLOITED=(jq′.vulnerabilitiesexploited′logs/(jq
'.vulnerabilities_exploited' logs/
(jq′.vulnerabilitiese​xploited′logs/SUMMARY_FILE)
CRITICAL_FINDINGS=(jq′.findingsbreakdown.critical′logs/(jq
'.findings_breakdown.critical' logs/
(jq′.findingsb​reakdown.critical′logs/SUMMARY_FILE)
HIGH_FINDINGS=(jq′.findingsbreakdown.high′logs/(jq
'.findings_breakdown.high' logs/
(jq′.findingsb​reakdown.high′logs/SUMMARY_FILE)

aws cloudwatch put-metric-data \\

--namespace "TechNova/PenetrationTesting" \\

--metric-data \\

MetricName=PentestTargetsTested,Value=\$TARGETS_TESTED,Unit=Count \\

MetricName=VulnerabilitiesExploited,Value=\$VULNS_EXPLOITED,Unit=Count
\\

MetricName=CriticalPentestFindings,Value=\$CRITICAL_FINDINGS,Unit=Count
\\

MetricName=HighPentestFindings,Value=\$HIGH_FINDINGS,Unit=Count \\

--region \$AWS_DEFAULT_REGION \|\| echo "CloudWatch metrics failed"

fi

\# 重要な脆弱性発見時のSNS通知

if \[ "\$RISK_LEVEL" = "CRITICAL" \] \|\| \[ ! -z "\$BUILD_ERROR" \] &&
\[\[ "\$BUILD_ERROR" == \*"CRITICAL"\* \]\]; then

aws sns publish \\

--topic-arn \$CRITICAL_SECURITY_ALERTS_TOPIC \\

--subject "CRITICAL: Exploitable Vulnerabilities Found in Penetration
Test" \\

--message "Pipeline: \$PIPELINE_EXECUTION_ID\nRisk Level:
\$RISK_LEVEL\nTargets Tested: \$TARGET_COUNT\nSuccessful Exploits:
\$SUCCESSFUL_EXPLOITS\nCritical Findings: \$CRITICAL_FINDINGS\nHigh
Findings: \$HIGH_FINDINGS\nImmediate security remediation required." \\

--region \$AWS_DEFAULT_REGION \|\| echo "SNS notification failed"

fi

\# 結果ファイルをS3にアップロード

aws s3 cp logs/\$LOG_FILE s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$LOG_FILE
\|\| echo "Log upload failed"

if \[ -f logs/\$SUMMARY_FILE \]; then

aws s3 cp logs/\$SUMMARY_FILE
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/\$SUMMARY_FILE \|\| echo "Summary
upload failed"

fi

\# ペネトレーションテスト結果ファイルのアップロード

for pentest_file in logs/pentest-\*.xml logs/pentest-\*.log; do

if \[ -f "\$pentest_file" \]; then

aws s3 cp "\$pentest_file" s3://\$S3_LOG_BUCKET/\$S3_PREFIX/ \|\| echo
"\$(basename \$pentest_file) upload failed"

fi

done

\# ターゲット情報もアップロード

if \[ -f pentest-targets.json \]; then

aws s3 cp pentest-targets.json
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/pentest-targets.json \|\| echo "Pentest
targets upload failed"

fi

\# 統合レポート生成

if \[ -f logs/\$SUMMARY_FILE \]; then

cat \> logs/penetration-test-report.html \<\< EOF

\<!DOCTYPE html\> \<html\> \<head\> \<title\>Penetration Test Report -
Pipeline \$PIPELINE_EXECUTION_ID\</title\> \<style\> body { font-family:
Arial, sans-serif; margin: 40px; } .header { background: \#f0f0f0;
padding: 20px; border-radius: 5px; } .section { margin: 20px 0; padding:
15px; border-left: 4px solid \#007cba; } .critical { border-left-color:
\#d32f2f; background: \#ffebee; } .high { border-left-color: \#f57c00;
background: \#fff3e0; } .medium { border-left-color: \#fbc02d;
background: \#fffde7; } .low { border-left-color: \#388e3c; background:
\#e8f5e8; } .metric { display: inline-block; margin: 10px; padding:
10px; background: \#f5f5f5; border-radius: 3px; } .finding { margin:
10px 0; padding: 10px; background: \#fafafa; border-radius: 3px;
border-left: 3px solid \#ff9800; } .exploit-success { color: \#d32f2f;
font-weight: bold; } .warning { background: \#fff3e0; padding: 15px;
border-radius: 5px; margin: 20px 0; } \</style\> \</head\> \<body\>
\<div class="header"\> \<h1\>Penetration Test Report\</h1\>
\<p\>Pipeline Execution: \$PIPELINE_EXECUTION_ID\</p\> \<p\>Test Date:
\$(date)\</p\> \<p\>Risk Level: \<strong\>\$RISK_LEVEL\</strong\>\</p\>
\<p\>Scope: \$PENTEST_SCOPE \| Intensity: \$PENTEST_INTENSITY\</p\>
\</div\>

\<div class="warning"\>

\<strong\>Important:\</strong\> This penetration test was conducted in a
controlled environment on staging/development systems only.

Production systems are excluded from automated penetration testing for
security reasons.

\</div\>

\<div class="section \${RISK_LEVEL,,}"\>

\<h2\>Test Summary\</h2\>

\<div class="metric"\>Targets Tested:
\<strong\>\$TARGET_COUNT\</strong\>\</div\>

\<div class="metric"\>Attack Vectors:
\<strong\>\$TOTAL_EXPLOITS_ATTEMPTED\</strong\>\</div\>

\<div class="metric"\>Successful Exploits: \<strong
class="exploit-success"\>\$SUCCESSFUL_EXPLOITS\</strong\>\</div\>

\<div class="metric"\>Critical Findings:
\<strong\>\$CRITICAL_FINDINGS\</strong\>\</div\>

\<div class="metric"\>High Findings:
\<strong\>\$HIGH_FINDINGS\</strong\>\</div\>

\<div class="metric"\>Medium Findings:
\<strong\>\$MEDIUM_FINDINGS\</strong\>\</div\>

\<div class="metric"\>Test Duration:
\<strong\>\${PENTEST_DURATION}s\</strong\>\</div\>

\</div\>

\<div class="section"\>

\<h2\>Testing Methodology\</h2\>

\<ul\>

\<li\>Automated reconnaissance and enumeration\</li\>

\<li\>Port scanning and service detection\</li\>

\<li\>Web application vulnerability testing\</li\>

\<li\>SSH security configuration assessment\</li\>

\<li\>Network service exploitation attempts\</li\>

\</ul\>

\</div\>

\<div class="section"\>

\<h2\>Key Findings\</h2\>

\$(if \[ \$SUCCESSFUL_EXPLOITS -gt 0 \]; then echo "\<div class='finding
exploit-success'\>⚠️ \$SUCCESSFUL_EXPLOITS exploitable vulnerabilities
were successfully validated\</div\>"; fi)

\$(if \[ \$CRITICAL_FINDINGS -gt 0 \]; then echo "\<div
class='finding'\>🔴 \$CRITICAL_FINDINGS critical security issues require
immediate attention\</div\>"; fi)

\$(if \[ \$HIGH_FINDINGS -gt 0 \]; then echo "\<div class='finding'\>🟠
\$HIGH_FINDINGS high-severity findings need prompt remediation\</div\>";
fi)

\$(if \[ \$MEDIUM_FINDINGS -gt 0 \]; then echo "\<div
class='finding'\>🟡 \$MEDIUM_FINDINGS medium-severity issues should be
addressed\</div\>"; fi)

\</div\>

\<div class="section"\>

\<h2\>Detailed Results\</h2\>

\<p\>Complete penetration test results are available in the pipeline
artifacts:\</p\>

\<ul\>

\<li\>Nmap Vulnerability Scans: pentest-nmap-\*.xml\</li\>

\<li\>Web Application Tests: pentest-web-\*.log\</li\>

\<li\>SSH Security Audits: pentest-ssh-\*.log\</li\>

\<li\>Full Test Log: \$LOG_FILE\</li\>

\<li\>Target List: pentest-targets.json\</li\>

\</ul\>

\</div\>

\<div class="section"\>

\<h2\>Recommendations\</h2\>

\$(if \[ \$SUCCESSFUL_EXPLOITS -gt 0 \]; then echo
"\<p\>\<strong\>Priority 1:\</strong\> Address all exploitable
vulnerabilities immediately before production deployment.\</p\>"; fi)

\$(if \[ \$CRITICAL_FINDINGS -gt 0 \]; then echo
"\<p\>\<strong\>Priority 2:\</strong\> Remediate critical security
misconfigurations.\</p\>"; fi)

\$(if \[ \$HIGH_FINDINGS -gt 0 \]; then echo "\<p\>\<strong\>Priority
3:\</strong\> Fix high-severity vulnerabilities to reduce attack
surface.\</p\>"; fi)

\<p\>\<strong\>Ongoing:\</strong\> Implement regular penetration testing
in the CI/CD pipeline.\</p\>

\<p\>\<strong\>Security:\</strong\> Consider professional penetration
testing for production environments.\</p\>

\</div\>

\</body\> \</html\> EOF

aws s3 cp logs/penetration-test-report.html
s3://\$S3_LOG_BUCKET/\$S3_PREFIX/penetration-test-report.html \|\| echo
"HTML report upload failed"

fi

\# エラーハンドリング

if \[ "\$ERROR_HANDLING_MODE" = "STOP" \] && \[ ! -z "\$BUILD_ERROR" \];
then

echo "\[POST_BUILD\] Stopping pipeline due to critical penetration test
findings" \| tee -a logs/\$LOG_FILE

exit \$BUILD_EXIT_CODE

elif \[ "\$ERROR_HANDLING_MODE" = "CONTINUE" \] && \[ ! -z
"\$BUILD_ERROR" \]; then

echo "\[POST_BUILD\] Continuing pipeline despite penetration test
findings" \| tee -a logs/\$LOG_FILE

exit 0

else

exit 0

fi

artifacts: files: - logs/\* - pentest-targets.json name:
penetration-test-results

\## 5. エラーハンドリング Lambda 関数詳細実装

\### 5.1 Lambda関数のコア実装

\`\`\`hcl

resource "aws_lambda_function" "pipeline_error_handler" {

filename = "lambda/pipeline_error_handler.zip"

function_name = "pipeline-error-handler"

role = aws_iam_role.lambda_error_handler_role.arn

handler = "index.handler"

source_code_hash =
data.archive_file.pipeline_error_handler_zip.output_base64sha256

runtime = "python3.9"

timeout = 300

environment {

variables = {

SNS_TOPIC_ARN = aws_sns_topic.pipeline_errors.arn

DYNAMODB_TABLE = aws_dynamodb_table.pipeline_errors.name

S3_BUCKET = aws_s3_bucket.build_logs.id

SLACK_WEBHOOK_SECRET = aws_ssm_parameter.slack_webhook.name

}

}

tags = {

Purpose = "Pipeline Error Handling"

Component = "ErrorHandling"

}

}

data "archive_file" "pipeline_error_handler_zip" {

type = "zip"

output_path = "lambda/pipeline_error_handler.zip"

source {

content = file("\${path.module}/lambda/pipeline_error_handler.py")

filename = "index.py"

}

}

**5.2 pipeline_error_handler.py（包括的エラーハンドリング）**

python

import json

import boto3

import os

import logging

from datetime import datetime, timezone

from typing import Dict, List, Any

import traceback

*\# ログ設定*

logger = logging.getLogger()

logger.setLevel(logging.INFO)

*\# AWSクライアント初期化*

sns = boto3.client('sns')

dynamodb = boto3.resource('dynamodb')

s3 = boto3.client('s3')

ssm = boto3.client('ssm')

codepipeline = boto3.client('codepipeline')

*\# 環境変数*

SNS_TOPIC_ARN = os.environ\['SNS_TOPIC_ARN'\]

DYNAMODB_TABLE = os.environ\['DYNAMODB_TABLE'\]

S3_BUCKET = os.environ\['S3_BUCKET'\]

SLACK_WEBHOOK_SECRET = os.environ\['SLACK_WEBHOOK_SECRET'\]

class PipelineErrorHandler:

def \_\_init\_\_(self):

self.table = dynamodb.Table(DYNAMODB_TABLE)

def handler(self, event, context):

"""

パイプラインエラーハンドリングのメインハンドラー

"""

try:

logger.info(f"Error handler invoked with event: {json.dumps(event)}")

*\# イベント形式の判定（CodePipeline vs Lambda直接呼び出し）*

if 'CodePipeline.job' in event:

return self.\_handle_codepipeline_event(event, context)

else:

return self.\_handle_direct_invocation(event, context)

except Exception as e:

logger.error(f"Error handler failed: {str(e)}")

logger.error(traceback.format_exc())

return {

'statusCode': 500,

'body': json.dumps({'error': 'Error handler failed', 'details': str(e)})

}

def \_handle_codepipeline_event(self, event, context):

"""

CodePipelineからの呼び出し処理

"""

job_id = event\['CodePipeline.job'\]\['id'\]

job_data = event\['CodePipeline.job'\]\['data'\]

try:

*\# ユーザーパラメータから詳細取得*

user_params = json.loads(job_data.get('actionConfiguration',
{}).get('configuration', {}).get('UserParameters', '{}'))

error_details = {

'job_id': job_id,

'pipeline_name': user_params.get('pipeline_name', 'unknown'),

'stage_name': user_params.get('stage_name', 'unknown'),

'error_type': user_params.get('error_type', 'UNKNOWN_ERROR'),

'pipeline_execution_id': job_data.get('inputArtifacts',
\[{}\])\[0\].get('location', {}).get('s3Location', {}).get('objectKey',
'unknown'),

'timestamp': datetime.now(timezone.utc).isoformat()

}

*\# エラー処理実行*

self.\_process_error(error_details)

*\# CodePipelineにジョブ成功を通知*

codepipeline.put_job_success_result(jobId=job_id)

return {'statusCode': 200, 'body': 'Error handled successfully'}

except Exception as e:

logger.error(f"Failed to handle CodePipeline event: {str(e)}")

codepipeline.put_job_failure_result(

jobId=job_id,

failureDetails={'message': f'Error handler failed: {str(e)}', 'type':
'JobFailed'}

)

raise

def \_handle_direct_invocation(self, event, context):

"""

Lambda直接呼び出しの処理

"""

error_details = {

'pipeline_execution_id': event.get('pipeline_execution_id', 'unknown'),

'stage': event.get('stage', 'unknown'),

'error_type': event.get('error_type', 'UNKNOWN_ERROR'),

'exit_code': event.get('exit_code', -1),

'log_file': event.get('log_file', ''),

'error_handling_mode': event.get('error_handling_mode', 'STOP'),

'timestamp': datetime.now(timezone.utc).isoformat()

}

*\# エラー処理実行*

self.\_process_error(error_details)

return {

'statusCode': 200,

'body': json.dumps({'status': 'processed', 'error_details':
error_details})

}

def \_process_error(self, error_details: Dict\[str, Any\]):

"""

エラー処理のメインロジック

"""

logger.info(f"Processing error: {error_details}")

*\# 1. エラー情報をDynamoDBに記録*

self.\_store_error_record(error_details)

*\# 2. エラーの重要度分析*

severity = self.\_analyze_error_severity(error_details)

error_details\['severity'\] = severity

*\# 3. 関連ログの取得と*

log_analysis = self.\_analyze_error_logs(error_details)

error_details\['log_analysis'\] = log_analysis

\# 4. 通知の送信

self.\_send_notifications(error_details)

\# 5. 自動修復の試行（可能な場合）

if self.\_can_auto_remediate(error_details):

remediation_result = self.\_attempt_auto_remediation(error_details)

error_details\['remediation'\] = remediation_result

\# 6. エスカレーション判定

if self.\_should_escalate(error_details):

self.\_escalate_error(error_details)

logger.info(f"Error processing completed for:
{error_details\['pipeline_execution_id'\]}")

def \_store_error_record(self, error_details: Dict\[str, Any\]):

"""

エラー情報をDynamoDBに永続化

"""

try:

item = {

'pipeline_execution_id': error_details\['pipeline_execution_id'\],

'timestamp': error_details\['timestamp'\],

'stage_name': error_details.get('stage', error_details.get('stage_name',
'unknown')),

'error_type': error_details\['error_type'\],

'exit_code': error_details.get('exit_code', -1),

'pipeline_name': error_details.get('pipeline_name',
'security-integrated-deployment-pipeline'),

'error_handling_mode': error_details.get('error_handling_mode', 'STOP'),

'status': 'PROCESSING',

'created_at': datetime.now(timezone.utc).isoformat(),

'ttl': int((datetime.now(timezone.utc).timestamp() + (90 \* 24 \* 60 \*
60))) \# 90日後に期限切れ

}

self.table.put_item(Item=item)

logger.info(f"Error record stored:
{error_details\['pipeline_execution_id'\]}")

except Exception as e:

logger.error(f"Failed to store error record: {str(e)}")

\# エラー記録の失敗は処理を停止させない

def \_analyze_error_severity(self, error_details: Dict\[str, Any\]) -\>
str:

"""

エラーの重要度を分析

"""

error_type = error_details.get('error_type', '').upper()

stage = error_details.get('stage', error_details.get('stage_name',
'')).upper()

exit_code = error_details.get('exit_code', 0)

\# セキュリティ関連エラーの重要度分析

if any(keyword in error_type for keyword in \[

'CRITICAL', 'HIGH_SEVERITY', 'SECURITY_VIOLATION',

'EXTERNAL_ACCESS', 'VULNERABILITY', 'PENTEST'

\]):

return 'CRITICAL'

\# 段階別重要度

if 'CHECKOV' in stage or 'IAM_ANALYSIS' in stage or 'DYNAMIC' in stage:

if 'HIGH' in error_type or exit_code \> 10:

return 'HIGH'

elif 'MEDIUM' in error_type or exit_code \> 0:

return 'MEDIUM'

\# 静的解析エラー

if any(stage_name in stage for stage_name in \['TERRAFORM', 'TFLINT'\]):

if exit_code \> 0:

return 'MEDIUM'

else:

return 'LOW'

\# その他のエラー

if exit_code \> 0:

return 'MEDIUM'

return 'LOW'

def \_analyze_error_logs(self, error_details: Dict\[str, Any\]) -\>
Dict\[str, Any\]:

"""

関連ログファイルを取得して分析

"""

log_analysis = {

'log_retrieved': False,

'error_patterns': \[\],

'recommendations': \[\],

'log_size': 0

}

try:

log_file = error_details.get('log_file', '')

pipeline_execution_id = error_details\['pipeline_execution_id'\]

if log_file and pipeline_execution_id:

\# S3からログファイルを取得

s3_key = f"logs/{pipeline_execution_id}/{log_file}"

try:

response = s3.get_object(Bucket=S3_BUCKET, Key=s3_key)

log_content = response\['Body'\].read().decode('utf-8')

log_analysis\['log_retrieved'\] = True

log_analysis\['log_size'\] = len(log_content)

\# ログ内容の分析

log_analysis\['error_patterns'\] =
self.\_extract_error_patterns(log_content,
error_details\['error_type'\])

log_analysis\['recommendations'\] =
self.\_generate_recommendations(log_content, error_details)

except s3.exceptions.NoSuchKey:

logger.warning(f"Log file not found: {s3_key}")

except Exception as e:

logger.error(f"Failed to retrieve log file: {str(e)}")

except Exception as e:

logger.error(f"Log analysis failed: {str(e)}")

return log_analysis

def \_extract_error_patterns(self, log_content: str, error_type: str)
-\> List\[str\]:

"""

ログからエラーパターンを抽出

"""

patterns = \[\]

try:

lines = log_content.split('\n')

error_lines = \[line for line in lines if any(keyword in line.upper()
for keyword in \['ERROR', 'FAIL', 'CRITICAL', 'VIOLATION'\])\]

\# エラータイプ別のパターン抽出

if 'TERRAFORM' in error_type:

terraform_errors = \[line for line in error_lines if any(tf_keyword in
line for tf_keyword in \['Invalid', 'Missing', 'Duplicate'\])\]

patterns.extend(terraform_errors\[:5\]) \# 最初の5つのエラー

elif 'TFLINT' in error_type:

tflint_errors = \[line for line in error_lines if 'tflint' in
line.lower()\]

patterns.extend(tflint_errors\[:5\])

elif 'CHECKOV' in error_type:

checkov_errors = \[line for line in error_lines if any(ckv in line for
ckv in \['CKV\_', 'Check:', 'FAILED'\])\]

patterns.extend(checkov_errors\[:10\])

elif 'IAM' in error_type:

iam_errors = \[line for line in error_lines if any(iam_keyword in
line.upper() for iam_keyword in \['ACCESS', 'PERMISSION', 'ROLE',
'POLICY'\])\]

patterns.extend(iam_errors\[:5\])

elif 'VULNERABILITY' in error_type:

vuln_errors = \[line for line in error_lines if any(vuln_keyword in
line.upper() for vuln_keyword in \['CVE', 'VULN', 'EXPLOIT', 'HIGH',
'CRITICAL'\])\]

patterns.extend(vuln_errors\[:10\])

else:

\# 一般的なエラーパターン

patterns.extend(error_lines\[:5\])

except Exception as e:

logger.error(f"Error pattern extraction failed: {str(e)}")

return patterns\[:10\] \# 最大10個のパターンを返す

def \_generate_recommendations(self, log_content: str, error_details:
Dict\[str, Any\]) -\> List\[str\]:

"""

エラーに基づく修復推奨事項を生成

"""

recommendations = \[\]

error_type = error_details.get('error_type', '').upper()

try:

\# エラータイプ別の推奨事項

if 'TERRAFORM_VALIDATE_FAILED' in error_type:

if 'Invalid reference' in log_content:

recommendations.append("Fix invalid resource references in Terraform
configuration")

if 'Missing required argument' in log_content:

recommendations.append("Add missing required arguments to resource
blocks")

if 'Duplicate resource' in log_content:

recommendations.append("Remove duplicate resource definitions")

recommendations.append("Run 'terraform validate' locally before
committing")

elif 'TFLINT' in error_type:

recommendations.extend(\[

"Review TFLint findings and fix code quality issues",

"Update Terraform modules to latest versions",

"Follow Terraform best practices and naming conventions",

"Consider using terraform fmt for code formatting"

\])

elif 'CHECKOV' in error_type or 'SECURITY_VIOLATION' in error_type:

recommendations.extend(\[

"Address security misconfigurations identified by Checkov",

"Enable encryption for all data at rest and in transit",

"Review and restrict security group rules",

"Implement least privilege access principles",

"Enable logging and monitoring for all resources"

\])

elif 'IAM' in error_type:

recommendations.extend(\[

"Review and remove unused IAM roles and policies",

"Implement least privilege access principles",

"Remove cross-account trust relationships with external accounts",

"Enable IAM Access Analyzer findings remediation",

"Conduct regular IAM access reviews"

\])

elif 'VULNERABILITY' in error_type or 'PENTEST' in error_type:

recommendations.extend(\[

"Patch identified vulnerabilities immediately",

"Update software packages to latest secure versions",

"Review and harden network security configurations",

"Implement Web Application Firewall (WAF) rules",

"Conduct regular vulnerability assessments"

\])

else:

recommendations.extend(\[

"Review error logs for specific failure details",

"Check resource dependencies and configuration",

"Verify AWS permissions and service limits",

"Test changes in development environment first"

\])

except Exception as e:

logger.error(f"Recommendation generation failed: {str(e)}")

return recommendations\[:8\] \# 最大8個の推奨事項

def \_send_notifications(self, error_details: Dict\[str, Any\]):

"""

エラー通知の送信

"""

try:

severity = error_details.get('severity', 'MEDIUM')

\# SNS通知

self.\_send_sns_notification(error_details)

\# 重要度が高い場合はSlack通知も送信

if severity in \['CRITICAL', 'HIGH'\]:

self.\_send_slack_notification(error_details)

logger.info(f"Notifications sent for error:
{error_details\['pipeline_execution_id'\]}")

except Exception as e:

logger.error(f"Failed to send notifications: {str(e)}")

def \_send_sns_notification(self, error_details: Dict\[str, Any\]):

"""

SNS通知の送信

"""

try:

subject = f"Pipeline Error: {error_details\['error_type'\]} in
{error_details.get('stage', 'unknown')}"

message_parts = \[

f"Pipeline Execution ID: {error_details\['pipeline_execution_id'\]}",

f"Stage: {error_details.get('stage', error_details.get('stage_name',
'unknown'))}",

f"Error Type: {error_details\['error_type'\]}",

f"Severity: {error_details.get('severity', 'MEDIUM')}",

f"Timestamp: {error_details\['timestamp'\]}",

""

\]

\# ログ分析結果の追加

if error_details.get('log_analysis', {}).get('error_patterns'):

message_parts.append("Error Patterns:")

for pattern in
error_details\['log_analysis'\]\['error_patterns'\]\[:3\]:

message_parts.append(f" - {pattern\[:100\]}...")

message_parts.append("")

\# 推奨事項の追加

if error_details.get('log_analysis', {}).get('recommendations'):

message_parts.append("Recommendations:")

for rec in error_details\['log_analysis'\]\['recommendations'\]\[:3\]:

message_parts.append(f" - {rec}")

message_parts.append("")

message_parts.append(f"View full details in CloudWatch Logs and S3
bucket: {S3_BUCKET}")

message = "\n".join(message_parts)

sns.publish(

TopicArn=SNS_TOPIC_ARN,

Subject=subject,

Message=message

)

except Exception as e:

logger.error(f"SNS notification failed: {str(e)}")

def \_send_slack_notification(self, error_details: Dict\[str, Any\]):

"""

Slack通知の送信（重要度の高いエラー用）

"""

try:

\# Slack Webhook URLをSSMから取得

webhook_response = ssm.get_parameter(Name=SLACK_WEBHOOK_SECRET,
WithDecryption=True)

webhook_url = webhook_response\['Parameter'\]\['Value'\]

severity = error_details.get('severity', 'MEDIUM')

color = {'CRITICAL': 'danger', 'HIGH': 'warning', 'MEDIUM': '#ffaa00',
'LOW': 'good'}.get(severity, '#ffaa00')

slack_message = {

"attachments": \[

{

"color": color,

"title": f"🚨 Pipeline Security Error - {severity}",

"title_link":
f"https://console.aws.amazon.com/codesuite/codepipeline/pipelines/{error_details.get('pipeline_name',
'unknown')}/view",

"fields": \[

{

"title": "Pipeline Execution",

"value": error_details\['pipeline_execution_id'\],

"short": True

},

{

"title": "Stage",

"value": error_details.get('stage', error_details.get('stage_name',
'unknown')),

"short": True

},

{

"title": "Error Type",

"value": error_details\['error_type'\],

"short": True

},

{

"title": "Severity",

"value": severity,

"short": True

}

\],

"footer": "TechNova DevSecOps Pipeline",

"ts": int(datetime.now(timezone.utc).timestamp())

}

\]

}

\# 推奨事項がある場合は追加

if error_details.get('log_analysis', {}).get('recommendations'):

recommendations_text = "\n".join(\[f"• {rec}" for rec in
error_details\['log_analysis'\]\['recommendations'\]\[:3\]\])

slack_message\["attachments"\]\[0\]\["fields"\].append({

"title": "Immediate Actions",

"value": recommendations_text,

"short": False

})

\# Slack WebhookにPOST（requests使用を避けてurllib使用）

import urllib.request

import urllib.parse

data = json.dumps(slack_message).encode('utf-8')

req = urllib.request.Request(webhook_url, data=data,
headers={'Content-Type': 'application/json'})

urllib.request.urlopen(req)

logger.info("Slack notification sent successfully")

except Exception as e:

logger.error(f"Slack notification failed: {str(e)}")

def \_can_auto_remediate(self, error_details: Dict\[str, Any\]) -\>
bool:

"""

自動修復可能かどうかを判定

"""

error_type = error_details.get('error_type', '').upper()

\# 自動修復可能なエラータイプ

auto_remediable_errors = \[

'TERRAFORM_VALIDATE_FAILED',

'TFLINT_LOW_SEVERITY_VIOLATIONS',

'UNUSED_PERMISSIONS'

\]

return any(remediable in error_type for remediable in
auto_remediable_errors)

def \_attempt_auto_remediation(self, error_details: Dict\[str, Any\])
-\> Dict\[str, Any\]:

"""

自動修復の試行

"""

remediation_result = {

'attempted': True,

'success': False,

'actions_taken': \[\],

'error': None

}

try:

error_type = error_details.get('error_type', '').upper()

if 'TERRAFORM_VALIDATE' in error_type:

\# Terraformフォーマット修正の試行

remediation_result\['actions_taken'\].append("Attempted terraform fmt on
configuration files")

elif 'UNUSED_PERMISSIONS' in error_type:

\# 未使用権限のドキュメント化

remediation_result\['actions_taken'\].append("Documented unused
permissions for manual review")

\# 実際の修復アクションは安全性のため制限的に実装

remediation_result\['success'\] = True

except Exception as e:

remediation_result\['error'\] = str(e)

logger.error(f"Auto-remediation failed: {str(e)}")

return remediation_result

def \_should_escalate(self, error_details: Dict\[str, Any\]) -\> bool:

"""

エスカレーションが必要かどうかを判定

"""

severity = error_details.get('severity', 'LOW')

error_type = error_details.get('error_type', '').upper()

\# 自動エスカレーション条件

escalation_conditions = \[

severity == 'CRITICAL',

'SECURITY_VIOLATION' in error_type,

'VULNERABILITY' in error_type and 'HIGH' in error_type,

'EXTERNAL_ACCESS' in error_type,

'PENTEST' in error_type and 'CRITICAL' in error_type

\]

return any(escalation_conditions)

def \_escalate_error(self, error_details: Dict\[str, Any\]):

"""

エラーのエスカレーション処理

"""

try:

\# エスカレーション専用のSNSトピックに通知

escalation_subject = f"🚨 ESCALATION REQUIRED:
{error_details\['error_type'\]}"

escalation_message = f"""

CRITICAL SECURITY ISSUE REQUIRES IMMEDIATE ATTENTION

Pipeline Execution: {error_details\['pipeline_execution_id'\]} Error
Type: {error_details\['error_type'\]} Severity:
{error_details.get('severity', 'UNKNOWN')} Stage:
{error_details.get('stage', 'unknown')} Timestamp:
{error_details\['timestamp'\]}

This error has been automatically escalated due to its critical nature.
Immediate investigation and remediation required.

Security Team: Please review and take immediate action. DevOps Team:
Pipeline execution has been halted pending resolution. """

\# 管理者向けSNS通知

sns.publish(

TopicArn=SNS_TOPIC_ARN.replace('pipeline-errors',
'security-escalations'), \# エスカレーション用トピック

Subject=escalation_subject,

Message=escalation_message

)

\# DynamoDBの記録を更新

self.table.update_item(

Key={

'pipeline_execution_id': error_details\['pipeline_execution_id'\],

'timestamp': error_details\['timestamp'\]

},

UpdateExpression='SET \#status = :status, escalated_at = :escalated_at',

ExpressionAttributeNames={'#status': 'status'},

ExpressionAttributeValues={

':status': 'ESCALATED',

':escalated_at': datetime.now(timezone.utc).isoformat()

}

)

logger.warning(f"Error escalated:
{error_details\['pipeline_execution_id'\]}")

except Exception as e:

logger.error(f"Escalation failed: {str(e)}")

**Lambda ハンドラー**

def handler(event, context): error_handler = PipelineErrorHandler()
return error_handler.handler(event, context)

\### 5.3 エラーハンドリング用のLambda IAMロール

\`\`\`hcl

resource "aws_iam_role" "lambda_error_handler_role" {

name = "lambda-pipeline-error-handler-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "lambda.amazonaws.com"

}

}

\]

})

tags = {

Purpose = "Lambda Error Handler Role"

Component = "ErrorHandling"

}

}

resource "aws_iam_role_policy" "lambda_error_handler_policy" {

name = "lambda-pipeline-error-handler-policy"

role = aws_iam_role.lambda_error_handler_role.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\]

Resource = "arn:aws:logs:\*:\*:\*"

},

{

Effect = "Allow"

Action = \[

"sns:Publish"

\]

Resource = \[

aws_sns_topic.pipeline_errors.arn,

aws_sns_topic.security_escalations.arn

\]

},

{

Effect = "Allow"

Action = \[

"dynamodb:PutItem",

"dynamodb:UpdateItem",

"dynamodb:GetItem",

"dynamodb:Query"

\]

Resource = aws_dynamodb_table.pipeline_errors.arn

},

{

Effect = "Allow"

Action = \[

"s3:GetObject",

"s3:PutObject"

\]

Resource = \[

"\${aws_s3_bucket.build_logs.arn}/\*"

\]

},

{

Effect = "Allow"

Action = \[

"ssm:GetParameter"

\]

Resource = \[

aws_ssm_parameter.slack_webhook.arn

\]

},

{

Effect = "Allow"

Action = \[

"codepipeline:PutJobSuccessResult",

"codepipeline:PutJobFailureResult"

\]

Resource = "\*"

}

\]

})

}

5.4 エラー記録用DynamoDBテーブル

resource "aws_dynamodb_table" "pipeline_errors" {

name = "pipeline-errors"

billing_mode = "PAY_PER_REQUEST"

hash_key = "pipeline_execution_id"

range_key = "timestamp"

attribute {

name = "pipeline_execution_id"

type = "S"

}

attribute {

name = "timestamp"

type = "S"

}

attribute {

name = "error_type"

type = "S"

}

attribute {

name = "severity"

type = "S"

}

global_secondary_index {

name = "ErrorTypeIndex"

hash_key = "error_type"

range_key = "timestamp"

}

global_secondary_index {

name = "SeverityIndex"

hash_key = "severity"

range_key = "timestamp"

}

ttl {

attribute_name = "ttl"

enabled = true

}

tags = {

Purpose = "Pipeline Error Tracking"

Component = "ErrorHandling"

}

}

**6. 監視とレポーティングシステム**

**6.1 CloudWatchダッシュボード**

resource "aws_cloudwatch_dashboard" "security_pipeline_dashboard" {

dashboard_name = "TechNova-SecurityPipeline-Dashboard"

dashboard_body = jsonencode({

widgets = \[

{

type = "metric"

x = 0

y = 0

width = 12

height = 6

properties = {

metrics = \[

\["TechNova/SecurityAnalysis", "TFLintErrors"\],

\[".", "TFLintWarnings"\],

\[".", "CheckovTotalChecks"\],

\[".", "CheckovFailedChecks"\],

\[".", "CheckovComplianceScore"\]

\]

view = "timeSeries"

stacked = false

region = "us-east-1"

title = "Static Analysis Metrics"

period = 300

}

},

{

type = "metric"

x = 12

y = 0

width = 12

height = 6

properties = {

metrics = \[

\["TechNova/IAMSecurity", "ExternalAccessFindings"\],

\[".", "UnusedPermissions"\],

\[".", "CrossAccountTrusts"\],

\[".", "TotalSecurityFindings"\]

\]

view = "timeSeries"

stacked = false

region = "us-east-1"

title = "IAM Security Metrics"

period = 300

}

},

{

type = "metric"

x = 0

y = 6

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/VulnerabilityScanning", "VulnerabilitiesFound"\],

\[".", "HighSeverityVulns"\],

\[".", "MediumSeverityVulns"\]

\]

view = "timeSeries"

stacked = true

region = "us-east-1"

title = "Vulnerability Scan Results"

period = 300

}

},

{

type = "metric"

x = 8

y = 6

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/ApplicationSecurity", "AppVulnerabilitiesFound"\],

\[".", "AppHighSeverityVulns"\],

\[".", "InjectionVulnerabilities"\]

\]

view = "timeSeries"

stacked = false

region = "us-east-1"

title = "Application Security Metrics"

period = 300

}

},

{

type = "metric"

x = 16

y = 6

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/PenetrationTesting", "VulnerabilitiesExploited"\],

\[".", "CriticalPentestFindings"\],

\[".", "HighPentestFindings"\]

\]

view = "timeSeries"

stacked = false

region = "us-east-1"

title = "Penetration Test Results"

period = 300

}

},

{

type = "log"

x = 0

y = 12

width = 24

height = 6

properties = {

query = "SOURCE '/aws/codebuild/terraform-validate-with-error-handling'
\| fields @timestamp, @message \| filter @message like /ERROR/ \| sort
@timestamp desc \| limit 50"

region = "us-east-1"

title = "Recent Pipeline Errors"

view = "table"

}

}

\]

})

}

6.2 セキュリティメトリクス集約Lambda

resource "aws_lambda_function" "security_metrics_aggregator" {

filename = "lambda/security_metrics_aggregator.zip"

function_name = "security-metrics-aggregator"

role = aws_iam_role.lambda_metrics_role.arn

handler = "index.handler"

source_code_hash =
data.archive_file.security_metrics_aggregator_zip.output_base64sha256

runtime = "python3.9"

timeout = 900

environment {

variables = {

DYNAMODB_TABLE = aws_dynamodb_table.pipeline_errors.name

S3_BUCKET = aws_s3_bucket.build_logs.id

SNS_TOPIC_ARN = aws_sns_topic.security_reports.arn

}

}

tags = {

Purpose = "Security Metrics Aggregation"

Component = "Monitoring"

}

}

\# EventBridge rule for daily execution

resource "aws_cloudwatch_event_rule" "daily_security_report" {

name = "daily-security-metrics-aggregation"

description = "Trigger security metrics aggregation daily"

schedule_expression = "cron(0 8 \* \* ? \*)" \# 毎日午前8時UTC

tags = {

Purpose = "Daily Security Reporting"

}

}

resource "aws_cloudwatch_event_target" "security_metrics_target" {

rule = aws_cloudwatch_event_rule.daily_security_report.name

target_id = "SecurityMetricsAggregatorTarget"

arn = aws_lambda_function.security_metrics_aggregator.arn

}

resource "aws_lambda_permission" "allow_eventbridge" {

statement_id = "AllowExecutionFromEventBridge"

action = "lambda:InvokeFunction"

function_name =
aws_lambda_function.security_metrics_aggregator.function_name

principal = "events.amazonaws.com"

source_arn = aws_cloudwatch_event_rule.daily_security_report.arn

}

6.3 security_metrics_aggregator.py（日次セキュリティレポート）

import json

import boto3

import os

from datetime import datetime, timezone, timedelta

from typing import Dict, List, Any

import logging

logger = logging.getLogger()

logger.setLevel(logging.INFO)

\# AWSクライアント

cloudwatch = boto3.client('cloudwatch')

dynamodb = boto3.resource('dynamodb')

s3 = boto3.client('s3')

sns = boto3.client('sns')

\# 環境変数

DYNAMODB_TABLE = os.environ\['DYNAMODB_TABLE'\]

S3_BUCKET = os.environ\['S3_BUCKET'\] SNS_TOPIC_ARN =
os.environ\['SNS_TOPIC_ARN'\]

class SecurityMetricsAggregator: def **init**(self): self.table =
dynamodb.Table(DYNAMODB_TABLE)

def handler(self, event, context):

"""

日次セキュリティメトリクス集約のメインハンドラー

"""

try:

logger.info("Starting daily security metrics aggregation")

\# 過去24時間のメトリクス取得

end_time = datetime.now(timezone.utc)

start_time = end_time - timedelta(days=1)

\# 各セキュリティ領域のメトリクス集約

static_analysis_metrics = self.\_get_static_analysis_metrics(start_time,
end_time)

iam_security_metrics = self.\_get_iam_security_metrics(start_time,
end_time)

vulnerability_metrics = self.\_get_vulnerability_metrics(start_time,
end_time)

app_security_metrics = self.\_get_app_security_metrics(start_time,
end_time)

pentest_metrics = self.\_get_pentest_metrics(start_time, end_time)

error_metrics = self.\_get_error_metrics(start_time, end_time)

\# 統合レポート作成

daily_report = {

'report_date': end_time.strftime('%Y-%m-%d'),

'report_period': {

'start': start_time.isoformat(),

'end': end_time.isoformat()

},

'static_analysis': static_analysis_metrics,

'iam_security': iam_security_metrics,

'vulnerability_scanning': vulnerability_metrics,

'application_security': app_security_metrics,

'penetration_testing': pentest_metrics,

'error_analysis': error_metrics,

'overall_security_score': self.\_calculate_security_score(

static_analysis_metrics, iam_security_metrics,

vulnerability_metrics, app_security_metrics, pentest_metrics

)

}

\# レポート保存とトレンド分析

self.\_save_report(daily_report)

trend_analysis = self.\_analyze_trends(daily_report)

daily_report\['trend_analysis'\] = trend_analysis

\# 通知とアラート

self.\_send_daily_report(daily_report)

\# 重要な問題がある場合はアラート

if self.\_should_alert(daily_report):

self.\_send_security_alert(daily_report)

logger.info("Daily security metrics aggregation completed successfully")

return {

'statusCode': 200,

'body': json.dumps({

'status': 'success',

'report_date': daily_report\['report_date'\],

'overall_security_score': daily_report\['overall_security_score'\]

})

}

except Exception as e:

logger.error(f"Security metrics aggregation failed: {str(e)}")

return {

'statusCode': 500,

'body': json.dumps({'error': str(e)})

}

def \_get_static_analysis_metrics(self, start_time: datetime, end_time:
datetime) -\> Dict\[str, Any\]:

"""

静的解析メトリクスの取得

"""

metrics = {}

try:

\# TFLintメトリクス

tflint_errors = self.\_get_cloudwatch_metric_sum(

'TechNova/SecurityAnalysis', 'TFLintErrors', start_time, end_time

)

tflint_warnings = self.\_get_cloudwatch_metric_sum(

'TechNova/SecurityAnalysis', 'TFLintWarnings', start_time, end_time

)

\# Checkovメトリクス

checkov_total = self.\_get_cloudwatch_metric_sum(

'TechNova/SecurityAnalysis', 'CheckovTotalChecks', start_time, end_time

)

checkov_failed = self.\_get_cloudwatch_metric_sum(

'TechNova/SecurityAnalysis', 'CheckovFailedChecks', start_time, end_time

)

checkov_compliance = self.\_get_cloudwatch_metric_average(

'TechNova/SecurityAnalysis', 'CheckovComplianceScore', start_time,
end_time

)

metrics = {

'tflint': {

'errors': tflint_errors,

'warnings': tflint_warnings,

'total_issues': tflint_errors + tflint_warnings

},

'checkov': {

'total_checks': checkov_total,

'failed_checks': checkov_failed,

'compliance_score': checkov_compliance,

'pass_rate': ((checkov_total - checkov_failed) / checkov_total \* 100)
if checkov_total \> 0 else 100

},

'overall_static_score':
self.\_calculate_static_analysis_score(tflint_errors, tflint_warnings,
checkov_compliance)

}

except Exception as e:

logger.error(f"Failed to get static analysis metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_iam_security_metrics(self, start_time: datetime, end_time:
datetime) -\> Dict\[str, Any\]:

"""

IAMセキュリティメトリクスの取得

"""

metrics = {}

try:

external_access = self.\_get_cloudwatch_metric_sum(

'TechNova/IAMSecurity', 'ExternalAccessFindings', start_time, end_time

)

unused_permissions = self.\_get_cloudwatch_metric_sum(

'TechNova/IAMSecurity', 'UnusedPermissions', start_time, end_time

)

cross_account_trusts = self.\_get_cloudwatch_metric_sum(

'TechNova/IAMSecurity', 'CrossAccountTrusts', start_time, end_time

)

total_findings = self.\_get_cloudwatch_metric_sum(

'TechNova/IAMSecurity', 'TotalSecurityFindings', start_time, end_time

)

metrics = {

'external_access_findings': external_access,

'unused_permissions': unused_permissions,

'cross_account_trusts': cross_account_trusts,

'total_findings': total_findings,

'iam_security_score':
self.\_calculate_iam_security_score(external_access, unused_permissions,
cross_account_trusts),

'risk_level': self.\_determine_iam_risk_level(external_access,
unused_permissions, total_findings)

}

except Exception as e:

logger.error(f"Failed to get IAM security metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_vulnerability_metrics(self, start_time: datetime, end_time:
datetime) -\> Dict\[str, Any\]:

"""

脆弱性スキャンメトリクスの取得

"""

metrics = {}

try:

targets_scanned = self.\_get_cloudwatch_metric_sum(

'TechNova/VulnerabilityScanning', 'TargetsScanned', start_time, end_time

)

vulnerabilities_found = self.\_get_cloudwatch_metric_sum(

'TechNova/VulnerabilityScanning', 'VulnerabilitiesFound', start_time,
end_time

)

high_severity = self.\_get_cloudwatch_metric_sum(

'TechNova/VulnerabilityScanning', 'HighSeverityVulns', start_time,
end_time

)

medium_severity = self.\_get_cloudwatch_metric_sum(

'TechNova/VulnerabilityScanning', 'MediumSeverityVulns', start_time,
end_time

)

metrics = {

'targets_scanned': targets_scanned,

'vulnerabilities_found': vulnerabilities_found,

'high_severity_vulns': high_severity,

'medium_severity_vulns': medium_severity,

'vulnerability_density': vulnerabilities_found / targets_scanned if
targets_scanned \> 0 else 0,

'critical_vulnerability_rate': high_severity / vulnerabilities_found \*
100 if vulnerabilities_found \> 0 else 0,

'vulnerability_risk_score':
self.\_calculate_vulnerability_risk_score(high_severity,
medium_severity, vulnerabilities_found)

}

except Exception as e:

logger.error(f"Failed to get vulnerability metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_app_security_metrics(self, start_time: datetime, end_time:
datetime) -\> Dict\[str, Any\]:

"""

アプリケーションセキュリティメトリクスの取得

"""

metrics = {}

try:

app_targets = self.\_get_cloudwatch_metric_sum(

'TechNova/ApplicationSecurity', 'AppTargetsScanned', start_time,
end_time

)

app_vulns = self.\_get_cloudwatch_metric_sum(

'TechNova/ApplicationSecurity', 'AppVulnerabilitiesFound', start_time,
end_time

)

app_high_severity = self.\_get_cloudwatch_metric_sum(

'TechNova/ApplicationSecurity', 'AppHighSeverityVulns', start_time,
end_time

)

injection_vulns = self.\_get_cloudwatch_metric_sum(

'TechNova/ApplicationSecurity', 'InjectionVulnerabilities', start_time,
end_time

)

metrics = {

'applications_scanned': app_targets,

'vulnerabilities_found': app_vulns,

'high_severity_vulns': app_high_severity,

'injection_vulnerabilities': injection_vulns,

'owasp_top10_coverage': self.\_calculate_owasp_coverage(app_vulns,
injection_vulns),

'application_security_score':
self.\_calculate_app_security_score(app_high_severity, app_vulns,
app_targets)

}

except Exception as e:

logger.error(f"Failed to get application security metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_pentest_metrics(self, start_time: datetime, end_time:
datetime) -\> Dict\[str, Any\]:

"""

ペネトレーションテストメトリクスの取得

"""

metrics = {}

try:

pentest_targets = self.\_get_cloudwatch_metric_sum(

'TechNova/PenetrationTesting', 'PentestTargetsTested', start_time,
end_time

)

vulns_exploited = self.\_get_cloudwatch_metric_sum(

'TechNova/PenetrationTesting', 'VulnerabilitiesExploited', start_time,
end_time

)

critical_findings = self.\_get_cloudwatch_metric_sum(

'TechNova/PenetrationTesting', 'CriticalPentestFindings', start_time,
end_time

)

high_findings = self.\_get_cloudwatch_metric_sum(

'TechNova/PenetrationTesting', 'HighPentestFindings', start_time,
end_time

)

metrics = {

'targets_tested': pentest_targets,

'vulnerabilities_exploited': vulns_exploited,

'critical_findings': critical_findings,

'high_findings': high_findings,

'exploitation_rate': vulns_exploited / pentest_targets \* 100 if
pentest_targets \> 0 else 0,

'pentest_security_score':
self.\_calculate_pentest_security_score(vulns_exploited,
critical_findings, high_findings)

}

except Exception as e:

logger.error(f"Failed to get penetration test metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_error_metrics(self, start_time: datetime, end_time: datetime)
-\> Dict\[str, Any\]:

"""

エラーメトリクスの取得

"""

metrics = {}

try:

\# DynamoDBからエラー統計を取得

response = self.table.scan(

FilterExpression='#ts BETWEEN :start AND :end',

ExpressionAttributeNames={'#ts': 'timestamp'},

ExpressionAttributeValues={

':start': start_time.isoformat(),

':end': end_time.isoformat()

}

)

errors = response\['Items'\]

total_errors = len(errors)

\# 重要度別集計

severity_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0}

error_type_counts = {}

stage_error_counts = {}

for error in errors:

severity = error.get('severity', 'UNKNOWN')

error_type = error.get('error_type', 'UNKNOWN')

stage = error.get('stage_name', 'UNKNOWN')

severity_counts\[severity\] = severity_counts.get(severity, 0) + 1

error_type_counts\[error_type\] = error_type_counts.get(error_type, 0) +
1

stage_error_counts\[stage\] = stage_error_counts.get(stage, 0) + 1

metrics = {

'total_errors': total_errors,

'severity_breakdown': severity_counts,

'top_error_types': dict(sorted(error_type_counts.items(), key=lambda x:
x\[1\], reverse=True)\[:5\]),

'stage_error_distribution': stage_error_counts,

'error_rate_trend': self.\_calculate_error_rate_trend(start_time,
end_time),

'pipeline_reliability_score':
self.\_calculate_pipeline_reliability_score(severity_counts,
total_errors)

}

except Exception as e:

logger.error(f"Failed to get error metrics: {str(e)}")

metrics = {'error': str(e)}

return metrics

def \_get_cloudwatch_metric_sum(self, namespace: str, metric_name: str,
start_time: datetime, end_time: datetime) -\> float:

"""

CloudWatchメトリクスの合計値を取得

"""

try:

response = cloudwatch.get_metric_statistics(

Namespace=namespace,

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600, \# 1時間ごと

Statistics=\['Sum'\]

)

return sum(point\['Sum'\] for point in response\['Datapoints'\])

except Exception:

return 0.0

def \_get_cloudwatch_metric_average(self, namespace: str, metric_name:
str, start_time: datetime, end_time: datetime) -\> float:

"""

CloudWatchメトリクスの平均値を取得

"""

try:

response = cloudwatch.get_metric_statistics(

Namespace=namespace,

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600,

Statistics=\['Average'\]

)

if response\['Datapoints'\]:

return sum(point\['Average'\] for point in response\['Datapoints'\]) /
len(response\['Datapoints'\])

return 0.0

except Exception:

return 0.0

def \_calculate_security_score(self, static_analysis: Dict,
iam_security: Dict,

vulnerability: Dict, app_security: Dict, pentest: Dict) -\> Dict\[str,
Any\]:

"""

全体的なセキュリティスコアの計算

"""

try:

\# 各領域のスコア（0-100）

static_score = static_analysis.get('overall_static_score', 50)

iam_score = iam_security.get('iam_security_score', 50)

vuln_score = 100 - vulnerability.get('vulnerability_risk_score', 50)

app_score = app_security.get('application_security_score', 50)

pentest_score = pentest.get('pentest_security_score', 50)

\# 重み付け平均（静的解析とIAMを重視）

weights = {

'static_analysis': 0.25,

'iam_security': 0.25,

'vulnerability_scanning': 0.20,

'application_security': 0.15,

'penetration_testing': 0.15

}

overall_score = (

static_score \* weights\['static_analysis'\] +

iam_score \* weights\['iam_security'\] +

vuln_score \* weights\['vulnerability_scanning'\] +

app_score \* weights\['application_security'\] +

pentest_score \* weights\['penetration_testing'\]

)

\# リスクレベルの決定

if overall_score \>= 90:

risk_level = 'LOW'

elif overall_score \>= 70:

risk_level = 'MEDIUM'

elif overall_score \>= 50:

risk_level = 'HIGH'

else:

risk_level = 'CRITICAL'

return {

'overall_score': round(overall_score, 2),

'risk_level': risk_level,

'component_scores': {

'static_analysis': static_score,

'iam_security': iam_score,

'vulnerability_scanning': vuln_score,

'application_security': app_score,

'penetration_testing': pentest_score

},

'score_breakdown': weights

}

except Exception as e:

logger.error(f"Failed to calculate security score: {str(e)}")

return {'overall_score': 0, 'risk_level': 'UNKNOWN', 'error': str(e)}

def \_calculate_static_analysis_score(self, tflint_errors: int,
tflint_warnings: int, checkov_compliance: float) -\> float:

"""

静的解析スコアの計算

"""

\# TFLintスコア（エラーとワーニングの影響）

tflint_penalty = min(tflint_errors \* 10 + tflint_warnings \* 5, 50)

tflint_score = max(100 - tflint_penalty, 0)

\# Checkovスコア（コンプライアンススコア直接使用）

checkov_score = checkov_compliance if checkov_compliance \> 0 else 50

\# 重み付け平均

return (tflint_score \* 0.4 + checkov_score \* 0.6)

def \_calculate_iam_security_score(self, external_access: int,
unused_permissions: int, cross_account_trusts: int) -\> float:

"""

IAMセキュリティスコアの計算

"""

\# 各要素のペナルティ計算

external_penalty = min(external_access \* 15, 40) \# 外部アクセスは重要

unused_penalty = min(unused_permissions \* 2, 30) \# 未使用権限

trust_penalty = min(cross_account_trusts \* 5, 30) \#
クロスアカウント信頼

total_penalty = external_penalty + unused_penalty + trust_penalty

return max(100 - total_penalty, 0)

def \_calculate_vulnerability_risk_score(self, high_severity: int,
medium_severity: int, total_vulns: int) -\> float:

"""

脆弱性リスクスコアの計算（高いほど危険）

"""

if total_vulns == 0:

return 0

\# 重要度別重み付け

risk_score = (high_severity \* 10 + medium_severity \* 5) /
max(total_vulns, 1)

return min(risk_score, 100)

def \_calculate_app_security_score(self, high_severity: int,
total_vulns: int, targets: int) -\> float:

"""

アプリケーションセキュリティスコアの計算

"""

if targets == 0:

return 100 \# スキャン対象なしは満点

\# 脆弱性密度とスコア

vuln_density = total_vulns / targets

high_severity_rate = high_severity / max(total_vulns, 1) \* 100

penalty = min(vuln_density \* 20 + high_severity_rate, 100)

return max(100 - penalty, 0)

def \_calculate_pentest_security_score(self, exploited: int, critical:
int, high: int) -\> float:

"""

ペネトレーションテストセキュリティスコアの計算

"""

\# 実際に悪用された脆弱性は重大なペナルティ

exploit_penalty = exploited \* 25

critical_penalty = critical \* 15

high_penalty = high \* 10

total_penalty = exploit_penalty + critical_penalty + high_penalty

return max(100 - total_penalty, 0)

def \_calculate_owasp_coverage(self, total_vulns: int, injection_vulns:
int) -\> float:

"""

OWASP Top 10カバレッジの計算

"""

if total_vulns == 0:

return 100

\# 注入攻撃の割合から推定（簡略化）

injection_rate = injection_vulns / total_vulns \* 100

return min(injection_rate \* 2, 100) \# 概算カバレッジ

def \_calculate_error_rate_trend(self, start_time: datetime, end_time:
datetime) -\> str:

"""

エラー率のトレンド分析

"""

try:

\# 前日と比較

prev_start = start_time - timedelta(days=1)

prev_end = start_time

\# 前日のエラー数を取得

prev_response = self.table.scan(

FilterExpression='#ts BETWEEN :start AND :end',

ExpressionAttributeNames={'#ts': 'timestamp'},

ExpressionAttributeValues={

':start': prev_start.isoformat(),

':end': prev_end.isoformat()

}

)

prev_error_count = len(prev_response\['Items'\])

\# 今日のエラー数を取得

current_response = self.table.scan(

FilterExpression='#ts BETWEEN :start AND :end',

ExpressionAttributeNames={'#ts': 'timestamp'},

ExpressionAttributeValues={

':start': start_time.isoformat(),

':end': end_time.isoformat()

}

)

current_error_count = len(current_response\['Items'\])

if prev_error_count == 0 and current_error_count == 0:

return 'STABLE'

elif prev_error_count == 0:

return 'INCREASING'

elif current_error_count == 0:

return 'DECREASING'

else:

change_rate = (current_error_count - prev_error_count) /
prev_error_count \* 100

if change_rate \> 20:

return 'INCREASING'

elif change_rate \< -20:

return 'DECREASING'

else:

return 'STABLE'

except Exception:

return 'UNKNOWN'

def \_calculate_pipeline_reliability_score(self, severity_counts: Dict,
total_errors: int) -\> float:

"""

パイプライン信頼性スコアの計算

"""

if total_errors == 0:

return 100.0

\# 重要度別ペナルティ

penalty = (

severity_counts.get('CRITICAL', 0) \* 20 +

severity_counts.get('HIGH', 0) \* 15 +

severity_counts.get('MEDIUM', 0) \* 10 +

severity_counts.get('LOW', 0) \* 5

)

return max(100 - penalty, 0)

def \_analyze_trends(self, daily_report: Dict) -\> Dict\[str, Any\]:

"""

トレンド分析

"""

trends = {}

try:

\# 過去7日間のレポートを取得してトレンド分析

\# 簡略化版 - 実際の実装では過去データとの比較を行う

overall_score =
daily_report\['overall_security_score'\]\['overall_score'\]

if overall_score \>= 80:

trends\['security_trend'\] = 'IMPROVING'

elif overall_score \>= 60:

trends\['security_trend'\] = 'STABLE'

else:

trends\['security_trend'\] = 'DETERIORATING'

trends\['key_improvements'\] = \[\]

trends\['areas_of_concern'\] = \[\]

\# 改善点の特定

if daily_report\['static_analysis'\].get('checkov',
{}).get('compliance_score', 0) \> 80:

trends\['key_improvements'\].append('Strong compliance posture
maintained')

if daily_report\['iam_security'\].get('external_access_findings', 0) ==
0:

trends\['key_improvements'\].append('No external access violations
detected')

\# 懸念点の特定

if daily_report\['vulnerability_scanning'\].get('high_severity_vulns',
0) \> 0:

trends\['areas_of_concern'\].append('High severity vulnerabilities
detected')

if
daily_report\['penetration_testing'\].get('vulnerabilities_exploited',
0) \> 0:

trends\['areas_of_concern'\].append('Exploitable vulnerabilities found')

except Exception as e:

logger.error(f"Trend analysis failed: {str(e)}")

trends = {'error': str(e)}

return trends

def \_save_report(self, daily_report: Dict):

"""

日次レポートをS3に保存

"""

try:

report_date = daily_report\['report_date'\]

s3_key = f"daily-security-reports/{report_date}/security-report.json"

s3.put_object(

Bucket=S3_BUCKET,

Key=s3_key,

Body=json.dumps(daily_report, indent=2, default=str),

ContentType='application/json'

)

logger.info(f"Daily report saved to S3: {s3_key}")

except Exception as e:

logger.error(f"Failed to save daily report: {str(e)}")

def \_send_daily_report(self, daily_report: Dict):

"""

日次レポートの送信

"""

try:

overall_score =
daily_report\['overall_security_score'\]\['overall_score'\]

risk_level = daily_report\['overall_security_score'\]\['risk_level'\]

subject = f"Daily Security Report - {daily_report\['report_date'\]}
(Score: {overall_score:.1f})"

\# レポート本文作成

message_parts = \[

f"TechNova DevSecOps Daily Security Report",

f"Report Date: {daily_report\['report_date'\]}",

f"Overall Security Score: {overall_score:.1f}/100",

f"Risk Level: {risk_level}",

"",

"=== Security Metrics Summary ===",

""

\]

\# 静的解析サマリー

static = daily_report.get('static_analysis', {})

if 'error' not in static:

message_parts.extend(\[

"Static Analysis:",

f" • TFLint Issues: {static.get('tflint', {}).get('total_issues', 0)}",

f" • Checkov Compliance: {static.get('checkov',
{}).get('compliance_score', 0):.1f}%",

""

\])

\# IAMセキュリティサマリー

iam = daily_report.get('iam_security', {})

if 'error' not in iam:

message_parts.extend(\[

"IAM Security:",

f" • External Access Findings: {iam.get('external_access_findings',
0)}",

f" • Unused Permissions: {iam.get('unused_permissions', 0)}",

f" • Risk Level: {iam.get('risk_level', 'UNKNOWN')}",

""

\])

\# 脆弱性スキャンサマリー

vuln = daily_report.get('vulnerability_scanning', {})

if 'error' not in vuln:

message_parts.extend(\[

"Vulnerability Scanning:",

f" • Total Vulnerabilities: {vuln.get('vulnerabilities_found', 0)}",

f" • High Severity: {vuln.get('high_severity_vulns', 0)}",

f" • Targets Scanned: {vuln.get('targets_scanned', 0)}",

""

\])

\# トレンド分析

trends = daily_report.get('trend_analysis', {})

if 'error' not in trends:

message_parts.extend(\[

"Trend Analysis:",

f" • Security Trend: {trends.get('security_trend', 'UNKNOWN')}",

""

\])

if trends.get('key_improvements'):

message_parts.append("Key Improvements:")

for improvement in trends\['key_improvements'\]\[:3\]:

message_parts.append(f" ✓ {improvement}")

message_parts.append("")

if trends.get('areas_of_concern'):

message_parts.append("Areas of Concern:")

for concern in trends\['areas_of_concern'\]\[:3\]:

message_parts.append(f" ⚠ {concern}")

message_parts.append("")

message_parts.extend(\[

"Detailed metrics available in CloudWatch Dashboard:",

"https://console.aws.amazon.com/cloudwatch/home#dash

message_parts.extend(\[ "Detailed metrics available in CloudWatch
Dashboard:",
"<https://console.aws.amazon.com/cloudwatch/home#dashboards>:name=TechNova-SecurityPipeline-Dashboard",
"", f"Full report stored in S3:
s3://{S3_BUCKET}/daily-security-reports/{daily_report\['report_date'\]}/security-report.json"
\])

message = "\n".join(message_parts)

sns.publish(

TopicArn=SNS_TOPIC_ARN,

Subject=subject,

Message=message

)

logger.info("Daily security report sent successfully")

except Exception as e:

logger.error(f"Failed to send daily report: {str(e)}")

def \_should_alert(self, daily_report: Dict) -\> bool:

"""

アラートが必要かどうかの判定

"""

try:

overall_score =
daily_report\['overall_security_score'\]\['overall_score'\]

risk_level = daily_report\['overall_security_score'\]\['risk_level'\]

\# アラート条件

alert_conditions = \[

overall_score \< 50, \# 全体スコアが50未満

risk_level in \['CRITICAL', 'HIGH'\], \# リスクレベルが高い

daily_report.get('vulnerability_scanning',
{}).get('high_severity_vulns', 0) \> 5, \# 高深刻度脆弱性が5個以上

daily_report.get('penetration_testing',
{}).get('vulnerabilities_exploited', 0) \> 0, \# 悪用可能な脆弱性

daily_report.get('iam_security', {}).get('external_access_findings', 0)
\> 0, \# 外部アクセス検出

daily_report.get('error_analysis', {}).get('severity_breakdown',
{}).get('CRITICAL', 0) \> 0 \# クリティカルエラー

\]

return any(alert_conditions)

except Exception:

return False

def \_send_security_alert(self, daily_report: Dict):

"""

セキュリティアラートの送信

"""

try:

overall_score =
daily_report\['overall_security_score'\]\['overall_score'\]

risk_level = daily_report\['overall_security_score'\]\['risk_level'\]

subject = f"🚨 SECURITY ALERT: Daily Security Score Below Threshold
({overall_score:.1f}/100)"

alert_reasons = \[\]

\# アラート理由の特定

if overall_score \< 50:

alert_reasons.append(f"Overall security score critically low:
{overall_score:.1f}/100")

if daily_report.get('vulnerability_scanning',
{}).get('high_severity_vulns', 0) \> 5:

high_vulns =
daily_report\['vulnerability_scanning'\]\['high_severity_vulns'\]

alert_reasons.append(f"High severity vulnerabilities detected:
{high_vulns}")

if daily_report.get('penetration_testing',
{}).get('vulnerabilities_exploited', 0) \> 0:

exploited =
daily_report\['penetration_testing'\]\['vulnerabilities_exploited'\]

alert_reasons.append(f"Exploitable vulnerabilities found: {exploited}")

if daily_report.get('iam_security', {}).get('external_access_findings',
0) \> 0:

external = daily_report\['iam_security'\]\['external_access_findings'\]

alert_reasons.append(f"External access violations detected: {external}")

message_parts = \[

"CRITICAL SECURITY ALERT",

f"Date: {daily_report\['report_date'\]}",

f"Overall Security Score: {overall_score:.1f}/100",

f"Risk Level: {risk_level}",

"",

"ALERT TRIGGERS:",

\]

for reason in alert_reasons:

message_parts.append(f" 🔴 {reason}")

message_parts.extend(\[

"",

"IMMEDIATE ACTION REQUIRED:",

"1. Review CloudWatch security dashboard immediately",

"2. Investigate high-priority security findings",

"3. Execute security remediation procedures",

"4. Notify security team and stakeholders",

"",

"Security Dashboard:",

"https://console.aws.amazon.com/cloudwatch/home#dashboards:name=TechNova-SecurityPipeline-Dashboard",

"",

f"Detailed report:
s3://{S3_BUCKET}/daily-security-reports/{daily_report\['report_date'\]}/security-report.json"

\])

message = "\n".join(message_parts)

\# 重要度の高いアラートは別のSNSトピックに送信

critical_topic_arn = SNS_TOPIC_ARN.replace('security-reports',
'security-alerts')

sns.publish(

TopicArn=critical_topic_arn,

Subject=subject,

Message=message

)

logger.warning(f"Security alert sent for report:
{daily_report\['report_date'\]}")

except Exception as e:

logger.error(f"Failed to send security alert: {str(e)}")

def handler(event, context): aggregator = SecurityMetricsAggregator()
return aggregator.handler(event, context)

\## 7. 実装まとめ

\### 7.1 システム全体の依存関係と追加リソース

\`\`\`hcl

\# S3バケット群

resource "aws_s3_bucket" "pipeline_artifacts" {

bucket = "technova-pipeline-artifacts-\${random_id.bucket_suffix.hex}"

tags = {

Purpose = "CodePipeline Artifacts"

Environment = "Multi-Account"

}

}

resource "aws_s3_bucket" "build_logs" {

bucket = "technova-build-logs-\${random_id.bucket_suffix.hex}"

tags = {

Purpose = "Build Logs Storage"

Environment = "Multi-Account"

}

}

resource "aws_s3_bucket" "security_configs" {

bucket = "technova-security-configs-\${random_id.bucket_suffix.hex}"

tags = {

Purpose = "Security Configuration Storage"

Environment = "Multi-Account"

}

}

resource "random_id" "bucket_suffix" {

byte_length = 4

}

\# S3バケット暗号化

resource "aws_s3_bucket_server_side_encryption_configuration"
"pipeline_artifacts_encryption" {

bucket = aws_s3_bucket.pipeline_artifacts.id

rule {

apply_server_side_encryption_by_default {

kms_master_key_id = aws_kms_key.pipeline_key.arn

sse_algorithm = "aws:kms"

}

}

}

resource "aws_s3_bucket_server_side_encryption_configuration"
"build_logs_encryption" {

bucket = aws_s3_bucket.build_logs.id

rule {

apply_server_side_encryption_by_default {

kms_master_key_id = aws_kms_key.pipeline_key.arn

sse_algorithm = "aws:kms"

}

}

}

resource "aws_s3_bucket_server_side_encryption_configuration"
"security_configs_encryption" {

bucket = aws_s3_bucket.security_configs.id

rule {

apply_server_side_encryption_by_default {

kms_master_key_id = aws_kms_key.pipeline_key.arn

sse_algorithm = "aws:kms"

}

}

}

\# KMS暗号化キー

resource "aws_kms_key" "pipeline_key" {

description = "TechNova Pipeline Encryption Key"

deletion_window_in_days = 7

tags = {

Purpose = "Pipeline Encryption"

Environment = "Multi-Account"

}

}

resource "aws_kms_alias" "pipeline_key_alias" {

name = "alias/technova-pipeline-key"

target_key_id = aws_kms_key.pipeline_key.key_id

}

\# SNS通知トピック群

resource "aws_sns_topic" "pipeline_errors" {

name = "technova-pipeline-errors"

tags = {

Purpose = "Pipeline Error Notifications"

}

}

resource "aws_sns_topic" "security_reports" {

name = "technova-security-reports"

tags = {

Purpose = "Daily Security Reports"

}

}

resource "aws_sns_topic" "security_alerts" {

name = "technova-security-alerts"

tags = {

Purpose = "Critical Security Alerts"

}

}

resource "aws_sns_topic" "critical_security_alerts" {

name = "technova-critical-security-alerts"

tags = {

Purpose = "Critical Security Alerts"

}

}

resource "aws_sns_topic" "pipeline_approvals" {

name = "technova-pipeline-approvals"

tags = {

Purpose = "Pipeline Manual Approvals"

}

}

resource "aws_sns_topic" "iam_analysis_approvals" {

name = "technova-iam-analysis-approvals"

tags = {

Purpose = "IAM Analysis Approvals"

}

}

resource "aws_sns_topic" "production_approvals" {

name = "technova-production-approvals"

tags = {

Purpose = "Production Deployment Approvals"

}

}

\# SNSトピックポリシー

resource "aws_sns_topic_policy" "pipeline_errors_policy" {

arn = aws_sns_topic.pipeline_errors.arn

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Principal = {

Service = \[

"codebuild.amazonaws.com",

"codepipeline.amazonaws.com",

"lambda.amazonaws.com"

\]

}

Action = "sns:Publish"

Resource = aws_sns_topic.pipeline_errors.arn

}

\]

})

}

\# CodeCommitリポジトリ

resource "aws_codecommit_repository" "iac_repo" {

repository_name = "technova-iac-repository"

repository_description = "TechNova Infrastructure as Code Repository"

tags = {

Purpose = "IaC Source Code"

Environment = "Multi-Account"

}

}

\# SSMパラメータ（Slack Webhook等）

resource "aws_ssm_parameter" "slack_webhook" {

name = "/technova/pipeline/slack-webhook"

type = "SecureString"

value = var.slack_webhook_url

tags = {

Purpose = "Slack Integration"

Component = "Notifications"

}

}

\# 変数定義

variable "slack_webhook_url" {

description = "Slack Webhook URL for notifications"

type = string

default = "https://hooks.slack.com/services/CHANGEME"

sensitive = true

}

variable "error_handling_mode" {

description = "Error handling mode: STOP, CONTINUE, or MANUAL_APPROVAL"

type = string

default = "MANUAL_APPROVAL"

validation {

condition = contains(\["STOP", "CONTINUE", "MANUAL_APPROVAL"\],
var.error_handling_mode)

error_message = "Error handling mode must be STOP, CONTINUE, or
MANUAL_APPROVAL."

}

}

\# Lambda関数のZIPファイル作成用データソース

data "archive_file" "security_metrics_aggregator_zip" {

type = "zip"

output_path = "lambda/security_metrics_aggregator.zip"

source {

content = file("\${path.module}/lambda/security_metrics_aggregator.py")

filename = "index.py"

}

}

\# Lambda IAMロール（メトリクス集約用）

resource "aws_iam_role" "lambda_metrics_role" {

name = "lambda-security-metrics-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "lambda.amazonaws.com"

}

}

\]

})

}

resource "aws_iam_role_policy" "lambda_metrics_policy" {

name = "lambda-security-metrics-policy"

role = aws_iam_role.lambda_metrics_role.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\]

Resource = "arn:aws:logs:\*:\*:\*"

},

{

Effect = "Allow"

Action = \[

"cloudwatch:GetMetricStatistics",

"cloudwatch:ListMetrics"

\]

Resource = "\*"

},

{

Effect = "Allow"

Action = \[

"dynamodb:Scan",

"dynamodb:Query"

\]

Resource = aws_dynamodb_table.pipeline_errors.arn

},

{

Effect = "Allow"

Action = \[

"s3:PutObject",

"s3:GetObject"

\]

Resource = "\${aws_s3_bucket.build_logs.arn}/\*"

},

{

Effect = "Allow"

Action = \[

"sns:Publish"

\]

Resource = \[

aws_sns_topic.security_reports.arn,

aws_sns_topic.security_alerts.arn

\]

}

\]

})

}

7.2 アウトプット定義

\# 重要なリソースの出力

output "pipeline_name" {

description = "Name of the security integrated pipeline"

value = aws_codepipeline.security_integrated_pipeline.name

}

output "pipeline_arn" {

description = "ARN of the security integrated pipeline"

value = aws_codepipeline.security_integrated_pipeline.arn

}

output "artifacts_bucket" {

description = "S3 bucket for pipeline artifacts"

value = aws_s3_bucket.pipeline_artifacts.bucket

}

output "build_logs_bucket" {

description = "S3 bucket for build logs and security reports"

value = aws_s3_bucket.build_logs.bucket

}

output "security_dashboard_url" {

description = "CloudWatch Security Dashboard URL"

value =
"https://console.aws.amazon.com/cloudwatch/home#dashboards:name=\${aws_cloudwatch_dashboard.security_pipeline_dashboard.dashboard_name}"

}

output "pipeline_url" {

description = "CodePipeline Console URL"

value =
"https://console.aws.amazon.com/codesuite/codepipeline/pipelines/\${aws_codepipeline.security_integrated_pipeline.name}/view"

}

output "error_handler_function_name" {

description = "Error handler Lambda function name"

value = aws_lambda_function.pipeline_error_handler.function_name

}

output "metrics_aggregator_function_name" {

description = "Security metrics aggregator Lambda function name"

value = aws_lambda_function.security_metrics_aggregator.function_name

}

output "sns_topics" {

description = "SNS notification topics"

value = {

pipeline_errors = aws_sns_topic.pipeline_errors.arn

security_reports = aws_sns_topic.security_reports.arn

security_alerts = aws_sns_topic.security_alerts.arn

critical_security_alerts = aws_sns_topic.critical_security_alerts.arn

}

}

output "access_analyzer_arn" {

description = "Organization Access Analyzer ARN"

value = aws_accessanalyzer_analyzer.organization_analyzer.arn

}

7.3 デプロイメント手順書

\# TechNova DevSecOps Pipeline デプロイメント手順

\## 前提条件

1\. \*\*AWS Organizations設定\*\*

\- 120アカウント構成のAWS Organizations

\- 管理アカウントでの実行権限

2\. \*\*必要な権限\*\*

\- AdministratorAccess（初期構築時）

\- 以下のサービスへのフルアクセス権限：

\- CodePipeline, CodeBuild, CodeCommit

\- IAM, Organizations, Access Analyzer

\- S3, DynamoDB, Lambda, SNS, CloudWatch

3\. \*\*ツールバージョン\*\*

\- Terraform \>= 1.5.0

\- AWS CLI \>= 2.0

\- Python \>= 3.9

\## デプロイメント手順

\### ステップ1: 環境変数設定

\`\`\`bash

export AWS_REGION=us-east-1

export TECHNOVA_ENVIRONMENT=staging

export SLACK_WEBHOOK_URL="your-slack-webhook-url"

ステップ2: Terraformワークスペース準備

\# Terraformワークスペース初期化

terraform init

\# 環境別ワークスペース作成

terraform workspace new \$TECHNOVA_ENVIRONMENT

terraform workspace select \$TECHNOVA_ENVIRONMENT

ステップ3: 設定ファイル作成

\# terraform.tfvars作成

cat \> terraform.tfvars \<\< EOF

slack_webhook_url = "\$SLACK_WEBHOOK_URL"

error_handling_mode = "MANUAL_APPROVAL"

EOF

ステップ4: デプロイメント実行

\# 計画確認

terraform plan -var-file=terraform.tfvars

\# デプロイ実行

terraform apply -var-file=terraform.tfvars

ステップ5: 初期設定

\# CodeCommitリポジトリへの初期コミット

aws codecommit create-repository --repository-name
technova-iac-repository

git clone
https://git-codecommit.us-east-1.amazonaws.com/v1/repos/technova-iac-repository

cd technova-iac-repository

\# buildspecファイル配置

mkdir -p buildspecs

cp ../buildspecs/\* buildspecs/

\# 初期コミット

git add .

git commit -m "Initial pipeline configuration"

git push origin main

ステップ6: SNS通知設定

\# メール通知購読

aws sns subscribe \\

--topic-arn \$(terraform output -raw sns_topics \| jq -r
.security_alerts) \\

--protocol email \\

--notification-endpoint your-security-team@technova.com

aws sns subscribe \\

--topic-arn \$(terraform output -raw sns_topics \| jq -r
.pipeline_errors) \\

--protocol email \\

--notification-endpoint <your-devops-team@technova.com>

**運用開始後の確認項目**

**1. パイプライン動作確認**

- CodePipelineの初回実行成功

- 各ステージの正常動作確認

- エラーハンドリングの動作確認

**2. セキュリティ分析確認**

- 静的解析（Terraform Validate, TFLint, Checkov）結果確認

- IAM Access Analyzer分析結果確認

- 動的脆弱性スキャン結果確認

- ペネトレーションテスト結果確認

**3. 監視とアラート確認**

- CloudWatchダッシュボード表示確認

- SNS通知受信確認

- Slack通知受信確認（設定した場合）

- 日次セキュリティレポート受信確認

**4. エラーハンドリング確認**

- エラー発生時のLambda関数動作確認

- DynamoDBへのエラー記録確認

- エスカレーション機能確認

**トラブルシューティング**

**よくある問題と解決方法**

1.  **CodeBuildでのタイムアウト**

bash

*\# timeout_in_minutesを延長*

terraform apply -var="build_timeout=120"

2.  **IAM権限エラー**

bash

*\# 必要な権限をチェック*

aws iam simulate-principal-policy \\

--policy-source-arn arn:aws:iam::ACCOUNT:role/codebuild-role \\

--action-names iam:ListRoles

3.  **S3バケット作成エラー**

bash

*\# バケット名の重複を解決*

terraform destroy -target=aws_s3_bucket.pipeline_artifacts

terraform apply

**継続的な保守作業**

**週次作業**

- セキュリティダッシュボードの確認

- 高優先度のセキュリティ問題対応

- パイプライン実行成功率の確認

**月次作業**

- セキュリティポリシーの見直し

- 未使用IAM権限のクリーンアップ

- 脆弱性トレンドの分析

**四半期作業**

- セキュリティツールのバージョンアップ

- パイプライン設定の見直し

- コンプライアンス要件の確認

**緊急時対応手順**

**セキュリティインシデント発生時**

1.  パイプライン緊急停止

bash

aws codepipeline stop-pipeline-execution \\

--pipeline-name security-integrated-deployment-pipeline \\

--pipeline-execution-id \$EXECUTION_ID

2.  影響範囲の調査

3.  修復対応の実施

4.  パイプライン再開

**システム障害時**

1.  CloudWatchアラームの確認

2.  Lambda関数ログの確認

3.  必要に応じてマニュアル実行

この包括的なセキュリティ分析パイプラインにより、TechNova社の120アカウント環境における
Infrastructure as Code
のセキュリティ品質を確保し、DevSecOpsプラクティスを実現することができます。

これで、TechNova社の要件に基づく包括的なIaC &
CI/CD統合セキュリティ分析パイプラインの実装が完了しました。このシステムは、静的解析、IAM分析、動的脆弱性検証を統合した多層防御型のDevSecOpsパイプラインとして機能し、120アカウント環境全体のセキュリティガバナンスを実現します。

- 

## **AWSアカウント・権限設計（基本方針）**

目次

[**概要**](#%E6%A6%82%E8%A6%81)

[**権限設計の基本原則**](#1-%E6%A8%A9%E9%99%90%E8%A8%AD%E8%A8%88%)

[**IAM Identity
Center統合戦略**](#2-iam-identity-center%E7%B5%B1%E5%90%88)

[**職務分離と最小権限の実装**](#3-%E8%81%B7%E5%8B%99%E5%88%86%E9%9B%A2%)

[**クロスアカウント権限管理**](#4-%E3%82%AF%E3%83%AD%E3%82%B9%E3%82%A2%)

[**コンプライアンス・監査対応**](#5-%E3%82%B3%E3%83%B3%E3%83%97%E3%83%A9%)

[**セキュリティ境界設計**](#6-%E3%82%BB%E3%82%AD%E3%83%A5%E3%83%AA%)

[**緊急時アクセス管理**](#7-%E7%B7%8A%E6%80%A5%E6%99%82%E3%82%A2%)

[**監視・ログ戦略**](#8-%E7%9B%A3%E8%A6%96%E3%83%AD%E3%82%B0%)

[**実装ガイドライン**](#9-%E5%AE%9F%E8%A3%85%E3%82%AC%E3%82%A4%)

概要

設計背景

TechNova社の120アカウント構成における権限管理は、事業部門別アカウント構成と密接に連携し、セキュリティとガバナンスを両立させる必要があります。本方針書は、物理的なアカウント分離に対する論理的な権限管理戦略を定義します。

アカウント構成との整合性

事業部門別アカウント構成で定義された以下の構造に対応：

管理系アカウント: セキュリティ、ログ、ネットワーク、請求管理

事業部門アカウント: 製品開発、マーケティング、データ分析、HR

環境分離: 本番(prod)、ステージング(staging)、開発(dev)

特殊用途アカウント: サンドボックス、共有サービス

権限設計の目標

Zero Trust アーキテクチャの実現

最小権限原則の徹底

職務分離による不正防止

コンプライアンス要件への準拠

運用効率の向上

1\. 権限設計の基本原則

1.1 ゼロトラストセキュリティモデル

yaml

*\# Zero Trust の実装原則*

zero_trust_principles:

identity_verification:

\- "全てのアクセスを認証・認可"

\- "アカウント境界での検証強化"

\- "継続的な信頼度評価"

least_privilege:

\- "最小限の権限のみ付与"

\- "時間制限付きアクセス"

\- "Just-In-Time権限昇格"

assume_breach:

\- "侵害を前提とした設計"

\- "横展開の防止"

\- "異常検知と自動対応"

1.2 権限管理階層

┌─────────────────────────────────────────────────────────────┐

│ Organization Level │

│ ┌─────────────────┐ ┌─────────────────┐ ┌──────────────┐ │

│ │ Identity │ │ Compliance │ │ Audit │ │

│ │ Management │ │ Governance │ │ Logging │ │

│ └─────────────────┘ └─────────────────┘ └──────────────┘ │

└─────────────────────────────────────────────────────────────┘

│

┌─────────────────────────────────────────────────────────────┐

│ Business Unit Level │

│ ┌─────────────────┐ ┌─────────────────┐ ┌──────────────┐ │

│ │ Department │ │ Project │ │ Resource │ │

│ │ Admin │ │ Teams │ │ Access │ │

│ └─────────────────┘ └─────────────────┘ └──────────────┘ │

└─────────────────────────────────────────────────────────────┘

│

┌─────────────────────────────────────────────────────────────┐

│ Application Level │

│ ┌─────────────────┐ ┌─────────────────┐ ┌──────────────┐ │

│ │ Service │ │ Environment │ │ Resource │ │

│ │ Accounts │ │ Isolation │ │ Specific │ │

│ └─────────────────┘ └─────────────────┘ └──────────────┘ │

└─────────────────────────────────────────────────────────────┘

1.3 権限付与の原則

最小権限原則 (Principle of Least Privilege)

json

{

"minimum_required_access": {

"default_policy": "DENY_ALL",

"explicit_grants": "SPECIFIC_RESOURCES_ONLY",

"time_bounds": "LIMITED_DURATION",

"scope_bounds": "NARROWEST_POSSIBLE"

},

"progressive_access": {

"initial_access": "READ_ONLY",

"proven_need": "ADDITIONAL_PERMISSIONS",

"regular_review": "ACCESS_CERTIFICATION"

}

}

職務分離原則 (Separation of Duties)

yaml

separation_of_duties:

development_vs_production:

\- "開発者は本番環境への直接アクセス不可"

\- "本番変更は承認プロセス必須"

\- "緊急時のみ例外的な直接アクセス"

security_vs_operations:

\- "セキュリティ設定は専門チームのみ"

\- "運用チームは日常管理のみ"

\- "相互監視による不正防止"

audit_independence:

\- "監査ログは独立アカウントで管理"

\- "監査担当者は被監査システムにアクセス不可"

\- "ログの改ざん防止機能"

2\. IAM Identity Center統合戦略

2.1 アーキテクチャ概要

hcl

*\# IAM Identity Center の組織レベル設定*

resource "aws_ssoadmin_instances" "main" {

*\# Organization の管理アカウントで設定*

}

*\# 外部IDプロバイダー統合*

resource "aws_ssoadmin_instance_access_control_attributes" "main" {

instance_arn = aws_ssoadmin_instances.main.arn

attribute {

key = "Department"

value {

source = \["\${path:enterprise.department}"\]

}

}

attribute {

key = "CostCenter"

value {

source = \["\${path:enterprise.costCenter}"\]

}

}

attribute {

key = "JobTitle"

value {

source = \["\${path:enterprise.title}"\]

}

}

}

2.2 Permission Set 設計戦略

基本Permission Set階層

yaml

permission_sets:

*\# 管理系権限*

administrative:

OrganizationAdministrator:

description: "組織全体の管理権限"

accounts: \["management-\*"\]

policies: \["AdministratorAccess"\]

conditions:

mfa_required: true

session_duration: "2hours"

SecurityAdministrator:

description: "セキュリティ設定管理"

accounts: \["security-\*", "audit-\*"\]

policies: \["SecurityAudit", "CustomSecurityAdmin"\]

conditions:

ip_restriction: "office_networks"

mfa_required: true

*\# 事業部門権限*

business_units:

ProductDeveloper:

description: "製品開発チーム"

accounts: \["product-dev-\*", "product-staging-\*"\]

policies: \["EC2FullAccess", "S3Developer", "RDSReadAccess"\]

conditions:

time_restriction: "business_hours"

ProductionSupport:

description: "本番環境監視・サポート"

accounts: \["product-prod-\*"\]

policies: \["CloudWatchReadOnly", "LimitedEC2Access"\]

conditions:

approval_required: true

max_session_duration: "4hours"

*\# 環境別権限*

environment_specific:

DevelopmentFullAccess:

description: "開発環境フルアクセス"

accounts: \["\*-dev-\*"\]

policies: \["PowerUserAccess"\]

ProductionReadOnly:

description: "本番環境読み取り専用"

accounts: \["\*-prod-\*"\]

policies: \["ReadOnlyAccess", "SupportUser"\]

2.3 属性ベースアクセス制御 (ABAC)

json

{

"abac_policy_template": {

"Version": "2012-10-17",

"Statement": \[

{

"Effect": "Allow",

"Action": "\*",

"Resource": "\*",

"Condition": {

"StringEquals": {

"aws:PrincipalTag/Department": "\${aws:RequestedRegion}",

"ec2:ResourceTag/Environment": "\${saml:Environment}",

"s3:ResourceTag/CostCenter": "\${saml:CostCenter}"

},

"DateGreaterThan": {

"aws:CurrentTime": "\${saml:SessionStart}"

},

"DateLessThan": {

"aws:CurrentTime": "\${saml:SessionEnd}"

}

}

}

\]

}

}

2.4 外部IDプロバイダー統合

hcl

*\# Active Directory統合*

resource "aws_ssoadmin_external_identity_provider_configuration"
"ad_integration" {

instance_arn = aws_ssoadmin_instances.main.arn

identity_provider_configuration {

external_identity_provider_type = "SAML"

saml_provider_configuration {

metadata_document =
file("\${path.module}/saml/technova-ad-metadata.xml")

}

}

}

*\# Google Workspace統合 (将来対応)*

resource "aws_ssoadmin_external_identity_provider_configuration"
"google_workspace" {

instance_arn = aws_ssoadmin_instances.main.arn

identity_provider_configuration {

external_identity_provider_type = "OIDC"

oidc_provider_configuration {

issuer_url = "https://accounts.google.com"

authorization_endpoint = "https://accounts.google.com/o/oauth2/v2/auth"

token_endpoint = "https://oauth2.googleapis.com/token"

userinfo_endpoint = "https://openidconnect.googleapis.com/v1/userinfo"

jwks_uri = "https://www.googleapis.com/oauth2/v3/certs"

client_id = var.google_workspace_client_id

client_secret = var.google_workspace_client_secret

}

}

}

3\. 職務分離と最小権限の実装

3.1 職務分離マトリックス

yaml

role_separation_matrix:

*\# 開発チーム*

developers:

allowed_environments: \["dev", "staging"\]

forbidden_environments: \["prod"\]

allowed_actions:

\- "ec2:\*"

\- "s3:GetObject\*"

\- "s3:PutObject\*"

\- "rds:Describe\*"

forbidden_actions:

\- "iam:\*"

\- "organizations:\*"

\- "account:\*"

*\# インフラチーム*

infrastructure:

allowed_environments: \["dev", "staging", "prod"\]

allowed_actions:

\- "ec2:\*"

\- "vpc:\*"

\- "route53:\*"

approval_required:

\- "iam:CreateRole"

\- "iam:AttachRolePolicy"

forbidden_actions:

\- "organizations:\*"

\- "account:CloseAccount"

*\# セキュリティチーム*

security:

allowed_environments: \["all"\]

allowed_actions:

\- "iam:\*"

\- "organizations:\*"

\- "guardduty:\*"

\- "securityhub:\*"

read_only_access:

\- "logs:\*"

\- "cloudtrail:\*"

3.2 最小権限ポリシー実装

カスタムポリシーテンプレート

json

{

"Version": "2012-10-17",

"Statement": \[

{

"Sid": "DeveloperBaseAccess",

"Effect": "Allow",

"Action": \[

"ec2:Describe\*",

"ec2:List\*",

"s3:GetObject",

"s3:PutObject"

\],

"Resource": "\*",

"Condition": {

"StringEquals": {

"aws:RequestedRegion": \["ap-northeast-1", "us-east-1"\],

"ec2:ResourceTag/Environment": \["dev", "staging"\]

},

"IpAddress": {

"aws:SourceIp": \[

"10.0.0.0/8",

"172.16.0.0/12"

\]

}

}

},

{

"Sid": "DenyProductionAccess",

"Effect": "Deny",

"Action": "\*",

"Resource": "\*",

"Condition": {

"StringEquals": {

"ec2:ResourceTag/Environment": "prod"

}

}

}

\]

}

動的権限制御

hcl

*\# タグベースのリソースアクセス制御*

resource "aws_iam_policy" "tag_based_access" {

name = "TagBasedResourceAccess"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"ec2:StartInstances",

"ec2:StopInstances",

"ec2:RebootInstances"

\]

Resource = "\*"

Condition = {

StringEquals = {

"ec2:ResourceTag/Owner" = "\$\${saml:userid}"

"ec2:ResourceTag/Department" = "\$\${saml:department}"

}

}

}

\]

})

}

*\# 時間制限付きアクセス*

resource "aws_iam_policy" "time_based_access" {

name = "TimeBasedAccess"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = "\*"

Resource = "\*"

Condition = {

DateGreaterThan = {

"aws:CurrentTime" = "08:00Z"

}

DateLessThan = {

"aws:CurrentTime" = "18:00Z"

}

StringEquals = {

"aws:RequestedRegion" = \["ap-northeast-1"\]

}

}

}

\]

})

}

3.3 Just-In-Time (JIT) アクセス管理

python

*\# JITアクセス管理Lambda関数*

import boto3

import json

from datetime import datetime, timedelta

def lambda_handler(event, context):

"""

Just-In-Time権限昇格リクエスト処理

"""

try:

*\# リクエスト情報の取得*

user_id = event\['user_id'\]

requested_permissions = event\['permissions'\]

business_justification = event\['justification'\]

duration_hours = event.get('duration', 2) *\# デフォルト2時間*

*\# 承認プロセス*

approval_result = process_approval_workflow(

user_id, requested_permissions, business_justification

)

if approval_result\['approved'\]:

*\# 一時的な権限の付与*

temp_role_arn = create_temporary_role(

user_id, requested_permissions, duration_hours

)

*\# 自動削除の予約*

schedule_role_deletion(temp_role_arn, duration_hours)

return {

'statusCode': 200,

'body': json.dumps({

'status': 'approved',

'temporary_role_arn': temp_role_arn,

'expires_at': (datetime.now() +
timedelta(hours=duration_hours)).isoformat(),

'instructions': 'aws sts assume-role --role-arn ' + temp_role_arn

})

}

else:

return {

'statusCode': 403,

'body': json.dumps({

'status': 'denied',

'reason': approval_result\['reason'\]

})

}

except Exception as e:

return {

'statusCode': 500,

'body': json.dumps({'error': str(e)})

}

def process_approval_workflow(user_id, permissions, justification):

"""

承認ワークフローの処理

"""

*\# リスクレベルの評価*

risk_level = evaluate_risk_level(permissions)

if risk_level == 'LOW':

*\# 自動承認*

return {'approved': True, 'reason': 'Auto-approved: Low risk'}

elif risk_level == 'MEDIUM':

*\# マネージャー承認が必要*

return initiate_manager_approval(user_id, justification)

else:

*\# 複数レベルの承認が必要*

return initiate_multi_level_approval(user_id, justification)

def create_temporary_role(user_id, permissions, duration_hours):

"""

一時的なIAMロールの作成

"""

iam = boto3.client('iam')

*\# ロール名の生成*

role_name = f"TempAccess-{user_id}-{int(datetime.now().timestamp())}"

*\# 信頼ポリシー*

assume_role_policy = {

"Version": "2012-10-17",

"Statement": \[

{

"Effect": "Allow",

"Principal": {"AWS":
f"arn:aws:iam::{boto3.client('sts').get_caller_identity()\['Account'\]}:user/{user_id}"},

"Action": "sts:AssumeRole",

"Condition": {

"StringEquals": {

"sts:ExternalId": generate_external_id(user_id)

}

}

}

\]

}

*\# ロール作成*

response = iam.create_role(

RoleName=role_name,

AssumeRolePolicyDocument=json.dumps(assume_role_policy),

Description=f"Temporary elevated access for {user_id}",

MaxSessionDuration=duration_hours \* 3600,

Tags=\[

{'Key': 'Purpose', 'Value': 'JIT-Access'},

{'Key': 'User', 'Value': user_id},

{'Key': 'ExpiresAt', 'Value': (datetime.now() +
timedelta(hours=duration_hours)).isoformat()}

\]

)

*\# 権限の付与*

for permission in permissions:

iam.attach_role_policy(

RoleName=role_name,

PolicyArn=permission\['policy_arn'\]

)

return response\['Role'\]\['Arn'\]

4\. クロスアカウント権限管理

4.1 信頼関係設計

yaml

cross_account_trust_model:

*\# 管理アカウント → 全アカウント*

management_account:

trust_direction: "outbound"

trusted_accounts: \["all_organization_accounts"\]

permitted_roles:

\- "OrganizationAccountAccessRole"

\- "SecurityAuditRole"

conditions:

\- "mfa_required: true"

\- "source_ip_restriction: office_networks"

*\# セキュリティアカウント → 全アカウント（読み取り専用）*

security_account:

trust_direction: "outbound"

trusted_accounts: \["all_organization_accounts"\]

permitted_roles:

\- "SecurityAuditRole"

permissions: \["read_only", "security_findings"\]

*\# ログアカウント → 全アカウント（ログ収集）*

logging_account:

trust_direction: "inbound"

trusting_accounts: \["all_organization_accounts"\]

permitted_actions:

\- "logs:CreateLogGroup"

\- "logs:CreateLogStream"

\- "logs:PutLogEvents"

4.2 クロスアカウントロールの実装

hcl

*\# 組織レベルでのクロスアカウントロール*

resource "aws_iam_role" "cross_account_security_audit" {

for_each = toset(var.organization_account_ids)

name = "CrossAccountSecurityAudit"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Principal = {

AWS = "arn:aws:iam::\${var.security_account_id}:root"

}

Action = "sts:AssumeRole"

Condition = {

StringEquals = {

"sts:ExternalId" = var.cross_account_external_id

}

Bool = {

"aws:MultiFactorAuthPresent" = "true"

}

IpAddress = {

"aws:SourceIp" = var.allowed_ip_ranges

}

}

}

\]

})

tags = {

Purpose = "Cross-Account Security Audit"

ManagedBy = "Terraform"

}

}

*\# セキュリティ監査用の統一ポリシー*

resource "aws_iam_role_policy_attachment" "security_audit_policy" {

for_each = toset(var.organization_account_ids)

role = aws_iam_role.cross_account_security_audit\[each.key\].name

policy_arn = "arn:aws:iam::aws:policy/SecurityAudit"

}

*\# カスタムセキュリティポリシー*

resource "aws_iam_role_policy" "custom_security_audit" {

for_each = toset(var.organization_account_ids)

name = "CustomSecurityAuditPolicy"

role = aws_iam_role.cross_account_security_audit\[each.key\].id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = \[

"access-analyzer:List\*",

"access-analyzer:Get\*",

"guardduty:List\*",

"guardduty:Get\*",

"securityhub:List\*",

"securityhub:Get\*",

"config:List\*",

"config:Get\*",

"config:Describe\*"

\]

Resource = "\*"

},

{

Effect = "Allow"

Action = \[

"s3:GetBucketPolicy",

"s3:GetBucketAcl",

"s3:GetBucketPublicAccessBlock"

\]

Resource = "\*"

}

\]

})

}

4.3 アカウント間通信制御

hcl

*\# VPC エンドポイントポリシー（アカウント間制限）*

resource "aws_vpc_endpoint_policy" "s3_cross_account_policy" {

vpc_endpoint_id = aws_vpc_endpoint.s3.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Principal = "\*"

Action = \[

"s3:GetObject",

"s3:PutObject"

\]

Resource = "\*"

Condition = {

StringEquals = {

"aws:PrincipalAccount" = var.trusted_account_ids

}

}

},

{

Effect = "Deny"

Principal = "\*"

Action = "\*"

Resource = "\*"

Condition = {

StringNotEquals = {

"aws:PrincipalAccount" = var.trusted_account_ids

}

}

}

\]

})

}

*\# リソースベースポリシー例（S3バケット）*

resource "aws_s3_bucket_policy" "cross_account_access" {

bucket = aws_s3_bucket.shared_resources.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "CrossAccountAccess"

Effect = "Allow"

Principal = {

AWS = \[

for account_id in var.trusted_account_ids :

"arn:aws:iam::\${account_id}:root"

\]

}

Action = \[

"s3:GetObject",

"s3:PutObject"

\]

Resource = "\${aws_s3_bucket.shared_resources.arn}/\*"

Condition = {

StringEquals = {

"s3:x-amz-server-side-encryption" = "aws:kms"

}

Bool = {

"aws:SecureTransport" = "true"

}

}

}

\]

})

}

5\. コンプライアンス・監査対応

5.1 法的要件への対応

yaml

compliance_frameworks:

*\# SOC 2 Type II*

soc2_type2:

requirements:

\- "アクセス制御の文書化"

\- "権限変更の承認プロセス"

\- "定期的なアクセスレビュー"

\- "特権アクセスの監視"

implementation:

access_control_documentation: "IAM Policy文書化"

approval_process: "ServiceNow統合ワークフロー"

periodic_review: "四半期アクセス認証"

privileged_monitoring: "CloudTrail + GuardDuty"

*\# ISO 27001*

iso27001:

requirements:

\- "情報セキュリティ管理システム(ISMS)"

\- "リスクアセスメントとリスク処理"

\- "アクセス管理"

\- "暗号化"

implementation:

isms: "AWS Config Rules + Security Hub"

risk_assessment: "AWS Well-Architected Framework"

access_management: "IAM Identity Center + Access Analyzer"

encryption: "KMS + CloudTrail暗号化"

*\# PCI DSS (カード決済関連)*

pci_dss:

scope: "決済処理アカウント"

requirements:

\- "カード会員データへのアクセス制限"

\- "一意のユーザーIDの割り当て"

\- "物理的・論理的アクセスの制限"

\- "ネットワークリソースとCADへのアクセス監視"

implementation:

data_access_restriction: "専用VPC + セキュリティグループ"

unique_user_id: "IAM Identity Center強制"

access_restriction: "MFA + IP制限"

monitoring: "VPC Flow Logs + GuardDuty"

5.2 コンプライアンス自動化

hcl

*\# AWS Config Rules for コンプライアンス監視*

resource "aws_config_configuration_recorder" "compliance_recorder" {

name = "TechNovaComplianceRecorder"

role_arn = aws_iam_role.config_role.arn

recording_group {

all_supported = true

include_global_resource_types = true

}

}

*\# SOC 2コンプライアンス用Config Rules*

resource "aws_config_config_rule" "soc2_mfa_enabled" {

name = "soc2-mfa-enabled-for-console-access"

source {

owner = "AWS"

source_identifier = "MFA_ENABLED_FOR_ROOT"

}

depends_on = \[aws_config_configuration_recorder.compliance_recorder\]

}

resource "aws_config_config_rule" "soc2_password_policy" {

name = "soc2-iam-password-policy"

source {

owner = "AWS"

source_identifier = "IAM_PASSWORD_POLICY"

}

input_parameters = jsonencode({

RequireUppercaseCharacters = "true"

RequireLowercaseCharacters = "true"

RequireSymbols = "true"

RequireNumbers = "true"

MinimumPasswordLength = "14"

PasswordReusePrevention = "12"

MaxPasswordAge = "90"

})

}

*\# ISO 27001コンプライアンス用Rules*

resource "aws_config_config_rule" "iso27001_encryption_at_rest" {

name = "iso27001-s3-bucket-server-side-encryption-enabled"

source {

owner = "AWS"

source_identifier = "S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED"

}

}

*\# PCI DSSコンプライアンス用Rules（決済処理アカウント）*

resource "aws_config_config_rule" "pci_dss_security_groups" {

count = contains(var.pci_scope_accounts,
data.aws_caller_identity.current.account_id) ? 1 : 0

name = "pci-dss-security-groups-restricted"

source {

owner = "AWS"

再試行

C

続ける

編集

owner = "AWS" source_identifier = "INCOMING_SSH_DISABLED" } }

resource "aws_config_config_rule" "pci_dss_root_access_key" { count =
contains(var.pci_scope_accounts,
data.aws_caller_identity.current.account_id) ? 1 : 0

name = "pci-dss-root-access-key-check"

source { owner = "AWS" source_identifier = "ROOT_ACCESS_KEY_CHECK" } }

\### 5.3 監査証跡の設計

\`\`\`hcl

\# 組織レベルのCloudTrail設定

resource "aws_cloudtrail" "organization_trail" {

name = "TechNova-Organization-AuditTrail"

s3_bucket_name = aws_s3_bucket.audit_logs.bucket

\# 組織全体のイベントを記録

is_organization_trail = true

is_multi_region_trail = true

\# データイベントの記録

event_selector {

read_write_type = "All"

include_management_events = true

exclude_management_event_sources = \[\]

data_resource {

type = "AWS::S3::Object"

values = \["arn:aws:s3:::\*/sensitive-data/\*"\]

}

data_resource {

type = "AWS::KMS::Key"

values = \["\*"\]

}

}

\# 洞察セレクター（異常検知）

insight_selector {

insight_type = "ApiCallRateInsight"

}

tags = {

Purpose = "Compliance Audit Trail"

Compliance = "SOC2,ISO27001,PCI-DSS"

}

}

\# 監査ログ用S3バケット

resource "aws_s3_bucket" "audit_logs" {

bucket = "technova-audit-logs-\${random_id.audit_suffix.hex}"

tags = {

Purpose = "Audit Log Storage"

Retention = "7years"

Compliance = "SOC2,ISO27001"

}

}

resource "aws_s3_bucket_lifecycle_configuration" "audit_logs_lifecycle"
{

bucket = aws_s3_bucket.audit_logs.id

rule {

id = "audit_log_retention"

status = "Enabled"

\# 90日後にIA移行

transition {

days = 90

storage_class = "STANDARD_IA"

}

\# 1年後にGlacier移行

transition {

days = 365

storage_class = "GLACIER"

}

\# 7年後にDeep Archive移行

transition {

days = 2555 \# 7年

storage_class = "DEEP_ARCHIVE"

}

\# 10年後に削除

expiration {

days = 3650 \# 10年

}

}

}

\# 監査ログへの不正アクセス防止

resource "aws_s3_bucket_policy" "audit_logs_policy" {

bucket = aws_s3_bucket.audit_logs.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "DenyDirectAccess"

Effect = "Deny"

Principal = "\*"

Action = "s3:\*"

Resource = \[

aws_s3_bucket.audit_logs.arn,

"\${aws_s3_bucket.audit_logs.arn}/\*"

\]

Condition = {

StringNotEquals = {

"aws:PrincipalServiceName" = \[

"cloudtrail.amazonaws.com",

"config.amazonaws.com"

\]

}

StringNotLike = {

"aws:PrincipalArn" = \[

"arn:aws:iam::\${var.audit_account_id}:role/AuditRole\*"

\]

}

}

},

{

Sid = "AllowAuditAccountReadOnly"

Effect = "Allow"

Principal = {

AWS = "arn:aws:iam::\${var.audit_account_id}:root"

}

Action = \[

"s3:GetObject",

"s3:ListBucket"

\]

Resource = \[

aws_s3_bucket.audit_logs.arn,

"\${aws_s3_bucket.audit_logs.arn}/\*"

\]

Condition = {

Bool = {

"aws:MultiFactorAuthPresent" = "true"

}

}

}

\]

})

}

5.4 アクセス認証プロセス

python

*\# 四半期アクセス認証の自動化*

import boto3

import json

from datetime import datetime, timedelta

import csv

class AccessCertificationManager:

def \_\_init\_\_(self):

self.iam_client = boto3.client('iam')

self.identity_store = boto3.client('identitystore')

self.sso_admin = boto3.client('sso-admin')

def generate_access_report(self):

"""

全組織のアクセス権限レポート生成

"""

report = {

'generated_at': datetime.now().isoformat(),

'certification_period': self.\_get_certification_period(),

'accounts': \[\]

}

*\# 各アカウントのアクセス情報を収集*

for account in self.\_get_organization_accounts():

account_report = self.\_analyze_account_access(account\['Id'\])

report\['accounts'\].append(account_report)

return report

def \_get_certification_period(self):

"""

認証期間の取得（四半期）

"""

now = datetime.now()

quarter_start = datetime(now.year, ((now.month - 1) // 3) \* 3 + 1, 1)

quarter_end = quarter_start + timedelta(days=90)

return {

'start': quarter_start.isoformat(),

'end': quarter_end.isoformat()

}

def \_analyze_account_access(self, account_id):

"""

アカウント別アクセス分析

"""

try:

*\# アカウント内のIAMユーザー分析*

users_analysis = self.\_analyze_iam_users(account_id)

*\# ロール分析*

roles_analysis = self.\_analyze_iam_roles(account_id)

*\# SSO Permission Sets分析*

sso_analysis = self.\_analyze_sso_assignments(account_id)

return {

'account_id': account_id,

'analysis_date': datetime.now().isoformat(),

'iam_users': users_analysis,

'iam_roles': roles_analysis,

'sso_assignments': sso_analysis,

'compliance_score': self.\_calculate_compliance_score(

users_analysis, roles_analysis, sso_analysis

)

}

except Exception as e:

return {

'account_id': account_id,

'error': str(e),

'analysis_date': datetime.now().isoformat()

}

def \_analyze_iam_users(self, account_id):

"""

IAMユーザーのアクセス分析

"""

*\# AssumeRoleでターゲットアカウントにアクセス*

assumed_role = self.\_assume_audit_role(account_id)

target_iam = boto3.client('iam',

aws_access_key_id=assumed_role\['AccessKeyId'\],

aws_secret_access_key=assumed_role\['SecretAccessKey'\],

aws_session_token=assumed_role\['SessionToken'\]

)

users = target_iam.list_users()\['Users'\]

user_analysis = \[\]

for user in users:

*\# 最終ログイン確認*

last_activity = self.\_get_user_last_activity(target_iam,
user\['UserName'\])

*\# 付与されたポリシー確認*

attached_policies = self.\_get_user_policies(target_iam,
user\['UserName'\])

*\# MFA設定確認*

mfa_devices = target_iam.list_mfa_devices(UserName=user\['UserName'\])

user_analysis.append({

'username': user\['UserName'\],

'creation_date': user\['CreateDate'\].isoformat(),

'last_activity': last_activity,

'attached_policies': attached_policies,

'mfa_enabled': len(mfa_devices\['MFADevices'\]) \> 0,

'compliance_issues': self.\_identify_user_compliance_issues(

user, last_activity, attached_policies, mfa_devices

)

})

return user_analysis

def \_identify_user_compliance_issues(self, user, last_activity,
policies, mfa_devices):

"""

コンプライアンス問題の特定

"""

issues = \[\]

*\# 90日以上未使用*

if last_activity and (datetime.now() - last_activity).days \> 90:

issues.append({

'type': 'UNUSED_ACCOUNT',

'severity': 'MEDIUM',

'description': f'Account unused for {(datetime.now() -
last_activity).days} days'

})

*\# MFA未設定*

if len(mfa_devices\['MFADevices'\]) == 0:

issues.append({

'type': 'MFA_NOT_ENABLED',

'severity': 'HIGH',

'description': 'Multi-Factor Authentication not enabled'

})

*\# 過剰権限の検知*

if any('AdministratorAccess' in policy\['PolicyName'\] for policy in
policies):

issues.append({

'type': 'EXCESSIVE_PRIVILEGES',

'severity': 'HIGH',

'description': 'Administrator access granted to regular user'

})

return issues

def generate_certification_tasks(self, access_report):

"""

認証タスクの生成

"""

certification_tasks = \[\]

for account in access_report\['accounts'\]:

for user in account.get('iam_users', \[\]):

if user.get('compliance_issues'):

task = {

'account_id': account\['account_id'\],

'user': user\['username'\],

'issues': user\['compliance_issues'\],

'recommended_actions':
self.\_generate_remediation_actions(user\['compliance_issues'\]),

'assigned_to': self.\_determine_assignee(account\['account_id'\],
user\['username'\]),

'due_date': (datetime.now() + timedelta(days=30)).isoformat()

}

certification_tasks.append(task)

return certification_tasks

def \_generate_remediation_actions(self, issues):

"""

修復アクションの生成

"""

actions = \[\]

for issue in issues:

if issue\['type'\] == 'UNUSED_ACCOUNT':

actions.append('Disable or remove unused account')

elif issue\['type'\] == 'MFA_NOT_ENABLED':

actions.append('Enable Multi-Factor Authentication')

elif issue\['type'\] == 'EXCESSIVE_PRIVILEGES':

actions.append('Review and reduce privileges to minimum required')

return actions

*\# 実行例*

def lambda_handler(event, context):

"""

四半期アクセス認証Lambda関数

"""

cert_manager = AccessCertificationManager()

*\# アクセスレポート生成*

access_report = cert_manager.generate_access_report()

*\# 認証タスク生成*

certification_tasks =
cert_manager.generate_certification_tasks(access_report)

*\# レポートをS3に保存*

s3_client = boto3.client('s3')

report_key =
f"access-certification/{datetime.now().strftime('%Y-%Q')}/access-report.json"

s3_client.put_object(

Bucket=os.environ\['COMPLIANCE_BUCKET'\],

Key=report_key,

Body=json.dumps(access_report, indent=2, default=str),

ContentType='application/json'

)

*\# ServiceNowにタスク作成（統合されている場合）*

if os.environ.get('SERVICENOW_INTEGRATION'):

create_servicenow_tasks(certification_tasks)

*\# 通知送信*

send_certification_notification(len(certification_tasks), report_key)

return {

'statusCode': 200,

'body': json.dumps({

'report_generated': True,

'tasks_created': len(certification_tasks),

's3_location': f"s3://{os.environ\['COMPLIANCE_BUCKET'\]}/{report_key}"

})

}

6\. セキュリティ境界設計

6.1 多層防御アーキテクチャ

yaml

security_layers:

*\# レイヤー1: 物理的境界（アカウント分離）*

account_isolation:

principle: "完全な論理分離"

implementation: "AWS Organizations + SCP"

scope: "120アカウント構成"

*\# レイヤー2: ネットワーク境界*

network_isolation:

principle: "ゼロトラストネットワーク"

implementation: "VPC + Security Groups + NACLs"

scope: "VPC間通信制御"

*\# レイヤー3: アプリケーション境界*

application_isolation:

principle: "マイクロセグメンテーション"

implementation: "IAM + Resource Tags + Policies"

scope: "リソースレベルアクセス制御"

*\# レイヤー4: データ境界*

data_isolation:

principle: "暗号化とアクセス制御"

implementation: "KMS + S3 Bucket Policies + Database Security"

scope: "データレベル保護"

6.2 Service Control Policies (SCP) 実装

json

{

"Version": "2012-10-17",

"Statement": \[

{

"Sid": "DenyRootUserActions",

"Effect": "Deny",

"Principal": "\*",

"Action": "\*",

"Resource": "\*",

"Condition": {

"StringEquals": {

"aws:PrincipalType": "Root"

},

"StringNotEquals": {

"aws:PrincipalServiceName": \[

"cloudformation.amazonaws.com",

"config.amazonaws.com"

\]

}

}

},

{

"Sid": "RestrictRegions",

"Effect": "Deny",

"Principal": "\*",

"Action": "\*",

"Resource": "\*",

"Condition": {

"StringNotEquals": {

"aws:RequestedRegion": \[

"ap-northeast-1",

"us-east-1",

"eu-west-1"

\]

},

"ForAllValues:StringNotEquals": {

"aws:PrincipalServiceName": \[

"cloudformation.amazonaws.com",

"support.amazonaws.com"

\]

}

}

},

{

"Sid": "DenyUnencryptedStorage",

"Effect": "Deny",

"Principal": "\*",

"Action": \[

"s3:PutObject",

"rds:CreateDBInstance",

"ec2:CreateVolume"

\],

"Resource": "\*",

"Condition": {

"Bool": {

"aws:SecureTransport": "false"

}

}

},

{

"Sid": "RestrictInstanceTypes",

"Effect": "Deny",

"Principal": "\*",

"Action": \[

"ec2:RunInstances",

"ec2:StartInstances"

\],

"Resource": "arn:aws:ec2:\*:\*:instance/\*",

"Condition": {

"ForAllValues:StringNotLike": {

"ec2:InstanceType": \[

"t3.\*",

"t4g.\*",

"m5.\*",

"m6i.\*",

"c5.\*",

"c6i.\*"

\]

}

}

}

\]

}

6.3 データ分類とアクセス制御

hcl

*\# データ分類に基づくS3バケットポリシー*

resource "aws_s3_bucket_policy" "data_classification_policy" {

bucket = aws_s3_bucket.classified_data.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "RestrictedDataAccess"

Effect = "Allow"

Principal = {

AWS = \[

"arn:aws:iam::\${data.aws_caller_identity.current.account_id}:role/DataScientistRole",

"arn:aws:iam::\${data.aws_caller_identity.current.account_id}:role/ComplianceAuditorRole"

\]

}

Action = \[

"s3:GetObject"

\]

Resource = "\${aws_s3_bucket.classified_data.arn}/restricted/\*"

Condition = {

StringEquals = {

"s3:x-amz-server-side-encryption" = "aws:kms",

"aws:userid" = \[

"\${aws_iam_role.data_scientist.unique_id}:\*",

"\${aws_iam_role.compliance_auditor.unique_id}:\*"

\]

}

Bool = {

"aws:MultiFactorAuthPresent" = "true"

}

DateGreaterThan = {

"aws:TokenIssueTime" = "2024-01-01T00:00:00Z"

}

}

},

{

Sid = "PublicDataAccess"

Effect = "Allow"

Principal = {

AWS =
"arn:aws:iam::\${data.aws_caller_identity.current.account_id}:root"

}

Action = \[

"s3:GetObject"

\]

Resource = "\${aws_s3_bucket.classified_data.arn}/public/\*"

},

{

Sid = "DenyUnencryptedUploads"

Effect = "Deny"

Principal = "\*"

Action = "s3:PutObject"

Resource = "\${aws_s3_bucket.classified_data.arn}/\*"

Condition = {

StringNotEquals = {

"s3:x-amz-server-side-encryption" = "aws:kms"

}

}

}

\]

})

}

*\# KMSキーによるデータ暗号化制御*

resource "aws_kms_key" "data_encryption_key" {

description = "Data encryption key with role-based access"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "Enable IAM User Permissions"

Effect = "Allow"

Principal = {

AWS =
"arn:aws:iam::\${data.aws_caller_identity.current.account_id}:root"

}

Action = "kms:\*"

Resource = "\*"

},

{

Sid = "Allow use of the key for specific roles"

Effect = "Allow"

Principal = {

AWS = \[

aws_iam_role.data_scientist.arn,

aws_iam_role.compliance_auditor.arn

\]

}

Action = \[

"kms:Encrypt",

"kms:Decrypt",

"kms:ReEncrypt\*",

"kms:GenerateDataKey\*",

"kms:DescribeKey"

\]

Resource = "\*"

Condition = {

StringEquals = {

"kms:ViaService": \[

"s3.ap-northeast-1.amazonaws.com",

"rds.ap-northeast-1.amazonaws.com"

\]

}

}

}

\]

})

tags = {

Purpose = "Data Classification Encryption"

DataClassification = "Restricted"

}

}

7\. 緊急時アクセス管理

7.1 Break Glass アクセス設計

hcl

*\# 緊急時アクセス用のIAMロール*

resource "aws_iam_role" "emergency_access_role" {

name = "EmergencyBreakGlassRole"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Principal = {

AWS = \[

for user in var.emergency_access_users :

"arn:aws:iam::\${data.aws_caller_identity.current.account_id}:user/\${user}"

\]

}

Action = "sts:AssumeRole"

Condition = {

Bool = {

"aws:MultiFactorAuthPresent" = "true"

}

StringEquals = {

"sts:ExternalId" = var.emergency_external_id

}

IpAddress = {

"aws:SourceIp" = var.emergency_access_ips

}

}

}

\]

})

*\# セッション期間を1時間に制限*

max_session_duration = 3600

tags = {

Purpose = "Emergency Break Glass Access"

CriticalRole = "true"

}

}

*\# 緊急時用のポリシー（制限付きAdministratorAccess）*

resource "aws_iam_role_policy" "emergency_access_policy" {

name = "EmergencyAccessPolicy"

role = aws_iam_role.emergency_access_role.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Effect = "Allow"

Action = "\*"

Resource = "\*"

Condition = {

StringNotEquals = {

"aws:PrincipalServiceName": \[

"organizations.amazonaws.com",

"account.amazonaws.com"

\]

}

}

},

{

Effect = "Deny"

Action = \[

"organizations:\*",

"account:CloseAccount",

"iam:DeleteRole",

"iam:DeleteUser"

\]

Resource = "\*"

}

\]

})

}

7.2 緊急時アクセス監視システム

python

*\# 緊急時アクセス監視Lambda関数*

import boto3

import json

import os

from datetime import datetime

def lambda_handler(event, context):

"""

Break Glassロールの使用を監視・通知

"""

try:

*\# CloudTrailイベントから緊急時アクセスを検出*

records = event.get('Records', \[\])

for record in records:

if 'cloudtrail' in record.get('eventSource', '').lower():

cloudtrail_data = json.loads(record\['body'\])

*\# AssumeRoleイベントの確認*

if cloudtrail_data.get('eventName') == 'AssumeRole':

role_arn = cloudtrail_data.get('responseElements',
{}).get('assumedRoleUser', {}).get('arn', '')

*\# Break Glassロールの使用検出*

if 'EmergencyBreakGlassRole' in role_arn:

handle_emergency_access_event(cloudtrail_data)

except Exception as e:

print(f"Error processing emergency access event: {str(e)}")

send_error_notification(str(e))

return {'statusCode': 200}

def handle_emergency_access_event(event_data):

"""

緊急時アクセスイベントの処理

"""

*\# イベント詳細の抽出*

user_identity = event_data.get('userIdentity', {})

source_ip = event_data.get('sourceIPAddress', 'Unknown')

event_time = event_data.get('eventTime', datetime.now().isoformat())

user_name = user_identity.get('userName', 'Unknown')

mfa_used = event_data.get('requestContext', {}).get('mfaAuthenticated',
False)

*\# セキュリティ情報の収集*

security_context = {

'user_name': user_name,

'source_ip': source_ip,

'event_time': event_time,

'mfa_authenticated': mfa_used,

'user_agent': event_data.get('userAgent', 'Unknown'),

'aws_region': event_data.get('awsRegion', 'Unknown')

}

*\# DynamoDBに記録*

record_emergency_access(security_context)

*\# 即座に通知送信*

send_emergency_access_alert(security_context)

*\# 追加の監視開始*

initiate_enhanced_monitoring(user_name, source_ip)

def record_emergency_access(security_context):

"""

緊急時アクセスをDynamoDBに記録

"""

dynamodb = boto3.resource('dynamodb')

table = dynamodb.Table(os.environ\['EMERGENCY_ACCESS_TABLE'\])

try:

table.put_item(

Item={

'access_id':
f"{security_context\['user_name'\]}-{security_context\['event_time'\]}",

'user_name': security_context\['user_name'\],

'source_ip': security_context\['source_ip'\],

'event_time': security_context\['event_time'\],

'mfa_authenticated': security_context\['mfa_authenticated'\],

'user_agent': security_context\['user_agent'\],

'aws_region': security_context\['aws_region'\],

'status': 'ACTIVE',

'created_at': datetime.now().isoformat(),

'ttl': int((datetime.now().timestamp() + (365 \* 24 \* 60 \* 60))) *\#
1年保持*

}

)

except Exception as e:

print(f"Failed to record emergency access: {str(e)}")

def send_emergency_access_alert(security_context):

"""

緊急時アクセスアラートの送信

"""

sns = boto3.client('sns')

*\# アラートメッセージの作成*

alert_message = f"""

🚨 CRITICAL: Emergency Break Glass Access Detected 🚨

User: {security_context\['user_name'\]}

Time: {security_context\['event_time'\]}

Source IP: {security_context\['source_ip'\]}

MFA Used: {'Yes' if security_context\['mfa_authenticated'\] else 'No'}

User Agent: {security_context\['user_agent'\]}

Region: {security_context\['aws_region'\]}

This is an automated alert for emergency administrative access.

Immediate investigation required.

Security Dashboard: https://console.aws.amazon.com/securityhub/

CloudTrail Logs: https://console.aws.amazon.com/cloudtrail/

"""

*\# 複数チャネルに通知*

notification_topics = \[

os.environ\['SECURITY_ALERTS_TOPIC'\],

os.environ\['EMERGENCY_ALERTS_TOPIC'\]

\]

for topic_arn in notification_topics:

try:

sns.publish(

TopicArn=topic_arn,

Subject="🚨 EMERGENCY: Break Glass Access Detected",

Message=alert_message

)

except Exception as e:

print(f"Failed to send alert to {topic_arn}: {str(e)}")

def initiate_enhanced_monitoring(user_name, source_ip):

"""

緊急時アクセス後の強化監視開始

"""

cloudwatch = boto3.client('cloudwatch')

*\# カスタムメトリクスアラームの作成*

try:

cloudwatch.put_metric_alarm(

AlarmName=f'EmergencyAccess-{user_name}-EnhancedMonitoring',

ComparisonOperator='GreaterThanThreshold',

EvaluationPeriods=1,

MetricName='APICallCount',

Namespace='TechNova/EmergencyAccess',

Period=300, *\# 5分間隔*

Statistic='Sum',

Threshold=50.0, *\# 5分間で50回以上のAPI呼び出し*

ActionsEnabled=True,

AlarmActions=\[

os.environ\['EMERGENCY_ALERTS_TOPIC'\]

\],

AlarmDescription=f'Enhanced monitoring for emergency access by
{user_name}',

Dimensions=\[

{

'Name': 'UserName',

'Value': user_name

},

{

'Name': 'SourceIP',

'Value': source_ip

}

\]

)

except Exception as e:

print(f"Failed to create enhanced monitoring alarm: {str(e)}")

7.3 緊急時プロシージャ

yaml

emergency_procedures:

*\# レベル1: サービス障害対応*

service_outage:

trigger: "重要サービスの完全停止"

response_time: "15分以内"

authorized_personnel:

\- "SREチームリーダー"

\- "ITマネージャー"

access_scope: "影響を受けたサービスのアカウントのみ"

approval_process: "口頭承認 + 事後報告"

*\# レベル2: セキュリティインシデント*

security_incident:

trigger: "セキュリティ侵害の疑い"

response_time: "5分以内"

authorized_personnel:

\- "CISOまたは代理"

\- "セキュリティチームリーダー"

access_scope: "全アカウント（必要に応じて）"

approval_process: "CISO承認 + リアルタイム監視"

*\# レベル3: 法的・規制対応*

legal_compliance:

trigger: "法執行機関からの要請"

response_time: "状況に応じて"

authorized_personnel:

\- "法務部長"

\- "コンプライアンス責

再試行

C

続ける

編集

authorized_personnel: - "法務部長" - "コンプライアンス責任者" -
"CEO承認済み担当者" access_scope: "要請対象のアカウント・データのみ"
approval_process: "CEO + 法務部長の書面承認"

emergency_access_matrix: break_glass_levels: level_1_service_recovery:
max_duration: "2時間" required_approvals: 1 post_incident_review:
"24時間以内" automatic_revocation: true

level_2_security_response:

max_duration: "4時間"

required_approvals: 2

post_incident_review: "12時間以内"

automatic_revocation: true

continuous_monitoring: true

level_3_legal_compliance:

max_duration: "状況に応じて"

required_approvals: 3

post_incident_review: "即時"

automatic_revocation: false

legal_documentation: true

post_emergency_procedures: immediate_actions: - "アクセス終了の確認" -
"実行されたアクションの記録" - "関係者への報告"

documentation_requirements: - "緊急時アクセス理由書" -
"実行されたコマンド・変更のログ" - "インシデント対応レポート" -
"改善提案書"

review_process: - "48時間以内のレビュー会議" - "根本原因分析" -
"プロセス改善の検討" - "必要に応じた権限見直し"

\## 8. 監視・ログ戦略

\### 8.1 包括的監視アーキテクチャ

\`\`\`hcl

\# AWS Config - 設定変更監視

resource "aws_config_configuration_recorder" "security_recorder" {

name = "TechNova-Security-Configuration-Recorder"

role_arn = aws_iam_role.config_recorder_role.arn

recording_group {

all_supported = true

include_global_resource_types = true

\# 重要なリソースタイプを明示的に指定

resource_types = \[

"AWS::IAM::Role",

"AWS::IAM::Policy",

"AWS::IAM::User",

"AWS::S3::Bucket",

"AWS::KMS::Key",

"AWS::EC2::SecurityGroup",

"AWS::Organizations::Account"

\]

}

depends_on = \[aws_config_delivery_channel.security_channel\]

}

\# GuardDuty - 脅威検出

resource "aws_guardduty_detector" "main" {

enable = true

\# S3保護の有効化

datasources {

s3_logs {

enable = true

}

kubernetes {

audit_logs {

enable = true

}

}

malware_protection {

scan_ec2_instance_with_findings {

ebs_volumes {

enable = true

}

}

}

}

tags = {

Purpose = "Threat Detection"

Environment = "Organization"

}

}

\# Security Hub - 統合セキュリティ監視

resource "aws_securityhub_account" "main" {

enable_default_standards = true

}

\# CloudWatch メトリクスフィルター - 重要なIAMイベント

resource "aws_cloudwatch_log_metric_filter" "root_usage" {

name = "RootAccountUsage"

log_group_name = aws_cloudwatch_log_group.cloudtrail.name

pattern = "{ \$.userIdentity.type = \\Root\\ &&
\$.userIdentity.invokedBy NOT EXISTS && \$.eventType !=
\\AwsServiceEvent\\ }"

metric_transformation {

name = "RootAccountUsageCount"

namespace = "TechNova/Security"

value = "1"

}

}

resource "aws_cloudwatch_log_metric_filter" "unauthorized_api_calls" {

name = "UnauthorizedAPICalls"

log_group_name = aws_cloudwatch_log_group.cloudtrail.name

pattern = "{ (\$.errorCode = \\\*UnauthorizedOperation\\) \|\|
(\$.errorCode = \\AccessDenied\*\\) }"

metric_transformation {

name = "UnauthorizedAPICallsCount"

namespace = "TechNova/Security"

value = "1"

}

}

resource "aws_cloudwatch_log_metric_filter" "iam_policy_changes" {

name = "IAMPolicyChanges"

log_group_name = aws_cloudwatch_log_group.cloudtrail.name

pattern = "{ (\$.eventName = CreatePolicy) \|\| (\$.eventName =
DeletePolicy) \|\| (\$.eventName = CreatePolicyVersion) \|\|
(\$.eventName = DeletePolicyVersion) \|\| (\$.eventName =
AttachRolePolicy) \|\| (\$.eventName = DetachRolePolicy) }"

metric_transformation {

name = "IAMPolicyChangesCount"

namespace = "TechNova/Security"

value = "1"

}

}

8.2 リアルタイム脅威検出

python

*\# リアルタイム脅威検出Lambda関数*

import boto3

import json

import os

from datetime import datetime

import hashlib

class ThreatDetectionEngine:

def \_\_init\_\_(self):

self.guardduty = boto3.client('guardduty')

self.securityhub = boto3.client('securityhub')

self.sns = boto3.client('sns')

self.dynamodb = boto3.resource('dynamodb')

self.threat_table =
self.dynamodb.Table(os.environ\['THREAT_DETECTION_TABLE'\])

def process_security_event(self, event):

"""

セキュリティイベントの処理

"""

try:

*\# イベントソースの判定*

if 'guardduty' in event.get('source', '').lower():

return self.handle_guardduty_finding(event)

elif 'securityhub' in event.get('source', '').lower():

return self.handle_securityhub_finding(event)

elif 'cloudtrail' in event.get('source', '').lower():

return self.handle_cloudtrail_event(event)

else:

return self.handle_generic_security_event(event)

except Exception as e:

print(f"Error processing security event: {str(e)}")

return {'statusCode': 500, 'error': str(e)}

def handle_guardduty_finding(self, event):

"""

GuardDuty脅威検出の処理

"""

detail = event.get('detail', {})

finding_id = detail.get('id', 'unknown')

severity = detail.get('severity', 0)

finding_type = detail.get('type', 'Unknown')

*\# 脅威レベルの判定*

threat_level = self.determine_threat_level(severity, finding_type)

*\# 脅威情報の記録*

threat_record = {

'finding_id': finding_id,

'source': 'GuardDuty',

'type': finding_type,

'severity': severity,

'threat_level': threat_level,

'timestamp': datetime.now().isoformat(),

'account_id': detail.get('accountId', 'unknown'),

'region': detail.get('region', 'unknown'),

'resource': detail.get('resource', {}),

'evidence': detail.get('service', {}).get('evidence', {})

}

self.store_threat_record(threat_record)

*\# 自動対応の実行*

if threat_level in \['CRITICAL', 'HIGH'\]:

self.initiate_automated_response(threat_record)

*\# 通知送信*

self.send_threat_notification(threat_record)

return {'statusCode': 200, 'threat_level': threat_level}

def determine_threat_level(self, severity, finding_type):

"""

脅威レベルの判定

"""

*\# GuardDutyの数値重要度を文字列に変換*

if severity \>= 7.0:

base_level = 'HIGH'

elif severity \>= 4.0:

base_level = 'MEDIUM'

else:

base_level = 'LOW'

*\# 脅威タイプによる調整*

critical_threats = \[

'UnauthorizedAPICall',

'InstanceCredentialExfiltration',

'CryptoCurrency',

'Backdoor',

'Trojan'

\]

high_priority_threats = \[

'Recon',

'ResourceConsumption',

'Stealth',

'Persistence'

\]

if any(critical in finding_type for critical in critical_threats):

return 'CRITICAL'

elif any(high in finding_type for high in high_priority_threats):

return 'HIGH' if base_level != 'LOW' else 'MEDIUM'

else:

return base_level

def initiate_automated_response(self, threat_record):

"""

自動対応の実行

"""

finding_type = threat_record\['type'\]

resource = threat_record.get('resource', {})

try:

*\# EC2インスタンス関連の脅威*

if 'EC2' in resource.get('resourceType', ''):

instance_id = resource.get('instanceDetails', {}).get('instanceId')

if instance_id:

self.isolate_ec2_instance(instance_id, threat_record\['account_id'\])

*\# IAM関連の脅威*

elif 'IAMUser' in resource.get('resourceType', ''):

user_name = resource.get('accessKeyDetails', {}).get('userName')

if user_name:

self.disable_iam_user(user_name, threat_record\['account_id'\])

*\# S3関連の脅威*

elif 'S3Bucket' in resource.get('resourceType', ''):

bucket_name = resource.get('s3BucketDetails', \[{}\])\[0\].get('name')

if bucket_name:

self.secure_s3_bucket(bucket_name, threat_record\['account_id'\])

except Exception as e:

print(f"Automated response failed: {str(e)}")

*\# 自動対応失敗の通知*

self.send_response_failure_alert(threat_record, str(e))

def isolate_ec2_instance(self, instance_id, account_id):

"""

EC2インスタンスの隔離

"""

*\# クロスアカウントロールでターゲットアカウントにアクセス*

assumed_role = self.assume_security_role(account_id)

ec2 = boto3.client('ec2',

aws_access_key_id=assumed_role\['AccessKeyId'\],

aws_secret_access_key=assumed_role\['SecretAccessKey'\],

aws_session_token=assumed_role\['SessionToken'\]

)

try:

*\# 隔離用セキュリティグループの作成/取得*

isolation_sg = self.get_or_create_isolation_security_group(ec2)

*\# インスタンスのセキュリティグループを隔離用に変更*

ec2.modify_instance_attribute(

InstanceId=instance_id,

Groups=\[isolation_sg\['GroupId'\]\]

)

*\# インスタンスにタグ付け*

ec2.create_tags(

Resources=\[instance_id\],

Tags=\[

{'Key': 'SecurityStatus', 'Value': 'ISOLATED'},

{'Key': 'IsolationReason', 'Value': 'GuardDuty_Threat_Detection'},

{'Key': 'IsolationTime', 'Value': datetime.now().isoformat()}

\]

)

print(f"Successfully isolated EC2 instance: {instance_id}")

except Exception as e:

print(f"Failed to isolate EC2 instance {instance_id}: {str(e)}")

raise

def disable_iam_user(self, user_name, account_id):

"""

IAMユーザーの無効化

"""

assumed_role = self.assume_security_role(account_id)

iam = boto3.client('iam',

aws_access_key_id=assumed_role\['AccessKeyId'\],

aws_secret_access_key=assumed_role\['SecretAccessKey'\],

aws_session_token=assumed_role\['SessionToken'\]

)

try:

*\# アクセスキーの無効化*

access_keys = iam.list_access_keys(UserName=user_name)

for key in access_keys\['AccessKeyMetadata'\]:

iam.update_access_key(

UserName=user_name,

AccessKeyId=key\['AccessKeyId'\],

Status='Inactive'

)

*\# ユーザーにタグ付け*

iam.tag_user(

UserName=user_name,

Tags=\[

{'Key': 'SecurityStatus', 'Value': 'DISABLED'},

{'Key': 'DisableReason', 'Value': 'GuardDuty_Threat_Detection'},

{'Key': 'DisableTime', 'Value': datetime.now().isoformat()}

\]

)

print(f"Successfully disabled IAM user: {user_name}")

except Exception as e:

print(f"Failed to disable IAM user {user_name}: {str(e)}")

raise

def send_threat_notification(self, threat_record):

"""

脅威通知の送信

"""

threat_level = threat_record\['threat_level'\]

*\# 通知内容の作成*

notification_message = f"""

🚨 SECURITY THREAT DETECTED 🚨

Threat Level: {threat_level}

Source: {threat_record\['source'\]}

Type: {threat_record\['type'\]}

Severity: {threat_record\['severity'\]}

Account: {threat_record\['account_id'\]}

Region: {threat_record\['region'\]}

Time: {threat_record\['timestamp'\]}

Resource Details:

{json.dumps(threat_record\['resource'\], indent=2)}

Automated Response: {'Initiated' if threat_level in \['CRITICAL',
'HIGH'\] else 'Not Required'}

View in Security Hub: https://console.aws.amazon.com/securityhub/

View in GuardDuty: https://console.aws.amazon.com/guardduty/

"""

*\# 脅威レベルに応じた通知先の選択*

if threat_level == 'CRITICAL':

topic_arn = os.environ\['CRITICAL_SECURITY_ALERTS_TOPIC'\]

elif threat_level == 'HIGH':

topic_arn = os.environ\['HIGH_SECURITY_ALERTS_TOPIC'\]

else:

topic_arn = os.environ\['GENERAL_SECURITY_ALERTS_TOPIC'\]

try:

self.sns.publish(

TopicArn=topic_arn,

Subject=f"🚨 {threat_level} Security Threat: {threat_record\['type'\]}",

Message=notification_message

)

except Exception as e:

print(f"Failed to send threat notification: {str(e)}")

def lambda_handler(event, context):

"""

脅威検出Lambda関数のメインハンドラー

"""

detector = ThreatDetectionEngine()

try:

*\# イベントレコードの処理*

if 'Records' in event:

results = \[\]

for record in event\['Records'\]:

*\# SNSレコードからの実際のイベント抽出*

if 'Sns' in record:

actual_event = json.loads(record\['Sns'\]\['Message'\])

result = detector.process_security_event(actual_event)

results.append(result)

return {'statusCode': 200, 'results': results}

else:

*\# 直接のイベント処理*

return detector.process_security_event(event)

except Exception as e:

print(f"Lambda handler error: {str(e)}")

return {'statusCode': 500, 'error': str(e)}

8.3 セキュリティメトリクスとアラート

hcl

*\# CloudWatch アラーム設定*

resource "aws_cloudwatch_metric_alarm" "root_account_usage" {

alarm_name = "RootAccountUsage"

comparison_operator = "GreaterThanOrEqualToThreshold"

evaluation_periods = "1"

metric_name = "RootAccountUsageCount"

namespace = "TechNova/Security"

period = "60"

statistic = "Sum"

threshold = "1"

alarm_description = "Root account usage detected"

alarm_actions = \[aws_sns_topic.critical_security_alerts.arn\]

tags = {

Severity = "CRITICAL"

Purpose = "Root Account Monitoring"

}

}

resource "aws_cloudwatch_metric_alarm" "failed_console_logins" {

alarm_name = "FailedConsoleLogins"

comparison_operator = "GreaterThanThreshold"

evaluation_periods = "2"

metric_name = "ConsoleLoginFailures"

namespace = "TechNova/Security"

period = "300"

statistic = "Sum"

threshold = "5"

alarm_description = "Multiple failed console login attempts detected"

alarm_actions = \[aws_sns_topic.security_alerts.arn\]

tags = {

Severity = "HIGH"

Purpose = "Login Monitoring"

}

}

*\# GuardDutyカスタムアラート*

resource "aws_cloudwatch_event_rule" "guardduty_high_severity" {

name = "guardduty-high-severity-findings"

description = "GuardDuty high severity findings"

event_pattern = jsonencode({

source = \["aws.guardduty"\]

detail-type = \["GuardDuty Finding"\]

detail = {

severity = \[{

numeric = \["\>", 7.0\]

}\]

}

})

}

resource "aws_cloudwatch_event_target" "guardduty_lambda_target" {

rule = aws_cloudwatch_event_rule.guardduty_high_severity.name

target_id = "GuardDutyLambdaTarget"

arn = aws_lambda_function.threat_detection.arn

}

*\# セキュリティメトリクスダッシュボード*

resource "aws_cloudwatch_dashboard" "security_metrics" {

dashboard_name = "TechNova-Security-Metrics"

dashboard_body = jsonencode({

widgets = \[

{

type = "metric"

x = 0

y = 0

width = 12

height = 6

properties = {

metrics = \[

\["TechNova/Security", "RootAccountUsageCount"\],

\[".", "UnauthorizedAPICallsCount"\],

\[".", "IAMPolicyChangesCount"\],

\[".", "ConsoleLoginFailures"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "Security Events Timeline"

period = 300

}

},

{

type = "metric"

x = 12

y = 0

width = 12

height = 6

properties = {

metrics = \[

\["AWS/GuardDuty", "FindingCount", "DetectorId",
aws_guardduty_detector.main.id\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "GuardDuty Findings"

period = 300

}

},

{

type = "log"

x = 0

y = 6

width = 24

height = 6

properties = {

query = "SOURCE '/aws/lambda/threat-detection' \| fields @timestamp,
@message \| filter @message like /CRITICAL/ \| sort @timestamp desc \|
limit 20"

region = "ap-northeast-1"

title = "Critical Security Events"

view = "table"

}

}

\]

})

}

9\. 実装ガイドライン

9.1 フェーズ別実装計画

yaml

implementation_phases:

*\# フェーズ1: 基盤構築（1-2ヶ月）*

phase_1_foundation:

duration: "8週間"

objectives:

\- "IAM Identity Center設定"

\- "基本Permission Set作成"

\- "CloudTrail・Config設定"

\- "基本監視の実装"

deliverables:

\- "Identity Center統合完了"

\- "基本権限体系構築"

\- "監査ログ基盤構築"

success_criteria:

\- "全アカウントでSSO認証可能"

\- "監査ログ100%取得"

\- "基本セキュリティアラート動作"

*\# フェーズ2: 権限最適化（2-3ヶ月）*

phase_2_optimization:

duration: "6週間"

objectives:

\- "最小権限ポリシー実装"

\- "ABAC導入"

\- "JITアクセス実装"

\- "クロスアカウント権限最適化"

deliverables:

\- "カスタムPermission Set完了"

\- "JITアクセス機能稼働"

\- "権限認証プロセス確立"

success_criteria:

\- "過剰権限50%削減"

\- "JITアクセス利用率80%"

\- "権限認証プロセス100%遵守"

*\# フェーズ3: 高度なセキュリティ（3-4ヶ月）*

phase_3_advanced_security:

duration: "6週間"

objectives:

\- "脅威検出システム完全実装"

\- "自動対応機能実装"

\- "Break Glassプロセス確立"

\- "コンプライアンス自動化"

deliverables:

\- "脅威検出・対応システム稼働"

\- "緊急時アクセス体制確立"

\- "コンプライアンス監視自動化"

success_criteria:

\- "脅威検出率95%以上"

\- "自動対応時間5分以内"

\- "コンプライアンス準拠率100%"

*\# フェーズ4: 運用最適化（継続）*

phase_4_optimization:

duration: "継続的"

objectives:

\- "運用プロセス最適化"

\- "性能監視・改善"

\- "セキュリティポスチャ向上"

\- "ユーザビリティ改善"

deliverables:

\- "運用手順書完備"

\- "性能ベンチマーク確立"

\- "継続的改善プロセス"

success_criteria:

\- "運用効率20%向上"

\- "ユーザー満足度90%以上"

\- "セキュリティインシデント0件"

9.2 実装チェックリスト

yaml

implementation_checklist:

*\# 事前準備*

prerequisites:

\- name: "AWS Organizations設定確認"

status: "required"

owner: "IT管理者"

estimated_hours: 8

\- name: "既存IAMユーザー・ロール調査"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 40

\- name: "コンプライアンス要件整理"

status: "required"

owner: "コンプライアンス"

estimated_hours: 16

\- name: "既存権限の文書化"

status: "required"

owner: "各事業部門"

estimated_hours: 80

*\# IAM Identity Center設定*

identity_center_setup:

\- name: "Identity Center有効化"

status: "required"

owner: "IT管理者"

estimated_hours: 4

dependencies: \["Organizations設定確認"\]

\- name: "外部IDプロバイダー統合"

status: "required"

owner: "IT管理者"

estimated_hours: 16

dependencies: \["Identity Center有効化"\]

\- name: "基本Permission Set作成"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 24

dependencies: \["外部IDプロバイダー統合"\]

\- name: "ユーザー・グループマッピング"

status: "required"

owner: "HR・IT管理者"

estimated_hours: 32

dependencies: \["基本Permission Set作成"\]

*\# セキュリティ監視設定*

security_monitoring:

\- name: "CloudTrail組織レベル設定"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 8

\- name: "GuardDuty全アカウント有効化"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 16

\- name: "Security Hub統合設定"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 12

\- name: "Config Rules設定"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 20

*\# 権限最適化*

permission_optimization:

\- name: "最小権限ポリシー作成"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 60

\- name: "ABAC実装"

status: "recommended"

owner: "セキュリティチーム"

estimated_hours: 40

\- name: "JITアクセス実装"

status: "recommended"

owner: "セキュリティチーム"

estimated_hours: 80

\- name: "クロスアカウント権限整理"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 48

*\# テスト・検証*

testing_validation:

\- name: "権限テストシナリオ実行"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 40

\- name: "緊急時アクセステスト"

status: "required"

owner: "セキュリティチーム"

estimated_hours: 16

\- name: "ユーザー受け入れテスト"

status: "required"

owner: "各事業部門"

estimated_hours: 80

\- name: "性能・可用性テスト"

status: "recommended"

owner: "SREチーム"

estimated_hours: 32

estimated_total_effort:

total_hours: 592

total_weeks: "約15週間（複数人並行作業想定）"

critical_path: "既存権限調査 → Permission Set作成 → ユーザーマッピング →
テスト"

9.3 トレーニングと変更管理

yaml

training_change_management:

*\# ステークホルダー別トレーニング*

stakeholder_training:

executives:

content:

\- "セキュリティガバナンス概要"

\- "コンプライアンス要件と対応"

\- "ROI・リスク削減効果"

duration: "2時間"

delivery_method: "プレゼンテーション"

it_administrators:

content:

\- "IAM Identity Center管理"

\- "Permission Set設計・運用"

\- "トラブルシューティング"

\- "緊急時対応手順"

duration: "2日間"

delivery_method: "ハンズオン研修"

security_team:

content:

\- "セキュリティ監視・分析"

\- "脅威検出・対応"

\- "コンプライアンス監査"

\- "インシデント対応"

duration: "3日間"

delivery_method: "専門研修"

end_users:

content:

\- "新しいログイン方法"

\- "権限申請プロセス"

\- "セキュリティベストプラクティス"

duration: "1時間"

delivery_method: "eラーニング"

developers:

content:

\- "開発環境でのアクセス管理"

\- "IaCでの権限設定"

\- "セキュリティ考慮事項"

duration: "4時間"

delivery_method: "技術研修"

*\# 変更管理プロセス*

change_management:

communication_plan:

\- phase: "事前告知（4週間前）"

content: "変更概要・スケジュール・影響"

channels: \["全社メール", "イントラネット"\]

\- phase: "詳細説明（2週間前）"

content: "具体的な変更内容・手順"

channels: \["部門説明会", "FAQ公開"\]

\- phase: "直前リマインダー（1週間前）"

再試行

C

続ける

編集

content: "最終確認・準備事項" channels: \["個別メール", "Slack通知"\]

\- phase: "実施中（リアルタイム）"

content: "進捗状況・問題報告"

channels: \["専用Slackチャネル", "ステータスページ"\]

\- phase: "完了報告（実施後）"

content: "完了確認・次のステップ"

channels: \["全社メール", "成果レポート"\]

risk_mitigation:

rollback_plan:

\- "各フェーズでのロールバックポイント設定"

\- "緊急時の権限復旧手順"

\- "ビジネス継続性確保策"

user_support:

\- "移行期間中のヘルプデスク体制強化"

\- "FAQ・トラブルシューティングガイド"

\- "エスカレーション手順明確化"

business_continuity:

\- "段階的移行による影響最小化"

\- "重要業務への影響回避"

\- "緊急時アクセス経路確保"

成功指標とモニタリング

success_metrics: adoption_metrics: - name: "SSO利用率" target: "95%以上"
measurement: "月次"

\- name: "権限申請処理時間"

target: "平均2時間以内"

measurement: "週次"

\- name: "ユーザー満足度"

target: "4.0/5.0以上"

measurement: "四半期"

security_metrics:

\- name: "過剰権限削減率"

target: "50%以上削減"

measurement: "月次"

\- name: "セキュリティインシデント"

target: "前年比50%削減"

measurement: "月次"

\- name: "コンプライアンススコア"

target: "95%以上"

measurement: "月次"

operational_metrics:

\- name: "権限管理工数"

target: "前年比30%削減"

measurement: "四半期"

\- name: "システム可用性"

target: "99.9%以上"

measurement: "月次"

\- name: "問い合わせ件数"

target: "導入前の20%以下"

measurement: "週次"

\### 9.4 運用・保守計画

\`\`\`yaml

operations_maintenance:

\# 日常運用業務

daily_operations:

monitoring_tasks:

\- name: "セキュリティアラート確認"

frequency: "毎時"

owner: "NOCチーム"

estimated_time: "15分"

\- name: "システム健全性チェック"

frequency: "日次"

owner: "SREチーム"

estimated_time: "30分"

\- name: "権限申請処理"

frequency: "随時"

owner: "IT管理者"

estimated_time: "1件10分"

incident_response:

\- name: "セキュリティインシデント対応"

sla: "検知から15分以内"

owner: "セキュリティチーム"

\- name: "システム障害対応"

sla: "検知から30分以内"

owner: "SREチーム"

\- name: "権限関連問題対応"

sla: "報告から2時間以内"

owner: "IT管理者"

\# 定期保守業務

periodic_maintenance:

weekly_tasks:

\- name: "アクセスログレビュー"

owner: "セキュリティチーム"

estimated_time: "2時間"

\- name: "システム性能分析"

owner: "SREチーム"

estimated_time: "1時間"

\- name: "新規アカウント設定"

owner: "IT管理者"

estimated_time: "可変"

monthly_tasks:

\- name: "権限利用状況分析"

owner: "セキュリティチーム"

estimated_time: "4時間"

\- name: "セキュリティポスチャ評価"

owner: "セキュリティチーム"

estimated_time: "8時間"

\- name: "コンプライアンスレポート作成"

owner: "コンプライアンス"

estimated_time: "6時間"

quarterly_tasks:

\- name: "アクセス権限認証"

owner: "各部門管理者"

estimated_time: "部門あたり4時間"

\- name: "災害復旧テスト"

owner: "SREチーム"

estimated_time: "1日"

\- name: "セキュリティ設定見直し"

owner: "セキュリティチーム"

estimated_time: "16時間"

\# 継続的改善

continuous_improvement:

performance_optimization:

\- name: "レスポンス時間最適化"

frequency: "月次"

method: "性能メトリクス分析"

\- name: "コスト最適化"

frequency: "四半期"

method: "利用状況分析・rightsizing"

\- name: "ユーザビリティ改善"

frequency: "四半期"

method: "ユーザーフィードバック分析"

security_enhancement:

\- name: "脅威ランドスケープ更新"

frequency: "月次"

method: "脅威インテリジェンス分析"

\- name: "検知ルール最適化"

frequency: "月次"

method: "偽陽性・偽陰性分析"

\- name: "新規セキュリティサービス評価"

frequency: "四半期"

method: "技術動向調査・PoC実施"

compliance_maintenance:

\- name: "規制要件更新対応"

frequency: "随時"

method: "法規制動向監視"

\- name: "内部監査対応"

frequency: "年次"

method: "監査要件準拠確認"

\- name: "外部監査対応"

frequency: "年次"

method: "第三者監査準備・対応"

9.5 成功要因と注意点

yaml

success_factors:

*\# 成功要因*

critical_success_factors:

executive_support:

importance: "最重要"

description: "経営陣の明確なサポートとリソース確保"

actions:

\- "CXOレベルでのプロジェクト承認"

\- "十分な予算・人的リソース確保"

\- "変更管理への積極的関与"

cross_functional_collaboration:

importance: "重要"

description: "部門横断的な協力体制構築"

actions:

\- "セキュリティ・IT・事業部門の連携"

\- "定期的なステークホルダー会議"

\- "明確な役割・責任分担"

phased_implementation:

importance: "重要"

description: "段階的な実装による影響最小化"

actions:

\- "パイロットアカウントでの検証"

\- "段階的ロールアウト"

\- "各フェーズでの成果確認"

user_training:

importance: "重要"

description: "十分なユーザートレーニングと支援"

actions:

\- "役割別トレーニングプログラム"

\- "充実したドキュメント"

\- "継続的なサポート体制"

*\# 注意点・リスク*

implementation_risks:

technical_risks:

\- risk: "既存システムとの統合問題"

impact: "高"

probability: "中"

mitigation: "事前の互換性検証・テスト環境での確認"

\- risk: "大規模権限変更による業務影響"

impact: "高"

probability: "中"

mitigation: "段階的移行・緊急時復旧手順準備"

\- risk: "複雑な権限設定による運用負荷増"

impact: "中"

probability: "高"

mitigation: "自動化推進・運用手順標準化"

organizational_risks:

\- risk: "ユーザーの変更への抵抗"

impact: "中"

probability: "高"

mitigation: "十分な事前説明・段階的導入"

\- risk: "スキル不足による運用品質低下"

impact: "高"

probability: "中"

mitigation: "継続的なトレーニング・外部支援活用"

\- risk: "変更管理プロセスの不備"

impact: "中"

probability: "中"

mitigation: "明確なプロセス定義・責任者設定"

security_risks:

\- risk: "移行期間中のセキュリティギャップ"

impact: "高"

probability: "中"

mitigation: "並行運用期間設定・監視強化"

\- risk: "緊急時アクセス手順の不備"

impact: "高"

probability: "低"

mitigation: "詳細な緊急時手順・定期的な訓練"

\- risk: "過度なセキュリティによる業務阻害"

impact: "中"

probability: "中"

mitigation: "ユーザビリティとセキュリティのバランス"

*\# 成功指標の設定*

kpi_framework:

security_kpis:

\- name: "セキュリティインシデント削減率"

baseline: "現状のインシデント数"

target: "50%削減"

measurement_period: "年次"

\- name: "権限過剰付与削減率"

baseline: "現状の過剰権限数"

target: "70%削減"

measurement_period: "四半期"

\- name: "コンプライアンス準拠率"

baseline: "現状の準拠率"

target: "100%"

measurement_period: "月次"

operational_kpis:

\- name: "権限管理工数削減率"

baseline: "現状の管理工数"

target: "40%削減"

measurement_period: "四半期"

\- name: "システム可用性"

baseline: "現状の可用性"

target: "99.9%以上"

measurement_period: "月次"

\- name: "平均権限付与時間"

baseline: "現状の処理時間"

target: "2時間以内"

measurement_period: "週次"

user_satisfaction_kpis:

\- name: "ユーザー満足度スコア"

baseline: "導入前の満足度"

target: "4.0/5.0以上"

measurement_period: "四半期"

\- name: "サポート問い合わせ削減率"

baseline: "現状の問い合わせ数"

target: "60%削減"

measurement_period: "月次"

\- name: "権限申請完了率"

baseline: "N/A（新指標）"

target: "95%以上"

measurement_period: "週次"

まとめ

本AWSアカウント・権限設計（基本方針）は、TechNova社の120アカウント構成における包括的な権限管理戦略を定義しています。

主要成果物

ゼロトラスト権限モデルの確立

IAM Identity Centerによる統合認証基盤

最小権限原則の徹底実装

職務分離による不正防止機能

コンプライアンス自動化システム

緊急時アクセス管理機能

包括的監視・ログシステム

事業部門別アカウント構成との統合

本方針は、既に定義された事業部門別アカウント構成の物理的な120アカウント分離構造に対し、論理的な権限管理レイヤーを提供します。両文書が相互補完することで、完全なマルチアカウント戦略が実現されます。

実装による期待効果

セキュリティリスク50%削減

権限管理工数40%削減

コンプライアンス準拠100%達成

運用効率30%向上

監査対応時間75%短縮

この包括的な権限設計により、TechNova社は安全で効率的な、そして規制要件に完全準拠したクラウド環境を実現することができます。

## 自動化要件 - TechNova社マルチアカウント環境

目次

[**概要**](#%E6%A6%82%E8%A6%81)

[**Account Factory for Terraform (AFT)
統合戦略**](#1-account-factory-for-terraform-aft-%E7)

[**CI/CD パイプライン要件**](#2-cicd-%E3%83%91%E3%82%A4%E3%83%97%E3%8)

[**データ移行自動化**](#3-%E3%83%87%E3%83%BC%E3%82%BF%E7%A7%BB%)

[**Infrastructure as Code
自動化**](#4-infrastructure-as-code-%E8%87%AA%E5%8)

[**セキュリティ自動化統合**](#5-%E3%82%BB%E3%82%AD%E3%83%A5%E3%83%AA%)

[**監視・運用自動化**](#6-%E7%9B%A3%E8%A6%96%E9%81%8B%E7%94%A8%)

[**コンプライアンス自動化**](#7-%E3%82%B3%E3%83%B3%E3%83%97%E3%83%A9%)

[**災害復旧自動化**](#8-%E7%81%BD%E5%AE%B3%E5%BE%A9%E6%97%A7%)

[**実装ロードマップ**](#9-%E5%AE%9F%E8%A3%85%E3%83%AD%E3%83%BC%)

概要

自動化戦略の背景

TechNova社の120アカウント構成、事業部門別アカウント分離、およびDevSecOpsパイプラインを支援する包括的な自動化基盤を構築します。既存のIaC
&
CI/CD統合セキュリティ分析パイプラインとAWSアカウント・権限設計と完全に整合した自動化要件を定義します。

自動化の目標

アカウントライフサイクル管理の完全自動化

セキュリティ設定の一貫性確保

CI/CDパイプラインの標準化

データ移行プロセスの自動化

運用業務の効率化

コンプライアンスの自動検証

アーキテクチャ概要

┌─────────────────────────────────────────────────────────────────┐

│ Management Account │

│ ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │

│ │ AFT │ │ Control │ │ Audit & │ │

│ │ Master │ │ Tower │ │ Logging │ │

│ └──────────────┘ └──────────────┘ └──────────────────────┘ │

└─────────────────────────────────────────────────────────────────┘

│

▼

┌─────────────────────────────────────────────────────────────────┐

│ AFT Management Account │

│ ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │

│ │ Account │ │ Baseline │ │ Customization │ │

│ │ Vending │ │ Pipeline │ │ Pipeline │ │

│ └──────────────┘ └──────────────┘ └──────────────────────┘ │

└─────────────────────────────────────────────────────────────────┘

│

▼

┌─────────────────────────────────────────────────────────────────┐

│ Provisioned Accounts │

│ ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │

│ │ Product │ │ Marketing │ │ Data Analytics │ │

│ │ Development │ │ Platform │ │ Platform │ │

│ └──────────────┘ └──────────────┘ └──────────────────────┘ │

└─────────────────────────────────────────────────────────────────┘

1\. Account Factory for Terraform (AFT) 統合戦略

1.1 AFT アーキテクチャ設計

hcl

*\# AFT Module Configuration*

module "aft" {

source = "github.com/aws-ia/terraform-aws-control_tower_account_factory"

*\# AFT管理設定*

ct_management_account_id = var.management_account_id

log_archive_account_id = var.log_archive_account_id

audit_account_id = var.audit_account_id

aft_management_account_id = var.aft_management_account_id

*\# リージョン設定（事業部門別アカウント構成と整合）*

ct_home_region = "ap-northeast-1"

tf_backend_secondary_region = "us-east-1"

*\# VCS統合設定*

vcs_provider = "github"

account_request_repo_name = "technova-aft-account-requests"

global_customizations_repo_name = "technova-aft-global-customizations"

account_customizations_repo_name = "technova-aft-account-customizations"

account_provisioning_customizations_repo_name =
"technova-aft-account-provisioning"

*\# セキュリティ設定（権限設計と整合）*

aft_enable_vpc_logs = true

aft_vpc_cidr = "10.192.0.0/20"

aft_vpc_private_subnet_01_cidr = "10.192.0.0/24"

aft_vpc_private_subnet_02_cidr = "10.192.1.0/24"

aft_vpc_public_subnet_01_cidr = "10.192.2.0/24"

aft_vpc_public_subnet_02_cidr = "10.192.3.0/24"

*\# Terraform設定*

terraform_distribution = "oss"

terraform_version = "1.5.7"

tags = {

Environment = "AFT-Management"

Purpose = "Account Factory"

Owner = "TechNova-Platform-Team"

}

}

1.2 アカウント要求テンプレート

python

*\# Account Request Template Generator*

import json

import yaml

from typing import Dict, List, Any

from datetime import datetime

class AccountRequestGenerator:

def \_\_init\_\_(self):

self.account_templates = {

"product_development": self.\_get_product_dev_template(),

"marketing_platform": self.\_get_marketing_template(),

"data_analytics": self.\_get_data_analytics_template(),

"shared_services": self.\_get_shared_services_template(),

"security_tooling": self.\_get_security_template()

}

def generate_account_request(self,

business_unit: str,

environment: str,

requester_info: Dict\[str, str\],

additional_configs: Dict\[str, Any\] = None) -\> Dict\[str, Any\]:

"""

事業部門別アカウント要求の生成

"""

base_template = self.account_templates.get(business_unit)

if not base_template:

raise ValueError(f"Unknown business unit: {business_unit}")

*\# アカウント名の生成（事業部門別アカウント構成に従う）*

account_name = f"technova-{business_unit}-{environment}"

account_email = f"aws-{business_unit}-{environment}@technova.com"

account_request = {

"control_tower_parameters": {

"AccountName": account_name,

"AccountEmail": account_email,

"SSOUserEmail": requester_info\["email"\],

"SSOUserFirstName": requester_info\["first_name"\],

"SSOUserLastName": requester_info\["last_name"\],

"ManagedOrganizationalUnit":
self.\_get_ou_for_business_unit(business_unit, environment),

"SSOUserPortalAccess": "STANDARD"

},

"account_tags": {

"BusinessUnit": business_unit,

"Environment": environment,

"Owner": requester_info\["email"\],

"CostCenter": requester_info.get("cost_center", ""),

"Project": requester_info.get("project", ""),

"CreatedDate": datetime.now().strftime("%Y-%m-%d"),

"Compliance": self.\_get_compliance_requirements(business_unit),

"BackupRequired": "true" if environment == "prod" else "false"

},

"account_customizations_name":
f"{business_unit}-{environment}-customizations",

"custom_fields": base_template\["custom_fields"\]

}

*\# 追加設定の適用*

if additional_configs:

account_request\["custom_fields"\].update(additional_configs)

return account_request

def \_get_product_dev_template(self) -\> Dict\[str, Any\]:

"""

製品開発アカウント用テンプレート

"""

return {

"custom_fields": {

"vpc_configuration": {

"enable_vpc": True,

"vpc_cidr": "10.0.0.0/16",

"availability_zones": \["ap-northeast-1a", "ap-northeast-1c",
"ap-northeast-1d"\],

"private_subnets": \["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"\],

"public_subnets": \["10.0.11.0/24", "10.0.12.0/24", "10.0.13.0/24"\],

"enable_nat_gateway": True,

"enable_vpn_gateway": False

},

"security_baseline": {

"enable_guardduty": True,

"enable_security_hub": True,

"enable_config": True,

"enable_cloudtrail": True,

"cloudtrail_kms_encryption": True

},

"development_tools": {

"enable_codecommit": True,

"enable_codebuild": True,

"enable_codepipeline": True,

"enable_ecr": True

},

"monitoring": {

"enable_cloudwatch": True,

"enable_xray": True,

"log_retention_days": 90

},

"backup_configuration": {

"enable_backup": True,

"backup_retention_days": 35,

"backup_schedule": "cron(0 2 ? \* SUN \*)"

}

}

}

def \_get_marketing_template(self) -\> Dict\[str, Any\]:

"""

マーケティングプラットフォーム用テンプレート

"""

return {

"custom_fields": {

"vpc_configuration": {

"enable_vpc": True,

"vpc_cidr": "10.1.0.0/16",

"availability_zones": \["ap-northeast-1a", "ap-northeast-1c"\],

"private_subnets": \["10.1.1.0/24", "10.1.2.0/24"\],

"public_subnets": \["10.1.11.0/24", "10.1.12.0/24"\],

"enable_nat_gateway": True,

"enable_vpn_gateway": False

},

"security_baseline": {

"enable_guardduty": True,

"enable_security_hub": True,

"enable_config": True,

"enable_cloudtrail": True,

"cloudtrail_kms_encryption": True

},

"marketing_tools": {

"enable_personalize": True,

"enable_pinpoint": True,

"enable_ses": True,

"enable_analytics": True

},

"data_storage": {

"enable_s3_data_lake": True,

"enable_redshift": False,

"enable_quicksight": True

},

"compliance": {

"gdpr_compliance": True,

"ccpa_compliance": True,

"data_classification": "PII"

}

}

}

def \_get_data_analytics_template(self) -\> Dict\[str, Any\]:

"""

データ分析プラットフォーム用テンプレート

"""

return {

"custom_fields": {

"vpc_configuration": {

"enable_vpc": True,

"vpc_cidr": "10.2.0.0/16",

"availability_zones": \["ap-northeast-1a", "ap-northeast-1c",
"ap-northeast-1d"\],

"private_subnets": \["10.2.1.0/24", "10.2.2.0/24", "10.2.3.0/24"\],

"database_subnets": \["10.2.21.0/24", "10.2.22.0/24", "10.2.23.0/24"\],

"public_subnets": \["10.2.11.0/24", "10.2.12.0/24", "10.2.13.0/24"\],

"enable_nat_gateway": True,

"enable_vpc_endpoints": True

},

"security_baseline": {

"enable_guardduty": True,

"enable_security_hub": True,

"enable_config": True,

"enable_cloudtrail": True,

"cloudtrail_kms_encryption": True,

"enable_macie": True

},

"analytics_services": {

"enable_emr": True,

"enable_glue": True,

"enable_athena": True,

"enable_kinesis": True,

"enable_redshift": True,

"enable_sagemaker": True

},

"storage_configuration": {

"data_lake_bucket": True,

"enable_s3_intelligent_tiering": True,

"enable_glacier": True,

"encryption_at_rest": True

},

"compliance": {

"sox_compliance": True,

"iso27001_compliance": True,

"data_classification": "CONFIDENTIAL"

}

}

}

def \_get_ou_for_business_unit(self, business_unit: str, environment:
str) -\> str:

"""

事業部門と環境に基づくOU決定

"""

ou_mapping = {

"product_development": {

"dev": "Product Development - Development",

"staging": "Product Development - Staging",

"prod": "Product Development - Production"

},

"marketing_platform": {

"dev": "Marketing - Development",

"staging": "Marketing - Staging",

"prod": "Marketing - Production"

},

"data_analytics": {

"dev": "Data Analytics - Development",

"staging": "Data Analytics - Staging",

"prod": "Data Analytics - Production"

},

"shared_services": {

"prod": "Shared Services"

},

"security_tooling": {

"prod": "Security"

}

}

return ou_mapping.get(business_unit, {}).get(environment, "Sandbox")

def \_get_compliance_requirements(self, business_unit: str) -\> str:

"""

事業部門別コンプライアンス要件

"""

compliance_mapping = {

"product_development": "SOC2,ISO27001",

"marketing_platform": "GDPR,CCPA,SOC2",

"data_analytics": "SOX,ISO27001,SOC2",

"shared_services": "SOC2,ISO27001",

"security_tooling": "SOC2,ISO27001,FedRAMP"

}

return compliance_mapping.get(business_unit, "SOC2")

*\# アカウント要求の自動生成例*

def generate_account_requests():

generator = AccountRequestGenerator()

*\# 製品開発環境のアカウント要求*

prod_dev_request = generator.generate_account_request(

business_unit="product_development",

environment="dev",

requester_info={

"email": "dev-team-lead@technova.com",

"first_name": "Taro",

"last_name": "Yamada",

"cost_center": "TECH-001",

"project": "NextGen-Platform"

}

)

return prod_dev_request

*\# 実際のアカウント要求YAML出力*

def export_account_request_yaml(account_request: Dict\[str, Any\],
filename: str):

"""

AFT用のYAML形式でアカウント要求をエクスポート

"""

with open(filename, 'w') as f:

yaml.dump(account_request, f, default_flow_style=False, sort_keys=False)

1.3 グローバルカスタマイゼーション

hcl

*\# Global Customizations - すべてのアカウントに適用される基本設定*

*\# File: terraform/global-customizations/main.tf*

*\# プロバイダー設定*

terraform {

required_version = "\>= 1.5.0"

required_providers {

aws = {

source = "hashicorp/aws"

version = "~\> 5.0"

}

}

}

*\# 基本的なセキュリティ設定*

module "security_baseline" {

source = "./modules/security-baseline"

account_id = data.aws_caller_identity.current.account_id

region = data.aws_region.current.name

*\# IAM Password Policy（権限設計と整合）*

password_policy = {

minimum_password_length = 14

require_lowercase_characters = true

require_uppercase_characters = true

require_numbers = true

require_symbols = true

allow_users_to_change_password = true

max_password_age = 90

password_reuse_prevention = 12

hard_expiry = false

}

*\# CloudTrail設定（統合セキュリティ監視）*

cloudtrail_config = {

enable_log_file_validation = true

include_global_service_events = true

is_multi_region_trail = true

enable_logging = true

kms_key_id = aws_kms_key.cloudtrail.arn

}

tags = local.common_tags

}

*\# Config Rules（コンプライアンス自動化）*

module "config_rules" {

source = "./modules/config-rules"

*\# 必須のConfig Rules*

required_rules = \[

"encrypted-volumes",

"root-access-key-check",

"mfa-enabled-for-root",

"s3-bucket-server-side-encryption-enabled",

"iam-password-policy",

"cloudtrail-enabled",

"guardduty-enabled-centralized"

\]

tags = local.common_tags

}

*\# GuardDuty設定*

resource "aws_guardduty_detector" "main" {

enable = true

datasources {

s3_logs {

enable = true

}

kubernetes {

audit_logs {

enable = true

}

}

malware_protection {

scan_ec2_instance_with_findings {

ebs_volumes {

enable = true

}

}

}

}

tags = local.common_tags

}

*\# Security Hub設定*

resource "aws_securityhub_account" "main" {

enable_default_standards = true

}

resource "aws_securityhub_standards_subscription" "aws_foundational" {

standards_arn =
"arn:aws:securityhub:::standard/aws-foundational-security"

depends_on = \[aws_securityhub_account.main\]

}

resource "aws_securityhub_standards_subscription" "cis" {

standards_arn =
"arn:aws:securityhub:::standard/cis-aws-foundations-benchmark/v/1.2.0"

depends_on = \[aws_securityhub_account.main\]

}

*\# KMS Key for CloudTrail*

resource "aws_kms_key" "cloudtrail" {

description = "KMS key for CloudTrail logs encryption"

deletion_window_in_days = 7

tags = local.common_tags

}

resource "aws_kms_alias" "cloudtrail" {

name = "alias/cloudtrail-logs"

target_key_id = aws_kms_key.cloudtrail.key_id

}

*\# CloudWatch設定*

module "cloudwatch_baseline" {

source = "./modules/cloudwatch-baseline"

*\# メトリクスフィルター*

metric_filters = \[

{

name = "RootAccountUsage"

pattern = "{ \$.userIdentity.type = \\Root\\ &&
\$.userIdentity.invokedBy NOT EXISTS && \$.eventType !=
\\AwsServiceEvent\\ }"

metric_name = "RootAccountUsageCount"

namespace = "TechNova/Security"

},

{

name = "UnauthorizedAPICalls"

pattern = "{ (\$.errorCode = \\\*UnauthorizedOperation\\) \|\|
(\$.errorCode = \\AccessDenied\*\\) }"

metric_name = "UnauthorizedAPICallsCount"

namespace = "TechNova/Security"

}

\]

tags = local.common_tags

}

*\# 共通タグ*

locals {

common_tags = {

ManagedBy = "AFT"

Organization = "TechNova"

Compliance = "SOC2-ISO27001"

Environment = "baseline"

CostCenter = "IT-PLATFORM"

}

}

*\# データソース*

data "aws_caller_identity" "current" {}

data "aws_region" "current" {}

1.4 アカウント固有カスタマイゼーション

hcl

*\# Account-specific Customizations*

*\# File:
terraform/account-customizations/product-development-dev/main.tf*

*\# 製品開発アカウント専用設定*

module "product_development_vpc" {

source = "../../modules/vpc"

name = "product-dev-vpc"

cidr = "10.0.0.0/16"

azs = \["ap-northeast-1a", "ap-northeast-1c", "ap-northeast-1d"\]

private_subnets = \["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"\]

public_subnets = \["10.0.11.0/24", "10.0.12.0/24", "10.0.13.0/24"\]

enable_nat_gateway = true

enable_vpn_gateway = false

*\# VPC Endpoints for secure access*

enable_s3_endpoint = true

enable_ec2_endpoint = true

enable_ecr_api_endpoint = true

enable_ecr_dkr_endpoint = true

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

ManagedBy = "AFT"

}

}

*\# CI/CD Pipeline Infrastructure*

module "cicd_infrastructure" {

source = "../../modules/cicd"

vpc_id = module.product_development_vpc.vpc_id

private_subnets = module.product_development_vpc.private_subnets

*\# CodeBuild Projects*

codebuild_projects = \[

{

name = "product-api-build"

description = "Product API Build Project"

service_role = aws_iam_role.codebuild_role.arn

artifacts_type = "CODEPIPELINE"

environment = {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/standard:7.0"

type = "LINUX_CONTAINER"

}

source_type = "CODEPIPELINE"

buildspec = "buildspecs/api-build.yml"

},

{

name = "product-frontend-build"

description = "Product Frontend Build Project"

service_role = aws_iam_role.codebuild_role.arn

artifacts_type = "CODEPIPELINE"

environment = {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/standard:7.0"

type = "LINUX_CONTAINER"

}

source_type = "CODEPIPELINE"

buildspec = "buildspecs/frontend-build.yml"

}

\]

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

Purpose = "CICD"

}

}

*\# ECR Repositories*

module "ecr_repositories" {

source = "../../modules/ecr"

repositories = \[

{

name = "product-api"

image_tag_mutability = "MUTABLE"

scan_on_push = true

},

{

name = "product-frontend"

image_tag_mutability = "MUTABLE"

scan_on_push = true

},

{

name = "product-worker"

image_tag_mutability = "MUTABLE"

scan_on_push = true

}

\]

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

Purpose = "ContainerRegistry"

}

}

*\# Application Load Balancer for Development*

module "application_load_balancer" {

source = "../../modules/alb"

name = "product-dev-alb"

vpc_id = module.product_development_vpc.vpc_id

subnets = module.product_development_vpc.public_subnets

security_groups = \[aws_security_group.alb_sg.id\]

*\# HTTPS Certificate*

certificate_arn = aws_acm_certificate.product_dev_cert.arn

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

Purpose = "LoadBalancer"

}

}

*\# EKS Cluster for Development*

module "eks_cluster" {

source = "../../modules/eks"

cluster_name = "product-dev-cluster"

cluster_version = "1.28"

vpc_id = module.product_development_vpc.vpc_id

subnet_ids = module.product_development_vpc.private_subnets

*\# Node Groups*

node_groups = {

general = {

desired_size = 2

max_size = 4

min_size = 1

instance_types = \["t3.medium"\]

capacity_type = "ON_DEMAND"

k8s_labels = {

Environment = "development"

NodeType = "general"

}

}

}

*\# Fargate Profiles*

fargate_profiles = {

default = {

selectors = \[

{

namespace = "default"

},

{

namespace = "kube-system"

}

\]

}

}

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

Purpose = "EKS"

}

}

*\# RDS Aurora for Development*

module "rds_aurora" {

source = "../../modules/rds-aurora"

cluster_identifier = "product-dev-aurora"

engine = "aurora-postgresql"

engine_version = "15.4"

database_name = "productdb"

master_username = "dbadmin"

vpc_id = module.product_development_vpc.vpc_id

db_subnet_group_name =
module.product_development_vpc.database_subnet_group_name

security_group_ids = \[aws_security_group.rds_sg.id\]

*\# Development Configuration*

instances = {

1 = {

instance_class = "db.r6g.large"

}

}

backup_retention_period = 7

preferred_backup_window = "03:00-04:00"

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

Purpose = "Database"

}

}

*\# Security Groups*

resource "aws_security_group" "alb_sg" {

name_prefix = "product-dev-alb-"

vpc_id = module.product_development_vpc.vpc_id

ingress {

from_port = 80

to_port = 80

protocol = "tcp"

cidr_blocks = \["0.0.0.0/0"\]

}

ingress {

from_port = 443

to_port = 443

protocol = "tcp"

cidr_blocks = \["0.0.0.0/0"\]

}

egress {

from_port = 0

to_port = 0

protocol = "-1"

cidr_blocks = \["0.0.0.0/0"\]

}

tags = {

Name = "product-dev-alb-sg"

}

}

resource "aws_security_group" "rds_sg" {

name_prefix = "product-dev-rds-"

vpc_id = module.product_development_vpc.vpc_id

ingress {

from_port = 5432

to_port = 5432

protocol = "tcp"

security_groups = \[module.eks_cluster.node_security_group_id\]

}

tags = {

Name = "product-dev-rds-sg"

}

}

*\# ACM Certificate*

resource "aws_acm_certificate" "product_dev_cert" {

domain_name = "dev.product.technova.com"

validation_method = "DNS"

lifecycle {

create_before_destroy = true

}

tags = {

BusinessUnit = "ProductDevelopment"

Environment = "Development"

}

}

2\. CI/CD パイプライン要件

2.1 マイクロサービスCI/CDアーキテクチャ

yaml

*\# CI/CD Pipeline Architecture for Microservices*

cicd_architecture:

*\# パイプライン階層*

pipeline_t

再試行

C

続ける

編集

yaml

*\# CI/CD Pipeline Architecture for Microservices*

cicd_architecture:

*\# パイプライン階層*

pipeline_tiers:

infrastructure_pipeline:

purpose: "IaCの管理とデプロイ"

trigger: "Infrastructure repository changes"

stages: \["validate", "plan", "security-scan", "apply"\]

integration: "セキュリティ分析パイプラインと統合"

application_pipeline:

purpose: "アプリケーションのビルドとデプロイ"

trigger: "Application code changes"

stages: \["build", "test", "security-scan", "deploy"\]

integration: "マイクロサービス別並列実行"

promotion_pipeline:

purpose: "環境間のプロモーション"

trigger: "Manual approval or automated conditions"

stages: \["validate", "smoke-test", "deploy", "verify"\]

integration: "事業部門別アカウント構成との連携"

*\# マイクロサービス戦略*

microservices_strategy:

repository_structure: "mono-repo with service isolation"

build_parallelization: "service-based parallel builds"

deployment_strategy: "blue-green with canary"

rollback_capability: "automatic rollback on failure"

2.2 統合CI/CDパイプライン実装

hcl

*\# マイクロサービス CI/CD Pipeline*

resource "aws_codepipeline" "microservices_pipeline" {

name = "technova-microservices-pipeline"

role_arn = aws_iam_role.codepipeline_service_role.arn

artifact_store {

location = aws_s3_bucket.codepipeline_artifacts.bucket

type = "S3"

encryption_key {

id = aws_kms_key.codepipeline_kms.arn

type = "KMS"

}

}

*\# Source Stage - Multi-Repository Support*

stage {

name = "Source"

action {

name = "SourceAction-Infrastructure"

category = "Source"

owner = "AWS"

provider = "CodeCommit"

version = "1"

output_artifacts = \["infrastructure_source"\]

configuration = {

RepositoryName = "technova-infrastructure"

BranchName = "main"

}

}

action {

name = "SourceAction-Applications"

category = "Source"

owner = "AWS"

provider = "CodeCommit"

version = "1"

output_artifacts = \["application_source"\]

configuration = {

RepositoryName = "technova-microservices"

BranchName = "main"

}

run_order = 1

}

}

*\# Build Stage - Parallel Microservice Builds*

stage {

name = "Build"

*\# API Service Build*

action {

name = "Build-API-Service"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

output_artifacts = \["api_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.api_service_build.name

EnvironmentVariables = jsonencode(\[

{

name = "SERVICE_NAME"

value = "api-service"

type = "PLAINTEXT"

},

{

name = "BUILD_ENV"

value = "development"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

*\# Frontend Service Build*

action {

name = "Build-Frontend-Service"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

output_artifacts = \["frontend_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.frontend_service_build.name

EnvironmentVariables = jsonencode(\[

{

name = "SERVICE_NAME"

value = "frontend-service"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

*\# Worker Service Build*

action {

name = "Build-Worker-Service"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

output_artifacts = \["worker_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.worker_service_build.name

EnvironmentVariables = jsonencode(\[

{

name = "SERVICE_NAME"

value = "worker-service"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

*\# Security Testing Stage - Integration with Security Pipeline*

stage {

name = "SecurityTesting"

action {

name = "Container-Security-Scan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["api_build_output", "frontend_build_output",
"worker_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.container_security_scan.name

EnvironmentVariables = jsonencode(\[

{

name = "SECURITY_PIPELINE_INTEGRATION"

value = "true"

type = "PLAINTEXT"

},

{

name = "TRIVY_SCAN_ENABLED"

value = "true"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

action {

name = "SAST-Security-Scan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

configuration = {

ProjectName = aws_codebuild_project.sast_security_scan.name

EnvironmentVariables = jsonencode(\[

{

name = "SONARQUBE_INTEGRATION"

value = "true"

type = "PLAINTEXT"

},

{

name = "SECURITY_GATE_THRESHOLD"

value = "HIGH"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

*\# Deploy to Development*

stage {

name = "DeployDevelopment"

action {

name = "Deploy-to-EKS-Dev"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["api_build_output", "frontend_build_output",
"worker_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.eks_deployment.name

EnvironmentVariables = jsonencode(\[

{

name = "TARGET_ENVIRONMENT"

value = "development"

type = "PLAINTEXT"

},

{

name = "EKS_CLUSTER_NAME"

value = "product-dev-cluster"

type = "PLAINTEXT"

},

{

name = "DEPLOYMENT_STRATEGY"

value = "rolling-update"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

*\# Integration Testing*

stage {

name = "IntegrationTesting"

action {

name = "API-Integration-Tests"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

configuration = {

ProjectName = aws_codebuild_project.integration_tests.name

EnvironmentVariables = jsonencode(\[

{

name = "TEST_ENVIRONMENT"

value = "development"

type = "PLAINTEXT"

},

{

name = "API_BASE_URL"

value = "https://dev-api.technova.com"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

action {

name = "E2E-Tests"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["application_source"\]

configuration = {

ProjectName = aws_codebuild_project.e2e_tests.name

EnvironmentVariables = jsonencode(\[

{

name = "FRONTEND_URL"

value = "https://dev.technova.com"

type = "PLAINTEXT"

},

{

name = "HEADLESS_BROWSER"

value = "true"

type = "PLAINTEXT"

}

\])

}

run_order = 2

}

}

*\# Staging Approval*

stage {

name = "StagingApproval"

action {

name = "StagingDeploymentApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.pipeline_approvals.arn

CustomData = "Development testing completed. Approve deployment to
staging environment."

}

}

}

*\# Deploy to Staging*

stage {

name = "DeployStaging"

action {

name = "Deploy-to-EKS-Staging"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["api_build_output", "frontend_build_output",
"worker_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.eks_deployment.name

EnvironmentVariables = jsonencode(\[

{

name = "TARGET_ENVIRONMENT"

value = "staging"

type = "PLAINTEXT"

},

{

name = "EKS_CLUSTER_NAME"

value = "product-staging-cluster"

type = "PLAINTEXT"

},

{

name = "DEPLOYMENT_STRATEGY"

value = "blue-green"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

*\# Production Approval*

stage {

name = "ProductionApproval"

action {

name = "ProductionDeploymentApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.production_approvals.arn

CustomData = "Staging testing completed. Approve deployment to
production environment."

}

}

}

*\# Deploy to Production*

stage {

name = "DeployProduction"

action {

name = "Deploy-to-EKS-Production"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["api_build_output", "frontend_build_output",
"worker_build_output"\]

configuration = {

ProjectName = aws_codebuild_project.eks_deployment.name

EnvironmentVariables = jsonencode(\[

{

name = "TARGET_ENVIRONMENT"

value = "production"

type = "PLAINTEXT"

},

{

name = "EKS_CLUSTER_NAME"

value = "product-prod-cluster"

type = "PLAINTEXT"

},

{

name = "DEPLOYMENT_STRATEGY"

value = "canary"

type = "PLAINTEXT"

},

{

name = "CANARY_PERCENTAGE"

value = "10"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

tags = {

Purpose = "Microservices CICD"

Environment = "Multi-Environment"

Integration = "Security-Pipeline"

}

}

2.3 CodeBuildプロジェクト定義

hcl

*\# API Service Build Project*

resource "aws_codebuild_project" "api_service_build" {

name = "technova-api-service-build"

description = "Build project for API microservice with security
integration"

service_role = aws_iam_role.codebuild_service_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

privileged_mode = true

environment_variable {

name = "AWS_DEFAULT_REGION"

value = "ap-northeast-1"

}

environment_variable {

name = "AWS_ACCOUNT_ID"

value = data.aws_caller_identity.current.account_id

}

environment_variable {

name = "IMAGE_REPO_NAME"

value = "technova/api-service"

}

environment_variable {

name = "IMAGE_TAG"

value = "latest"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/api-service-build.yml"

}

tags = {

Service = "API"

Purpose = "Microservice Build"

}

}

*\# Container Security Scan Project*

resource "aws_codebuild_project" "container_security_scan" {

name = "technova-container-security-scan"

description = "Container security scanning with Trivy and integration
with security pipeline"

service_role = aws_iam_role.codebuild_service_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

privileged_mode = true

environment_variable {

name = "TRIVY_VERSION"

value = "0.45.0"

}

environment_variable {

name = "SECURITY_THRESHOLD"

value = "HIGH"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/container-security-scan.yml"

}

tags = {

Purpose = "Container Security"

Integration = "Security Pipeline"

}

}

*\# EKS Deployment Project*

resource "aws_codebuild_project" "eks_deployment" {

name = "technova-eks-deployment"

description = "EKS deployment with blue-green and canary strategies"

service_role = aws_iam_role.codebuild_eks_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "KUBECTL_VERSION"

value = "1.28.0"

}

environment_variable {

name = "HELM_VERSION"

value = "3.12.0"

}

environment_variable {

name = "ARGO_ROLLOUTS_VERSION"

value = "1.5.0"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/eks-deployment.yml"

}

tags = {

Purpose = "EKS Deployment"

Strategy = "Blue-Green-Canary"

}

}

2.4 Build Specification Files

yaml

*\# api-service-build.yml*

version: 0.2

env:

variables:

DOCKER_BUILDKIT: 1

SERVICE_PATH: "services/api"

phases:

install:

runtime-versions:

docker: 20

nodejs: 18

commands:

\- echo "\[INSTALL\] Installing dependencies..."

\- cd \$SERVICE_PATH

\- npm ci --only=production

pre_build:

commands:

\- echo "\[PRE_BUILD\] Logging into ECR..."

\- aws ecr get-login-password --region \$AWS_DEFAULT_REGION \| docker
login --username AWS --password-stdin
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com

\- echo "\[PRE_BUILD\] Running unit tests..."

\- npm test -- --coverage --watchAll=false

\- echo "\[PRE_BUILD\] Running linting..."

\- npm run lint

\- echo "\[PRE_BUILD\] Security audit..."

\- npm audit --audit-level high

build:

commands:

\- echo "\[BUILD\] Building Docker image..."

\- docker build -t \$IMAGE_REPO_NAME:\$IMAGE_TAG .

\- docker tag \$IMAGE_REPO_NAME:\$IMAGE_TAG
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/\$IMAGE_REPO_NAME:\$IMAGE_TAG

\- docker tag \$IMAGE_REPO_NAME:\$IMAGE_TAG
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/\$IMAGE_REPO_NAME:\$CODEBUILD_BUILD_NUMBER

post_build:

commands:

\- echo "\[POST_BUILD\] Pushing Docker image to ECR..."

\- docker push
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/\$IMAGE_REPO_NAME:\$IMAGE_TAG

\- docker push
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/\$IMAGE_REPO_NAME:\$CODEBUILD_BUILD_NUMBER

\- echo "\[POST_BUILD\] Generating image definitions..."

\- printf '\[{"name":"api-service","imageUri":"%s"}\]'
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/\$IMAGE_REPO_NAME:\$CODEBUILD_BUILD_NUMBER
\> imagedefinitions.json

artifacts:

files:

\- imagedefinitions.json

\- k8s/api-service/\*\*/\*

\- helm/api-service/\*\*/\*

name: api-service-build-output

cache:

paths:

\- '/root/.npm/\*\*/\*'

\- 'node_modules/\*\*/\*'

yaml

*\# container-security-scan.yml*

version: 0.2

env:

variables:

TRIVY_CACHE_DIR: "/tmp/trivy-cache"

SECURITY_REPORT_FORMAT: "json"

phases:

install:

commands:

\- echo "\[INSTALL\] Installing Trivy..."

\- wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key
\| apt-key add -

\- echo "deb https://aquasecurity.github.io/trivy-repo/deb
\$(lsb_release -sc) main" \| tee -a /etc/apt/sources.list.d/trivy.list

\- apt-get update

\- apt-get install trivy=\$TRIVY_VERSION

pre_build:

commands:

\- echo "\[PRE_BUILD\] Updating Trivy database..."

\- trivy --cache-dir \$TRIVY_CACHE_DIR image --download-db-only

\- echo "\[PRE_BUILD\] ECR login..."

\- aws ecr get-login-password --region \$AWS_DEFAULT_REGION \| docker
login --username AWS --password-stdin
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com

build:

commands:

\- echo "\[BUILD\] Scanning container images..."

*\# API Service Scan*

\- echo "\[BUILD\] Scanning API service image..."

\- trivy --cache-dir \$TRIVY_CACHE_DIR image --format
\$SECURITY_REPORT_FORMAT --output api-service-security-report.json
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/technova/api-service:latest

*\# Frontend Service Scan*

\- echo "\[BUILD\] Scanning Frontend service image..."

\- trivy --cache-dir \$TRIVY_CACHE_DIR image --format
\$SECURITY_REPORT_FORMAT --output frontend-service-security-report.json
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/technova/frontend-service:latest

*\# Worker Service Scan*

\- echo "\[BUILD\] Scanning Worker service image..."

\- trivy --cache-dir \$TRIVY_CACHE_DIR image --format
\$SECURITY_REPORT_FORMAT --output worker-service-security-report.json
\$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_DEFAULT_REGION.amazonaws.com/technova/worker-service:latest

post_build:

commands:

\- echo "\[POST_BUILD\] Processing security scan results..."

*\# 結果分析とレポート生成*

\- \|

echo "Analyzing security scan results..."

*\# 高深刻度脆弱性のカウント*

API_HIGH_VULNS=\$(jq '\[.Results\[\]?.Vulnerabilities\[\]? \|
select(.Severity == "HIGH" or .Severity == "CRITICAL")\] \| length'
api-service-security-report.json)

FRONTEND_HIGH_VULNS=\$(jq '\[.Results\[\]?.Vulnerabilities\[\]? \|
select(.Severity == "HIGH" or .Severity == "CRITICAL")\] \| length'
frontend-service-security-report.json)

WORKER_HIGH_VULNS=\$(jq '\[.Results\[\]?.Vulnerabilities\[\]? \|
select(.Severity == "HIGH" or .Severity == "CRITICAL")\] \| length'
worker-service-security-report.json)

TOTAL_HIGH_VULNS=\$((API_HIGH_VULNS + FRONTEND_HIGH_VULNS +
WORKER_HIGH_VULNS))

echo "High/Critical vulnerabilities found: \$TOTAL_HIGH_VULNS"

*\# セキュリティ閾値チェック*

if \[ "\$SECURITY_THRESHOLD" = "HIGH" \] && \[ \$TOTAL_HIGH_VULNS -gt 0
\]; then

echo "FAILED: High/Critical vulnerabilities detected"

exit 1

elif \[ "\$SECURITY_THRESHOLD" = "MEDIUM" \] && \[ \$TOTAL_HIGH_VULNS
-gt 5 \]; then

echo "FAILED: Too many high severity vulnerabilities"

exit 1

else

echo "PASSED: Security scan within acceptable limits"

fi

*\# セキュリティレポートをS3にアップロード*

\- aws s3 cp api-service-security-report.json
s3://\$SECURITY_REPORTS_BUCKET/container-scans/\$CODEBUILD_BUILD_ID/

\- aws s3 cp frontend-service-security-report.json
s3://\$SECURITY_REPORTS_BUCKET/container-scans/\$CODEBUILD_BUILD_ID/

\- aws s3 cp worker-service-security-report.json
s3://\$SECURITY_REPORTS_BUCKET/container-scans/\$CODEBUILD_BUILD_ID/

artifacts:

files:

\- '\*-security-report.json'

name: container-security-scan-results

cache:

paths:

\- '\$TRIVY_CACHE_DIR/\*\*/\*'

yaml

*\# eks-deployment.yml*

version: 0.2

env:

variables:

KUBECONFIG: "/tmp/kubeconfig"

HELM_CACHE_HOME: "/tmp/helm"

phases:

install:

commands:

\- echo "\[INSTALL\] Installing kubectl, helm, and deployment tools..."

*\# kubectl installation*

\- curl -LO
"https://dl.k8s.io/release/v\$KUBECTL_VERSION/bin/linux/amd64/kubectl"

\- chmod +x kubectl

\- mv kubectl /usr/local/bin/

*\# helm installation*

\- curl -fsSL -o get_helm.sh
https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3

\- chmod 700 get_helm.sh

\- ./get_helm.sh --version v\$HELM_VERSION

*\# Argo Rollouts CLI (for advanced deployment strategies)*

\- curl -LO
https://github.com/argoproj/argo-rollouts/releases/download/v\$ARGO_ROLLOUTS_VERSION/kubectl-argo-rollouts-linux-amd64

\- chmod +x kubectl-argo-rollouts-linux-amd64

\- mv kubectl-argo-rollouts-linux-amd64
/usr/local/bin/kubectl-argo-rollouts

pre_build:

commands:

\- echo "\[PRE_BUILD\] Configuring EKS access..."

\- aws eks update-kubeconfig --region \$AWS_DEFAULT_REGION --name
\$EKS_CLUSTER_NAME --kubeconfig \$KUBECONFIG

\- echo "\[PRE_BUILD\] Verifying cluster connectivity..."

\- kubectl --kubeconfig=\$KUBECONFIG get nodes

\- echo "\[PRE_BUILD\] Setting up Helm repositories..."

\- helm repo add stable https://charts.helm.sh/stable

\- helm repo add argo https://argoproj.github.io/argo-helm

\- helm repo update

build:

commands:

\- echo "\[BUILD\] Deploying microservices to EKS..."

*\# Create namespace if not exists*

\- kubectl --kubeconfig=\$KUBECONFIG create namespace
\$TARGET_ENVIRONMENT --dry-run=client -o yaml \| kubectl
--kubeconfig=\$KUBECONFIG apply -f -

*\# Deploy based on strategy*

\- \|

if \[ "\$DEPLOYMENT_STRATEGY" = "blue-green" \]; then

echo "\[BUILD\] Executing Blue-Green deployment..."

\# Install/Upgrade Argo Rollouts if not present

helm --kubeconfig=\$KUBECONFIG upgrade --install argo-rollouts
argo/argo-rollouts \\

--namespace argo-rollouts --create-namespace \\

--wait --timeout=300s

\# Deploy services with blue-green strategy

for service in api-service frontend-service worker-service; do

echo "Deploying \$service with blue-green strategy"

helm --kubeconfig=\$KUBECONFIG upgrade --install \$service
./helm/\$service \\

--namespace \$TARGET_ENVIRONMENT \\

--set image.tag=\$CODEBUILD_BUILD_NUMBER \\

--set deployment.strategy=bluegreen \\

--wait --timeout=600s

done

elif \[ "\$DEPLOYMENT_STRATEGY" = "canary" \]; then

echo "\[BUILD\] Executing Canary deployment..."

\# Deploy services with canary strategy

for service in api-service frontend-service worker-service; do

echo "Deploying \$service with canary strategy (\${CANARY_PERCENTAGE}%)"

helm --kubeconfig=\$KUBECONFIG upgrade --install \$service
./helm/\$service \\

--namespace \$TARGET_ENVIRONMENT \\

--set image.tag=\$CODEBUILD_BUILD_NUMBER \\

--set deployment.strategy=canary \\

--set canary.percentage=\$CANARY_PERCENTAGE \\

--wait --timeout=600s

done

else

echo "\[BUILD\] Executing Rolling Update deployment..."

\# Standard rolling update deployment

for service in api-service frontend-service worker-service; do

echo "Deploying \$service with rolling update"

helm --kubeconfig=\$KUBECONFIG upgrade --install \$service
./helm/\$service \\

--namespace \$TARGET_ENVIRONMENT \\

--set image.tag=\$CODEBUILD_BUILD_NUMBER \\

--wait --timeout=600s

done

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Verifying deployment..."

*\# Verify all pods are running*

\- kubectl --kubeconfig=\$KUBECONFIG get pods -n \$TARGET_ENVIRONMENT

*\# Run basic health checks*

\- \|

echo "Running health checks..."

for service in api-service frontend-service worker-service; do

kubectl --kubeconfig=\$KUBECONFIG wait --namespace=\$TARGET_ENVIRONMENT
\\

--for=condition=ready pod \\

--selector=app=\$service \\

--timeout=300s

done

*\# Generate deployment report*

\- \|

cat \> deployment-report.json \<\< EOF

{

"deployment_id": "\$CODEBUILD_BUILD_ID",

"environment": "\$TARGET_ENVIRONMENT",

"cluster": "\$EKS_CLUSTER_NAME",

"strategy": "\$DEPLOYMENT_STRATEGY",

"image_tag": "\$CODEBUILD_BUILD_NUMBER",

"timestamp": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",

"services": \["api-service", "frontend-service", "worker-service"\],

"status": "SUCCESS"

}

EOF

\- echo "\[POST_BUILD\] Deployment completed successfully"

artifacts:

files:

\- deployment-report.json

name: eks-deployment-report

cache:

paths:

\- '\$HELM_CACHE_HOME/\*\*/\*'

3\. データ移行自動化

3.1 オンプレミスからAurora移行パイプライン

hcl

*\# Data Migration Pipeline Infrastructure*

resource "aws_codepipeline" "data_migration_pipeline" {

name = "technova-data-migration-pipeline"

role_arn = aws_iam_role.data_migration_pipeline_role.arn

artifact_store {

location = aws_s3_bucket.data_migration_artifacts.bucket

type = "S3"

encryption_key {

id = aws_kms_key.data_migration_kms.arn

type = "KMS"

}

}

*\# Source Stage - Migration Scripts and Configuration*

stage {

name = "Source"

action {

name = "MigrationScripts"

category = "Source"

owner = "AWS"

provider = "CodeCommit"

再試行

C

続ける

編集

provider = "CodeCommit" version = "1" output_artifacts =
\["migration_source"\]

configuration = {

RepositoryName = "technova-data-migration"

BranchName = "main"

}

}

}

Pre-Migration Validation

stage { name = "PreMigrationValidation"

action {

name = "DatabaseConnectivityTest"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["migration_source"\]

configuration = {

ProjectName = aws_codebuild_project.pre_migration_validation.name

EnvironmentVariables = jsonencode(\[

{

name = "SOURCE_DB_TYPE"

value = "oracle"

type = "PLAINTEXT"

},

{

name = "TARGET_DB_TYPE"

value = "aurora-postgresql"

type = "PLAINTEXT"

}

\])

}

}

}

Schema Migration

stage { name = "SchemaMigration"

action {

name = "SchemaConversion"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["migration_source"\]

output_artifacts = \["schema_conversion_output"\]

configuration = {

ProjectName = aws_codebuild_project.schema_migration.name

EnvironmentVariables = jsonencode(\[

{

name = "DMS_REPLICATION_INSTANCE"

value = aws_dms_replication_instance.main.replication_instance_id

type = "PLAINTEXT"

},

{

name = "SCT_PROJECT_PATH"

value = "schema-conversion/technova-project.sct"

type = "PLAINTEXT"

}

\])

}

}

}

Schema Validation and Approval

stage { name = "SchemaValidationApproval"

action {

name = "SchemaApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.data_migration_approvals.arn

CustomData = "Schema conversion completed. Review schema changes before
proceeding with data migration."

}

}

}

Data Migration

stage { name = "DataMigration"

action {

name = "InitialDataLoad"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["migration_source", "schema_conversion_output"\]

configuration = {

ProjectName = aws_codebuild_project.data_migration.name

EnvironmentVariables = jsonencode(\[

{

name = "MIGRATION_TYPE"

value = "full-load-and-cdc"

type = "PLAINTEXT"

},

{

name = "PARALLEL_LOAD_THREADS"

value = "8"

type = "PLAINTEXT"

}

\])

}

}

}

Data Validation

stage { name = "DataValidation"

action {

name = "DataConsistencyCheck"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["migration_source"\]

configuration = {

ProjectName = aws_codebuild_project.data_validation.name

EnvironmentVariables = jsonencode(\[

{

name = "VALIDATION_TYPE"

value = "COMPREHENSIVE"

type = "PLAINTEXT"

},

{

name = "SAMPLE_PERCENTAGE"

value = "10"

type = "PLAINTEXT"

}

\])

}

}

}

Cutover Approval

stage { name = "CutoverApproval"

action {

name = "CutoverApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.data_migration_approvals.arn

CustomData = "Data migration and validation completed. Approve cutover
to Aurora database."

}

}

}

Application Cutover

stage { name = "ApplicationCutover"

action {

name = "UpdateConnectionStrings"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["migration_source"\]

configuration = {

ProjectName = aws_codebuild_project.application_cutover.name

EnvironmentVariables = jsonencode(\[

{

name = "CUTOVER_TYPE"

value = "GRADUAL"

type = "PLAINTEXT"

},

{

name = "ROLLBACK_ENABLED"

value = "true"

type = "PLAINTEXT"

}

\])

}

}

}

tags = { Purpose = "Data Migration" Source = "OnPremises" Target =
"Aurora" } }

DMS Replication Instance

resource "aws_dms_replication_instance" "main" { allocated_storage = 100
apply_immediately = true auto_minor_version_upgrade = true
availability_zone = "ap-northeast-1a" engine_version = "3.5.1" multi_az
= false preferred_maintenance_window = "sun:10:30-sun:14:30"
publicly_accessible = false replication_instance_class = "dms.t3.medium"
replication_instance_id = "technova-dms-instance"

replication_subnet_group_id = aws_dms_replication_subnet_group.main.id
vpc_security_group_ids = \[aws_security_group.dms_sg.id\]

tags = { Name = "TechNova DMS Instance" Purpose = "Data Migration" } }

resource "aws_dms_replication_subnet_group" "main" {
replication_subnet_group_description = "DMS replication subnet group"
replication_subnet_group_id = "technova-dms-subnet-group"

subnet_ids = data.aws_subnets.private.ids

tags = { Name = "TechNova DMS Subnet Group" } }

\### 3.2 データ移行CodeBuildプロジェクト

\`\`\`hcl

\# Pre-Migration Validation Project

resource "aws_codebuild_project" "pre_migration_validation" {

name = "technova-pre-migration-validation"

description = "Pre-migration validation and connectivity testing"

service_role = aws_iam_role.data_migration_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "SOURCE_DB_HOST"

value = "/technova/migration/source-db-host"

type = "PARAMETER_STORE"

}

environment_variable {

name = "TARGET_DB_HOST"

value = aws_rds_cluster.aurora_target.endpoint

type = "PLAINTEXT"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/pre-migration-validation.yml"

}

tags = {

Purpose = "Migration Validation"

}

}

\# Schema Migration Project

resource "aws_codebuild_project" "schema_migration" {

name = "technova-schema-migration"

description = "Schema conversion using AWS SCT and DMS"

service_role = aws_iam_role.data_migration_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "SCT_VERSION"

value = "1.0.672"

}

environment_variable {

name = "FLYWAY_VERSION"

value = "9.15.1"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/schema-migration.yml"

}

tags = {

Purpose = "Schema Migration"

Tool = "AWS-SCT"

}

}

\# Data Migration Project

resource "aws_codebuild_project" "data_migration" {

name = "technova-data-migration"

description = "Data migration using AWS DMS"

service_role = aws_iam_role.data_migration_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_LARGE"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "DMS_TASK_SETTINGS_S3"

value = aws_s3_bucket.data_migration_artifacts.bucket

type = "PLAINTEXT"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/data-migration.yml"

}

timeout_in_minutes = 480 \# 8 hours for large data migrations

tags = {

Purpose = "Data Migration"

Tool = "AWS-DMS"

}

}

3.3 Flyway スキーマ管理統合

python

*\# Flyway Schema Management Integration*

import os

import subprocess

import boto3

import json

from typing import Dict, List, Any

class FlywaySchemaManager:

def \_\_init\_\_(self, config: Dict\[str, Any\]):

self.config = config

self.flyway_version = config.get('flyway_version', '9.15.1')

self.db_config = config\['database'\]

self.s3_client = boto3.client('s3')

def setup_flyway(self):

"""

Flyway のセットアップとインストール

"""

print(f"\[SETUP\] Installing Flyway {self.flyway_version}")

*\# Flyway ダウンロードとインストール*

download_url =
f"https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/{self.flyway_version}/flyway-commandline-{self.flyway_version}-linux-x64.tar.gz"

subprocess.run(\[

"wget", "-O", "flyway.tar.gz", download_url

\], check=True)

subprocess.run(\[

"tar", "-xzf", "flyway.tar.gz"

\], check=True)

subprocess.run(\[

"mv", f"flyway-{self.flyway_version}", "/opt/flyway"

\], check=True)

subprocess.run(\[

"chmod", "+x", "/opt/flyway/flyway"

\], check=True)

*\# PATH に追加*

os.environ\['PATH'\] = f"/opt/flyway:{os.environ\['PATH'\]}"

print("\[SETUP\] Flyway installation completed")

def create_flyway_config(self):

"""

Flyway 設定ファイルの作成

"""

config_content = f"""

\# Flyway Configuration for TechNova Migration

flyway.url={self.db_config\['url'\]}

flyway.user={self.db_config\['username'\]}

flyway.password={self.db_config\['password'\]}

flyway.schemas={self.db_config\['schema'\]}

flyway.locations=filesystem:./sql/migrations

flyway.baselineOnMigrate=true

flyway.validateOnMigrate=true

flyway.outOfOrder=false

flyway.placeholderReplacement=true

flyway.placeholders.environment={self.config.get('environment',
'development')}

flyway.placeholders.tenant={self.config.get('tenant', 'technova')}

\# Migration settings

flyway.table=schema_version

flyway.sqlMigrationPrefix=V

flyway.sqlMigrationSeparator=\_\_

flyway.sqlMigrationSuffixes=.sql

flyway.encoding=UTF-8

\# Callbacks

flyway.callbacks=com.technova.migration.callbacks.MigrationCallback

"""

with open('flyway.conf', 'w') as f:

f.write(config_content)

print("\[CONFIG\] Flyway configuration created")

def download_migration_scripts(self):

"""

S3からマイグレーションスクリプトをダウンロード

"""

bucket = self.config\['migration_scripts_bucket'\]

prefix = self.config\['migration_scripts_prefix'\]

print(f"\[DOWNLOAD\] Downloading migration scripts from
s3://{bucket}/{prefix}")

*\# S3からマイグレーションスクリプトを取得*

paginator = self.s3_client.get_paginator('list_objects_v2')

for page in paginator.paginate(Bucket=bucket, Prefix=prefix):

if 'Contents' in page:

for obj in page\['Contents'\]:

key = obj\['Key'\]

local_path = key.replace(prefix, 'sql/migrations/', 1)

*\# ディレクトリ作成*

os.makedirs(os.path.dirname(local_path), exist_ok=True)

*\# ファイルダウンロード*

self.s3_client.download_file(bucket, key, local_path)

print(f"\[DOWNLOAD\] Downloaded {key} -\> {local_path}")

def validate_migration_scripts(self):

"""

マイグレーションスクリプトの検証

"""

print("\[VALIDATE\] Validating migration scripts")

try:

*\# Flyway validate コマンド実行*

result = subprocess.run(\[

"flyway",

"-configFiles=flyway.conf",

"validate"

\], capture_output=True, text=True, check=True)

print("\[VALIDATE\] Migration scripts validation passed")

return True

except subprocess.CalledProcessError as e:

print(f"\[VALIDATE\] Migration scripts validation failed: {e.stderr}")

return False

def execute_migration(self, migration_type: str = "migrate"):

"""

マイグレーションの実行

"""

print(f"\[MIGRATE\] Executing {migration_type}")

try:

if migration_type == "info":

*\# マイグレーション情報の表示*

result = subprocess.run(\[

"flyway",

"-configFiles=flyway.conf",

"info"

\], capture_output=True, text=True, check=True)

print("\[MIGRATE\] Migration info:")

print(result.stdout)

elif migration_type == "migrate":

*\# マイグレーション実行*

result = subprocess.run(\[

"flyway",

"-configFiles=flyway.conf",

"migrate"

\], capture_output=True, text=True, check=True)

print("\[MIGRATE\] Migration completed successfully")

print(result.stdout)

elif migration_type == "baseline":

*\# ベースライン設定*

result = subprocess.run(\[

"flyway",

"-configFiles=flyway.conf",

"baseline"

\], capture_output=True, text=True, check=True)

print("\[MIGRATE\] Baseline established")

print(result.stdout)

return True

except subprocess.CalledProcessError as e:

print(f"\[MIGRATE\] Migration failed: {e.stderr}")

return False

def generate_migration_report(self):

"""

マイグレーションレポートの生成

"""

print("\[REPORT\] Generating migration report")

try:

*\# マイグレーション履歴の取得*

result = subprocess.run(\[

"flyway",

"-configFiles=flyway.conf",

"info",

"-outputType=json"

\], capture_output=True, text=True, check=True)

migration_info = json.loads(result.stdout)

*\# レポート生成*

report = {

"migration_timestamp": datetime.now().isoformat(),

"database_url": self.db_config\['url'\],

"schema": self.db_config\['schema'\],

"migrations": migration_info.get('migrations', \[\]),

"summary": {

"total_migrations": len(migration_info.get('migrations', \[\])),

"successful_migrations": len(\[m for m in
migration_info.get('migrations', \[\]) if m.get('state') ==
'Success'\]),

"failed_migrations": len(\[m for m in migration_info.get('migrations',
\[\]) if m.get('state') == 'Failed'\]),

"pending_migrations": len(\[m for m in migration_info.get('migrations',
\[\]) if m.get('state') == 'Pending'\])

}

}

*\# レポートをファイルに保存*

with open('migration-report.json', 'w') as f:

json.dump(report, f, indent=2)

*\# S3にアップロード*

self.s3_client.upload_file(

'migration-report.json',

self.config\['reports_bucket'\],

f"migration-reports/{datetime.now().strftime('%Y/%m/%d')}/migration-report-{os.environ.get('CODEBUILD_BUILD_ID',
'local')}.json"

)

print("\[REPORT\] Migration report generated and uploaded")

return report

except subprocess.CalledProcessError as e:

print(f"\[REPORT\] Failed to generate migration report: {e.stderr}")

return None

*\# 使用例*

def main():

config = {

'flyway_version': '9.15.1',

'environment': os.environ.get('TARGET_ENVIRONMENT', 'development'),

'database': {

'url':
f"jdbc:postgresql://{os.environ\['TARGET_DB_HOST'\]}:5432/{os.environ\['TARGET_DB_NAME'\]}",

'username': os.environ\['TARGET_DB_USERNAME'\],

'password': os.environ\['TARGET_DB_PASSWORD'\],

'schema': os.environ.get('TARGET_DB_SCHEMA', 'public')

},

'migration_scripts_bucket': os.environ\['MIGRATION_SCRIPTS_BUCKET'\],

'migration_scripts_prefix': 'flyway/migrations/',

'reports_bucket': os.environ\['MIGRATION_REPORTS_BUCKET'\]

}

schema_manager = FlywaySchemaManager(config)

*\# セットアップ*

schema_manager.setup_flyway()

schema_manager.create_flyway_config()

*\# マイグレーションスクリプトダウンロード*

schema_manager.download_migration_scripts()

*\# 検証*

if not schema_manager.validate_migration_scripts():

exit(1)

*\# マイグレーション実行*

schema_manager.execute_migration("info")

if not schema_manager.execute_migration("migrate"):

exit(1)

*\# レポート生成*

schema_manager.generate_migration_report()

print("Schema migration completed successfully")

if \_\_name\_\_ == "\_\_main\_\_":

main()

3.4 データ移行 BuildSpec ファイル

yaml

*\# pre-migration-validation.yml*

version: 0.2

env:

variables:

VALIDATION_RESULTS_FILE: "pre-migration-validation-report.json"

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "\[INSTALL\] Installing validation tools..."

\- pip install psycopg2-binary cx_Oracle boto3 pymongo redis

pre_build:

commands:

\- echo "\[PRE_BUILD\] Preparing validation environment..."

\- mkdir -p validation-results

*\# Source database credentials from Parameter Store*

\- export SOURCE_DB_USERNAME=\$(aws ssm get-parameter --name
"/technova/migration/source-db-username" --with-decryption --query
'Parameter.Value' --output text)

\- export SOURCE_DB_PASSWORD=\$(aws ssm get-parameter --name
"/technova/migration/source-db-password" --with-decryption --query
'Parameter.Value' --output text)

\- export TARGET_DB_USERNAME=\$(aws ssm get-parameter --name
"/technova/migration/target-db-username" --with-decryption --query
'Parameter.Value' --output text)

\- export TARGET_DB_PASSWORD=\$(aws ssm get-parameter --name
"/technova/migration/target-db-password" --with-decryption --query
'Parameter.Value' --output text)

build:

commands:

\- echo "\[BUILD\] Running pre-migration validations..."

*\# Database connectivity test*

\- \|

python3 \<\< 'EOF'

import json

import os

from datetime import datetime

validation_results = {

"validation_timestamp": datetime.now().isoformat(),

"tests": \[\]

}

*\# Source database connectivity test*

try:

if os.environ\['SOURCE_DB_TYPE'\] == 'oracle':

import cx_Oracle

dsn =
f"{os.environ\['SOURCE_DB_HOST'\]}:1521/{os.environ.get('SOURCE_DB_SERVICE',
'ORCL')}"

with
cx_Oracle.connect(f"{os.environ\['SOURCE_DB_USERNAME'\]}/{os.environ\['SOURCE_DB_PASSWORD'\]}@{dsn}")
as conn:

cursor = conn.cursor()

cursor.execute("SELECT 1 FROM DUAL")

result = cursor.fetchone()

validation_results\["tests"\].append({

"test_name": "source_db_connectivity",

"status": "PASSED",

"message": "Source Oracle database connection successful"

})

elif os.environ\['SOURCE_DB_TYPE'\] == 'mysql':

import pymysql

conn = pymysql.connect(

host=os.environ\['SOURCE_DB_HOST'\],

user=os.environ\['SOURCE_DB_USERNAME'\],

password=os.environ\['SOURCE_DB_PASSWORD'\],

database=os.environ.get('SOURCE_DB_NAME', 'test')

)

with conn.cursor() as cursor:

cursor.execute("SELECT 1")

result = cursor.fetchone()

validation_results\["tests"\].append({

"test_name": "source_db_connectivity",

"status": "PASSED",

"message": "Source MySQL database connection successful"

})

except Exception as e:

validation_results\["tests"\].append({

"test_name": "source_db_connectivity",

"status": "FAILED",

"message": f"Source database connection failed: {str(e)}"

})

*\# Target database connectivity test*

try:

import psycopg2

conn = psycopg2.connect(

host=os.environ\['TARGET_DB_HOST'\],

database=os.environ.get('TARGET_DB_NAME', 'postgres'),

user=os.environ\['TARGET_DB_USERNAME'\],

password=os.environ\['TARGET_DB_PASSWORD'\]

)

with conn.cursor() as cursor:

cursor.execute("SELECT 1")

result = cursor.fetchone()

validation_results\["tests"\].append({

"test_name": "target_db_connectivity",

"status": "PASSED",

"message": "Target Aurora PostgreSQL connection successful"

})

except Exception as e:

validation_results\["tests"\].append({

"test_name": "target_db_connectivity",

"status": "FAILED",

"message": f"Target database connection failed: {str(e)}"

})

*\# Source database schema analysis*

try:

if os.environ\['SOURCE_DB_TYPE'\] == 'oracle':

with
cx_Oracle.connect(f"{os.environ\['SOURCE_DB_USERNAME'\]}/{os.environ\['SOURCE_DB_PASSWORD'\]}@{dsn}")
as conn:

cursor = conn.cursor()

cursor.execute("""

SELECT COUNT(\*) as table_count

FROM user_tables

""")

table_count = cursor.fetchone()\[0\]

cursor.execute("""

SELECT COUNT(\*) as index_count

FROM user_indexes

""")

index_count = cursor.fetchone()\[0\]

validation_results\["source_schema_stats"\] = {

"table_count": table_count,

"index_count": index_count

}

validation_results\["tests"\].append({

"test_name": "source_schema_analysis",

"status": "PASSED",

"message": f"Source schema analyzed: {table_count} tables, {index_count}
indexes"

})

except Exception as e:

validation_results\["tests"\].append({

"test_name": "source_schema_analysis",

"status": "FAILED",

"message": f"Source schema analysis failed: {str(e)}"

})

*\# Write validation results*

with open(os.environ\['VALIDATION_RESULTS_FILE'\], 'w') as f:

json.dump(validation_results, f, indent=2)

*\# Check if any tests failed*

failed_tests = \[test for test in validation_results\["tests"\] if
test\["status"\] == "FAILED"\]

if failed_tests:

print(f"Validation failed: {len(failed_tests)} test(s) failed")

exit(1)

else:

print("All pre-migration validations passed")

EOF

post_build:

commands:

\- echo "\[POST_BUILD\] Uploading validation results..."

\- aws s3 cp \$VALIDATION_RESULTS_FILE
s3://\$DATA_MIGRATION_ARTIFACTS_BUCKET/validation-reports/\$CODEBUILD_BUILD_ID/

artifacts:

files:

\- pre-migration-validation-report.json

name: pre-migration-validation-results

yaml

*\# data-migration.yml*

version: 0.2

env:

variables:

MIGRATION_LOG_FILE: "data-migration-log.json"

MIGRATION_RESULTS_FILE: "data-migration-results.json"

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "\[INSTALL\] Installing DMS and migration tools..."

\- pip install boto3 psycopg2-binary cx_Oracle

\- apt-get update && apt-get install -y awscli

pre_build:

commands:

\- echo "\[PRE_BUILD\] Preparing data migration..."

*\# DMS task configuration from S3*

\- aws s3 cp s3://\$DMS_TASK_SETTINGS_S3/task-settings.json
./task-settings.json

\- aws s3 cp s3://\$DMS_TASK_SETTINGS_S3/table-mappings.json
./table-mappings.json

*\# Create DMS endpoints if not exist*

\- \|

python3 \<\< 'EOF'

import boto3

import json

import os

dms = boto3.client('dms')

*\# Source endpoint configuration*

source_endpoint_config = {

'EndpointIdentifier': 'technova-source-endpoint',

'EndpointType': 'source',

'EngineName': os.environ.get('SOURCE_DB_TYPE', 'oracle'),

'ServerName': os.environ\['SOURCE_DB_HOST'\],

'Port': int(os.environ.get('SOURCE_DB_PORT', '1521')),

'Username': os.environ\['SOURCE_DB_USERNAME'\],

'Password': os.environ\['SOURCE_DB_PASSWORD'\]

}

if os.environ.get('SOURCE_DB_TYPE') == 'oracle':

source_endpoint_config\['DatabaseName'\] =
os.environ.get('SOURCE_DB_SERVICE', 'ORCL')

*\# Target endpoint configuration*

target_endpoint_config = {

'EndpointIdentifier': 'technova-target-endpoint',

'EndpointType': 'target',

'EngineName': 'aurora-postgresql',

'ServerName': os.environ\['TARGET_DB_HOST'\],

'Port': 5432,

'Username': os.environ\['TARGET_DB_USERNAME'\],

'Password': os.environ\['TARGET_DB_PASSWORD'\],

'DatabaseName': os.environ.get('TARGET_DB_NAME', 'postgres')

}

try:

*\# Create source endpoint*

dms.create_endpoint(\*\*source_endpoint_config)

print("Source endpoint created")

except dms.exceptions.ResourceAlreadyExistsFault:

print("Source endpoint already exists")

except Exception as e:

print(f"Error creating source endpoint: {e}")

try:

*\# Create target endpoint*

dms.create_endpoint(\*\*target_endpoint_config)

print("Target endpoint created")

except dms.exceptions.ResourceAlreadyExistsFault:

print("Target endpoint already exists")

except Exception as e:

print(f"Error creating target endpoint: {e}")

EOF

build:

commands:

\- echo "\[BUILD\] Starting data migration..."

*\# Create and start DMS task*

\- \|

python3 \<\< 'EOF'

import boto3

import json

import time

import os

from datetime import datetime

dms = boto3.client('dms')

*\# Load task settings and table mappings*

with open('task-settings.json', 'r') as f:

task_settings = f.read()

with open('table-mappings.json', 'r') as f:

table_mappings = f.read()

*\# Create DMS task*

task_config = {

'ReplicationTaskIdentifier': f'technova-migration-{

再試行

C

続ける

編集

task_config = { 'ReplicationTaskIdentifier':
f'technova-migration-{os.environ.get("CODEBUILD_BUILD_NUMBER", "1")}',
'SourceEndpointArn':
f'arn:aws:dms:{os.environ\["AWS_DEFAULT_REGION"\]}:{os.environ\["AWS_ACCOUNT_ID"\]}:endpoint:technova-source-endpoint',
'TargetEndpointArn':
f'arn:aws:dms:{os.environ\["AWS_DEFAULT_REGION"\]}:{os.environ\["AWS_ACCOUNT_ID"\]}:endpoint:technova-target-endpoint',
'ReplicationInstanceArn':
f'arn:aws:dms:{os.environ\["AWS_DEFAULT_REGION"\]}:{os.environ\["AWS_ACCOUNT_ID"\]}:repl-inst:{os.environ\["DMS_REPLICATION_INSTANCE"\]}',
'MigrationType': os.environ.get('MIGRATION_TYPE', 'full-load-and-cdc'),
'TableMappings': table_mappings, 'ReplicationTaskSettings':
task_settings }

migration_log = {

'migration_start_time': datetime.now().isoformat(),

'task_identifier': task_config\['ReplicationTaskIdentifier'\],

'migration_type': task_config\['MigrationType'\],

'events': \[\]

}

try:

\# Create replication task

response = dms.create_replication_task(\*\*task_config)

task_arn = response\['ReplicationTask'\]\['ReplicationTaskArn'\]

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'task_created',

'message': f'DMS task created: {task_arn}'

})

\# Wait for task to be ready

print("Waiting for DMS task to be ready...")

waiter = dms.get_waiter('replication_task_ready')

waiter.wait(

Filters=\[

{

'Name': 'replication-task-arn',

'Values': \[task_arn\]

}

\],

WaiterConfig={

'Delay': 30,

'MaxAttempts': 60

}

)

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'task_ready',

'message': 'DMS task is ready to start'

})

\# Start replication task

dms.start_replication_task(

ReplicationTaskArn=task_arn,

StartReplicationTaskType='start-replication'

)

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'task_started',

'message': 'DMS task started'

})

\# Monitor migration progress

print("Monitoring migration progress...")

start_time = time.time()

max_duration = int(os.environ.get('MAX_MIGRATION_DURATION', '14400')) \#
4 hours default

while True:

\# Check task status

response = dms.describe_replication_tasks(

Filters=\[

{

'Name': 'replication-task-arn',

'Values': \[task_arn\]

}

\]

)

task = response\['ReplicationTasks'\]\[0\]

status = task\['Status'\]

print(f"Task status: {status}")

if status == 'stopped':

stop_reason = task.get('StopReason', 'Unknown')

if 'FULL_LOAD_FINISHED' in stop_reason or 'Stop Reason
FULL_LOAD_ONLY_FINISHED' in stop_reason:

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'migration_completed',

'message': f'Migration completed successfully: {stop_reason}'

})

break

else:

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'migration_failed',

'message': f'Migration failed: {stop_reason}'

})

raise Exception(f"Migration failed: {stop_reason}")

elif status == 'failed':

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'migration_failed',

'message': 'Migration task failed'

})

raise Exception("Migration task failed")

elif status == 'running':

\# Get migration statistics

stats_response = dms.describe_table_statistics(

ReplicationTaskArn=task_arn

)

if stats_response\['TableStatistics'\]:

total_records = sum(stat.get('FullLoadRows', 0) for stat in
stats_response\['TableStatistics'\])

total_errors = sum(stat.get('FullLoadErrorRows', 0) for stat in
stats_response\['TableStatistics'\])

print(f"Progress: {total_records} records migrated, {total_errors}
errors")

migration_log\['current_stats'\] = {

'total_records': total_records,

'total_errors': total_errors,

'timestamp': datetime.now().isoformat()

}

\# Check timeout

if time.time() - start_time \> max_duration:

migration_log\['events'\].append({

'timestamp': datetime.now().isoformat(),

'event': 'migration_timeout',

'message': f'Migration exceeded maximum duration of {max_duration}
seconds'

})

raise Exception(f"Migration timeout after {max_duration} seconds")

time.sleep(60) \# Wait 1 minute before next check

\# Get final statistics

final_stats_response = dms.describe_table_statistics(

ReplicationTaskArn=task_arn

)

migration_results = {

'migration_end_time': datetime.now().isoformat(),

'status': 'SUCCESS',

'total_tables': len(final_stats_response\['TableStatistics'\]),

'table_statistics': final_stats_response\['TableStatistics'\]

}

migration_log\['final_results'\] = migration_results

\# Save migration log

with open(os.environ\['MIGRATION_LOG_FILE'\], 'w') as f:

json.dump(migration_log, f, indent=2)

\# Save migration results

with open(os.environ\['MIGRATION_RESULTS_FILE'\], 'w') as f:

json.dump(migration_results, f, indent=2)

print("Data migration completed successfully")

except Exception as e:

error_log = {

'migration_end_time': datetime.now().isoformat(),

'status': 'FAILED',

'error': str(e)

}

migration_log\['final_results'\] = error_log

with open(os.environ\['MIGRATION_LOG_FILE'\], 'w') as f:

json.dump(migration_log, f, indent=2)

print(f"Data migration failed: {e}")

exit(1)

EOF

post_build: commands: - echo "\[POST_BUILD\] Processing migration
results..."

\# Upload migration logs and results

\- aws s3 cp \$MIGRATION_LOG_FILE
s3://\$DATA_MIGRATION_ARTIFACTS_BUCKET/migration-logs/\$CODEBUILD_BUILD_ID/

\- aws s3 cp \$MIGRATION_RESULTS_FILE
s3://\$DATA_MIGRATION_ARTIFACTS_BUCKET/migration-results/\$CODEBUILD_BUILD_ID/

\# Send notification

\- \|

if \[ -f "\$MIGRATION_RESULTS_FILE" \]; then

MIGRATION_STATUS=\$(jq -r '.status' \$MIGRATION_RESULTS_FILE)

TOTAL_TABLES=\$(jq -r '.total_tables' \$MIGRATION_RESULTS_FILE)

aws sns publish \\

--topic-arn \$DATA_MIGRATION_NOTIFICATIONS_TOPIC \\

--subject "Data Migration Status: \$MIGRATION_STATUS" \\

--message "Migration completed with status: \$MIGRATION_STATUS. Total
tables migrated: \$TOTAL_TABLES. Build ID: \$CODEBUILD_BUILD_ID"

fi

artifacts: files: - data-migration-log.json -
data-migration-results.json name: data-migration-artifacts

\## 4. Infrastructure as Code 自動化

\### 4.1 Terraform 自動化パイプライン

\`\`\`hcl

\# Infrastructure CI/CD Pipeline

resource "aws_codepipeline" "infrastructure_pipeline" {

name = "technova-infrastructure-pipeline"

role_arn = aws_iam_role.infrastructure_pipeline_role.arn

artifact_store {

location = aws_s3_bucket.terraform_artifacts.bucket

type = "S3"

encryption_key {

id = aws_kms_key.terraform_kms.arn

type = "KMS"

}

}

\# Source Stage

stage {

name = "Source"

action {

name = "SourceAction"

category = "Source"

owner = "AWS"

provider = "CodeCommit"

version = "1"

output_artifacts = \["source_output"\]

configuration = {

RepositoryName = "technova-infrastructure"

BranchName = "main"

}

}

}

\# Terraform Plan Stage (Multi-Environment)

stage {

name = "TerraformPlan"

\# Development Plan

action {

name = "Plan-Development"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

output_artifacts = \["dev_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_plan.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "development"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "development"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

\# Staging Plan

action {

name = "Plan-Staging"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

output_artifacts = \["staging_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_plan.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "staging"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "staging"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

\# Production Plan

action {

name = "Plan-Production"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output"\]

output_artifacts = \["prod_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_plan.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "production"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "production"

type = "PLAINTEXT"

}

\])

}

run_order = 1

}

}

\# Security Analysis Integration (統合セキュリティパイプラインと連携)

stage {

name = "SecurityAnalysis"

action {

name = "InfrastructureSecurityScan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output", "dev_plan_output",
"staging_plan_output", "prod_plan_output"\]

configuration = {

ProjectName = "terraform-validate-with-error-handling" \#
既存のセキュリティパイプラインと統合

EnvironmentVariables = jsonencode(\[

{

name = "SECURITY_SCAN_TYPE"

value = "INFRASTRUCTURE"

type = "PLAINTEXT"

},

{

name = "INTEGRATION_MODE"

value = "INFRASTRUCTURE_PIPELINE"

type = "PLAINTEXT"

}

\])

}

}

}

\# Development Deploy

stage {

name = "DeployDevelopment"

action {

name = "Apply-Development"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output", "dev_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_apply.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "development"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "development"

type = "PLAINTEXT"

}

\])

}

}

}

\# Staging Approval

stage {

name = "StagingApproval"

action {

name = "StagingDeploymentApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.infrastructure_approvals.arn

CustomData = "Development infrastructure deployment completed. Review
and approve staging deployment."

}

}

}

\# Staging Deploy

stage {

name = "DeployStaging"

action {

name = "Apply-Staging"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output", "staging_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_apply.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "staging"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "staging"

type = "PLAINTEXT"

}

\])

}

}

}

\# Production Approval

stage {

name = "ProductionApproval"

action {

name = "ProductionDeploymentApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

NotificationArn = aws_sns_topic.production_approvals.arn

CustomData = "Staging infrastructure deployment completed. Review and
approve production deployment."

}

}

}

\# Production Deploy

stage {

name = "DeployProduction"

action {

name = "Apply-Production"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

version = "1"

input_artifacts = \["source_output", "prod_plan_output"\]

configuration = {

ProjectName = aws_codebuild_project.terraform_apply.name

EnvironmentVariables = jsonencode(\[

{

name = "TF_WORKSPACE"

value = "production"

type = "PLAINTEXT"

},

{

name = "TF_VAR_environment"

value = "production"

type = "PLAINTEXT"

}

\])

}

}

}

tags = {

Purpose = "Infrastructure CI/CD"

Integration = "AFT-SecurityPipeline"

}

}

\# Terraform Plan Project

resource "aws_codebuild_project" "terraform_plan" {

name = "technova-terraform-plan"

description = "Terraform plan execution with multi-workspace support"

service_role = aws_iam_role.terraform_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "TF_VERSION"

value = "1.5.7"

}

environment_variable {

name = "TF_IN_AUTOMATION"

value = "true"

}

environment_variable {

name = "TF_INPUT"

value = "false"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/terraform-plan.yml"

}

tags = {

Purpose = "Terraform Planning"

Tool = "Terraform"

}

}

\# Terraform Apply Project

resource "aws_codebuild_project" "terraform_apply" {

name = "technova-terraform-apply"

description = "Terraform apply execution with state management"

service_role = aws_iam_role.terraform_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

compute_type = "BUILD_GENERAL1_MEDIUM"

image = "aws/codebuild/amazonlinux2-x86_64-standard:5.0"

type = "LINUX_CONTAINER"

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "TF_VERSION"

value = "1.5.7"

}

environment_variable {

name = "TF_IN_AUTOMATION"

value = "true"

}

environment_variable {

name = "TF_INPUT"

value = "false"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/terraform-apply.yml"

}

tags = {

Purpose = "Terraform Apply"

Tool = "Terraform"

}

}

4.2 Terraform BuildSpec ファイル

yaml

*\# terraform-plan.yml*

version: 0.2

env:

variables:

TF_ROOT: "environments"

PLAN_OUTPUT_FILE: "tfplan.json"

PLAN_SUMMARY_FILE: "plan-summary.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Installing Terraform \$TF_VERSION..."

\- wget
https://releases.hashicorp.com/terraform/\${TF_VERSION}/terraform\_\${TF_VERSION}\_linux_amd64.zip

\- unzip terraform\_\${TF_VERSION}\_linux_amd64.zip

\- mv terraform /usr/local/bin/

\- terraform version

\- echo "\[INSTALL\] Installing additional tools..."

\- curl -L
https://github.com/minamijoyo/tfcmt/releases/download/v4.0.0/tfcmt_linux_amd64.tar.gz
\| tar -xz

\- mv tfcmt /usr/local/bin/

pre_build:

commands:

\- echo "\[PRE_BUILD\] Setting up Terraform environment..."

\- cd \$TF_ROOT

*\# Initialize Terraform*

\- terraform init

*\# Select or create workspace*

\- terraform workspace select \$TF_WORKSPACE \|\| terraform workspace
new \$TF_WORKSPACE

*\# Validate configuration*

\- terraform validate

*\# Format check*

\- terraform fmt -check=true -diff=true

build:

commands:

\- echo "\[BUILD\] Creating Terraform plan for workspace:
\$TF_WORKSPACE..."

*\# Create plan with detailed output*

\- terraform plan -detailed-exitcode -out=tfplan
-var-file="environments/\${TF_WORKSPACE}.tfvars"

\- PLAN_EXIT_CODE=\$?

*\# Convert plan to JSON for analysis*

\- terraform show -json tfplan \> \$PLAN_OUTPUT_FILE

*\# Generate plan summary*

\- \|

cat \> \$PLAN_SUMMARY_FILE \<\< EOF

{

"workspace": "\$TF_WORKSPACE",

"environment": "\$TF_VAR_environment",

"plan_timestamp": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",

"plan_exit_code": \$PLAN_EXIT_CODE,

"resources_to_add": \$(jq '.resource_changes\[\] \|
select(.change.actions\[\] == "create") \| length' \$PLAN_OUTPUT_FILE \|
wc -l),

"resources_to_change": \$(jq '.resource_changes\[\] \|
select(.change.actions\[\] == "update") \| length' \$PLAN_OUTPUT_FILE \|
wc -l),

"resources_to_destroy": \$(jq '.resource_changes\[\] \|
select(.change.actions\[\] == "delete") \| length' \$PLAN_OUTPUT_FILE \|
wc -l),

"plan_file_size": \$(stat -c%s tfplan)

}

EOF

*\# Analyze plan for potential issues*

\- \|

echo "\[BUILD\] Analyzing Terraform plan..."

*\# Check for destructive changes*

DESTRUCTIVE_CHANGES=\$(jq '\[.resource_changes\[\] \|
select(.change.actions\[\] == "delete" or (.change.actions\[\] ==
"create" and .change.actions\[\] == "delete"))\] \| length'
\$PLAN_OUTPUT_FILE)

if \[ \$DESTRUCTIVE_CHANGES -gt 0 \]; then

echo "WARNING: Plan contains \$DESTRUCTIVE_CHANGES destructive changes"

jq '.resource_changes\[\] \| select(.change.actions\[\] == "delete" or
(.change.actions\[\] == "create" and .change.actions\[\] == "delete"))
\| {address: .address, actions: .change.actions}' \$PLAN_OUTPUT_FILE

fi

*\# Check for sensitive changes*

SENSITIVE_CHANGES=\$(jq '\[.resource_changes\[\] \|
select(.change.after_sensitive or .change.before_sensitive)\] \| length'
\$PLAN_OUTPUT_FILE)

if \[ \$SENSITIVE_CHANGES -gt 0 \]; then

echo "INFO: Plan contains \$SENSITIVE_CHANGES changes to sensitive
values"

fi

*\# Generate human-readable plan*

\- terraform show tfplan \> plan.txt

post_build:

commands:

\- echo "\[POST_BUILD\] Processing Terraform plan results..."

*\# Upload plan files to S3*

\- aws s3 cp tfplan
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/tfplan

\- aws s3 cp \$PLAN_OUTPUT_FILE
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/\$PLAN_OUTPUT_FILE

\- aws s3 cp \$PLAN_SUMMARY_FILE
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/\$PLAN_SUMMARY_FILE

\- aws s3 cp plan.txt
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/plan.txt

*\# Send plan summary notification*

\- \|

RESOURCES_TO_ADD=\$(jq -r '.resources_to_add' \$PLAN_SUMMARY_FILE)

RESOURCES_TO_CHANGE=\$(jq -r '.resources_to_change' \$PLAN_SUMMARY_FILE)

RESOURCES_TO_DESTROY=\$(jq -r '.resources_to_destroy'
\$PLAN_SUMMARY_FILE)

aws sns publish \\

--topic-arn \$TERRAFORM_NOTIFICATIONS_TOPIC \\

--subject "Terraform Plan: \$TF_WORKSPACE Environment" \\

--message "Terraform plan completed for \$TF_WORKSPACE environment.

Changes Summary:

\- Resources to Add: \$RESOURCES_TO_ADD

\- Resources to Change: \$RESOURCES_TO_CHANGE

\- Resources to Destroy: \$RESOURCES_TO_DESTROY

Plan details:
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/"

*\# Exit with plan exit code for pipeline decision*

\- exit \$PLAN_EXIT_CODE

artifacts:

files:

\- \$TF_ROOT/tfplan

\- \$TF_ROOT/\$PLAN_OUTPUT_FILE

\- \$TF_ROOT/\$PLAN_SUMMARY_FILE

\- \$TF_ROOT/plan.txt

name: terraform-plan-output

yaml

*\# terraform-apply.yml*

version: 0.2

env:

variables:

TF_ROOT: "environments"

APPLY_LOG_FILE: "apply-log.json"

phases:

install:

commands:

\- echo "\[INSTALL\] Installing Terraform \$TF_VERSION..."

\- wget
https://releases.hashicorp.com/terraform/\${TF_VERSION}/terraform\_\${TF_VERSION}\_linux_amd64.zip

\- unzip terraform\_\${TF_VERSION}\_linux_amd64.zip

\- mv terraform /usr/local/bin/

\- terraform version

pre_build:

commands:

\- echo "\[PRE_BUILD\] Setting up Terraform environment..."

\- cd \$TF_ROOT

*\# Initialize Terraform*

\- terraform init

*\# Select workspace*

\- terraform workspace select \$TF_WORKSPACE

*\# Download plan file from previous stage*

\- aws s3 cp
s3://\$TERRAFORM_PLANS_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/tfplan
./tfplan

*\# Verify plan is still valid*

\- terraform show tfplan \> current_plan.txt

build:

commands:

\- echo "\[BUILD\] Applying Terraform plan for workspace:
\$TF_WORKSPACE..."

*\# Initialize apply log*

\- \|

cat \> \$APPLY_LOG_FILE \<\< EOF

{

"workspace": "\$TF_WORKSPACE",

"environment": "\$TF_VAR_environment",

"apply_start_time": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",

"build_id": "\$CODEBUILD_BUILD_ID",

"events": \[\]

}

EOF

*\# Apply the plan*

\- \|

echo "Starting Terraform apply..."

terraform apply -auto-approve tfplan 2\>&1 \| tee apply_output.log

APPLY_EXIT_CODE=\${PIPESTATUS\[0\]}

*\# Update apply log with result*

if \[ \$APPLY_EXIT_CODE -eq 0 \]; then

APPLY_STATUS="SUCCESS"

echo "Terraform apply completed successfully"

else

APPLY_STATUS="FAILED"

echo "Terraform apply failed with exit code \$APPLY_EXIT_CODE"

fi

*\# Extract resource changes from apply output*

RESOURCES_CREATED=\$(grep -c "Creation complete after" apply_output.log
\|\| echo "0")

RESOURCES_MODIFIED=\$(grep -c "Modifications complete after"
apply_output.log \|\| echo "0")

RESOURCES_DESTROYED=\$(grep -c "Destruction complete after"
apply_output.log \|\| echo "0")

*\# Update log with final results*

jq --arg status "\$APPLY_STATUS" \\

--arg end_time "\$(date -u +%Y-%m-%dT%H:%M:%SZ)" \\

--argjson exit_code \$APPLY_EXIT_CODE \\

--argjson created \$RESOURCES_CREATED \\

--argjson modified \$RESOURCES_MODIFIED \\

--argjson destroyed \$RESOURCES_DESTROYED \\

'.apply_end_time = \$end_time \| .status = \$status \| .exit_code =
\$exit_code \| .resources_created = \$created \| .resources_modified =
\$modified \| .resources_destroyed = \$destroyed' \\

\$APPLY_LOG_FILE \> temp.json && mv temp.json \$APPLY_LOG_FILE

if \[ \$APPLY_EXIT_CODE -ne 0 \]; then

exit \$APPLY_EXIT_CODE

fi

post_build:

commands:

\- echo "\[POST_BUILD\] Processing Terraform apply results..."

*\# Generate state information*

\- terraform show -json \> current_state.json

*\# Upload results to S3*

\- aws s3 cp apply_output.log
s3://\$TERRAFORM_STATES_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/apply_output.log

\- aws s3 cp \$APPLY_LOG_FILE
s3://\$TERRAFORM_STATES_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/\$APPLY_LOG_FILE

\- aws s3 cp current_state.json
s3://\$TERRAFORM_STATES_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/current_state.json

*\# Send completion notification*

\- \|

if \[ -f "\$APPLY_LOG_FILE" \]; then

APPLY_STATUS=\$(jq -r '.status' \$APPLY_LOG_FILE)

RESOURCES_CREATED=\$(jq -r '.resources_created' \$APPLY_LOG_FILE)

RESOURCES_MODIFIED=\$(jq -r '.resources_modified' \$APPLY_LOG_FILE)

RESOURCES_DESTROYED=\$(jq -r '.resources_destroyed' \$APPLY_LOG_FILE)

aws sns publish \\

--topic-arn \$TERRAFORM_NOTIFICATIONS_TOPIC \\

--subject "Terraform Apply: \$TF_WORKSPACE Environment - \$APPLY_STATUS"
\\

--message "Terraform apply completed for \$TF_WORKSPACE environment.

Status: \$APPLY_STATUS

Resources Created: \$RESOURCES_CREATED

Resources Modified: \$RESOURCES_MODIFIED

Resources Destroyed: \$RESOURCES_DESTROYED

Apply logs:
s3://\$TERRAFORM_STATES_BUCKET/\$TF_WORKSPACE/\$CODEBUILD_BUILD_ID/"

fi

*\# Update infrastructure inventory*

\- \|

echo "Updating infrastructure inventory..."

python3 \<\< 'EOF'

import json

import boto3

from datetime import datetime

*\# Load current state*

with open('current_state.json', 'r') as f:

state = json.load(f)

*\# Extract resource inventory*

inventory = {

'workspace': os.environ\['TF_WORKSPACE'\],

'environment': os.environ\['TF_VAR_environment'\],

'last_updated': datetime.now().isoformat(),

'terraform_version

再試行

C

続ける

編集

'terraform_version': state.get('terraform_version', 'unknown'),
'resources': \[\] }

if 'values' in state and 'root_module' in state\['values'\]:

resources = state\['values'\]\['root_module'\].get('resources', \[\])

for resource in resources:

inventory\['resources'\].append({

'address': resource.get('address', ''),

'type': resource.get('type', ''),

'name': resource.get('name', ''),

'provider_name': resource.get('provider_name', ''),

'values': {

'id': resource.get('values', {}).get('id', ''),

'arn': resource.get('values', {}).get('arn', ''),

'tags': resource.get('values', {}).get('tags', {})

}

})

\# Save inventory

with open('infrastructure_inventory.json', 'w') as f:

json.dump(inventory, f, indent=2)

\# Upload to S3

s3 = boto3.client('s3')

s3.upload_file(

'infrastructure_inventory.json',

os.environ\['TERRAFORM_STATES_BUCKET'\],

f"{os.environ\['TF_WORKSPACE'\]}/current/infrastructure_inventory.json"

)

print(f"Infrastructure inventory updated:
{len(inventory\['resources'\])} resources")

EOF

artifacts: files: - \$TF_ROOT/apply_output.log - TFROOT/TF_ROOT/
TFR​OOT/APPLY_LOG_FILE - \$TF_ROOT/current_state.json -
\$TF_ROOT/infrastructure_inventory.json name: terraform-apply-output

\## 5. セキュリティ自動化統合

\### 5.1 セキュリティパイプライン統合ポイント

\`\`\`yaml

\# セキュリティ自動化統合マトリックス

security_integration_matrix:

\# AFT統合ポイント

aft_integration:

account_provisioning:

\- "アカウント作成時のセキュリティベースライン自動適用"

\- "GuardDuty, Security Hub, Config の自動有効化"

\- "IAM Identity Center Permission Set 自動適用"

global_customizations:

\- "組織レベルセキュリティポリシーの強制"

\- "CloudTrail組織トレイルの自動設定"

\- "Config Rules の統一適用"

account_customizations:

\- "事業部門別セキュリティ要件の適用"

\- "環境別セキュリティ設定の差分管理"

\- "コンプライアンス要件の自動検証"

\# CI/CD統合ポイント

cicd_integration:

pre_deployment:

\- "静的セキュリティ分析（SAST）"

\- "コンテナイメージ脆弱性スキャン"

\- "IaCセキュリティ検証"

deployment:

\- "デプロイ時セキュリティ検証"

\- "ランタイムセキュリティ監視開始"

\- "セキュリティベースライン確認"

post_deployment:

\- "動的セキュリティテスト（DAST）"

\- "ペネトレーションテスト実行"

\- "セキュリティメトリクス収集"

\# データ移行統合ポイント

data_migration_integration:

pre_migration:

\- "データ分類とセキュリティタグ付け"

\- "暗号化要件の検証"

\- "アクセス制御設定の確認"

during_migration:

\- "データ転送時暗号化の監視"

\- "不正アクセス検知"

\- "データ整合性チェック"

post_migration:

\- "データアクセス監査"

\- "暗号化状態の検証"

\- "コンプライアンス準拠確認"

5.2 統合セキュリティ自動化Lambda

python

*\# 統合セキュリティ自動化オーケストレーター*

import boto3

import json

import os

from datetime import datetime

from typing import Dict, List, Any

import asyncio

import concurrent.futures

class SecurityAutomationOrchestrator:

def \_\_init\_\_(self):

self.codebuild = boto3.client('codebuild')

self.codepipeline = boto3.client('codepipeline')

self.sns = boto3.client('sns')

self.cloudwatch = boto3.client('cloudwatch')

self.ssm = boto3.client('ssm')

*\# 統合設定の取得*

self.config = self.\_load_integration_config()

def \_load_integration_config(self) -\> Dict\[str, Any\]:

"""

統合設定の読み込み

"""

try:

response = self.ssm.get_parameter(

Name='/technova/security-automation/integration-config',

WithDecryption=True

)

return json.loads(response\['Parameter'\]\['Value'\])

except Exception as e:

print(f"Failed to load integration config: {e}")

return {

'security_pipeline': {

'name': 'security-integrated-deployment-pipeline',

'integration_enabled': True

},

'infrastructure_pipeline': {

'name': 'technova-infrastructure-pipeline',

'integration_enabled': True

},

'microservices_pipeline': {

'name': 'technova-microservices-pipeline',

'integration_enabled': True

}

}

def lambda_handler(self, event, context):

"""

統合セキュリティ自動化のメインハンドラー

"""

try:

event_source = event.get('source', '')

detail_type = event.get('detail-type', '')

print(f"Processing security automation event: {event_source} -
{detail_type}")

*\# イベント種別による処理分岐*

if event_source == 'aws.codepipeline':

return self.\_handle_pipeline_event(event)

elif event_source == 'aws.organizations':

return self.\_handle_account_event(event)

elif event_source == 'aws.guardduty':

return self.\_handle_security_finding(event)

elif event_source == 'technova.aft':

return self.\_handle_aft_event(event)

else:

return self.\_handle_generic_event(event)

except Exception as e:

print(f"Security automation orchestrator error: {str(e)}")

return {

'statusCode': 500,

'body': json.dumps({'error': str(e)})

}

def \_handle_pipeline_event(self, event):

"""

パイプラインイベントの処理

"""

detail = event.get('detail', {})

pipeline_name = detail.get('pipeline', '')

state = detail.get('state', '')

print(f"Processing pipeline event: {pipeline_name} - {state}")

if state == 'STARTED':

return self.\_initiate_security_checks(pipeline_name, detail)

elif state == 'SUCCEEDED':

return self.\_complete_security_validation(pipeline_name, detail)

elif state == 'FAILED':

return self.\_handle_pipeline_failure(pipeline_name, detail)

return {'statusCode': 200, 'message': 'Pipeline event processed'}

def \_initiate_security_checks(self, pipeline_name: str, detail:
Dict\[str, Any\]):

"""

パイプライン開始時のセキュリティチェック開始

"""

execution_id = detail.get('execution-id', '')

security_checks = \[\]

*\# パイプライン別のセキュリティチェック定義*

if 'infrastructure' in pipeline_name.lower():

security_checks = \[

'terraform-security-scan',

'iac-compliance-check',

'infrastructure-vulnerability-scan'

\]

elif 'microservices' in pipeline_name.lower():

security_checks = \[

'container-security-scan',

'sast-analysis',

'dependency-scan'

\]

elif 'data-migration' in pipeline_name.lower():

security_checks = \[

'data-classification-scan',

'encryption-validation',

'access-control-verification'

\]

*\# 並列セキュリティチェック実行*

with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:

futures = \[\]

for check in security_checks:

future = executor.submit(self.\_execute_security_check, check,
pipeline_name, execution_id)

futures.append(future)

*\# 結果収集*

results = \[\]

for future in concurrent.futures.as_completed(futures):

try:

result = future.result(timeout=300) *\# 5分タイムアウト*

results.append(result)

except Exception as e:

print(f"Security check failed: {e}")

results.append({'status': 'FAILED', 'error': str(e)})

*\# 結果の集約と通知*

self.\_aggregate_security_results(pipeline_name, execution_id, results)

return {

'statusCode': 200,

'security_checks_initiated': len(security_checks),

'results': results

}

def \_execute_security_check(self, check_type: str, pipeline_name: str,
execution_id: str):

"""

個別セキュリティチェックの実行

"""

try:

*\# CodeBuildプロジェクトマッピング*

project_mapping = {

'terraform-security-scan': 'terraform-validate-with-error-handling',

'iac-compliance-check': 'checkov-security-compliance',

'infrastructure-vulnerability-scan':
'dynamic-infrastructure-vulnerability-scan',

'container-security-scan': 'technova-container-security-scan',

'sast-analysis': 'technova-sast-security-scan',

'dependency-scan': 'dependency-vulnerability-scan',

'data-classification-scan': 'data-classification-scanner',

'encryption-validation': 'encryption-compliance-validator',

'access-control-verification': 'access-control-verifier'

}

project_name = project_mapping.get(check_type)

if not project_name:

raise ValueError(f"Unknown security check type: {check_type}")

*\# セキュリティチェック実行*

response = self.codebuild.start_build(

projectName=project_name,

environmentVariablesOverride=\[

{

'name': 'TRIGGERED_BY_PIPELINE',

'value': pipeline_name,

'type': 'PLAINTEXT'

},

{

'name': 'PIPELINE_EXECUTION_ID',

'value': execution_id,

'type': 'PLAINTEXT'

},

{

'name': 'SECURITY_CHECK_TYPE',

'value': check_type,

'type': 'PLAINTEXT'

}

\]

)

build_id = response\['build'\]\['id'\]

*\# ビルド完了まで待機（簡略版 - 実際は非同期処理推奨）*

waiter = self.codebuild.get_waiter('build_complete')

waiter.wait(ids=\[build_id\])

*\# 結果取得*

build_info =
self.codebuild.batch_get_builds(ids=\[build_id\])\['builds'\]\[0\]

return {

'check_type': check_type,

'build_id': build_id,

'status': build_info\['buildStatus'\],

'duration': (build_info.get('endTime', datetime.now()) -
build_info\['startTime'\]).total_seconds()

}

except Exception as e:

print(f"Security check {check_type} failed: {e}")

return {

'check_type': check_type,

'status': 'FAILED',

'error': str(e)

}

def \_handle_aft_event(self, event):

"""

AFTイベントの処理（アカウント作成・カスタマイゼーション）

"""

detail = event.get('detail', {})

event_type = detail.get('eventType', '')

account_id = detail.get('accountId', '')

print(f"Processing AFT event: {event_type} for account {account_id}")

if event_type == 'ACCOUNT_PROVISIONED':

return self.\_apply_security_baseline(account_id, detail)

elif event_type == 'CUSTOMIZATION_COMPLETED':

return self.\_validate_security_configuration(account_id, detail)

return {'statusCode': 200, 'message': 'AFT event processed'}

def \_apply_security_baseline(self, account_id: str, detail: Dict\[str,
Any\]):

"""

新規アカウントへのセキュリティベースライン適用

"""

business_unit = detail.get('businessUnit', 'unknown')

environment = detail.get('environment', 'unknown')

*\# セキュリティベースライン適用タスク*

baseline_tasks = \[

{

'name': 'enable-guardduty',

'project': 'security-baseline-guardduty',

'priority': 'HIGH'

},

{

'name': 'configure-security-hub',

'project': 'security-baseline-securityhub',

'priority': 'HIGH'

},

{

'name': 'setup-cloudtrail',

'project': 'security-baseline-cloudtrail',

'priority': 'HIGH'

},

{

'name': 'configure-config-rules',

'project': 'security-baseline-config',

'priority': 'MEDIUM'

},

{

'name': 'setup-iam-policies',

'project': 'security-baseline-iam',

'priority': 'HIGH'

}

\]

*\# 並列実行でセキュリティベースライン適用*

with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:

futures = \[\]

for task in baseline_tasks:

future = executor.submit(

self.\_execute_baseline_task,

task,

account_id,

business_unit,

environment

)

futures.append((task\['name'\], future))

*\# 結果収集*

results = {}

for task_name, future in futures:

try:

result = future.result(timeout=600) *\# 10分タイムアウト*

results\[task_name\] = result

except Exception as e:

print(f"Baseline task {task_name} failed: {e}")

results\[task_name\] = {'status': 'FAILED', 'error': str(e)}

*\# 結果通知*

self.\_notify_baseline_completion(account_id, business_unit,
environment, results)

return {

'statusCode': 200,

'account_id': account_id,

'baseline_tasks_completed': len(results),

'results': results

}

def \_execute_baseline_task(self, task: Dict\[str, Any\], account_id:
str, business_unit: str, environment: str):

"""

個別セキュリティベースラインタスクの実行

"""

try:

response = self.codebuild.start_build(

projectName=task\['project'\],

environmentVariablesOverride=\[

{

'name': 'TARGET_ACCOUNT_ID',

'value': account_id,

'type': 'PLAINTEXT'

},

{

'name': 'BUSINESS_UNIT',

'value': business_unit,

'type': 'PLAINTEXT'

},

{

'name': 'ENVIRONMENT',

'value': environment,

'type': 'PLAINTEXT'

},

{

'name': 'TASK_PRIORITY',

'value': task\['priority'\],

'type': 'PLAINTEXT'

}

\]

)

build_id = response\['build'\]\['id'\]

*\# 優先度に応じた待機戦略*

if task\['priority'\] == 'HIGH':

*\# 高優先度タスクは完了まで待機*

waiter = self.codebuild.get_waiter('build_complete')

waiter.wait(ids=\[build_id\])

build_info =
self.codebuild.batch_get_builds(ids=\[build_id\])\['builds'\]\[0\]

return {

'task': task\['name'\],

'build_id': build_id,

'status': build_info\['buildStatus'\]

}

else:

*\# 中・低優先度タスクは非同期実行*

return {

'task': task\['name'\],

'build_id': build_id,

'status': 'STARTED_ASYNC'

}

except Exception as e:

print(f"Baseline task {task\['name'\]} execution failed: {e}")

return {

'task': task\['name'\],

'status': 'FAILED',

'error': str(e)

}

def \_aggregate_security_results(self, pipeline_name: str, execution_id:
str, results: List\[Dict\[str, Any\]\]):

"""

セキュリティチェック結果の集約

"""

*\# 結果サマリー作成*

total_checks = len(results)

passed_checks = len(\[r for r in results if r.get('status') ==
'SUCCEEDED'\])

failed_checks = len(\[r for r in results if r.get('status') ==
'FAILED'\])

summary = {

'pipeline_name': pipeline_name,

'execution_id': execution_id,

'timestamp': datetime.now().isoformat(),

'total_checks': total_checks,

'passed_checks': passed_checks,

'failed_checks': failed_checks,

'success_rate': (passed_checks / total_checks \* 100) if total_checks \>
0 else 0,

'details': results

}

*\# CloudWatchメトリクス送信*

self.cloudwatch.put_metric_data(

Namespace='TechNova/SecurityAutomation',

MetricData=\[

{

'MetricName': 'SecurityChecksTotal',

'Value': total_checks,

'Unit': 'Count',

'Dimensions': \[

{

'Name': 'PipelineName',

'Value': pipeline_name

}

\]

},

{

'MetricName': 'SecurityChecksPassed',

'Value': passed_checks,

'Unit': 'Count',

'Dimensions': \[

{

'Name': 'PipelineName',

'Value': pipeline_name

}

\]

},

{

'MetricName': 'SecurityChecksFailed',

'Value': failed_checks,

'Unit': 'Count',

'Dimensions': \[

{

'Name': 'PipelineName',

'Value': pipeline_name

}

\]

},

{

'MetricName': 'SecuritySuccessRate',

'Value': summary\['success_rate'\],

'Unit': 'Percent',

'Dimensions': \[

{

'Name': 'PipelineName',

'Value': pipeline_name

}

\]

}

\]

)

*\# 失敗がある場合は通知*

if failed_checks \> 0:

self.\_send_security_alert(summary)

return summary

def \_send_security_alert(self, summary: Dict\[str, Any\]):

"""

セキュリティアラートの送信

"""

try:

message = f"""

🚨 セキュリティチェック失敗アラート 🚨

パイプライン: {summary\['pipeline_name'\]}

実行ID: {summary\['execution_id'\]}

失敗したチェック数:
{summary\['failed_checks'\]}/{summary\['total_checks'\]}

成功率: {summary\['success_rate'\]:.1f}%

失敗詳細:

"""

for result in summary\['details'\]:

if result.get('status') == 'FAILED':

message += f"- {result.get('check_type', 'Unknown')}:
{result.get('error', 'No details')}\n"

message += f"\n詳細は CloudWatch Logs で確認してください。\n実行時刻:
{summary\['timestamp'\]}"

self.sns.publish(

TopicArn=os.environ.get('SECURITY_ALERTS_TOPIC'),

Subject=f"セキュリティチェック失敗: {summary\['pipeline_name'\]}",

Message=message

)

except Exception as e:

print(f"Failed to send security alert: {e}")

def lambda_handler(event, context):

"""

Lambda エントリーポイント

"""

orchestrator = SecurityAutomationOrchestrator()

return orchestrator.lambda_handler(event, context)

6\. 監視・運用自動化

6.1 統合監視ダッシュボード

hcl

*\# 統合監視ダッシュボード*

resource "aws_cloudwatch_dashboard" "automation_integrated_dashboard" {

dashboard_name = "TechNova-Automation-Integrated-Dashboard"

dashboard_body = jsonencode({

widgets = \[

*\# AFT メトリクス*

{

type = "metric"

x = 0

y = 0

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/AFT", "AccountsProvisioned"\],

\[".", "AccountProvisioningErrors"\],

\[".", "CustomizationSuccessRate"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "AFT Account Provisioning"

period = 300

}

},

*\# CI/CD パイプライン メトリクス*

{

type = "metric"

x = 8

y = 0

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/CICD", "PipelineExecutions"\],

\[".", "PipelineSuccessRate"\],

\[".", "AverageExecutionTime"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "CI/CD Pipeline Performance"

period = 300

}

},

*\# セキュリティ自動化メトリクス*

{

type = "metric"

x = 16

y = 0

width = 8

height = 6

properties = {

metrics = \[

\["TechNova/SecurityAutomation", "SecurityChecksTotal"\],

\[".", "SecurityChecksPassed"\],

\[".", "SecurityChecksFailed"\],

\[".", "SecuritySuccessRate"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "Security Automation"

period = 300

}

},

*\# データ移行メトリクス*

{

type = "metric"

x = 0

y = 6

width = 12

height = 6

properties = {

metrics = \[

\["TechNova/DataMigration", "MigrationJobsCompleted"\],

\[".", "MigrationSuccessRate"\],

\[".", "DataVolumeTransferred"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "Data Migration Progress"

period = 300

}

},

*\# インフラストラクチャ自動化*

{

type = "metric"

x = 12

y = 6

width = 12

height = 6

properties = {

metrics = \[

\["TechNova/Infrastructure", "TerraformAppliesSucceeded"\],

\[".", "TerraformAppliesFailed"\],

\[".", "ResourcesManaged"\]

\]

view = "timeSeries"

stacked = false

region = "ap-northeast-1"

title = "Infrastructure Automation"

period = 300

}

},

*\# 統合ログ検索*

{

type = "log"

x = 0

y = 12

width = 24

height = 8

properties = {

query = """

fields @timestamp, @message, @logStream

\| filter @message like /ERROR\|FAILED\|CRITICAL/

\| sort @timestamp desc

\| limit 50

"""

region = "ap-northeast-1"

title = "Recent Errors Across All Automation"

view = "table"

sources = \[

"/aws/codebuild/technova-terraform-plan",

"/aws/codebuild/technova-api-service-build",

"/aws/codebuild/technova-data-migration",

"/aws/lambda/security-automation-orchestrator"

\]

}

}

\]

})

}

6.2 自動化運用監視Lambda

python

*\# 自動化システム運用監視*

import boto3

import json

import os

from datetime import datetime, timedelta

from typing import Dict, List, Any

class AutomationOperationsMonitor:

def \_\_init\_\_(self):

self.cloudwatch = boto3.client('cloudwatch')

self.codepipeline = boto3.client('codepipeline')

self.codebuild = boto3.client('codebuild')

self.sns = boto3.client('sns')

self.dynamodb = boto3.resource('dynamodb')

*\# 監視対象の設定*

self.monitoring_config = {

'pipelines': \[

'security-integrated-deployment-pipeline',

'technova-infrastructure-pipeline',

'technova-microservices-pipeline',

'technova-data-migration-pipeline'

\],

'thresholds': {

'pipeline_failure_rate': 10, *\# 10%以上の失敗率でアラート*

'build_duration_minutes': 60, *\# 60分以上でアラート*

'security_check_failure_rate': 5 *\# 5%以上でアラート*

}

}

def lambda_handler(self, event, context):

"""

定期実行される運用監視のメインハンドラー

"""

try:

print("Starting automation operations monitoring...")

*\# 各システムの健全性チェック*

pipeline_health = self.\_check_pipeline_health()

security_health = self.\_check_security_automation_health()

infrastructure_health = self.\_check_infrastructure_automation_health()

data_migration_health = self.\_check_data_migration_health()

*\# 総合ヘルススコア計算*

overall_health = self.\_calculate_overall_health(\[

pipeline_health,

security_health,

infrastructure_health,

data_migration_health

\])

*\# アラート判定と通知*

alerts = self.\_evaluate_alerts({

'pipeline': pipeline_health,

'security': security_health,

'infrastructure': infrastructure_health,

'data_migration': data_migration_health,

'overall': overall_health

})

if alerts:

self.\_send_operations_alerts(alerts)

*\# 運用レポート生成*

operations_report = self.\_generate_operations_report({

'pipeline_health': pipeline_health,

'security_health': security_health,

'infrastructure_health': infrastructure_health,

'data_migration_health': data_migration_health,

'overall_health': overall_health,

'alerts': alerts

})

return {

'statusCode': 200,

'body': json.dumps(operations_report, default=str)

}

except Exception as e:

print(f"Operations monitoring failed: {str(e)}")

return {

'statusCode': 500,

'body': json.dumps({'error': str(e)})

}

def \_check_pipeline_health(self) -\> Dict\[str, Any\]:

"""

パイプライン全体の健全性チェック

"""

health_data = {

'status': 'HEALTHY',

'pipelines': {},

'metrics': {

'total_executions': 0,

'successful_executions': 0,

'failed_executions': 0,

'success_rate': 0,

'average_duration': 0

}

}

try:

end_time = datetime.now()

start_time = end_time - timedelta(hours=24)

total_executions = 0

successful_executions = 0

failed_executions = 0

total_duration = 0

for pipeline_name in self.monitoring_config\['pipelines'\]:

try:

*\# パイプライン実行履歴の取得*

executions = self.codepipeline.list_pipeline_executions(

pipelineName=pipeline_name

)

recent_executions = \[

exec for exec in executions\['pipelineExecutionSummaries'\]

if exec\['startTime'\] \>= start_time

\]

pipeline_success = 0

pipeline_failed = 0

pipeline_duration = 0

for execution in recent_executions:

total_executions += 1

if execution\['status'\] == 'Succeeded':

successful_executions

再試行

C

続ける

編集

successful_executions += 1 pipeline_success += 1 elif
execution\['status'\] == 'Failed': failed_executions += 1
pipeline_failed += 1

\# 実行時間の計算

if 'endTime' in execution:

duration = (execution\['endTime'\] -
execution\['startTime'\]).total_seconds() / 60

total_duration += duration

pipeline_duration += duration

\# パイプライン別の健全性評価

pipeline_total = len(recent_executions)

pipeline_success_rate = (pipeline_success / pipeline_total \* 100) if
pipeline_total \> 0 else 100

health_data\['pipelines'\]\[pipeline_name\] = {

'total_executions': pipeline_total,

'successful_executions': pipeline_success,

'failed_executions': pipeline_failed,

'success_rate': pipeline_success_rate,

'average_duration': (pipeline_duration / pipeline_total) if
pipeline_total \> 0 else 0,

'status': 'UNHEALTHY' if pipeline_success_rate \< (100 -
self.monitoring_config\['thresholds'\]\['pipeline_failure_rate'\]) else
'HEALTHY'

}

except Exception as e:

print(f"Failed to check pipeline {pipeline_name}: {e}")

health_data\['pipelines'\]\[pipeline_name\] = {

'status': 'ERROR',

'error': str(e)

}

\# 全体メトリクスの計算

health_data\['metrics'\]\['total_executions'\] = total_executions

health_data\['metrics'\]\['successful_executions'\] =
successful_executions

health_data\['metrics'\]\['failed_executions'\] = failed_executions

health_data\['metrics'\]\['success_rate'\] = (successful_executions /
total_executions \* 100) if total_executions \> 0 else 100

health_data\['metrics'\]\['average_duration'\] = (total_duration /
total_executions) if total_executions \> 0 else 0

\# 全体ステータスの判定

if health_data\['metrics'\]\['success_rate'\] \< (100 -
self.monitoring_config\['thresholds'\]\['pipeline_failure_rate'\]):

health_data\['status'\] = 'UNHEALTHY'

except Exception as e:

print(f"Pipeline health check failed: {e}")

health_data\['status'\] = 'ERROR'

health_data\['error'\] = str(e)

return health_data

def \_check_security_automation_health(self) -\> Dict\[str, Any\]:

"""

セキュリティ自動化の健全性チェック

"""

health_data = {

'status': 'HEALTHY',

'metrics': {

'security_checks_total': 0,

'security_checks_passed': 0,

'security_checks_failed': 0,

'security_success_rate': 0,

'critical_alerts': 0

}

}

try:

end_time = datetime.now()

start_time = end_time - timedelta(hours=24)

\# CloudWatchメトリクスから セキュリティ自動化の統計を取得

metrics_to_check = \[

'SecurityChecksTotal',

'SecurityChecksPassed',

'SecurityChecksFailed'

\]

for metric_name in metrics_to_check:

try:

response = self.cloudwatch.get_metric_statistics(

Namespace='TechNova/SecurityAutomation',

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600,

Statistics=\['Sum'\]

)

total_value = sum(point\['Sum'\] for point in response\['Datapoints'\])

if metric_name == 'SecurityChecksTotal':

health_data\['metrics'\]\['security_checks_total'\] = int(total_value)

elif metric_name == 'SecurityChecksPassed':

health_data\['metrics'\]\['security_checks_passed'\] = int(total_value)

elif metric_name == 'SecurityChecksFailed':

health_data\['metrics'\]\['security_checks_failed'\] = int(total_value)

except Exception as e:

print(f"Failed to get metric {metric_name}: {e}")

\# セキュリティ成功率の計算

total_checks = health_data\['metrics'\]\['security_checks_total'\]

passed_checks = health_data\['metrics'\]\['security_checks_passed'\]

if total_checks \> 0:

health_data\['metrics'\]\['security_success_rate'\] = (passed_checks /
total_checks \* 100)

else:

health_data\['metrics'\]\['security_success_rate'\] = 100

\# 健全性判定

if health_data\['metrics'\]\['security_success_rate'\] \< (100 -
self.monitoring_config\['thresholds'\]\['security_check_failure_rate'\]):

health_data\['status'\] = 'UNHEALTHY'

except Exception as e:

print(f"Security automation health check failed: {e}")

health_data\['status'\] = 'ERROR'

health_data\['error'\] = str(e)

return health_data

def \_check_infrastructure_automation_health(self) -\> Dict\[str, Any\]:

"""

インフラストラクチャ自動化の健全性チェック

"""

health_data = {

'status': 'HEALTHY',

'terraform': {

'plans_executed': 0,

'applies_succeeded': 0,

'applies_failed': 0,

'success_rate': 0

},

'aft': {

'accounts_provisioned': 0,

'provisioning_errors': 0,

'success_rate': 0

}

}

try:

end_time = datetime.now()

start_time = end_time - timedelta(hours=24)

\# Terraform メトリクス

terraform_metrics = \[

'TerraformPlansExecuted',

'TerraformAppliesSucceeded',

'TerraformAppliesFailed'

\]

for metric_name in terraform_metrics:

try:

response = self.cloudwatch.get_metric_statistics(

Namespace='TechNova/Infrastructure',

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600,

Statistics=\['Sum'\]

)

total_value = sum(point\['Sum'\] for point in response\['Datapoints'\])

if metric_name == 'TerraformPlansExecuted':

health_data\['terraform'\]\['plans_executed'\] = int(total_value)

elif metric_name == 'TerraformAppliesSucceeded':

health_data\['terraform'\]\['applies_succeeded'\] = int(total_value)

elif metric_name == 'TerraformAppliesFailed':

health_data\['terraform'\]\['applies_failed'\] = int(total_value)

except Exception as e:

print(f"Failed to get Terraform metric {metric_name}: {e}")

\# Terraform成功率の計算

total_applies = health_data\['terraform'\]\['applies_succeeded'\] +
health_data\['terraform'\]\['applies_failed'\]

if total_applies \> 0:

health_data\['terraform'\]\['success_rate'\] =
(health_data\['terraform'\]\['applies_succeeded'\] / total_applies \*
100)

else:

health_data\['terraform'\]\['success_rate'\] = 100

\# AFT メトリクス

aft_metrics = \[

'AccountsProvisioned',

'AccountProvisioningErrors'

\]

for metric_name in aft_metrics:

try:

response = self.cloudwatch.get_metric_statistics(

Namespace='TechNova/AFT',

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600,

Statistics=\['Sum'\]

)

total_value = sum(point\['Sum'\] for point in response\['Datapoints'\])

if metric_name == 'AccountsProvisioned':

health_data\['aft'\]\['accounts_provisioned'\] = int(total_value)

elif metric_name == 'AccountProvisioningErrors':

health_data\['aft'\]\['provisioning_errors'\] = int(total_value)

except Exception as e:

print(f"Failed to get AFT metric {metric_name}: {e}")

\# AFT成功率の計算

total_provisions = health_data\['aft'\]\['accounts_provisioned'\] +
health_data\['aft'\]\['provisioning_errors'\]

if total_provisions \> 0:

health_data\['aft'\]\['success_rate'\] =
(health_data\['aft'\]\['accounts_provisioned'\] / total_provisions \*
100)

else:

health_data\['aft'\]\['success_rate'\] = 100

\# 全体健全性判定

if (health_data\['terraform'\]\['success_rate'\] \< 90 or

health_data\['aft'\]\['success_rate'\] \< 95):

health_data\['status'\] = 'UNHEALTHY'

except Exception as e:

print(f"Infrastructure automation health check failed: {e}")

health_data\['status'\] = 'ERROR'

health_data\['error'\] = str(e)

return health_data

def \_check_data_migration_health(self) -\> Dict\[str, Any\]:

"""

データ移行の健全性チェック

"""

health_data = {

'status': 'HEALTHY',

'metrics': {

'migration_jobs_total': 0,

'migration_jobs_completed': 0,

'migration_jobs_failed': 0,

'success_rate': 0,

'data_volume_transferred_gb': 0

}

}

try:

end_time = datetime.now()

start_time = end_time - timedelta(hours=24)

\# データ移行メトリクス

migration_metrics = \[

'MigrationJobsCompleted',

'MigrationJobsFailed',

'DataVolumeTransferred'

\]

for metric_name in migration_metrics:

try:

response = self.cloudwatch.get_metric_statistics(

Namespace='TechNova/DataMigration',

MetricName=metric_name,

StartTime=start_time,

EndTime=end_time,

Period=3600,

Statistics=\['Sum'\]

)

total_value = sum(point\['Sum'\] for point in response\['Datapoints'\])

if metric_name == 'MigrationJobsCompleted':

health_data\['metrics'\]\['migration_jobs_completed'\] =
int(total_value)

elif metric_name == 'MigrationJobsFailed':

health_data\['metrics'\]\['migration_jobs_failed'\] = int(total_value)

elif metric_name == 'DataVolumeTransferred':

health_data\['metrics'\]\['data_volume_transferred_gb'\] =
round(total_value / 1024, 2) \# MB to GB

except Exception as e:

print(f"Failed to get migration metric {metric_name}: {e}")

\# 移行成功率の計算

total_jobs = health_data\['metrics'\]\['migration_jobs_completed'\] +
health_data\['metrics'\]\['migration_jobs_failed'\]

health_data\['metrics'\]\['migration_jobs_total'\] = total_jobs

if total_jobs \> 0:

health_data\['metrics'\]\['success_rate'\] =
(health_data\['metrics'\]\['migration_jobs_completed'\] / total_jobs \*
100)

else:

health_data\['metrics'\]\['success_rate'\] = 100

\# 健全性判定

if health_data\['metrics'\]\['success_rate'\] \< 95:

health_data\['status'\] = 'UNHEALTHY'

except Exception as e:

print(f"Data migration health check failed: {e}")

health_data\['status'\] = 'ERROR'

health_data\['error'\] = str(e)

return health_data

def \_calculate_overall_health(self, health_checks: List\[Dict\[str,
Any\]\]) -\> Dict\[str, Any\]:

"""

全体的な健全性スコアの計算

"""

total_systems = len(health_checks)

healthy_systems = len(\[hc for hc in health_checks if hc\['status'\] ==
'HEALTHY'\])

unhealthy_systems = len(\[hc for hc in health_checks if hc\['status'\]
== 'UNHEALTHY'\])

error_systems = len(\[hc for hc in health_checks if hc\['status'\] ==
'ERROR'\])

overall_health_score = (healthy_systems / total_systems \* 100) if
total_systems \> 0 else 0

if overall_health_score \>= 90:

overall_status = 'HEALTHY'

elif overall_health_score \>= 70:

overall_status = 'DEGRADED'

else:

overall_status = 'UNHEALTHY'

return {

'status': overall_status,

'health_score': overall_health_score,

'systems': {

'total': total_systems,

'healthy': healthy_systems,

'unhealthy': unhealthy_systems,

'error': error_systems

}

}

def \_evaluate_alerts(self, health_data: Dict\[str, Any\]) -\>
List\[Dict\[str, Any\]\]:

"""

アラート条件の評価

"""

alerts = \[\]

\# パイプラインアラート

pipeline_health = health_data\['pipeline'\]

if pipeline_health\['status'\] == 'UNHEALTHY':

alerts.append({

'type': 'PIPELINE_DEGRADED',

'severity': 'HIGH',

'message': f"Pipeline success rate is
{pipeline_health\['metrics'\]\['success_rate'\]:.1f}% (threshold: {100 -
self.monitoring_config\['thresholds'\]\['pipeline_failure_rate'\]}%)",

'details': pipeline_health\['pipelines'\]

})

\# セキュリティアラート

security_health = health_data\['security'\]

if security_health\['status'\] == 'UNHEALTHY':

alerts.append({

'type': 'SECURITY_AUTOMATION_DEGRADED',

'severity': 'CRITICAL',

'message': f"Security automation success rate is
{security_health\['metrics'\]\['security_success_rate'\]:.1f}%",

'details': security_health\['metrics'\]

})

\# インフラストラクチャアラート

infra_health = health_data\['infrastructure'\]

if infra_health\['status'\] == 'UNHEALTHY':

alerts.append({

'type': 'INFRASTRUCTURE_AUTOMATION_DEGRADED',

'severity': 'HIGH',

'message': f"Infrastructure automation experiencing issues",

'details': {

'terraform_success_rate': infra_health\['terraform'\]\['success_rate'\],

'aft_success_rate': infra_health\['aft'\]\['success_rate'\]

}

})

\# データ移行アラート

migration_health = health_data\['data_migration'\]

if migration_health\['status'\] == 'UNHEALTHY':

alerts.append({

'type': 'DATA_MIGRATION_DEGRADED',

'severity': 'MEDIUM',

'message': f"Data migration success rate is
{migration_health\['metrics'\]\['success_rate'\]:.1f}%",

'details': migration_health\['metrics'\]

})

\# 全体健全性アラート

overall_health = health_data\['overall'\]

if overall_health\['status'\] == 'UNHEALTHY':

alerts.append({

'type': 'OVERALL_SYSTEM_DEGRADED',

'severity': 'CRITICAL',

'message': f"Overall automation health score is
{overall_health\['health_score'\]:.1f}%",

'details': overall_health\['systems'\]

})

return alerts

def \_send_operations_alerts(self, alerts: List\[Dict\[str, Any\]\]):

"""

運用アラートの送信

"""

try:

for alert in alerts:

severity = alert\['severity'\]

\# 重要度に応じた通知先の選択

if severity == 'CRITICAL':

topic_arn = os.environ.get('CRITICAL_OPERATIONS_ALERTS_TOPIC')

elif severity == 'HIGH':

topic_arn = os.environ.get('HIGH_OPERATIONS_ALERTS_TOPIC')

else:

topic_arn = os.environ.get('OPERATIONS_ALERTS_TOPIC')

if topic_arn:

message = f"""

🚨 自動化システム運用アラート 🚨

アラートタイプ: {alert\['type'\]} 重要度: {alert\['severity'\]}
メッセージ: {alert\['message'\]}

詳細情報: {json.dumps(alert\['details'\], indent=2)}

監視ダッシュボード:
[**https://console.aws.amazon.com/cloudwatch/home#dashboards:name=TechNova-Automation-Integrated-Dashboard**](https://console.aws.amazon.com/cloudwatch/home#dashboards:name=TechNova-Automation-Integrated-Dashboard)
"""

self.sns.publish(

TopicArn=topic_arn,

Subject=f"\[{alert\['severity'\]}\] {alert\['type'\]}",

Message=message

)

except Exception as e:

print(f"Failed to send operations alerts: {e}")

def \_generate_operations_report(self, health_summary: Dict\[str, Any\])
-\> Dict\[str, Any\]:

"""

運用レポートの生成

"""

report = {

'report_timestamp': datetime.now().isoformat(),

'report_period': '24_hours',

'overall_health': health_summary\['overall_health'\],

'system_health': {

'pipelines': health_summary\['pipeline_health'\],

'security_automation': health_summary\['security_health'\],

'infrastructure_automation': health_summary\['infrastructure_health'\],

'data_migration': health_summary\['data_migration_health'\]

},

'alerts': health_summary\['alerts'\],

'recommendations': self.\_generate_recommendations(health_summary)

}

return report

def \_generate_recommendations(self, health_summary: Dict\[str, Any\])
-\> List\[str\]:

"""

改善推奨事項の生成

"""

recommendations = \[\]

\# パイプライン推奨事項

pipeline_health = health_summary\['pipeline_health'\]

if pipeline_health\['status'\] == 'UNHEALTHY':

recommendations.append("パイプラインの失敗率が高くなっています。エラーログを確認し、根本原因を特定してください。")

\# セキュリティ推奨事項

security_health = health_summary\['security_health'\]

if security_health\['status'\] == 'UNHEALTHY':

recommendations.append("セキュリティ自動化チェックの失敗率が高くなっています。セキュリティ設定を見直してください。")

\# インフラ推奨事項

infra_health = health_summary\['infrastructure_health'\]

if infra_health\['status'\] == 'UNHEALTHY':

recommendations.append("インフラストラクチャ自動化に問題があります。Terraformコードとリソース状態を確認してください。")

\# データ移行推奨事項

migration_health = health_summary\['data_migration_health'\]

if migration_health\['status'\] == 'UNHEALTHY':

recommendations.append("データ移行の成功率が低下しています。移行設定とデータ品質を確認してください。")

\# 全体的な推奨事項

overall_health = health_summary\['overall_health'\]

if overall_health\['status'\] == 'UNHEALTHY':

recommendations.append("システム全体の健全性が低下しています。緊急対応チームを招集し、システム全体の状況確認を実施してください。")

if not recommendations:

recommendations.append("全システムが正常に動作しています。現在の運用品質を維持してください。")

return recommendations

def lambda_handler(event, context): """ Lambda エントリーポイント """
monitor = AutomationOperationsMonitor() return
monitor.lambda_handler(event, context)

\## 7. コンプライアンス自動化

\### 7.1 コンプライアンス監査自動化

\`\`\`hcl

\# コンプライアンス自動化Lambda

resource "aws_lambda_function" "compliance_automation" {

filename = "lambda/compliance_automation.zip"

function_name = "technova-compliance-automation"

role = aws_iam_role.compliance_automation_role.arn

handler = "index.handler"

source_code_hash =
data.archive_file.compliance_automation_zip.output_base64sha256

runtime = "python3.9"

timeout = 900

environment {

variables = {

COMPLIANCE_REPORTS_BUCKET = aws_s3_bucket.compliance_reports.bucket

COMPLIANCE_TABLE = aws_dynamodb_table.compliance_tracking.name

SNS_TOPIC_ARN = aws_sns_topic.compliance_notifications.arn

}

}

tags = {

Purpose = "Compliance Automation"

Frameworks = "SOC2-ISO27001-PCI-DSS"

}

}

\# 定期実行設定

resource "aws_cloudwatch_event_rule" "compliance_automation_schedule" {

name = "compliance-automation-daily"

description = "Trigger compliance automation daily"

schedule_expression = "cron(0 6 \* \* ? \*)" \# 毎日午前6時UTC

tags = {

Purpose = "Compliance Automation Schedule"

}

}

resource "aws_cloudwatch_event_target" "compliance_automation_target" {

rule = aws_cloudwatch_event_rule.compliance_automation_schedule.name

target_id = "ComplianceAutomationTarget"

arn = aws_lambda_function.compliance_automation.arn

}

resource "aws_lambda_permission" "allow_eventbridge_compliance" {

statement_id = "AllowExecutionFromEventBridge"

action = "lambda:InvokeFunction"

function_name = aws_lambda_function.compliance_automation.function_name

principal = "events.amazonaws.com"

source_arn =
aws_cloudwatch_event_rule.compliance_automation_schedule.arn

}

8\. 災害復旧自動化

8.1 自動バックアップとリストア

yaml

*\# 災害復旧自動化設定*

disaster_recovery_automation:

backup_automation:

*\# データベースバックアップ*

rds_automated_backups:

retention_period: 35

backup_window: "03:00-04:00"

cross_region_backup: true

backup_regions: \["us-east-1", "eu-west-1"\]

*\# EBSスナップショット*

ebs_snapshot_automation:

schedule: "cron(0 2 \* \* ? \*)"

retention_days: 30

cross_region_copy: true

*\# S3バックアップ*

s3_cross_region_replication:

primary_region: "ap-northeast-1"

backup_regions: \["us-east-1"\]

storage_class: "STANDARD_IA"

recovery_automation:

*\# RTO/RPO 目標*

rto_targets:

critical_systems: "1 hour"

important_systems: "4 hours"

standard_systems: "24 hours"

rpo_targets:

critical_data: "15 minutes"

important_data: "1 hour"

standard_data: "24 hours"

*\# 自動復旧手順*

automated_recovery_procedures:

\- "Infrastructure as Code による迅速な環境復旧"

\- "データベース ポイントインタイム リカバリ"

\- "アプリケーション自動デプロイメント"

\- "ネットワーク設定の自動復元"

9\. 実装ロードマップ

9.1 段階的実装計画

yaml

implementation_roadmap:

*\# フェーズ1: 基盤構築 (1-3ヶ月)*

phase_1_foundation:

duration: "12週間"

priority: "CRITICAL"

deliverables:

\- "AFT実装と基本カスタマイゼーション"

\- "CI/CDパイプライン基盤構築"

\- "基本的なセキュリティ統合"

\- "Terraform自動化パイプライン"

success_criteria:

\- "AFTによる新規アカウント作成成功率95%以上"

\- "CI/CDパイプライン基本動作確認完了"

\- "セキュリティベースライン自動適用100%"

*\# フェーズ2: 高度な自動化 (3-5ヶ月)*

phase_2_advanced_automation:

duration: "8週間"

priority: "HIGH"

deliverables:

\- "データ移行自動化パイプライン"

\- "高度なセキュリティ統合"

\- "監視・運用自動化"

\- "コンプライアンス自動化"

success_criteria:

\- "データ移行成功率90%以上"

\- "セキュリティチェック統合率100%"

\- "運用監視自動化完了"

*\# フェーズ3: 最適化と拡張 (5-6ヶ月)*

phase_3_optimization:

duration: "4週間"

priority: "MEDIUM"

deliverables:

\- "災害復旧自動化"

\- "性能最適化"

\- "運用プロセス改善"

\- "ドキュメント整備"

success_criteria:

\- "災害復旧テスト成功"

\- "システム性能要件達成"

\- "運用効率20%向上"

total_implementation_effort:

estimated_duration: "24週間"

required_resources:

\- "DevOpsエンジニア: 3名"

\- "セキュリティエンジニア: 2名"

\- "データエンジニア: 1名"

\- "SREエンジニア: 1名"

estimated_cost:

infrastructure: "\$50,000"

development: "\$200,000"

training: "\$30,000"

total: "\$280,000"

success_metrics:

automation_coverage: "95%以上の作業自動化"

deployment_frequency: "1日複数回のデプロイ可能"

lead_time: "アイデアから本番まで1週間以内"

mttr: "障害復旧時間1時間以内"

change_failure_rate: "5%以下"

まとめ

本自動化要件は、TechNova社の120アカウント構成における包括的な自動化戦略を定義し、以下の統合を実現します：

主要統合ポイント

AFT × 事業部門別アカウント構成:
組織構造に応じた自動アカウントプロビジョニング

CI/CD × セキュリティパイプライン: DevSecOpsの完全統合

データ移行 × セキュリティ: 安全で効率的なデータ移行自動化

インフラ自動化 × 権限管理: 最小権限でのIaC実行

監視 × 運用: 包括的な自動化システム監視

期待される効果

開発効率300%向上: 手動作業の大幅削減

セキュリティ品質向上: 自動化によるヒューマンエラー削減

運用コスト50%削減: 自動化による運用工数削減

コンプライアンス100%達成: 自動化による継続的準拠

災害復旧時間90%短縮: 自動化による迅速な復旧

この包括的な自動化要件により、TechNova社は効率的で安全、そして拡張可能なクラウド環境を実現できます。

# コア設計書：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化プロジェクト」（約525ページ）

## 1. プロジェクト全体像と移行戦略

## 本章の目的：オンプレミスからAWSへの移行戦略とAFT導入の位置づけを理解する

### **ハンズオン 1-1**: TechNova社の現状システム分析 

- オンプレミスシステム構成の詳細分析

- システム間連携の識別と依存関係マッピング

- パフォーマンス特性とスケーリング要件の評価

- 移行優先度の決定基準

### **ハンズオン 1-2**: マイクロサービス化戦略と境界設計 

- ドメイン駆動設計に基づくサービス境界定義

- マイクロサービスの粒度と責務範囲の決定

- サービス間連携パターンの選定

- データオーナーシップとデータ同期戦略

### **ハンズオン 1-3**: AWS移行基本設計のレビューと統合 

- 決定済みのAWS基本設計の確認

- AFT導入による実現可能性と利点の評価

- 移行フェーズの再構築と調整

- 移行のリスク評価と対策

### **ハンズオン 1-4**: AFT導入によるアカウント戦略の具体化 

- 必要アカウント構成のマッピング

- AFTによるアカウント管理自動化の範囲決定

- アカウント設計方針の確立

- アカウント間連携の設計

### **ハンズオン 1-5**: マイクロサービス実装とECS Fargate/Aurora選定の詳細化 

- コンテナ化戦略の具体化

- データベース設計と移行アプローチ

- スケーラビリティ要件とキャパシティプランニング

- パフォーマンス目標と検証方法

### **ハンズオン 1-6**: 移行ロードマップとリリース計画 

- フェーズ分割と段階的リリース計画

- 各フェーズの成功基準の定義

- 切り戻し計画と障害対応戦略

- 移行中のビジネス継続性確保策

### アンチパターン：移行戦略で失敗しやすいポイント

- 依存関係の分析が不十分で、移行順序に問題が生じる

- マイクロサービスの境界が適切に定義されず、密結合が残る

- すべてを一度に移行しようとして複雑性が増大する

- オンプレミス連携の複雑さを過小評価する

- 既存データの移行戦略が不十分で、データ整合性問題が発生する

- ビジネス部門の巻き込みが不足し、業務要件の反映が不十分になる

## 2. AWS Control TowerとOU設計（30-35ページ）

## 本章の目的：Control Tower導入とOU構造の設計手法を実践する

### **ハンズオン 2-1**: Control Tower導入と初期設定ワークショップ 

- Control Tower導入の前提条件確認

- Landing Zone構築の手順と注意点

- 管理アカウント・監査アカウント・ログアーカイブアカウントの設定

- 移行プロジェクトに最適な初期設定選択

### **ハンズオン 2-2**: OU構造設計ワークショップ 

- TechNova社の組織構造分析と業務システム反映

- 機能別OU(共通サービス、ネットワーク、セキュリティ)の設計

- 事業部門別OUの設計と環境区分（開発/テスト/本番）

- OU命名規則と構造化戦略

### **ハンズオン 2-3**: SCPポリシー設計と実装 

- セキュリティ要件分析と統制ポリシー定義

- 環境タイプ別のSCP設計（本番/テスト/開発）

- リージョン制限ポリシーの設計（東京/大阪限定）

- 最小権限原則に基づくサービス利用制限

### **ハンズオン 2-4**: OU構造のTerraform化 

- Organizations構造のコード化

- SCP割り当てのコード管理

- 既存アカウントの移行手順

- バージョン管理と変更追跡戦略

### **ハンズオン 2-5**: アカウント命名規則と分類体系の設計 

- 事業部門・機能・環境が分かる命名規則の設計

- アカウント属性のタグ設計

- アカウント一覧の管理・可視化手法

- メタデータ管理戦略

### **ハンズオン 2-6**: マイクロサービス展開を考慮したアカウント構成 

- サービス群ごとのアカウント分離戦略

- 共有リソースとクロスアカウントアクセス設計

- 環境間のデータ流通設計

- アカウント間通信のセキュリティ境界設計

### アンチパターン：OU設計で失敗しやすいポイント

- OUを細かく分けすぎて管理が複雑化する

- 将来の組織変更を考慮せず、現在の組織構造に強く紐づけた設計をする

- SCPが強すぎて運用業務や開発作業が阻害される

- OU設計が浅く、「Dev/Prod」のみの分類で終わってしまう

- アカウント命名規則が不明確で、後から何のアカウントか分からなくなる

- サービス間連携を考慮せず、アカウント間通信が複雑になりすぎる

## 3. AFT環境構築とアカウント自動化（30-35ページ）

## 本章の目的：AFT導入とアカウント自動化プロセスを構築する

### **ハンズオン 3-1**: AFT導入の前提条件と準備作業 

- Terraformバージョン・AWS CLIの準備

- GitLab環境の構築と接続設定

- 必要なIAMロールと権限の設定

- AFT管理アカウントの準備

### **ハンズオン 3-2**: AFT管理アカウントの設計と構築 

- AFT管理アカウントの位置づけと役割

- AFT実行用のIAMロール設計（最小権限の原則に基づく）

- CodePipeline/CodeBuild環境の構築

- セキュリティ監査設定

### **ハンズオン 3-3**: AFTパイプラインの設計と実装 

- パイプラインのステージ設計（Global/OU/Account）

- ワークフロー制御の実装

- エラーハンドリングと手動承認プロセスの組み込み

- パイプラインの監視とログ設定

### **ハンズオン 3-4**: アカウント申請プロセスの自動化 

- GitLabを用いたアカウント申請ワークフロー設計

- account-requests JSONテンプレートの設計

- 承認フローと監査証跡の実装

- マイクロサービス別アカウントテンプレート設計

### **ハンズオン 3-5**: AFT検証と初期アカウント作成テスト 

- テスト用アカウント作成シナリオの実行

- 作成プロセスの監視とログ確認

- 問題点の洗い出しと改善

- 性能評価と最適化

### **ハンズオン 3-6**: マイクロサービス向けアカウント構成の自動化 

- サービス群ごとのベースライン設定

- 環境別設定の差分管理

- 自動構成適用のテストと検証

- スケーラブルな構成管理アプローチ

### アンチパターン：AFT導入で失敗しやすいポイント

- AFT管理アカウントに過剰な権限を付与してしまう

- GitLab連携の認証情報が適切に保護されていない

- エラー通知設定が不足し、失敗を見逃す

- パイプラインのタイムアウト設定が不適切で長時間ハングする

- アカウント申請テンプレートに必須フィールドの検証が不足している

- マイクロサービス特有の構成要件を標準化しきれていない

## 4. IAM Identity CenterとPermission Set設計（25-30ページ）

## 本章の目的：最小権限アクセス管理と自動プロビジョニングを設計・実装する

### **ハンズオン 4-1**: Identity Center機能と基本設計 

- Identity Centerのコンセプトと機能

- IAMユーザーからの移行戦略（最小化アプローチ）

- Active Directory連携設計

- 認証フローと委任モデル

### **ハンズオン 4-2**: ユーザー・グループとアカウント構造の設計 

- ユーザー/グループ管理設計（Active Directory反映）

- 命名規則とグループ階層

- 職務分掌とセキュリティ境界設計

- グループ同期戦略

### **ハンズオン 4-3**: Permission Set設計とTerraform管理 

- 権限セットの体系設計

- 最小権限の原則に基づく設計

- AWS管理ポリシーとカスタムポリシーの使い分け

- マイクロサービス開発・運用に特化したPermission Set

### **ハンズオン 4-4**: アカウント・OU別アクセス割り当て 

- アカウントごとの権限差異設計

- OU単位の一括割り当て戦略

- 環境タイプ別の権限制限

- 特権アクセス制御と最小権限設計

### **ハンズオン 4-5**: ECS/Auroraサービスロール設計 

- コンテナタスク実行ロールの最小権限設計

- Auroraへのアクセスロール設計（IAM認証）

- クロスアカウントロール設計

- サービス間の安全な通信保証

### **ハンズオン 4-6**: アクセス監査とレビュープロセス 

- アクセス権限の定期レビュー設計

- 未使用権限の検出と削除

- CloudTrailとの統合監査

- IAM Access Analyzerの設定と連携

### アンチパターン：IAM設計で失敗しやすいポイント

- IAMユーザーへの依存が残り、統一的な認証基盤が構築できない

- Permission Setが少なすぎるか多すぎて管理が複雑化

- グループと権限設計が組織構造と合っていない

- コンテナサービスロールに過剰な権限を付与してしまう

- Aurora接続のIAM認証設定が複雑すぎて管理困難になる

- アクセスレビュープロセスが形骸化し、実効性がない

**5. ネットワークインフラ設計とDirectConnect連携（30-35ページ）**

**本章の目的：高可用性ハイブリッドネットワークの設計と実装を習得する**

### **ハンズオン 5-1**: 機能別VPC設計 

- VPC分離モデルの設計（認証/アプリケーション/DB/運用）

- CIDRプランニングと将来拡張考慮

- サブネット設計と可用性ゾーン配置

- ルーティングテーブル戦略

### **ハンズオン 5-2**: VPC間接続とTransit Gateway設計 

- Transit Gateway設計と接続トポロジー

- VPCアタッチメント設計

- ルーティング制御とセキュリティ

- Route53ドメイン設計

### **ハンズオン 5-3**: DirectConnect設計と実装 

- 冗長DirectConnectゲートウェイ設計

- Virtual Private Gatewayとの接続

- ルートポリシーとプレフィックスリスト

- BGP設定とフィルタリング

### **ハンズオン 5-4**: Site-to-Site VPNバックアップ回線設計 

- S2S VPN冗長構成設計

- フェイルオーバー戦略とテスト

- BGPルート広告とプリファレンス設定

- 回線品質モニタリング

### **ハンズオン 5-5**: オンプレミス-AWS間通信設計 

- 移行期間中のハイブリッド接続設計

- レイテンシとスループット要件分析

- トラフィックフロー最適化

- 安全なデータ転送パターン

### **ハンズオン 5-6**: マイクロサービス間ネットワーク設計 

- サービスディスカバリ設計

- サービスメッシュ検討

- 内部APIゲートウェイ設計

- サービス間通信の監視と可視化

### アンチパターン：ネットワーク設計で失敗しやすいポイント

- CIDR範囲の計画が不十分で後々拡張できない

- Transit Gateway設定が複雑すぎてルーティングが追跡困難になる

- DirectConnectとVPNのフェイルオーバーテストが不足

- オンプレミス依存が残るハイブリッド環境の複雑さを過小評価

- サービス間通信のセキュリティ境界が不明確

- マイクロサービス間の通信パターンが非効率で高遅延を引き起こす

## 6. 包括的セキュリティ設計と統合ガバナンス（35-40ページ）

## 本章の目的：多層防御のセキュリティアーキテクチャを設計・実装する

### **ハンズオン 6-1**: Security Hub統合基盤の設計 

- セキュリティ統合アーキテクチャ設計

- マルチアカウント・マルチリージョン設定

- セキュリティ標準の選択と設定

- 移行プロジェクトのセキュリティ監視体制

### **ハンズオン 6-2**: WAF + Shield Standardの実装設計 

- WAFルールセットの設計（OWASP Top 10対応）

- API Gateway、CloudFront、ALB連携設定

- WAFログ分析とアラート設定

- Shield Standardの設定と効果範囲

### **ハンズオン 6-3**: Firewall Managerとポリシー設計 

- 中央集権的ポリシー設計

- WAF、Shield、Security Group用ポリシー

- 自動修復と適用除外設計

- コンプライアンス監視設定

### **ハンズオン 6-4**: Network Firewall実装と統合 

- Network Firewall配置設計

- トラフィックインスペクションルール

- ステートフルフィルタリング設定

- ログ設定と分析基盤連携

### **ハンズオン 6-5**: コンテナとマイクロサービスのセキュリティ 

- コンテナイメージのセキュリティスキャン

- シークレット管理と安全な環境変数

- サービス間通信の暗号化

- ランタイムセキュリティ監視

### **ハンズオン 6-6**: クロスアカウントセキュリティ監視 

- 集中監視アカウント設計

- SecurityHub集約と委任管理

- アラート統合とエスカレーションフロー

- インシデント対応自動化

### **ハンズオン 6-7**: データ保護と暗号化戦略 

- Auroraデータの暗号化設計

- S3バケットのセキュリティ設定

- 転送中データの暗号化要件

- 鍵管理（KMS）戦略

### アンチパターン：セキュリティ設計で失敗しやすいポイント

- セキュリティツールの導入だけで対応が終わったと考える

- WAFルールが過剰に厳格で正常なトラフィックをブロックする

- Network Firewall配置が不適切でセキュリティギャップが生じる

- マイクロサービス間の通信セキュリティが不十分

- コンテナイメージのセキュリティスキャンが自動化されていない

- クロスアカウントセキュリティ監視の設定が複雑すぎて機能しない

## 7. ECS FargateとECR設計（25-30ページ）

## 本章の目的：マイクロサービスのコンテナ実行基盤の設計・実装を行う

### **ハンズオン 7-1**: マイクロサービスコンテナ化戦略 

- コンテナ化の原則と設計パターン

- イメージサイズ最適化とレイヤー設計

- マイクロサービス別のDockerfile設計

- ベースイメージ戦略とセキュリティ

### **ハンズオン 7-2**: ECRレポジトリ設計とライフサイクル管理 

- リポジトリ命名規則と構成

- イメージタグ付け戦略

- イメージライフサイクルポリシー設計

- 脆弱性発見時の自動更新戦略

### **ハンズオン 7-3**: ECS Fargateクラスタ設計 

- クラスタ構成と分離戦略

- タスク定義の設計

- オートスケーリング設定

- Service Discovery設計

### **ハンズオン 7-4**: コンテナログとモニタリング 

- CloudWatch Logs統合

- コンテナインサイト設定

- 分散トレーシング設計

- パフォーマンスモニタリング

### **ハンズオン 7-5**: コンテナセキュリティの設計 

- イメージスキャン自動化

- タスク実行ロールの最小権限設計

- ネットワークセキュリティ設計

- シークレット管理とランタイム保護

### **ハンズオン 7-6**: 環境間のコンテナイメージ管理戦略

- 環境別タグ付け（dev/staging/prod）

- イメージの不変性保証

- クロスアカウントイメージ共有

- イメージ推進（プロモーション）パイプライン設計

### **ハンズオン 7-7**: マルチリージョン対応（東京・大阪） 

- リージョン間のECRレプリケーション設計

- 両リージョンでのクラスター設計

- リージョン固有の構成管理

- フェイルオーバー戦略

### アンチパターン：ECS Fargate設計で失敗しやすいポイント

- コンテナイメージが肥大化し、起動時間とリソース消費が増大

- タスク定義のリソース設定が最適化されていない

- IAMロールが過剰な権限を持ち、セキュリティリスクとなる

- Auto Scalingの設定が不適切でスケーリングが効果的に機能しない

- ログ設定が不十分で、問題発生時のトラブルシューティングが困難

- 環境間のイメージ昇格プロセスが不明確で、本番環境の品質が保証できない

- 脆弱性発見時の更新プロセスが確立されておらず、古いイメージが使われ続ける

## 8. Aurora/Flywayデータベース設計（25-30ページ）

## 本章の目的：マイクロサービス向けデータベース基盤と自動マイグレーションの設計・実装を行う

### **ハンズオン 8-1**: マイクロサービスのデータ分離戦略 

- データ所有権とサービス境界設計

- マイクロサービスごとのスキーマ分離設計

- 共有データの識別と管理戦略

- 分散データの整合性確保戦略

### **ハンズオン 8-2**: Aurora設計と構成 

- クラスタータイプとサイジング選定

- マルチAZ構成とフェイルオーバー設計

- パラメータグループ最適化

- リーダーインスタンス戦略

### **ハンズオン 8-3**: IAMデータベース認証の実装 

- IAM認証フローと設定

- ECSタスクロールとの連携設計

- ユーザー/パスワード認証からの移行

- 認証監査と可視化設計

### **ハンズオン 8-4**: Flywayによるスキーママイグレーション 

- マイグレーション戦略とスクリプト設計

- バージョン管理とロールバック計画

- CI/CDとの統合

- 環境間の差分管理

### **ハンズオン 8-5**: オンプレミスからのデータ移行 

- ETL処理パイプライン設計

- S3を経由したデータ転送プロセス

- 大規模データの効率的移行手法

- 移行検証とデータ整合性確認

### **ハンズオン 8-6**: マイクロサービス間のデータ連携 

- イベント駆動データ連携パターン

- レプリケーション戦略

- データ一貫性と結果整合性の戦略

- リードモデルとライトモデルの分離

### **ハンズオン 8-7**: マルチリージョンデータ戦略 

- Aurora Global Databaseの設計

- リージョン間レプリケーション設定

- リージョン固有のデータ分離

- フェイルオーバー戦略

### アンチパターン：データベース設計で失敗しやすいポイント

- マイクロサービス間でデータベースを共有し、密結合が生じる

- Auroraのサイジングが過剰または過小で、コストまたはパフォーマンス問題が発生

- IAM認証の設定が不適切で、接続に失敗またはセキュリティリスクが生じる

- マイグレーションスクリプトのバージョン管理が不十分で、環境間の不整合が発生

- データ移行プロセスの検証が不十分で、データ損失やマッピング誤りが発生

- トランザクションの境界が不明確で、データ整合性が損なわれる

- マルチリージョン設定の複雑さを過小評価し、フェイルオーバー時に問題が発生

## 9. API GatewayとCognito認証基盤（25-30ページ）

## 本章の目的：マイクロサービスAPI層と認証基盤の設計・実装を行う

### **ハンズオン 9-1**: マイクロサービスAPIアーキテクチャ設計 

- APIファーストアプローチと設計原則

- OpenAPI仕様と標準化戦略

- APIバージョニング戦略

- エラーハンドリングとステータスコード標準化

### **ハンズオン 9-2**: API Gateway設計とBFFパターンの実装 

- API Gatewayのリソース設計

- BFFパターンのエンドポイント設計

- クライアント最適化API設計

- APIドキュメンテーション戦略

### **ハンズオン 9-3**: Cognito認証基盤の設計 

- ユーザープールとIDプールの設計

- Active Directory連携設計

- 多要素認証の実装

- ソーシャルIDプロバイダー連携

### **ハンズオン 9-4**: API認証と権限管理 

- CognitoとAPI Gatewayの統合

- JWTトークン検証フロー

- スコープベースの権限制御

- APIキー管理とUsage Plan設計

### **ハンズオン 9-5**: スロットリングと流量制御 

- リソース別のスロットリング設計

- クライアント別の使用制限設計

- WAFとの統合によるセキュリティ強化

- 異常検知と自動対応

### **ハンズオン 9-6**: クロスアカウントAPI連携 

- マイクロサービス間のAPI呼び出し設計

- 内部API認証と権限管理

- セキュリティ境界の設計

- 可観測性と障害追跡

### **ハンズオン 9-7**: マルチリージョンAPI戦略 

- リージョン間のAPI設計

- リージョン固有のエンドポイント管理

- フェイルオーバー設定

- レイテンシ最適化

### アンチパターン：API設計で失敗しやすいポイント

- APIリソース設計が不適切で管理困難やパフォーマンス低下を招く

- Cognitoの設定が複雑すぎてトラブルシューティングが困難になる

- API Gatewayのスロットリング設定が不適切で本番環境で性能問題が発生

- クロスアカウント設定のセキュリティホールが生じる

- 認証フローのユーザー体験が考慮されておらず、使いにくいシステムになる

- マイクロサービス間の依存関係が不透明で、問題発生時の原因特定が困難

- マルチリージョン考慮が不足し、リージョン障害時の可用性が確保できない

## 10. Step Functions/Lambdaによるバッチ処理自動化（25-30ページ）

## 本章の目的：マイクロサービス間連携とバッチ処理の自動化を設計・実装する

### **ハンズオン 10-1**: マイクロサービスのビジネスプロセス分析 

- オンプレミス基幹システムの業務フロー分析

- マイクロサービス間のビジネスフロー再設計

- イベント駆動アーキテクチャへの変換

- サービス連携パターンの選定

### **ハンズオン 10-2**: Step Functions ワークフロー設計 

- ステートマシン設計パターン

- 分岐と並列処理の実装

- エラー処理と復旧戦略

- サービス間連携フローの設計

### **ハンズオン 10-3**: Lambda関数の設計と実装 

- 関数分割とサイズ最適化

- 権限モデルと実行ロール設計

- エラーハンドリングとリトライ戦略

- 環境変数と設定管理

### **ハンズオン 10-4**: データ処理パイプラインの実装 

- ETL処理の設計

- 大規模データの分散処理

- 進捗追跡と状態管理

- 処理結果の検証と集約

### **ハンズオン 10-5**: バッチスケジューリングと運用管理 

- EventBridgeによるスケジュール設定

- バッチ処理の依存関係管理

- 実行ステータス監視と通知

- 失敗時のリカバリープロセス

### **ハンズオン 10-6**: クロスアカウントバッチ処理 

- アカウント間連携戦略

- セキュリティ境界とアクセス制御

- 集中監視と分散実行の両立

- 環境別の実行分離

### **ハンズオン 10-7**: マルチリージョンワークフロー対応 

- リージョン間のデータ連携設計

- リージョン固有の処理分離

- フェイルオーバー自動化

- リージョン間のステート共有

### アンチパターン：サーバーレスバッチ処理で失敗しやすいポイント

- Lambda関数が大きすぎてコールドスタート問題やタイムアウトが発生

- Step Functionsのワークフロー設計が複雑すぎて管理困難になる

- エラーハンドリング不足により、部分的失敗からの復旧が困難

- 並列処理のスケーリング制限を考慮せずに設計し、スロットリングが発生

- バッチ処理の状態管理が不十分で、実行ステータスが不明確になる

- クロスアカウント権限設定のミスでセキュリティリスクが生じる

- マルチリージョン考慮が不足し、リージョン障害時にバッチ処理が停止する

## 11. Terraform IaC設計と環境変数管理（25-30ページ）

## 本章の目的：マルチリージョン対応のIaC設計と環境変数管理の導入

### **ハンズオン 11-1**: Terraformプロジェクト構造設計 

- モジュール設計と分離戦略

- リポジトリ構造とブランチ戦略

- ディレクトリ階層と依存関係

- コード標準化とベストプラクティス

### **ハンズオン 11-2**: 環境変数によるモジュール管理 

- 環境変数設計と命名規則

- 環境別の設定分離

- 環境変数の安全な管理

- 変数のスコープと継承設計

### **ハンズオン 11-3**: マルチリージョン対応IaC設計 

- 東京・大阪両リージョン並記の実装方針

- プロバイダー構成とリージョン指定

- リージョン固有設定の分離

- 共通変数と固有変数の設計

### **ハンズオン 11-4**: 環境タグ付け戦略 

- 標準タグセットの設計

- 環境タグ（dev/staging/prod）の実装

- タグの継承と自動付与

- タグベースのリソース管理

### **ハンズオン 11-5**: Terraformステート管理戦略 

- ステートファイル分離原則

- バックエンド設定とリモートステート

- ステート参照と変数連携

- ステートロックとバージョン管理

### **ハンズオン 11-6**: Terraformコード品質管理 

- コード標準化とスタイルガイド

- 自動フォーマットと検証

- コメントとドキュメンテーション

- モジュールバージョニング

### **ハンズオン 11-7**: 秘密情報と変数管理 

- 秘密情報の安全な管理

- AWS Secrets Managerとの連携

- 変数のバリデーション設計

- デフォルト値と条件付き設定

### アンチパターン：Terraform設計で失敗しやすいポイント

- モジュールの粒度が不適切（細かすぎる/大きすぎる）で管理が複雑化

- 環境変数管理が不十分で環境間の差異が不明確

- マルチリージョン対応のプロバイダー設定不備でデプロイエラーが発生

- タグ付け戦略の一貫性がなく、リソース管理やコスト配分が困難になる

- ステート分離が不適切で構成競合やドリフトが発生

- 秘密情報がコードにハードコードされセキュリティリスクとなる

- 変数バリデーションが不足し、無効な値でデプロイが進行してしまう

## 12. CI/CDパイプラインとコード品質管理（30-35ページ）

## 本章の目的：高品質なIaCとアプリケーションのCI/CDパイプラインを設計・実装する

### **ハンズオン 12-1**: CI/CD戦略とツール選定 

- CodePipelineの位置づけと設計指針

- ブランチ戦略とGitLabワークフロー

- 環境別デプロイ戦略

- 品質ゲートと昇格基準

### **ハンズオン 12-2**: IaC向け静的解析パイプライン実装 

- tfsecの設定と統合

- TFLintの設定とルールカスタマイズ

- checkovによるコンプライアンス検証

- 解析結果のレポーティングと修正フロー

### **ハンズオン 12-3**: IaC向け動的解析の実装 

- IAM Access Analyzerの設定と統合

- terraform planの自動検証

- 検出された問題の分類と重要度判定

- セキュリティリスクの自動検知

### **ハンズオン 12-4**: 手動承認プロセスの組み込み 

- エラー検知時の手動承認フロー設計

- 承認権限の設定と分離

- エラー内容の可視化と決定支援

- 承認履歴の監査とトレーサビリティ

### **ハンズオン 12-5**: マイクロサービスビルドパイプライン 

- コードリポジトリ構成と分離

- ビルド環境の標準化

- ユニットテスト自動化

- コード品質チェックと脆弱性スキャン

### **ハンズオン 12-6**: コンテナイメージビルドとECR連携 

- イメージビルドプロセス自動化

- タグ付けとバージョン管理

- セキュリティスキャン統合

- ECRへの自動プッシュ

### **ハンズオン 12-7**: ECS Fargateデプロイパイプライン 

- デプロイ戦略（ブルー/グリーン、カナリア）

- タスク定義の自動更新

- ヘルスチェックと自動ロールバック

- デプロイ履歴と追跡

### **ハンズオン 12-8**: データベースマイグレーション自動化 

- Flywayマイグレーションの自動化

- デプロイとのマイグレーション同期

- ロールバック戦略

- データ整合性の検証

### **ハンズオン 12-9**: 環境間のプロモーションフロー 

- Dev → Test → Staging → Prodの昇格フロー

- 承認ゲートと検証プロセス

- 環境間の構成差異の管理

- リリース管理と変更履歴

### アンチパターン：CI/CD設計で失敗しやすいポイント

- 静的解析ツールの警告を無視し、セキュリティ問題が見過ごされる

- パイプラインが単一障害点となり、全デプロイが阻害される

- テスト自動化が不十分で、品質問題が検出されない

- 手動承認プロセスが形骸化し、意味のあるチェックが行われない

- 環境間の構成差異が大きく、本番デプロイの信頼性が低い

- デプロイとデータベースマイグレーションの同期が取れず、サービス障害が発生

- ロールバック戦略が不十分で、障害発生時に復旧が困難になる

- パイプラインのIAM権限が過剰で、セキュリティリスクとなる

## 13. DR戦略と東京-大阪間レプリケーション（20-25ページ）

## 本章の目的：本番環境のDR戦略と大阪リージョンへのレプリケーションを設計・実装する

### **ハンズオン 13-1**: DR要件とRTO/RPO設計 

- 業務継続性要件の分析

- サービス別の優先度とRTO/RPO定義

- フェイルオーバーとフェイルバックのシナリオ設計

- DR戦略の選定（ウォームスタンバイ/パイロットライト/マルチリージョン）

### **ハンズオン 13-2**: Aurora Global Databaseの設計と実装 

- クロスリージョンレプリケーション設定

- フェイルオーバープロセスの設計

- リードレプリカの活用戦略

- レプリケーションラグモニタリング

### **ハンズオン 13-3**: ECS/ECRのクロスリージョン設計 

- コンテナイメージのクロスリージョンレプリケーション

- マルチリージョンECSクラスタの管理

- リージョン固有の設定管理

- デプロイパイプラインのDR対応

### **ハンズオン 13-4**: APIとCognitoのDR戦略 

- API GatewayのクロスリージョンAPI管理

- Cognitoユーザーデータの同期戦略

- マルチリージョンフロントエンド設計

- DNS切り替え戦略

### **ハンズオン 13-5**: フェイルオーバー自動化とテスト 

- フェイルオーバー判断と実行の自動化

- Route 53ヘルスチェックとフェイルオーバールーティング

- DR訓練の設計と実施フロー

- フェイルバックプロセスの検証

### アンチパターン：DR設計で失敗しやすいポイント

- RTO/RPOの定義が曖昧で、実際の障害時に期待が一致しない

- レプリケーション設定が不完全で、データ損失や整合性問題が発生

- フェイルオーバー手順のテストが不足し、実際の障害時に機能しない

- マルチリージョン構成のコスト影響が過小評価される

- フェイルバックプロセスが考慮されていない

- DR環境のセキュリティ設定が本番環境と一致していない

- 東京・大阪間の通信レイテンシを考慮せず、パフォーマンス問題が発生

## 14. 監視・運用基盤の設計（20-25ページ）

## 本章の目的：マイクロサービス環境の統合監視と運用自動化を設計・実装する

### **ハンズオン 14-1**: マイクロサービスの可観測性設計 

- 3本柱（メトリクス、ログ、トレース）の実装戦略

- サービスレベル目標（SLO）とサービスレベル指標（SLI）の定義

- カスタムメトリクスの設計

- ダッシュボード構築戦略

### **ハンズオン 14-2**: 統合監視ダッシュボード構築 

- CloudWatchダッシュボード設計

- クロスアカウントメトリクス集約

- サービス健全性とビジネスKPIの可視化

- 異常検知設定

### **ハンズオン 14-3**: 分散トレーシングの実装 

- X-Ray統合の設計

- サービス間トレースの実装

- パフォーマンスボトルネック分析

- トレース検索と可視化

### **ハンズオン 14-4**: アラート通知フロー実装 

- SNSトピックとサブスクリプション設定

- アラートルーティングとエスカレーション

- オンコール管理とローテーション

- インシデント対応プロセス自動化

### **ハンズオン 14-5**: 運用自動化スクリプト実装 

- Lambda関数によるオートメーション

- 定期メンテナンスタスクの自動化

- 自己修復メカニズムの実装

- スケジュールタスク設定

### **ハンズオン 14-6**: コスト監視と最適化 

- タグベースのコスト分析

- 予算アラートと通知設定

- 異常検知と自動スケーリング最適化

- コスト配分とチャージバックモデル

### アンチパターン：監視・運用設計で失敗しやすいポイント

- メトリクスが多すぎて重要な情報が埋もれる「ダッシュボード疲れ」を引き起こす

- アラートが多すぎて「アラート疲れ」が生じ、重要な通知が見落とされる

- 分散トレーシングの実装が不完全で、問題の根本原因分析が困難になる

- 自動化スクリプトのエラーハンドリングが不足し、問題を解決せず悪化させる

- サービスレベル目標（SLO）が不明確で、運用の成功基準が評価できない

- コスト監視が表面的で、実際のコスト削減につながる洞察が得られない

- 環境タグ付けが不十分で、コスト分析が不正確になる

## 15. 移行実行計画と組織的導入（20-25ページ）

## 本章の目的：オンプレミスからの段階的移行と組織的な導入プロセスを設計する

### **ハンズオン 15-1**: 移行フェーズと優先順位付け 

- 依存関係に基づく移行順序

- ビジネスクリティカリティ評価

- 技術的複雑性分析

- フェーズ分割と成功基準設定

### **ハンズオン 15-2**: 並行運用と切り替え戦略 

- 並行運用期間中のデータ同期

- カットオーバー計画と実行手順

- ロールバック基準と手順

- 段階的なトラフィック移行戦略

### **ハンズオン 15-3**: ステークホルダーマップと組織変革計画 

- 主要ステークホルダーの特定と関与計画

- 部門間の役割と責任の再定義

- コミュニケーション戦略と進捗共有

- 意思決定フローと承認プロセス

### **ハンズオン 15-4**: トレーニングと技術移転計画 

- ロールベースのトレーニング内容

- ハンズオンワークショップの設計

- 自己学習リソース作成

- 継続的スキルアップ体制

### **ハンズオン 15-5**: 内部ドキュメント作成戦略 

- アカウント申請ガイド

- マイクロサービス開発・運用ガイドライン

- アーキテクチャ決定記録（ADR）管理

- トラブルシューティングガイド

### **ハンズオン 15-6**: AFTユーザーコミュニティ構築 

- 定期ミーティング設計

- ナレッジベース構築

- ベストプラクティス共有フォーラム

- 継続的改善プロセス

### アンチパターン：移行実行と組織的導入で失敗しやすいポイント

- 依存関係の分析が不十分で、移行順序に問題が生じる

- カットオーバー計画が不十分で、ビジネス中断リスクが生じる

- ステークホルダーの巻き込みが不足し、組織的な抵抗が発生する

- トレーニングが技術面に偏り、ビジネスプロセスの変更管理が不足する

- ドキュメントが過剰または不足し、実用性が低い

- 移行後の運用モデルへの移行が不十分で、持続的な運用に問題が生じる

- 教育・啓蒙活動が不足し、新しい技術やプロセスの採用率が低い

# 技術実装ガイド：「TechNova社オンプレミス基幹システムAWS移行・マイクロサービス化実装ハンドブック」（約325ページ）

## 16. AFT環境構築実践ガイド（30-35ページ）

## 本章の目的：AFT環境の実際の構築とControl Tower連携を実装する

### **実践ハンズオン 16-1**: Control Tower・Organizations設定の実践 

- AWS Management Consoleでの設定手順

- Landing Zone構築と初期設定

- AFT前提条件のチェックリスト確認

- 詳細なスクリーンショットと操作説明

### **実践ハンズオン 16-2**: AFT管理アカウントの構築 

- Terraformモジュールの適用手順

- パラメータ設定と環境変数

- 動作検証とトラブルシューティング

- IaCのベストプラクティス実装

### **実践ハンズオン 16-3**: GitLab環境の構築とAFT連携 

- GitLabインスタンスの構築手順

- リポジトリ構造の設計と作成

- CodePipelineとの連携設定

<!-- -->

- 認証とセキュリティ対策

- ブランチ保護と承認フローの設定

### **実践ハンズオン 16-4**: AFTパイプラインの構築と設定 

- CodePipelineの設定と構成

- トリガー設定とIAM権限

- ロギングと通知設定

- 各ステージの詳細設定

### **実践ハンズオン 16-5**: 静的解析ツールの統合設定 

- tfsec, TFLint, checkovの導入と設定

- カスタムルールセットの作成

- 分析結果の通知と記録

- 継続的な改善フロー

### **実践ハンズオン 16-6**: IAM Access Analyzerの設定 

- クロスアカウント分析の設定

- 検出ルールのカスタマイズ

- アラート設定と対応フロー

- 定期的なレビュープロセス

### **実践ハンズオン 16-7**: 手動承認ステージの実装 

- ステージ間の手動承認設定

- エラー発生時の判断支援情報

- 承認者グループと権限設定

- 監査証跡の設定

### 実践ハンズオン 16-8: AFT機能検証 

- テストアカウント作成

- ログと監査証跡の確認

- トラブルシューティングとデバッグ手法

- 性能最適化とスケーリング設定

### **実践ハンズオン 16-9**: マイクロサービスアカウントテンプレート構築 

- サービス群ごとの標準アカウント設定

- 環境別のベースライン定義

- 自動プロビジョニングのテスト

- 検証と調整

### アンチパターン：AFT環境構築で失敗しやすいポイント

- AFTのバージョン互換性を確認せずに導入し、依存関係エラーが発生

- IAM権限が不足またはバケットポリシーが不適切で、パイプラインが失敗

- GitLab連携の認証情報が適切に保護されていない

- 静的解析ツールの警告を無視し、セキュリティ問題がそのまま残る

- 手動承認プロセスが形骸化し、効果的なチェックが行われない

- Access
  Analyzerの検出結果への対応が遅れ、セキュリティリスクが長期間残存

- 詳細なログ設定を省略し、問題発生時の診断が困難になる

- 通知設定が不足し、パイプライン失敗に気づかない

## 17. IAM Identity CenterとPermission Set実装（25-30ページ）

## 本章の目的：IAMユーザーに依存しないアクセス管理基盤を実装する

### **実践ハンズオン 17-1**: Identity Center初期設定 

- Identity Center有効化と基本設定

- Active Directory連携設定

- グループとユーザー同期の設定

- サインインURL設定と検証

### **実践ハンズオン 17-2**: 権限設計とPermission Set構築 

- 標準Permission Setの設計と作成

- カスタムPermission Setの作成

- インラインポリシーの活用

- 最小権限の原則の適用

### **実践ハンズオン 17-3**: アカウント割り当ての自動化 

- Terraformによる割り当て自動化

- AFTとの統合設定

- グループベースの一括割り当て

- 動的更新メカニズム

### **実践ハンズオン 17-4**: ECS/Aurora用のIAMロール実装 

- ECSタスク実行ロールの作成

- Auroraアクセス用IAMロールの作成

- ロール間の信頼関係設定

- クロスアカウントロール設定

### **実践ハンズオン 17-5**: 緊急アクセス手順の実装 

- ブレークグラスアクセスの設計

- 特権アクセスワークフローの構築

- 監査と証跡の設定

- 定期的なテスト手順

### **実践ハンズオン 17-6**: アクセス監査とレビュー自動化 

- 定期レビュー用レポート自動化

- 未使用権限の検出スクリプト

- レビュープロセスのワークフロー化

- 自動修正メカニズム

### アンチパターン：Identity Center実装で失敗しやすいポイント

- AD連携の設定不備により、正しくID同期が行われない

- Permission Setの粒度が不適切で、過剰または過小な権限が付与される

- Terraformによる自動化とコンソールでの手動変更が混在する

- ECSタスク実行ロールに過剰な権限が付与される

- 緊急アクセス手順が不明確で、障害時にアクセスできない状況が発生

- アクセスレビューが形骸化し、不要な権限が残り続ける

- ロール命名規則の不統一により、管理が複雑化する

## 18. ネットワークインフラ実装（30-35ページ）

## 本章の目的：セキュアで高可用性のネットワークインフラを実装する

### 実践ハンズオン 18-1: 機能別VPC実装 

- VPCリソースの宣言的定義

- サブネット設計と詳細構成

- ルートテーブル設定

- セキュリティグループとNACL実装

### **実践ハンズオン 18-2**: マルチリージョンVPC設定 

- 東京・大阪両リージョンでのVPC構築

- リージョン固有パラメータの設定

- リージョン間の整合性確保

- 環境変数を活用した設定管理

### **実践ハンズオン 18-3**: Transit Gateway実装 

- Transit Gateway設定

- VPCアタッチメント設定

- ルートテーブル構成

- 接続性テストとトラブルシューティング

### **実践ハンズオン 18-4**: DirectConnect設定実装 

- DirectConnect仮想インターフェース設定

- 冗長性設定とフェイルオーバー

- BGP設定と経路制御

- 接続テストとモニタリング

### **実践ハンズオン 18-5**: S2S VPNバックアップ実装 

- カスタマーゲートウェイ設定

- VPN接続設定とトンネルオプション

- ルーティングとフェイルオーバー設定

- 監視とアラート設定

### **実践ハンズオン 18-6**: Network Firewall実装 

- Firewall配置と保護対象定義

- ファイアウォールポリシー設定

- ルールグループとフィルタリング設定

- ログと監視設定

### **実践ハンズオン 18-7**: マイクロサービス通信パターン実装 

- サービスディスカバリ設定

- サービス間通信の暗号化

- 内部ロードバランサー設定

- 通信パターンのテストと検証

### アンチパターン：ネットワーク実装で失敗しやすいポイント

- サブネットCIDR設計の不備により、後からのリソース拡張が困難になる

- リージョン間の設定不整合により、フェイルオーバー時に問題が発生

- Transit Gatewayのルートテーブル設計ミスで、接続性問題が発生

- DirectConnectとVPNのフェイルオーバー設定不備で、冗長性が確保できない

- Network Firewallルールが厳格すぎて、正常なトラフィックがブロックされる

- クロスアカウントアクセス設定のミスでセキュリティリスクが生じる

- ネットワーク設計のIaC化が不完全で、手動変更と競合が発生

## 19. WAF/Shield/Firewall Manager実装（25-30ページ）

## 本章の目的：多層防御のセキュリティ境界を実装する

### **実践ハンズオン 19-1**: WAF Web ACL設計と実装 

- WAFルールグループの設計と作成

- マネージドルールの選択と設定

- カスタムルールの作成と検証

- ログ記録とモニタリング

### **実践ハンズオン 19-2**: WAFとAPI Gateway/ALB/CloudFrontの連携 

- WAFとAPI Gatewayの統合設定

- ALBへのWAF適用と検証

- CloudFrontとWAFの統合実装

- 環境別のWAF保護戦略

### **実践ハンズオン 19-3**: Shield Standard設定 

- Shield保護の有効化と設定

- DDos対策設定

- シールドレスポンスチームとの連携設定

- 保護リソースの優先順位付け

### **実践ハンズオン 19-4**: Firewall Managerポリシー実装 

- セキュリティポリシーの設計と作成

- WAF管理ポリシーの構築

- Shield管理ポリシーの構築

- セキュリティグループポリシーの実装

### **実践ハンズオン 19-5**: Network Firewall高度設定 

- ステートフルインスペクションの設定

- カスタムプロトコル解析の実装

- ドメインフィルタリング設定

- トラフィック分析ログの活用

### **実践ハンズオン 19-6**: セキュリティ自動復旧設計 

- 自動修復ワークフローの実装

- 異常検知と自動応答

- セキュリティ違反の自動修正

- インシデント対応ワークフロー

### アンチパターン：セキュリティ境界実装で失敗しやすいポイント

- WAFルールが過剰に厳しく設定され、正常なビジネストラフィックがブロックされる

- セキュリティログが適切に管理されず、問題の診断や監査に支障をきたす

- Firewall Managerによるポリシー適用が一部環境でバイパスされる

- Network Firewallの配置が不適切で、保護が不十分なセグメントが生じる

- セキュリティ対策の自動化レベルが不十分で、手動操作の依存度が高い

- 各セキュリティレイヤー間の連携が不足し、包括的な可視性が得られない

- 脅威モデルが不明確で、セキュリティ対策の有効性を評価できない

## 20. ECS Fargate/ECRマイクロサービス実装（30-35ページ）

## 本章の目的：マイクロサービスのコンテナ実行基盤を実装する

### **実践ハンズオン 20-1**: マイクロサービスのコンテナ化 

- Dockerfileベストプラクティス

- マルチステージビルドの実装

- 最小特権原則の適用

- セキュリティスキャンの統合

### **実践ハンズオン 20-2**: ECRリポジトリ構築 

- リポジトリ作成と設定

- イメージスキャン設定

- ライフサイクルポリシー設定

- クロスアカウントアクセス設定

### **実践ハンズオン 20-3**: ECRセキュリティ自動化 

- コンテナ脆弱性スキャンの自動化

- 脆弱性検出時の自動通知

- 自動修復と再ビルドパイプライン

- バージョン管理と追跡

### **実践ハンズオン 20-4**: ECS Fargateクラスター実装 

- クラスター作成と設定

- タスク定義の作成

- サービス設定とロードバランサー連携

- オートスケーリング設定

### **実践ハンズオン 20-5**: サービスメッシュとサービスディスカバリ 

- サービスディスカバリの設定

- サービス間通信の実装

- トレース統合の設定

- メッシュの監視と管理

### **実践ハンズオン 20-6**: コンテナログとモニタリング 

- FireLensログルーターの設定

- CloudWatch Logsとの統合

- カスタムメトリクスの実装

- アラート設定とダッシュボード

### **実践ハンズオン 20-7**: マイクロサービス間の安全な通信 

- 内部ロードバランサーの設定

- TLS証明書の管理と更新

- サービス間認証の実装

- トラフィック制御とリトライパターン

### **実践ハンズオン 20-8**: 環境タグ付けとイメージプロモーション 

- 環境別タグ設計（dev/staging/prod）

- イメージプロモーションフローの実装

- 環境間の構成差分管理

- 安全なリリース手順

### アンチパターン：ECS Fargate/ECR実装で失敗しやすいポイント

- コンテナイメージの肥大化によるスタートアップレイテンシやリソース効率低下

- ECRのライフサイクルポリシーの不備で古いイメージが蓄積し続ける

- 脆弱性スキャンの対応が不十分で、既知の脆弱性を含むイメージが使われ続ける

- ECSタスク定義のリソース配分が不適切でコストまたはパフォーマンス問題が発生

- サービスディスカバリの設計不備でサービス間通信に障害が発生

- ログ・モニタリング設定の不足でトラブルシューティングが困難になる

- 環境タグ付けが不十分で、環境間のイメージ混在が発生する

- イメージプロモーションプロセスが不明確で、安全性が確保できない

## 21. Aurora/Flywayデータベース実装（25-30ページ）

## 本章の目的：マイクロサービス向けデータベース基盤を実装する

### **実践ハンズオン 21-1**: Auroraクラスター実装 

- クラスター作成と構成

- マルチAZ設定と冗長性確保

- パラメータグループの最適化

- メンテナンスとバックアップ設定

### **実践ハンズオン 21-2**: リージョン間のAurora設定 

- 東京・大阪両リージョンでの設定

- リージョン固有パラメータの管理

- 環境変数を用いた設定制御

- リージョン間整合性の確保

### **実践ハンズオン 21-3**: IAMデータベース認証実装 

- IAM認証の設定

- ECS/Fargateとの統合

- 認証フローのテスト

- 監査とログ設定

### **実践ハンズオン 21-4**: Flywayマイグレーション環境構築 

- プロジェクト構造と設定

- マイグレーションスクリプト作成

- バージョン管理と変更履歴

- CI/CDパイプライン統合

### **実践ハンズオン 21-5**: オンプレミスからのデータ移行 

- ETLパイプラインの構築

- データ変換とクレンジング

- S3ステージングと検証

- 移行検証と整合性チェック

### **実践ハンズオン 21-6**: マイクロサービス別スキーマ設計 

- サービス境界に応じたスキーマ分離

- 参照整合性とデータ一貫性

- パフォーマンス最適化

- データアクセスパターン実装

### **実践ハンズオン 21-7**: データベースパフォーマンスチューニング 

- インデックス戦略の最適化

- パフォーマンスインサイトの活用

- クエリ最適化と分析

- 自動スケーリング設定

### アンチパターン：Aurora/Flyway実装で失敗しやすいポイント

- Auroraのインスタンスタイプとクラスター設定が不適切でコスト/性能問題が発生

- リージョン間の設定不整合でレプリケーションが適切に機能しない

- IAMデータベース認証の設定不備で接続エラーが発生

- Flywayマイグレーションのバージョン管理不足で異なる環境間の不整合が生じる

- データ移行の検証不足で整合性問題やデータ損失が発生

- マイクロサービス境界を超えたデータアクセスパターンが生じ、密結合状態になる

- パフォーマンスモニタリングの不足で問題の早期発見ができない

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 22. API Gateway/Cognitoの実装（25-30ページ）

## 本章の目的：API層と認証基盤を実装する

### **実践ハンズオン 22-1**: API Gateway設計と実装 

- REST APIの作成と構成

- リソース階層とメソッド定義

- 統合タイプとマッピングテンプレート

- ステージとデプロイメント管理

### **実践ハンズオン 22-2**: マルチリージョンAPI設定 

- 東京・大阪両リージョンでのAPI設定

- リージョン固有エンドポイント管理

- 環境変数による設定制御

- リージョン間整合性確保

### **実践ハンズオン 22-3**: BFFパターン実装 

- クライアント最適化APIの実装

- バックエンドサービス統合

- データ変換とアグリゲーション

- エラーハンドリングパターン

### **実践ハンズオン 22-4**: Cognitoユーザープール実装 

- ユーザープール作成と設定

- MFA設定と強力なパスワードポリシー

- Active Directory連携設定

- サインアップとサインインフロー

### 実践ハンズオン 22-5: API認証の統合 

- CognitoオーソライザーとAPI Gateway連携

- スコープとアクセス制御

- JWTトークン検証

- APIキー管理とUsage Plan設定

### 実践ハンズオン 22-6: API性能最適化 

- キャッシング設定

- スロットリング最適化

- レイテンシモニタリング

- コストと性能のバランス管理

### **実践ハンズオン 22-7**: API監視とエラー対応 

- CloudWatchダッシュボード設定

- エラー率とレイテンシアラート

- エラーパターン分析

- 自動修復メカニズム

### アンチパターン：API Gateway/Cognito実装で失敗しやすいポイント

- APIのリソース構造が不適切で管理困難やURLの不整合が生じる

- リージョン間の設定不整合でフェイルオーバー時に問題が発生

- Cognitoの設定が複雑すぎてユーザー体験が低下する

- API認証の設定ミスでセキュリティ脆弱性やアクセス問題が発生

- スロットリング設定の不備で高負荷時にサービス停止が発生

- キャッシュ設定の誤りで古いデータが提供される

- エラーハンドリングが不十分でクライアント側での問題解決が困難になる

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 23. Step Functions/Lambdaバッチ処理実装（25-30ページ）

## 本章の目的：サーバーレスバッチ処理基盤を実装する

### **実践ハンズオン 23-1**: Step Functions実装 

- ステートマシン設計と作成

- ワークフロー定義とステート設定

- 条件分岐とエラーハンドリング

- 並列処理実装

### **実践ハンズオン 23-2**: マルチリージョンワークフロー設定 

- 東京・大阪両リージョンでのワークフロー設定

- リージョン固有パラメータの管理

- 環境変数による設定制御

- リージョン間整合性の確保

### **実践ハンズオン 23-3**: Lambda関数実装 

- 関数コード開発とベストプラクティス

- タイムアウトとメモリ最適化

- エラーハンドリングとリトライ

- 環境変数とコンテキスト管理

### **実践ハンズオン 23-4**: データ処理パイプライン実装 

- ETL処理フローの構築

- 大規模データ処理の並列化

- S3イベントトリガー設定

- 処理状態の可視化

### **実践ハンズオン 23-5**: バッチスケジューリング実装 

- EventBridgeルール設定

- バッチジョブ依存関係管理

- 定期実行と監視

- 失敗処理とリカバリー

### **実践ハンズオン 23-6**: クロスアカウントワークフロー 

- アカウント間のStep Functions連携

- クロスアカウントLambda呼び出し

- IAMロールとアクセス制御

- エンドツーエンド監視

### **実践ハンズオン 23-7**: バッチ処理の監視と最適化 

- CloudWatch Logs/Metricsの設定

- X-Ray分析統合

- コスト最適化戦略

- パフォーマンスチューニング

### アンチパターン：Step Functions/Lambda実装で失敗しやすいポイント

- Lambda関数のサイズが大きすぎてコールドスタート問題が発生

- メモリ割り当てが不適切でコストまたはパフォーマンスが最適でない

- リージョン間の設定不整合でフェイルオーバー時に問題が発生

- Step Functionsのステートマシン設計が複雑すぎて管理困難になる

- エラーハンドリングの不足で障害時に回復困難になる

- 大量のイベントによるLambda同時実行数の上限到達

- クロスアカウント設定の不備でワークフローの断絶が発生

- 環境変数の管理不足で、環境ごとの適切な設定が行われない

## 24. CI/CDパイプラインとデプロイ自動化実装（30-35ページ）

## 本章の目的：環境変数管理とマルチリージョン対応のCI/CDパイプラインを実装する

### **実践ハンズオン 24-1**: GitLabリポジトリとブランチ戦略 

- リポジトリ構造と設定

- ブランチ戦略とフロー定義

- マージリクエストルール

- コードレビュープロセス設定

### **実践ハンズオン 24-2**: 静的解析パイプライン実装 

- tfsec, TFLint, checkovの統合

- カスタムルール設定

- 分析結果のレポーティング

- 修正フローの自動化

### **実践ハンズオン 24-3**: IAM Access Analyzer統合 

- 動的解析プロセスの実装

- Access Analyzerのフィードバック処理

- 検出問題の分類と優先順位付け

- 修正推奨事項の自動生成

### **実践ハンズオン 24-4**: 環境変数管理システム実装 

- 環境変数階層の設計

- 環境別変数管理（dev/staging/prod）

- リージョン固有変数の管理

- 秘密情報の安全な処理

### **実践ハンズオン 24-5**: 手動承認プロセス実装 

- エラー検出時の承認フロー

- 承認情報の整理と表示

- 承認ワークフローの設定

- 承認履歴と監査記録

### **実践ハンズオン 24-6**: マイクロサービスビルド・デプロイパイプライン 

- ビルド環境の標準化

- テスト自動化

- 環境別のデプロイ戦略

- ロールバック機構の実装

### **実践ハンズオン 24-7**: マルチリージョンデプロイ 

- 東京・大阪両リージョンへの同時デプロイ

- リージョン固有設定の管理

- デプロイ順序と依存関係

- 検証と整合性確認

### **実践ハンズオン 24-8**: 環境間プロモーションフロー 

- 環境昇格プロセス（dev→staging→prod）

- 環境タグ付けとバージョン管理

- プロモーション承認フロー

- 環境間の構成差分管理

### アンチパターン：CI/CD実装で失敗しやすいポイント

- 静的解析警告を無視し、問題を残したままデプロイする

- 環境変数管理が不適切で環境間の設定が混同される

- リージョン間の設定不整合でマルチリージョンデプロイが失敗する

- 手動承認プロセスが形骸化し、実質的なチェックが行われない

- 環境タグ付けが不十分で、環境間のイメージ混在が発生する

- デプロイパイプラインが単一障害点となり、全環境のデプロイが停止する

- ロールバック手順の実装が不完全で、障害時の回復が困難になる

- 異なる環境間の構成差異が大きすぎて、環境間のプロモーションが難しくなる

## 25. DR設定と運用監視の実装（25-30ページ）

## 本章の目的：東京-大阪間の災害対策と統合監視基盤を実装する

### **実践ハンズオン 25-1**: Aurora Global Database設定 

- クロスリージョンレプリケーション設定

- レプリケーションモニタリング

- フェイルオーバー設定

- テストと検証

### **実践ハンズオン 25-2**: クロスリージョンコンテナ戦略 

- ECRレプリケーション設定

- クロスリージョンデプロイ戦略

- 構成同期メカニズム

- 動作検証手順

### **実践ハンズオン 25-3**: Route 53フェイルオーバールーティング 

- ヘルスチェック設定

- フェイルオーバーポリシー

- DNSレコード管理

- フェイルオーバーテスト

### **実践ハンズオン 25-4**: 統合監視ダッシュボード構築 

- CloudWatchクロスアカウントダッシュボード

- マイクロサービス健全性監視

- アラート集約と通知設定

- カスタムメトリクス実装

### **実践ハンズオン 25-5**: 環境タグベースの監視フィルタリング 

- 環境タグに基づく監視ビューの作成

- 環境別のアラートポリシー

- 環境タグを活用したメトリクス分析

- ダッシュボードのカスタマイズ

### **実践ハンズオン 25-6**: DR訓練とフェイルオーバー演習 

- 定期訓練の計画と実施

- フェイルオーバーチェックリスト

- パフォーマンス評価

- 改善サイクル

### アンチパターン：DR設定と運用監視で失敗しやすいポイント

- レプリケーション設定の不備でデータ同期の遅延や損失が発生

- 環境タグ付けが不十分で、環境ごとの適切なモニタリングができない

- フェイルオーバー手順のテストが不足し、実際の災害時に機能しない

- ヘルスチェックの設定不備で不要なフェイルオーバーが発生

- 監視ダッシュボードが複雑すぎて重要な情報が埋もれる

- DR環境のキャパシティが不足し、フェイルオーバー後にパフォーマンス問題が発生

- 定期的なDR訓練が行われず、手順やツールが陳腐化する

- 東京・大阪間のレイテンシ差異を考慮せず、パフォーマンス問題が生じる

## 技術ドキュメント例

## アカウント申請JSON例（生産管理マイクロサービス・テスト環境用）

json

{

"account_name": "test-production-management",

"email": "aws-test-production-management@technova.com",

"organizational_unit": "Test",

"tags": {

"Environment": "test",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "production-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "test",

"/dr_enabled": "false",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true

}

}

## マルチリージョン対応Terraform設定例

hcl

*\# プロバイダー設定 - 東京・大阪両リージョンを並記*

provider "aws" {

region = var.primary_region *\# ap-northeast-1（東京）*

alias = "tokyo"

default_tags {

tags = {

Environment = var.environment

Team = var.team

Application = var.application

ProvisionedBy = "Terraform"

PrimaryRegion = var.primary_region

}

}

}

provider "aws" {

region = var.secondary_region *\# ap-northeast-3（大阪）*

alias = "osaka"

default_tags {

tags = {

Environment = var.environment

Team = var.team

Application = var.application

ProvisionedBy = "Terraform"

SecondaryRegion = var.secondary_region

}

}

}

*\# 環境変数によるモジュール管理*

module "vpc_tokyo" {

source = "../modules/vpc"

providers = {

aws = aws.tokyo

}

environment = var.environment

vpc_cidr = var.vpc_cidr_tokyo

subnet_cidrs = var.subnet_cidrs_tokyo

availability_zones = \["ap-northeast-1a", "ap-northeast-1c"\]

*\# 環境変数に基づく条件付き設定*

enable_vpn_gateway = var.environment == "prod" ? true : false

nat_gateway_count = var.environment == "prod" ? 2 : 1

*\# 東京リージョン固有の設定*

transit_gateway_id = var.tgw_id_tokyo

tags = {

Region = "Tokyo"

}

}

module "vpc_osaka" {

source = "../modules/vpc"

providers = {

aws = aws.osaka

}

*\# DR環境は本番環境のみ構築*

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

environment = var.environment

vpc_cidr = var.vpc_cidr_osaka

subnet_cidrs = var.subnet_cidrs_osaka

availability_zones = \["ap-northeast-3a", "ap-northeast-3b"\]

*\# 環境変数に基づく条件付き設定*

enable_vpn_gateway = var.environment == "prod" ? true : false

nat_gateway_count = var.environment == "prod" ? 2 : 1

*\# 大阪リージョン固有の設定*

transit_gateway_id = var.tgw_id_osaka

tags = {

Region = "Osaka"

DR = "Enabled"

}

}

*\# 環境変数定義*

variable "environment" {

description = "Deployment environment (dev, test, staging, prod)"

type = string

validation {

condition = contains(\["dev", "test", "staging", "prod"\],
var.environment)

error_message = "Environment must be one of: dev, test, staging, prod."

}

}

variable "primary_region" {

description = "Primary AWS region"

type = string

default = "ap-northeast-1"

}

variable "secondary_region" {

description = "Secondary AWS region for DR"

type = string

default = "ap-northeast-3"

}

variable "dr_enabled" {

description = "Enable Disaster Recovery resources"

type = bool

default = false

}

## IaC静的解析とCI/CD設定例

yaml

*\# GitLab CI/CD パイプライン設定*

stages:

\- validate

\- plan

\- approve

\- apply

\- post-deploy

variables:

TF_ROOT: \${CI_PROJECT_DIR}/terraform

TF_STATE_NAME: \${CI_PROJECT_NAME}-\${CI_COMMIT_REF_SLUG}

TF_VAR_environment: \${CI_ENVIRONMENT_NAME}

AWS_DEFAULT_REGION: ap-northeast-1

*\# 静的解析ステージ*

static-analysis:

stage: validate

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform init -backend=false

\- terraform validate

*\# tfsec実行*

\- tfsec .

*\# TFLint実行*

\- tfswitch 1.2.3

\- tflint --recursive

*\# Checkov実行*

\- checkov -d .

artifacts:

reports:

junit: reports/tflint-report.xml

allow_failure:

exit_codes: \[0, 1\]

*\# 動的解析ステージ*

access-analyzer:

stage: validate

image: amazon/aws-cli:latest

script:

\- aws accessanalyzer validate-policy --policy-type IAM_POLICY
--policy-document file://policies/iam_policies.json

\- python3 scripts/analyze_access_findings.py

dependencies:

\- static-analysis

*\# Terraform計画ステージ*

terraform-plan:

stage: plan

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform init

\- terraform plan -out=tfplan

artifacts:

paths:

\- \${TF_ROOT}/tfplan

expire_in: 1 week

*\# 手動承認ステージ (エラーがあった場合も含む)*

manual-approval:

stage: approve

script:

\- echo "Terraform plan requires manual approval"

when: manual

allow_failure: false

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod" \|\| \$CI_ENVIRONMENT_NAME ==
"staging"

when: always

\- when: on_failure *\#
静的解析でエラーが発生した場合も手動承認を必要とする*

*\# 適用ステージ*

terraform-apply:

stage: apply

image: hashicorp/terraform:1.2.3

script:

\- cd \${TF_ROOT}

\- terraform apply -auto-approve tfplan

dependencies:

\- terraform-plan

\- manual-approval

environment:

name: \${CI_ENVIRONMENT_NAME}

on_stop: destroy

when: manual

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "staging"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "dev" \|\| \$CI_ENVIRONMENT_NAME ==
"test"

when: on_success

*\# デプロイ後検証*

post-deploy-validation:

stage: post-deploy

script:

\- aws cloudformation validate-stack --stack-name
\${CI_ENVIRONMENT_NAME}-stack

\- python3 scripts/verify_deployment.py

rules:

\- if: \$CI_COMMIT_BRANCH == "main" && \$CI_ENVIRONMENT_NAME == "prod"

## ECS TaskロールとAurora IAM認証サンプル

hcl

*\# ECSタスク実行ロール*

resource "aws_iam_role" "ecs_task_execution_role" {

name = "production-mgmt-ecs-execution-role-\${var.environment}"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

Action = "sts:AssumeRole"

}\]

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECSタスクロール（アプリケーション実行権限）*

resource "aws_iam_role" "ecs_task_role" {

name = "production-mgmt-ecs-task-role-\${var.environment}"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

Action = "sts:AssumeRole"

}\]

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# Aurora IAM認証用ポリシー*

resource "aws_iam_policy" "aurora_connect_policy" {

name = "production-mgmt-aurora-connect-\${var.environment}"

description = "Allow connection to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource = \[

"arn:aws:rds-db:\${var.primary_region}:\${var.account_id}:dbuser:\${var.db_cluster_resource_id_tokyo}/\${var.db_username}",

"arn:aws:rds-db:\${var.secondary_region}:\${var.account_id}:dbuser:\${var.db_cluster_resource_id_osaka}/\${var.db_username}"

\]

}\]

})

}

*\# タスクロールにAurora接続権限をアタッチ*

resource "aws_iam_role_policy_attachment" "task_aurora_connect" {

role = aws_iam_role.ecs_task_role.name

policy_arn = aws_iam_policy.aurora_connect_policy.arn

}

*\# タスク実行に必要な基本ポリシーをアタッチ*

resource "aws_iam_role_policy_attachment" "task_execution_basic" {

role = aws_iam_role.ecs_task_execution_role.name

policy_arn =
"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"

}

*\# シークレットアクセス権限（環境変数用）*

resource "aws_iam_policy" "secrets_access" {

name = "production-mgmt-secrets-access-\${var.environment}"

description = "Allow access to secrets manager for database credentials"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = \[

"secretsmanager:GetSecretValue",

"kms:Decrypt"

\]

Resource = \[

var.db_secret_arn,

var.kms_key_arn

\]

}\]

})

}

resource "aws_iam_role_policy_attachment" "task_execution_secrets" {

role = aws_iam_role.ecs_task_execution_role.name

policy_arn = aws_iam_policy.secrets_access.arn

}

## コンテナセキュリティスキャンと自動更新の設定例

yaml

*\# コンテナセキュリティスキャンとインシデント対応の自動化 - AWS
Lambda関数*

resource "aws_lambda_function" "image_vulnerability_handler" {

function_name = "ecr-vulnerability-handler-\${var.environment}"

description = "Handle ECR image vulnerability findings and trigger
auto-remediation"

role = aws_iam_role.image_vulnerability_handler_role.arn

handler = "index.handler"

runtime = "nodejs14.x"

timeout = 300

memory_size = 512

environment {

variables = {

ECR_REPO_PREFIX = "production-mgmt-"

NOTIFICATION_SNS = aws_sns_topic.vulnerability_alerts.arn

ENVIRONMENT = var.environment

CODEBUILD_PROJECT = aws_codebuild_project.image_rebuild.name

}

}

filename = "\${path.module}/lambda/vulnerability-handler.zip"

source_code_hash =
filebase64sha256("\${path.module}/lambda/vulnerability-handler.zip")

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECRイメージスキャン結果をLambdaに通知するイベントルール*

resource "aws_cloudwatch_event_rule" "ecr_scan_findings" {

name = "ecr-scan-findings-\${var.environment}"

description = "Capture ECR image scan findings"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[{

prefix = "production-mgmt-"

}\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# イベントルールとLambda関数の連携*

resource "aws_cloudwatch_event_target" "ecr_scan_findings_lambda" {

rule = aws_cloudwatch_event_rule.ecr_scan_findings.name

target_id = "SendToLambda"

arn = aws_lambda_function.image_vulnerability_handler.arn

}

*\# コンテナイメージ再ビルドのCodeBuildプロジェクト*

resource "aws_codebuild_project" "image_rebuild" {

name = "ecr-image-rebuild-\${var.environment}"

description = "Rebuild container images when vulnerabilities are
detected"

service_role = aws_iam_role.codebuild_service_role.arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = true

environment_variable {

name = "ECR_REPOSITORY"

value = "*\#{ECR_REPOSITORY}"*

}

environment_variable {

name = "IMAGE_TAG"

value = "*\#{IMAGE_TAG}"*

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

}

source {

type = "GITHUB"

location =
"https://github.com/technova/production-management-service.git"

buildspec = "buildspec.yml"

}

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# 脆弱性アラート用SNSトピック*

resource "aws_sns_topic" "vulnerability_alerts" {

name = "ecr-vulnerability-alerts-\${var.environment}"

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# 脆弱性レポート用S3バケット*

resource "aws_s3_bucket" "vulnerability_reports" {

bucket =
"technova-ecr-vulnerability-reports-\${var.aws_account_id}-\${var.environment}"

lifecycle_rule {

id = "reports-retention"

enabled = true

expiration {

days = 90

}

}

tags = merge(var.tags, {

Environment = var.environment

})

}

*\# ECRリポジトリのスキャン設定*

resource "aws_ecr_repository" "service_repo" {

name = "production-mgmt-service-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

tags = merge(var.tags, {

Environment = var.environment

})

}

## Flyway設定とマイグレーションサンプル

sql

*-- V1\_\_initial_schema.sql*

CREATE TABLE production_orders (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

order_number VARCHAR(50) NOT NULL UNIQUE,

product_code VARCHAR(50) NOT NULL,

quantity INT NOT NULL,

planned_start_date DATE NOT NULL,

planned_end_date DATE NOT NULL,

status VARCHAR(20) NOT NULL,

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP,

created_by VARCHAR(255),

updated_by VARCHAR(255)

);

CREATE TABLE production_materials (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL,

material_code VARCHAR(50) NOT NULL,

required_quantity DECIMAL(10, 2) NOT NULL,

allocated_quantity DECIMAL(10, 2) DEFAULT 0,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE

);

*-- V2\_\_add_workflow_tracking.sql*

CREATE TABLE production_workflow_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL,

step_name VARCHAR(50) NOT NULL,

start_time TIMESTAMP,

end_time TIMESTAMP,

status VARCHAR(20) NOT NULL,

notes TEXT,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE

);

yaml

*\# flyway.conf*

flyway.url=jdbc:mysql://\${AURORA_ENDPOINT}:3306/\${DB_NAME}

flyway.user=\${DB_USER}

flyway.password=\${DB_PASSWORD}

flyway.locations=filesystem:./sql

flyway.baselineOnMigrate=true

flyway.schemas=production_management

flyway.connectRetries=10

flyway.cleanDisabled=true

## Step Functions ワークフローサンプル（東京・大阪両リージョン対応）

json

{

"Comment": "Production Planning Workflow with Multi-Region Support",

"StartAt": "DetectRegion",

"States": {

"DetectRegion": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.region",

"StringEquals": "ap-northeast-1",

"Next": "FetchPendingOrdersTokyo"

},

{

"Variable": "\$.region",

"StringEquals": "ap-northeast-3",

"Next": "FetchPendingOrdersOsaka"

}

\],

"Default": "FetchPendingOrdersTokyo"

},

"FetchPendingOrdersTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:fetch-pending-orders",

"Next": "CheckOrdersExistTokyo"

},

"FetchPendingOrdersOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:fetch-pending-orders",

"Next": "CheckOrdersExistOsaka"

},

"CheckOrdersExistTokyo": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.orderCount",

"NumericEquals": 0,

"Next": "NoOrdersToProcessTokyo"

}

\],

"Default": "ProcessOrdersTokyo"

},

"CheckOrdersExistOsaka": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.orderCount",

"NumericEquals": 0,

"Next": "NoOrdersToProcessOsaka"

}

\],

"Default": "ProcessOrdersOsaka"

},

"NoOrdersToProcessTokyo": {

"Type": "Pass",

"End": true,

"Result": {

"region": "ap-northeast-1",

"processed": 0,

"message": "No orders to process in Tokyo region"

}

},

"NoOrdersToProcessOsaka": {

"Type": "Pass",

"End": true,

"Result": {

"region": "ap-northeast-3",

"processed": 0,

"message": "No orders to process in Osaka region"

}

},

"ProcessOrdersTokyo": {

"Type": "Map",

"ItemsPath": "\$.orders",

"MaxConcurrency": 10,

"Iterator": {

"StartAt": "CheckMaterialAvailabilityTokyo",

"States": {

"CheckMaterialAvailabilityTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:check-material-availability",

"Next": "MaterialsAvailableTokyo"

},

"MaterialsAvailableTokyo": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.allMaterialsAvailable",

"BooleanEquals": false,

"Next": "QueueForLaterPlanningTokyo"

}

\],

"Default": "ScheduleProductionTokyo"

},

"QueueForLaterPlanningTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:queue-for-later-planning",

"End": true

},

"ScheduleProductionTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:schedule-production",

"Next": "ReserveMaterialsTokyo"

},

"ReserveMaterialsTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:reserve-materials",

"Next": "NotifyProductionTeamTokyo"

},

"NotifyProductionTeamTokyo": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-1:123456789012:production-notifications",

"Message.\$": "\$.notificationMessage"

},

"End": true

}

}

},

"Next": "GenerateSummaryReportTokyo"

},

"ProcessOrdersOsaka": {

"Type": "Map",

"ItemsPath": "\$.orders",

"MaxConcurrency": 10,

"Iterator": {

"StartAt": "CheckMaterialAvailabilityOsaka",

"States": {

"CheckMaterialAvailabilityOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:check-material-availability",

"Next": "MaterialsAvailableOsaka"

},

"MaterialsAvailableOsaka": {

"Type": "Choice",

"Choices": \[

{

"Variable": "\$.allMaterialsAvailable",

"BooleanEquals": false,

"Next": "QueueForLaterPlanningOsaka"

}

\],

"Default": "ScheduleProductionOsaka"

},

"QueueForLaterPlanningOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:queue-for-later-planning",

"End": true

},

"ScheduleProductionOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:schedule-production",

"Next": "ReserveMaterialsOsaka"

},

"ReserveMaterialsOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:reserve-materials",

"Next": "NotifyProductionTeamOsaka"

},

"NotifyProductionTeamOsaka": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-3:123456789012:production-notifications",

"Message.\$": "\$.notificationMessage"

},

"End": true

}

}

},

"Next": "GenerateSummaryReportOsaka"

},

"GenerateSummaryReportTokyo": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-1:123456789012:function:generate-planning-summary",

"Next": "NotifyPlanningCompleteTokyo"

},

"GenerateSummaryReportOsaka": {

"Type": "Task",

"Resource":
"arn:aws:lambda:ap-northeast-3:123456789012:function:generate-planning-summary",

"Next": "NotifyPlanningCompleteOsaka"

},

"NotifyPlanningCompleteTokyo": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-1:123456789012:planning-notifications",

"Message.\$": "\$.summaryReport"

},

"End": true

},

"NotifyPlanningCompleteOsaka": {

"Type": "Task",

"Resource": "arn:aws:states:::sns:publish",

"Parameters": {

"TopicArn":
"arn:aws:sns:ap-northeast-3:123456789012:planning-notifications",

"Message.\$": "\$.summaryReport"

},

"End": true

}

}

}

#  AWS AFT ハンズオン設計書：具体的実装内容

# セキュリティとコード品質向上のための追加実装要件

AFTを活用したAWS環境構築においては、セキュリティとコード品質の確保が非常に重要です。TechNova社のプロジェクトでは、以下の追加要件を実装します：

**静的解析ツール統合**

- **tfsec**: Terraformコードのセキュリティ問題を検出

- **TFLint**: Terraformコードの問題や非推奨設定を検出

- **checkov**: IaCのセキュリティとコンプライアンス違反をスキャン

**動的解析統合**

- **IAM Access Analyzer**: 予期しないアクセス許可や権限設定の問題を検出

**CI/CDパイプラインの品質ゲート**

- 各ステージでエラーが検出された場合の手動承認プロセス

- エラー内容と影響評価に基づく継続/中止判断メカニズム

- 検出された問題の重要度に応じた通知と対応フロー

**環境管理とタグ付け**

- ステージング/本番などの環境タグ付けによるリソース管理

- 環境変数によるモジュール管理と環境別設定

- 東京リージョン(ap-northeast-1)と大阪リージョン(ap-northeast-3)の両方を統合管理

## 具体的実装サンプル

## tfsec, TFLint, checkovを統合したCI/CD設定

\# .gitlab-ci.yml

stages:

\- validate

\- plan

\- approve

\- apply

variables:

TERRAFORM_VERSION: "1.5.0"

TFLINT_VERSION: "0.47.0"

TFSEC_VERSION: "1.28.1"

CHECKOV_VERSION: "2.3.259"

before_script:

\- apt-get update && apt-get install -y curl unzip

\- curl -sSL
"https://releases.hashicorp.com/terraform/\${TERRAFORM_VERSION}/terraform\_\${TERRAFORM_VERSION}\_linux_amd64.zip"
-o terraform.zip

\- unzip terraform.zip && rm terraform.zip

\- mv terraform /usr/local/bin/

\- curl -sSL
"https://github.com/terraform-linters/tflint/releases/download/v\${TFLINT_VERSION}/tflint_linux_amd64.zip"
-o tflint.zip

\- unzip tflint.zip && rm tflint.zip

\- mv tflint /usr/local/bin/

\- curl -sSL
"https://github.com/aquasecurity/tfsec/releases/download/v\${TFSEC_VERSION}/tfsec-linux-amd64"
-o /usr/local/bin/tfsec

\- chmod +x /usr/local/bin/tfsec

\- pip install checkov==\${CHECKOV_VERSION}

\# 静的解析ジョブ

static_analysis:

stage: validate

script:

\- cd \${TF_ROOT}

\# Terraform構文チェック

\- terraform init -backend=false

\- terraform validate

\# TFLint実行

\- tflint --recursive --format junit \> tflint_report.xml

\# tfsec実行

\- tfsec . --format junit \> tfsec_report.xml

\# checkov実行

\- checkov -d . --output junitxml \> checkov_report.xml

\# 結果を表示

\- echo "Static analysis completed. Check reports for details."

artifacts:

reports:

junit:

\- tflint_report.xml

\- tfsec_report.xml

\- checkov_report.xml

paths:

\- \${TF_ROOT}/tflint_report.xml

\- \${TF_ROOT}/tfsec_report.xml

\- \${TF_ROOT}/checkov_report.xml

expire_in: 1 week

allow_failure:

exit_codes: \[0, 1, 2\]

\# IAM Access Analyzer動的解析ジョブ

access_analyzer:

stage: validate

script:

\- cd \${TF_ROOT}

\- terraform show -json tfplan \> tfplan.json

\- python3 scripts/analyze_iam_policies.py

dependencies:

\- terraform_plan

artifacts:

paths:

\- \${TF_ROOT}/access_analyzer_results.json

expire_in: 1 week

\# Terraformプランジョブ

terraform_plan:

stage: plan

script:

\- cd \${TF_ROOT}

\- terraform init

\- terraform plan -out=tfplan

artifacts:

paths:

\- \${TF_ROOT}/tfplan

expire_in: 1 week

\# 手動承認ジョブ (エラーがあった場合も含む)

manual_approval:

stage: approve

script:

\- echo "Review the analysis results and plan output before proceeding"

\- python3 scripts/summarize_findings.py

when: manual

allow_failure: false

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod" \|\| \$CI_ENVIRONMENT_NAME ==
"staging"

when: always

\- when: on_failure \#
静的解析でエラーが発生した場合も手動承認を必要とする

\# Terraform適用ジョブ

terraform_apply:

stage: apply

script:

\- cd \${TF_ROOT}

\- terraform apply -auto-approve tfplan

dependencies:

\- terraform_plan

\- manual_approval

environment:

name: \${CI_ENVIRONMENT_NAME}

when: manual

rules:

\- if: \$CI_ENVIRONMENT_NAME == "prod"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "staging"

when: manual

\- if: \$CI_ENVIRONMENT_NAME == "dev" \|\| \$CI_ENVIRONMENT_NAME ==
"test"

when: on_success

## Access Analyzerを活用したIAMポリシー分析スクリプト

\# scripts/analyze_iam_policies.py

import json

import boto3

import sys

import os

def analyze_iam_policies(tfplan_file):

\# Terraformプランからポリシーを抽出

with open(tfplan_file, 'r') as f:

tfplan = json.load(f)

\# IAMポリシーを抽出

policies = extract_iam_policies(tfplan)

\# Access Analyzerを使用して分析

analyzer = boto3.client('accessanalyzer')

findings = \[\]

for policy_name, policy_doc in policies:

response = analyzer.validate_policy(

policyDocument=json.dumps(policy_doc),

policyType='IDENTITY_POLICY'

)

if 'findings' in response and response\['findings'\]:

for finding in response\['findings'\]:

finding\['policyName'\] = policy_name

findings.append(finding)

\# 結果を保存

with open('access_analyzer_results.json', 'w') as f:

json.dump(findings, f, indent=2)

\# 重要な問題があれば報告

critical_findings = \[f for f in findings if f\['findingType'\] in
\['ERROR', 'SECURITY_WARNING'\]\]

if critical_findings:

print(f"Found {len(critical_findings)} critical issues in IAM
policies:")

for finding in critical_findings:

print(f"- {finding\['policyName'\]}: {finding\['findingType'\]} -
{finding\['findingDetails'\]}")

if os.environ.get('CI_ENVIRONMENT_NAME') == 'prod':

print("Critical issues found in production environment policies!")

sys.exit(1) \# 本番環境では重大な問題があればパイプラインを停止

print(f"IAM Policy analysis complete. Total findings: {len(findings)}")

return len(critical_findings) == 0

def extract_iam_policies(tfplan):

\# TerraformプランからIAMポリシーを抽出するロジック

policies = \[\]

\# ...抽出ロジックの実装...

return policies

if \_\_name\_\_ == "\_\_main\_\_":

analyze_iam_policies('tfplan.json')

## 環境変数とタグを活用したマルチリージョン設定

\# environments/variables.tf

variable "environment" {

description = "Deployment environment (dev, test, staging, prod)"

type = string

validation {

condition = contains(\["dev", "test", "staging", "prod"\],
var.environment)

error_message = "Environment must be one of: dev, test, staging, prod."

}

}

variable "primary_region" {

description = "Primary AWS region (Tokyo)"

type = string

default = "ap-northeast-1"

}

variable "secondary_region" {

description = "Secondary AWS region for DR (Osaka)"

type = string

default = "ap-northeast-3"

}

variable "dr_enabled" {

description = "Enable Disaster Recovery resources in secondary region"

type = bool

default = false

}

variable "team" {

description = "Team responsible for the resources"

type = string

}

variable "application" {

description = "Application name"

type = string

}

variable "cost_center" {

description = "Cost center code for billing"

type = string

}

\# common tag structure for all resources

locals {

common_tags = {

Environment = var.environment

Team = var.team

Application = var.application

CostCenter = var.cost_center

ManagedBy = "terraform"

}

tokyo_tags = merge(local.common_tags, {

Region = "Tokyo"

PrimaryRegion = "true"

})

osaka_tags = merge(local.common_tags, {

Region = "Osaka"

DR = var.dr_enabled ? "Enabled" : "Disabled"

})

}

## 両リージョンを並記したプロバイダー設定

\# providers.tf

provider "aws" {

region = var.primary_region \# Tokyo

alias = "tokyo"

default_tags {

tags = local.tokyo_tags

}

}

provider "aws" {

region = var.secondary_region \# Osaka

alias = "osaka"

default_tags {

tags = local.osaka_tags

}

}

\# Tokyo リージョンのリソース

module "vpc_tokyo" {

source = "../modules/vpc"

providers = {

aws = aws.tokyo

}

name = "\${var.application}-\${var.environment}"

cidr_block = var.vpc_cidr_tokyo

environment = var.environment

\# 環境変数に基づく条件付き設定

nat_gateway_count = var.environment == "prod" ? 2 : 1

\# その他のパラメータ

\# ...

}

\# Osaka リージョンのリソース (本番環境の場合のみ)

module "vpc_osaka" {

source = "../modules/vpc"

providers = {

aws = aws.osaka

}

\# DR環境は本番環境のみ構築

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

cidr_block = var.vpc_cidr_osaka

environment = var.environment

\# 環境変数に基づく条件付き設定

nat_gateway_count = var.environment == "prod" ? 2 : 1

\# その他のパラメータ

\# ...

}

## 環境変数を活用したマルチリージョンのAuroraクラスター設定

\# database/aurora.tf

\# 東京リージョンのAuroraクラスター

resource "aws_rds_cluster" "aurora_tokyo" {

provider = aws.tokyo

cluster_identifier = "\${var.application}-\${var.environment}"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

database_name = replace("\${var.application}\_\${var.environment}", "-",
"\_")

master_username = var.db_master_username

master_password = var.db_master_password

backup_retention_period = var.environment == "prod" ? 7 : 1

preferred_backup_window = "16:00-17:00" \# UTC (日本時間の朝1-2時)

deletion_protection = var.environment == "prod" \|\| var.environment ==
"staging"

skip_final_snapshot = var.environment != "prod"

final_snapshot_identifier = var.environment == "prod" ?
"\${var.application}-\${var.environment}-final" : null

\# 環境変数に基づく条件付き設定

iam_database_authentication_enabled = true

storage_encrypted = true

kms_key_id = var.kms_key_arn_tokyo

\# DR設定（本番環境のみ）

global_cluster_identifier = var.environment == "prod" && var.dr_enabled
? "\${var.application}-\${var.environment}-global" : null

\# その他のクラスター設定

\# ...

tags = local.tokyo_tags

}

\# 大阪リージョンのAuroraクラスター（本番環境のDR用）

resource "aws_rds_cluster" "aurora_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

cluster_identifier = "\${var.application}-\${var.environment}"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

\# グローバルクラスターの一部として設定

global_cluster_identifier =
"\${var.application}-\${var.environment}-global"

\# レプリカのため、以下の設定は必要ない

skip_final_snapshot = true

\# その他のクラスター設定

\# ...

tags = local.osaka_tags

}

\# DBインスタンス（東京リージョン）

resource "aws_rds_cluster_instance" "aurora_instances_tokyo" {

provider = aws.tokyo

count = var.environment == "prod" ? 2 : 1

identifier = "\${var.application}-\${var.environment}-\${count.index}"

cluster_identifier = aws_rds_cluster.aurora_tokyo.id

instance_class = var.environment == "prod" ? "db.r6g.large" :
"db.r6g.medium"

engine = aws_rds_cluster.aurora_tokyo.engine

engine_version = aws_rds_cluster.aurora_tokyo.engine_version

\# パフォーマンス最適化のための設定

performance_insights_enabled = var.environment == "prod" \|\|
var.environment == "staging"

tags = local.tokyo_tags

}

\# DBインスタンス（大阪リージョン）

resource "aws_rds_cluster_instance" "aurora_instances_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

identifier = "\${var.application}-\${var.environment}-\${count.index}"

cluster_identifier = aws_rds_cluster.aurora_osaka\[0\].id

instance_class = "db.r6g.large"

engine = aws_rds_cluster.aurora_osaka\[0\].engine

engine_version = aws_rds_cluster.aurora_osaka\[0\].engine_version

tags = local.osaka_tags

}

## 手動承認ステージを実装したAFTパイプライン設定

\# AFT/account-provisioning/pipeline.tf

resource "aws_codepipeline" "aft_account_provisioning" {

name = "aft-account-provisioning-pipeline"

role_arn = aws_iam_role.aft_codepipeline_role.arn

artifact_store {

location = aws_s3_bucket.aft_codepipeline_artifacts.bucket

type = "S3"

}

stage {

name = "Source"

action {

name = "Source"

category = "Source"

owner = "AWS"

provider = "CodeStarSourceConnection"

version = "1"

output_artifacts = \["source_output"\]

configuration = {

ConnectionArn = aws_codestarconnections_connection.gitlab.arn

FullRepositoryId = var.aft_account_request_repo

BranchName = var.aft_account_request_branch

}

}

}

stage {

name = "Validate"

action {

name = "TerraformValidate"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["validate_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_validate.name

}

}

action {

name = "StaticAnalysis"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["static_analysis_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_static_analysis.name

}

}

action {

name = "IAMValidation"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["iam_validation_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_iam_validation.name

}

}

}

stage {

name = "Plan"

action {

name = "TerraformPlan"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

output_artifacts = \["plan_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_plan.name

}

}

}

\# 必要に応じて手動承認ステージ

stage {

name = "Approval"

action {

name = "ManualApproval"

category = "Approval"

owner = "AWS"

provider = "Manual"

version = "1"

configuration = {

\# Plan段階でIssueが検出された場合、変更の承認方法に関する説明を含める

CustomData = "Review the Terraform plan and analysis results. Any
security findings or validation errors must be acknowledged before
proceeding."

\# SNSトピックを指定して、承認通知を送信

NotificationArn = aws_sns_topic.aft_approval_notification.arn

\# 承認にExternalEntityを使用（AWS CLIを使用した承認など）

ExternalEntityLink =
"https://technova.gitlab.com/projects/\${var.aft_account_request_repo}/pipelines/\${CODEPIPELINE_EXECUTION_ID}"

}

}

}

stage {

name = "Apply"

action {

name = "TerraformApply"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output", "plan_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_terraform_apply.name

PrimarySource = "source_output"

EnvironmentVariables = jsonencode(\[

{

name = "TERRAFORM_PLAN"

value = "plan_output"

type = "PLAINTEXT"

}

\])

}

}

}

stage {

name = "Validate-Resources"

action {

name = "ValidateDeployment"

category = "Build"

owner = "AWS"

provider = "CodeBuild"

input_artifacts = \["source_output"\]

version = "1"

configuration = {

ProjectName = aws_codebuild_project.aft_post_deployment_validation.name

}

}

}

}

\# 承認通知用SNSトピック

resource "aws_sns_topic" "aft_approval_notification" {

name = "aft-approval-notification"

tags = {

Name = "AFT Approval Notification"

Environment = "management"

}

}

\# CodeBuildプロジェクト：静的解析

resource "aws_codebuild_project" "aft_static_analysis" {

name = "aft-static-analysis"

description = "Static analysis of Terraform code using tfsec, TFLint,
and checkov"

service_role = aws_iam_role.aft_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "TFLINT_VERSION"

value = "0.47.0"

}

environment_variable {

name = "TFSEC_VERSION"

value = "1.28.1"

}

environment_variable {

name = "CHECKOV_VERSION"

value = "2.3.259"

}

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/static_analysis_buildspec.yml"

}

logs_config {

cloudwatch_logs {

group_name = "/aws/codebuild/aft-static-analysis"

stream_name = "%INITIATOR%-%BUILD_ID%"

}

}

tags = {

Name = "AFT Static Analysis"

Environment = "management"

}

}

\# CodeBuildプロジェクト：IAM検証

resource "aws_codebuild_project" "aft_iam_validation" {

name = "aft-iam-validation"

description = "Validate IAM policies using AWS Access Analyzer"

service_role = aws_iam_role.aft_codebuild_role.arn

artifacts {

type = "CODEPIPELINE"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

}

source {

type = "CODEPIPELINE"

buildspec = "buildspecs/iam_validation_buildspec.yml"

}

logs_config {

cloudwatch_logs {

group_name = "/aws/codebuild/aft-iam-validation"

stream_name = "%INITIATOR%-%BUILD_ID%"

}

}

tags = {

Name = "AFT IAM Validation"

Environment = "management"

}

}

## 静的解析用ビルドスペック

\# buildspecs/static_analysis_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "Installing static analysis tools"

\# TFLintのインストール

\- curl -sSL
"https://github.com/terraform-linters/tflint/releases/download/v\${TFLINT_VERSION}/tflint_linux_amd64.zip"
-o tflint.zip

\- unzip tflint.zip && rm tflint.zip

\- mv tflint /usr/local/bin/

\# tfsecのインストール

\- curl -sSL
"https://github.com/aquasecurity/tfsec/releases/download/v\${TFSEC_VERSION}/tfsec-linux-amd64"
-o /usr/local/bin/tfsec

\- chmod +x /usr/local/bin/tfsec

\# checkovのインストール

\- pip install checkov==\${CHECKOV_VERSION}

pre_build:

commands:

\- echo "Preparing for static analysis"

\- mkdir -p reports

build:

commands:

\- echo "Running static analysis"

\# TFLint実行

\- echo "Running TFLint..."

\- tflint --recursive --format=json \> reports/tflint-results.json \|\|
true

\# tfsec実行

\- echo "Running tfsec..."

\- tfsec . --format=json \> reports/tfsec-results.json \|\| true

\# checkov実行

\- echo "Running checkov..."

\- checkov -d . --output json \> reports/checkov-results.json \|\| true

post_build:

commands:

\- echo "Analyzing results..."

\- python scripts/summarize_analysis.py

\- echo "Static analysis completed"

artifacts:

files:

\- reports/\*\*/\*

\- scripts/summarize_analysis.py

discard-paths: no

reports:

static-analysis-reports:

files:

\- reports/tflint-report.xml

\- reports/tfsec-report.xml

\- reports/checkov-report.xml

file-format: "JUNITXML"

## IAM Access Analyzer用ビルドスペック

\# buildspecs/iam_validation_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

python: 3.9

commands:

\- echo "Installing tools for IAM validation"

\- pip install boto3

pre_build:

commands:

\- echo "Preparing for IAM validation"

\- mkdir -p reports

build:

commands:

\- echo "Extracting IAM policies from Terraform code..."

\- python scripts/extract_iam_policies.py

\- echo "Validating IAM policies with Access Analyzer..."

\- python scripts/validate_iam_policies.py

post_build:

commands:

\- echo "Analyzing results..."

\- python scripts/summarize_iam_findings.py

\- echo "IAM validation completed"

artifacts:

files:

\- reports/\*\*/\*

\- scripts/summarize_iam_findings.py

discard-paths: no

reports:

iam-validation-reports:

files:

\- reports/iam-findings.json

file-format: "JSON"

## 静的解析結果サマリー生成スクリプト

\# scripts/summarize_analysis.py

import json

import sys

import os

def parse_tflint_results():

try:

with open('reports/tflint-results.json', 'r') as f:

data = json.load(f)

issues = data.get('issues', \[\])

by_severity = {}

for issue in issues:

severity = issue.get('rule', {}).get('severity', 'unknown')

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(issues),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing TFLint results: {e}")

return {'total': 0, 'by_severity': {}}

def parse_tfsec_results():

try:

with open('reports/tfsec-results.json', 'r') as f:

data = json.load(f)

results = data.get('results', \[\])

by_severity = {}

for result in results:

severity = result.get('severity', 'UNKNOWN').upper()

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(results),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing tfsec results: {e}")

return {'total': 0, 'by_severity': {}}

def parse_checkov_results():

try:

with open('reports/checkov-results.json', 'r') as f:

data = json.load(f)

failed_checks = data.get('results', {}).get('failed_checks', \[\])

by_severity = {}

for check in failed_checks:

severity = check.get('severity', 'UNKNOWN').upper()

if severity not in by_severity:

by_severity\[severity\] = 0

by_severity\[severity\] += 1

return {

'total': len(failed_checks),

'by_severity': by_severity

}

except Exception as e:

print(f"Error parsing checkov results: {e}")

return {'total': 0, 'by_severity': {}}

def generate_summary():

tflint_results = parse_tflint_results()

tfsec_results = parse_tfsec_results()

checkov_results = parse_checkov_results()

total_issues = tflint_results\['total'\] + tfsec_results\['total'\] +
checkov_results\['total'\]

critical_issues = (

tflint_results\['by_severity'\].get('error', 0) +

tfsec_results\['by_severity'\].get('HIGH', 0) +

tfsec_results\['by_severity'\].get('CRITICAL', 0) +

checkov_results\['by_severity'\].get('HIGH', 0) +

checkov_results\['by_severity'\].get('CRITICAL', 0)

)

summary = {

'total_issues': total_issues,

'critical_issues': critical_issues,

'tool_summaries': {

'tflint': tflint_results,

'tfsec': tfsec_results,

'checkov': checkov_results

}

}

\# サマリーをJSONとして保存

with open('reports/analysis-summary.json', 'w') as f:

json.dump(summary, f, indent=2)

\# 人間が読める形式でコンソールに出力

print("===== STATIC ANALYSIS SUMMARY =====")

print(f"Total issues found: {total_issues}")

print(f"Critical issues found: {critical_issues}")

print("\nTFLint results:")

print(f" Total issues: {tflint_results\['total'\]}")

for severity, count in tflint_results\['by_severity'\].items():

print(f" {severity}: {count}")

print("\ntfsec results:")

print(f" Total issues: {tfsec_results\['total'\]}")

for severity, count in tfsec_results\['by_severity'\].items():

print(f" {severity}: {count}")

print("\ncheckov results:")

print(f" Total issues: {checkov_results\['total'\]}")

for severity, count in checkov_results\['by_severity'\].items():

print(f" {severity}: {count}")

\# 本番環境で重大な問題が見つかった場合はビルドを失敗させる

if critical_issues \> 0 and os.environ.get('DEPLOYMENT_ENV', '').lower()
== 'prod':

print("\nCRITICAL ISSUES FOUND IN PRODUCTION ENVIRONMENT!")

print("Please review and fix these issues before proceeding.")

sys.exit(1)

return summary

if \_\_name\_\_ == "\_\_main\_\_":

generate_summary()

## IAMポリシー検証スクリプト

\# scripts/validate_iam_policies.py

import json

import boto3

import os

import glob

def extract_iam_policies():

"""

Terraformファイルから抽出されたIAMポリシーを読み込む

"""

policies = \[\]

\# ポリシーファイルを探索

policy_files = glob.glob('extracted_policies/\*.json')

for filename in policy_files:

with open(filename, 'r') as f:

try:

policy_data = json.load(f)

policy_name = os.path.basename(filename).replace('.json', '')

policies.append((policy_name, policy_data))

except json.JSONDecodeError:

print(f"Warning: Failed to parse {filename} as JSON")

return policies

def validate_with_access_analyzer(policies):

"""

IAM Access Analyzerを使用してポリシーを検証

"""

client = boto3.client('accessanalyzer')

findings = \[\]

for policy_name, policy_doc in policies:

try:

print(f"Validating policy: {policy_name}")

response = client.validate_policy(

policyDocument=json.dumps(policy_doc),

policyType='IDENTITY_POLICY'

)

if 'findings' in response:

for finding in response\['findings'\]:

finding\['policyName'\] = policy_name

findings.append(finding)

except Exception as e:

print(f"Error validating policy {policy_name}: {e}")

findings.append({

'policyName': policy_name,

'findingType': 'ERROR',

'findingDetails': str(e),

'locations': \[\]

})

return findings

def summarize_findings(findings):

"""

検出結果をサマリー化して保存

"""

\# 重要度別の分類

by_severity = {}

for finding in findings:

finding_type = finding.get('findingType', 'UNKNOWN')

if finding_type not in by_severity:

by_severity\[finding_type\] = 0

by_severity\[finding_type\] += 1

\# サマリーの作成

summary = {

'total_findings': len(findings),

'by_severity': by_severity,

'findings': findings

}

\# 結果をJSONとして保存

os.makedirs('reports', exist_ok=True)

with open('reports/iam-findings.json', 'w') as f:

json.dump(summary, f, indent=2)

\# コンソールにサマリーを出力

print("\n===== IAM POLICY VALIDATION SUMMARY =====")

print(f"Total findings: {len(findings)}")

for severity, count in by_severity.items():

print(f"{severity}: {count}")

\# 重大な問題があるか確認

critical_findings = sum(\[

count for severity, count in by_severity.items()

if severity in \['ERROR', 'SECURITY_WARNING'\]

\])

if critical_findings \> 0:

print(f"\nWarning: {critical_findings} critical findings detected!")

\# 本番環境の場合は失敗

if os.environ.get('DEPLOYMENT_ENV', '').lower() == 'prod':

print("CRITICAL ISSUES FOUND IN PRODUCTION ENVIRONMENT!")

return False

return True

def main():

policies = extract_iam_policies()

print(f"Found {len(policies)} IAM policies to validate")

findings = validate_with_access_analyzer(policies)

success = summarize_findings(findings)

if not success:

exit(1)

if \_\_name\_\_ == "\_\_main\_\_":

main()

## マルチリージョン対応のECS Fargateクラスター設定

\# ecs/fargate.tf

\# 東京リージョンのECSクラスター

resource "aws_ecs_cluster" "tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}"

setting {

name = "containerInsights"

value = var.environment == "prod" \|\| var.environment == "staging" ?
"enabled" : "disabled"

}

tags = local.tokyo_tags

}

\# 大阪リージョンのECSクラスター（本番環境のDR用）

resource "aws_ecs_cluster" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

setting {

name = "containerInsights"

value = "enabled"

}

tags = local.osaka_tags

}

\# CloudWatch Logs用のロググループ（東京）

resource "aws_cloudwatch_log_group" "ecs_logs_tokyo" {

provider = aws.tokyo

name = "/ecs/\${var.application}-\${var.environment}"

retention_in_days = var.environment == "prod" ? 30 : 7

tags = local.tokyo_tags

}

\# CloudWatch Logs用のロググループ（大阪）

resource "aws_cloudwatch_log_group" "ecs_logs_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "/ecs/\${var.application}-\${var.environment}"

retention_in_days = 30

tags = local.osaka_tags

}

\# ECSタスク実行ロールの定義

resource "aws_iam_role" "ecs_task_execution_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-execution-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# ECSタスク実行ロールとポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"ecs_task_execution_role_policy" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_execution_role.name

policy_arn =
"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"

}

\# ECSタスクロールの定義（アプリケーション権限用）

resource "aws_iam_role" "ecs_task_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-task-role"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ecs-tasks.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# 東京リージョンのAuroraアクセス用ポリシー

resource "aws_iam_policy" "aurora_access_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-aurora-access"

description = "Allow ECS tasks to connect to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource =
"arn:aws:rds-db:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${var.db_cluster_resource_id}/\${var.application}"

}\]

})

tags = local.tokyo_tags

}

\# 大阪リージョンのAuroraアクセス用ポリシー（DR用）

resource "aws_iam_policy" "aurora_access_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-aurora-access"

description = "Allow ECS tasks to connect to Aurora using IAM auth"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = "rds-db:connect"

Resource =
"arn:aws:rds-db:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${var.db_cluster_resource_id_osaka}/\${var.application}"

}\]

})

tags = local.osaka_tags

}

\# タスクロールとAuroraアクセスポリシーのアタッチ

resource "aws_iam_role_policy_attachment" "task_role_aurora_access" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_role.name

policy_arn = aws_iam_policy.aurora_access_tokyo.arn

}

\# Secrets Manager アクセスポリシー

resource "aws_iam_policy" "secrets_access" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-secrets-access"

description = "Allow access to Secrets Manager for retrieving database
credentials"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Effect = "Allow"

Action = \[

"secretsmanager:GetSecretValue",

"kms:Decrypt"

\]

Resource = \[

var.db_secrets_arn,

var.kms_key_arn

\]

}\]

})

tags = local.tokyo_tags

}

\# タスク実行ロールへのシークレットアクセス権限付与

resource "aws_iam_role_policy_attachment"
"execution_role_secrets_access" {

provider = aws.tokyo

role = aws_iam_role.ecs_task_execution_role.name

policy_arn = aws_iam_policy.secrets_access.arn

}

\# サービスディスカバリのネームスペース（東京）

resource "aws_service_discovery_private_dns_namespace" "tokyo" {

provider = aws.tokyo

name = "\${var.environment}.\${var.application}.local"

vpc = var.vpc_id_tokyo

tags = local.tokyo_tags

}

\# サービスディスカバリのネームスペース（大阪）

resource "aws_service_discovery_private_dns_namespace" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.environment}.\${var.application}.local"

vpc = var.vpc_id_osaka

tags = local.osaka_tags

}

## マルチリージョン対応のECRリポジトリ設定

\# ecr/repositories.tf

\# 東京リージョンのECRリポジトリ

resource "aws_ecr_repository" "tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

encryption_configuration {

encryption_type = "KMS"

kms_key = var.kms_key_arn_tokyo

}

tags = local.tokyo_tags

}

\# 大阪リージョンのレプリケーションリポジトリ（本番環境のDR用）

resource "aws_ecr_repository" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}"

image_tag_mutability = "IMMUTABLE"

image_scanning_configuration {

scan_on_push = true

}

encryption_configuration {

encryption_type = "KMS"

kms_key = var.kms_key_arn_osaka

}

tags = local.osaka_tags

}

\# ECRのライフサイクルポリシー（東京）

resource "aws_ecr_lifecycle_policy" "tokyo" {

provider = aws.tokyo

repository = aws_ecr_repository.tokyo.name

policy = jsonencode({

rules = \[

{

rulePriority = 1,

description = "Keep only the last 10 untagged images",

selection = {

tagStatus = "untagged",

countType = "imageCountMoreThan",

countNumber = 10

},

action = {

type = "expire"

}

},

{

rulePriority = 2,

description = "Keep only the last 100 tagged non-prod images",

selection = {

tagStatus = "tagged",

tagPatternList = \["v\*", "dev-\*", "test-\*"\],

countType = "imageCountMoreThan",

countNumber = 100

},

action = {

type = "expire"

}

},

{

rulePriority = 3,

description = "Keep all production images",

selection = {

tagStatus = "tagged",

tagPatternList = \["prod-\*", "stable-\*"\],

countType = "imageCountMoreThan",

countNumber = 10000 \# 実質的に全て保持

},

action = {

type = "expire"

}

}

\]

})

}

\# ECRのライフサイクルポリシー（大阪）

resource "aws_ecr_lifecycle_policy" "osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

repository = aws_ecr_repository.osaka\[0\].name

policy = jsonencode({

rules = \[

{

rulePriority = 1,

description = "Keep only the last 10 untagged images",

selection = {

tagStatus = "untagged",

countType = "imageCountMoreThan",

countNumber = 10

},

action = {

type = "expire"

}

},

{

rulePriority = 2,

description = "Keep only the latest production images",

selection = {

tagStatus = "tagged",

tagPatternList = \["prod-\*", "stable-\*"\],

countType = "imageCountMoreThan",

countNumber = 20

},

action = {

type = "expire"

}

}

\]

})

}

\# クロスリージョンレプリケーション（本番環境のみ）

resource "aws_ecr_replication_configuration" "this" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

replication_configuration {

rule {

destination {

region = var.secondary_region

registry_id = data.aws_caller_identity.current.account_id

}

}

}

}

\# ECRイメージ脆弱性通知用のSNSトピック（東京）

resource "aws_sns_topic" "vulnerability_notification_tokyo" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-vulnerability-notification"

tags = local.tokyo_tags

}

\# ECRイメージ脆弱性通知用のSNSトピック（大阪）

resource "aws_sns_topic" "vulnerability_notification_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name =
"\${var.application}-\${var.environment}-vulnerability-notification"

tags = local.osaka_tags

}

\# ECRイベントルール - 脆弱性スキャン結果検出（東京）

resource "aws_cloudwatch_event_rule" "ecr_scan_findings_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-ecr-scan-findings"

description = "Capture ECR image scan findings for critical
vulnerabilities"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[aws_ecr_repository.tokyo.name\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = local.tokyo_tags

}

\# ECRイベントルール - SNSターゲット（東京）

resource "aws_cloudwatch_event_target" "ecr_scan_findings_to_sns_tokyo"
{

provider = aws.tokyo

rule = aws_cloudwatch_event_rule.ecr_scan_findings_tokyo.name

target_id = "SendToSNS"

arn = aws_sns_topic.vulnerability_notification_tokyo.arn

}

\# ECRイベントルール - 脆弱性スキャン結果検出（大阪）

resource "aws_cloudwatch_event_rule" "ecr_scan_findings_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-ecr-scan-findings"

description = "Capture ECR image scan findings for critical
vulnerabilities"

event_pattern = jsonencode({

source = \["aws.ecr"\],

detail-type = \["ECR Image Scan"\],

detail = {

repository-name = \[aws_ecr_repository.osaka\[0\].name\],

finding-severity-counts = {

CRITICAL = \[{

exists = true

}\],

HIGH = \[{

exists = true

}\]

}

}

})

tags = local.osaka_tags

}

\# ECRイベントルール - SNSターゲット（大阪）

resource "aws_cloudwatch_event_target" "ecr_scan_findings_to_sns_osaka"
{

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

rule = aws_cloudwatch_event_rule.ecr_scan_findings_osaka\[0\].name

target_id = "SendToSNS"

arn = aws_sns_topic.vulnerability_notification_osaka\[0\].arn

}

## 東京-大阪間のDR設定とフェイルオーバー自動化

\# dr/failover.tf

\# Aurora Global Database（本番環境のみ）

resource "aws_rds_global_cluster" "global" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

global_cluster_identifier =
"\${var.application}-\${var.environment}-global"

engine = "aurora-mysql"

engine_version = "8.0.mysql_aurora.3.02.0"

database_name = replace("\${var.application}\_\${var.environment}", "-",
"\_")

deletion_protection = true

tags = local.tokyo_tags

}

\# Route 53 ヘルスチェック（東京リージョン）

resource "aws_route53_health_check" "primary_region" {

provider = aws.tokyo

fqdn = var.api_endpoint_tokyo

port = 443

type = "HTTPS"

resource_path = "/health"

failure_threshold = 3

request_interval = 30

tags = merge(local.tokyo_tags, {

Name = "Primary Region Health Check"

})

}

\# フェイルオーバールーティングポリシー用のRoute 53レコード

resource "aws_route53_record" "api" {

provider = aws.tokyo

zone_id = var.route53_zone_id

name = "api.\${var.application}.\${var.domain_name}"

type = "CNAME"

ttl = 60

failover_routing_policy {

type = "PRIMARY"

}

set_identifier = "primary"

records = \[var.api_endpoint_tokyo\]

health_check_id = aws_route53_health_check.primary_region.id

}

\# DR用のRoute 53レコード（本番環境のみ）

resource "aws_route53_record" "api_dr" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

zone_id = var.route53_zone_id

name = "api.\${var.application}.\${var.domain_name}"

type = "CNAME"

ttl = 60

failover_routing_policy {

type = "SECONDARY"

}

set_identifier = "secondary"

records = \[var.api_endpoint_osaka\]

}

\# フェイルオーバー検知Lambda関数

resource "aws_lambda_function" "failover_detection" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

function_name =
"\${var.application}-\${var.environment}-failover-detection"

role = aws_iam_role.failover_lambda_role\[0\].arn

runtime = "nodejs14.x"

handler = "index.handler"

timeout = 60

memory_size = 128

filename = "lambda/failover-detection.zip"

environment {

variables = {

PRIMARY_REGION = var.primary_region

DR_REGION = var.secondary_region

SNS_TOPIC_ARN = aws_sns_topic.failover_notification\[0\].arn

APPLICATION = var.application

ENVIRONMENT = var.environment

}

}

tags = local.tokyo_tags

}

\# フェイルオーバー検知Lambda用のIAMロール

resource "aws_iam_role" "failover_lambda_role" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-lambda-role"

description = "Role for failover detection Lambda function"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "lambda.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# フェイルオーバー検知用のCloudWatch Events Rule

resource "aws_cloudwatch_event_rule" "route53_health_check_state_change"
{

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name =
"\${var.application}-\${var.environment}-health-check-state-change"

description = "Capture Route 53 health check state changes"

event_pattern = jsonencode({

source = \["aws.route53"\],

detail-type = \["AWS Health Event"\],

detail = {

service = \["ROUTE53"\],

eventTypeCategory = \["issue"\],

healthCheckId = \[aws_route53_health_check.primary_region.id\]

}

})

tags = local.tokyo_tags

}

\# フェイルオーバー通知用のSNSトピック

resource "aws_sns_topic" "failover_notification" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-notification"

tags = local.tokyo_tags

}

\# CloudWatch Events RuleとLambdaの連携

resource "aws_cloudwatch_event_target" "failover_lambda" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

rule =
aws_cloudwatch_event_rule.route53_health_check_state_change\[0\].name

target_id = "InvokeLambda"

arn = aws_lambda_function.failover_detection\[0\].arn

}

\# Lambda関数の実行権限

resource "aws_lambda_permission" "allow_cloudwatch" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

statement_id = "AllowExecutionFromCloudWatch"

action = "lambda:InvokeFunction"

function_name =
aws_lambda_function.failover_detection\[0\].function_name

principal = "events.amazonaws.com"

source_arn =
aws_cloudwatch_event_rule.route53_health_check_state_change\[0\].arn

}

\# フェイルオーバー検知Lambda用のポリシー

resource "aws_iam_policy" "failover_lambda_policy" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-failover-lambda-policy"

description = "Policy for failover detection Lambda function"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource = "arn:aws:logs:\*:\*:\*"

},

{

Action = \[

"sns:Publish"

\],

Effect = "Allow",

Resource = aws_sns_topic.failover_notification\[0\].arn

},

{

Action = \[

"route53:GetHealthCheck",

"route53:GetHealthCheckStatus"

\],

Effect = "Allow",

Resource = "\*"

}

\]

})

tags = local.tokyo_tags

}

\# フェイルオーバーLambda用ポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"failover_lambda_policy_attachment" {

provider = aws.tokyo

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

role = aws_iam_role.failover_lambda_role\[0\].name

policy_arn = aws_iam_policy.failover_lambda_policy\[0\].arn

}

## フェイルオーバー検知Lambdaの実装（コード例）

// lambda/index.js - フェイルオーバー検知Lambda

const AWS = require('aws-sdk');

const sns = new AWS.SNS();

const route53 = new AWS.Route53();

exports.handler = async (event) =\> {

console.log('Received event:', JSON.stringify(event, null, 2));

const primaryRegion = process.env.PRIMARY_REGION;

const drRegion = process.env.DR_REGION;

const snsTopicArn = process.env.SNS_TOPIC_ARN;

const application = process.env.APPLICATION;

const environment = process.env.ENVIRONMENT;

try {

// ヘルスチェックの状態を確認

const healthCheckId = event.detail.healthCheckId;

const healthCheckResponse = await route53.getHealthCheck({

HealthCheckId: healthCheckId

}).promise();

const healthCheckStatusResponse = await route53.getHealthCheckStatus({

HealthCheckId: healthCheckId

}).promise();

const healthCheckConfig =
healthCheckResponse.HealthCheck.HealthCheckConfig;

const healthCheckStatus =
healthCheckStatusResponse.HealthCheckObservations;

// 障害状態の確認

const failingObservations = healthCheckStatus.filter(obs =\>
obs.StatusReport.Status !== 'Success');

const failureRate = failingObservations.length /
healthCheckStatus.length;

// メッセージの構築

let message = \`Health check for \${application}-\${environment} is
experiencing issues.\n\n\`;

message += \`Primary Region: \${primaryRegion}\n\`;

message += \`DR Region: \${drRegion}\n\`;

message += \`Health Check:
\${healthCheckConfig.FullyQualifiedDomainName}\${healthCheckConfig.ResourcePath}\n\`;

message += \`Failure Rate: \${Math.round(failureRate \* 100)}%\n\n\`;

if (failureRate \> 0.5) {

message += \`ALERT: High failure rate detected. Route 53 may initiate
failover to the DR region (\${drRegion}).\n\`;

message += 'Please check the primary region infrastructure and
services.\n\n';

message += 'Actions to take:\n';

message += '1. Verify primary region services status\n';

message += '2. Check CloudWatch metrics and logs for errors\n';

message += '3. Confirm DR region is ready to handle traffic\n';

message += '4. Monitor the failover process\n';

} else {

message += 'Some observations are failing but the overall health check
is still passing.\n';

message += 'Monitor the situation closely for potential degradation.\n';

}

// SNS通知の送信

await sns.publish({

TopicArn: snsTopicArn,

Subject: \`\[\${environment.toUpperCase()}\] \${application} Health
Check Alert\`,

Message: message

}).promise();

return {

statusCode: 200,

body: JSON.stringify({

message: 'Notification sent successfully',

healthCheckId: healthCheckId,

failureRate: failureRate

})

};

} catch (error) {

console.error('Error:', error);

// エラー通知

await sns.publish({

TopicArn: snsTopicArn,

Subject: \`\[\${environment.toUpperCase()}\] \${application} Failover
Detection Error\`,

Message: \`Error in failover detection Lambda: \${error.message}\`

}).promise();

throw error;

}

};

## 環境タグ付けとCI/CDパイプラインでの自動タグ付け

\# buildspecs/build_deploy_buildspec.yml

version: 0.2

phases:

install:

runtime-versions:

nodejs: 14

commands:

\- echo "Installing dependencies..."

\- npm install -g aws-cdk

pre_build:

commands:

\- echo "Setting up environment tags..."

\- \|

\# 環境タグの設定

case "\${DEPLOYMENT_ENV}" in

"dev")

export AWS_TAG_ENVIRONMENT="dev"

export AWS_TAG_BACKUP="weekly"

export AWS_TAG_AUTOSCALING="business-hours"

;;

"test")

export AWS_TAG_ENVIRONMENT="test"

export AWS_TAG_BACKUP="weekly"

export AWS_TAG_AUTOSCALING="business-hours"

;;

"staging")

export AWS_TAG_ENVIRONMENT="staging"

export AWS_TAG_BACKUP="daily"

export AWS_TAG_AUTOSCALING="always-on"

;;

"prod")

export AWS_TAG_ENVIRONMENT="prod"

export AWS_TAG_BACKUP="daily"

export AWS_TAG_AUTOSCALING="always-on"

export AWS_TAG_DR_ENABLED="true"

;;

\*)

echo "Unknown environment: \${DEPLOYMENT_ENV}"

exit 1

;;

esac

\- echo "Environment tags set for \${DEPLOYMENT_ENV}"

build:

commands:

\- echo "Building the application..."

\- npm run build

\# コンテナイメージのビルド

\- echo "Building the Docker image..."

\- aws ecr get-login-password --region \${AWS_DEFAULT_REGION} \| docker
login --username AWS --password-stdin
\${AWS_ACCOUNT_ID}.dkr.ecr.\${AWS_DEFAULT_REGION}.amazonaws.com

\- docker build -t
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION} .

\# イメージタグにバージョンと環境タグを付与

\- COMMIT_HASH=\$(echo \$CODEBUILD_RESOLVED_SOURCE_VERSION \| cut -c
1-7)

\- VERSION=\$(jq -r '.version' package.json)

\- echo "Tagging image with version \${VERSION}, commit \${COMMIT_HASH},
and environment \${AWS_TAG_ENVIRONMENT}"

\- docker tag
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}

\- docker tag
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:\${AWS_TAG_ENVIRONMENT}-\${VERSION}

\# 本番環境の場合は安定版タグも付与

\- \|

if \[ "\${DEPLOYMENT_ENV}" = "prod" \]; then

echo "Adding stable tag for production release"

docker tag \${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:stable-\${VERSION}

docker tag \${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}
\${ECR_REPOSITORY_URI}:latest

fi

\# イメージのプッシュ

\- echo "Pushing the Docker image..."

\- docker push
\${ECR_REPOSITORY_URI}:\${CODEBUILD_RESOLVED_SOURCE_VERSION}

\- docker push \${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}

\- docker push
\${ECR_REPOSITORY_URI}:\${AWS_TAG_ENVIRONMENT}-\${VERSION}

\- \|

if \[ "\${DEPLOYMENT_ENV}" = "prod" \]; then

docker push \${ECR_REPOSITORY_URI}:stable-\${VERSION}

docker push \${ECR_REPOSITORY_URI}:latest

fi

\# ECSタスク定義の更新

\- echo "Updating ECS task definition..."

\- aws ecs describe-task-definition --task-definition
\${ECS_TASK_DEFINITION} --region \${AWS_DEFAULT_REGION} \>
task-definition.json

\- jq '.taskDefinition \| .containerDefinitions\[0\].image =
"'\${ECR_REPOSITORY_URI}':'\${VERSION}'-'\${COMMIT_HASH}'"'
task-definition.json \> container-definition.json

\- TASK_DEF_ARN=\$(aws ecs register-task-definition --family
\${ECS_TASK_DEFINITION} --container-definitions
file://container-definition.json --task-role-arn \${ECS_TASK_ROLE_ARN}
--execution-role-arn \${ECS_EXECUTION_ROLE_ARN} --network-mode awsvpc
--requires-compatibilities FARGATE --cpu \${ECS_TASK_CPU} --memory
\${ECS_TASK_MEMORY} --tags Key=Environment,Value=\${AWS_TAG_ENVIRONMENT}
Key=Application,Value=\${APPLICATION_NAME} Key=Team,Value=\${TEAM_NAME}
Key=CostCenter,Value=\${COST_CENTER} --region \${AWS_DEFAULT_REGION} \|
jq -r '.taskDefinition.taskDefinitionArn')

\# ECSサービスの更新

\- echo "Updating the ECS service..."

\- aws ecs update-service --cluster \${ECS_CLUSTER} --service
\${ECS_SERVICE} --task-definition \${TASK_DEF_ARN} --region
\${AWS_DEFAULT_REGION}

post_build:

commands:

\- echo "Build completed on \$(date)"

\- echo "Saving metadata for testing phase..."

\- echo
"{\\ImageURI\\:\\\${ECR_REPOSITORY_URI}:\${VERSION}-\${COMMIT_HASH}\\,\\TaskDefinitionArn\\:\\\${TASK_DEF_ARN}\\,\\Environment\\:\\\${AWS_TAG_ENVIRONMENT}\\}"
\> build-metadata.json

artifacts:

files:

\- build-metadata.json

\- task-definition.json

\- container-definition.json

\- appspec.yaml

discard-paths: yes

## マルチリージョン対応のFlywayデータベースマイグレーション設定

\# database/flyway.tf

\# FlywayマイグレーションのCodeBuildプロジェクト（東京）

resource "aws_codebuild_project" "flyway_migration_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-migration"

description = "Flyway database migration for \${var.application} in
\${var.environment} environment"

service_role = aws_iam_role.flyway_codebuild_role.arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "DB_ENDPOINT"

value = aws_rds_cluster.aurora_tokyo.endpoint

}

environment_variable {

name = "DB_NAME"

value = aws_rds_cluster.aurora_tokyo.database_name

}

environment_variable {

name = "DB_SECRET_ARN"

value = var.db_secrets_arn

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

environment_variable {

name = "REGION"

value = var.primary_region

}

}

source {

type = "GITHUB"

location = var.flyway_repository_url

buildspec = "buildspec-flyway.yml"

git_clone_depth = 1

git_submodules_config {

fetch_submodules = true

}

}

logs_config {

cloudwatch_logs {

group_name =
"/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration"

stream_name = "tokyo"

}

}

tags = local.tokyo_tags

}

\# FlywayマイグレーションのCodeBuildプロジェクト（大阪）

resource "aws_codebuild_project" "flyway_migration_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-migration"

description = "Flyway database migration for \${var.application} in
\${var.environment} environment (DR region)"

service_role = aws_iam_role.flyway_codebuild_role_osaka\[0\].arn

artifacts {

type = "NO_ARTIFACTS"

}

environment {

type = "LINUX_CONTAINER"

compute_type = "BUILD_GENERAL1_SMALL"

image = "aws/codebuild/amazonlinux2-x86_64-standard:3.0"

privileged_mode = false

image_pull_credentials_type = "CODEBUILD"

environment_variable {

name = "DB_ENDPOINT"

value = aws_rds_cluster.aurora_osaka\[0\].endpoint

}

environment_variable {

name = "DB_NAME"

value = aws_rds_cluster.aurora_osaka\[0\].database_name

}

environment_variable {

name = "DB_SECRET_ARN"

value = var.db_secrets_arn_osaka

}

environment_variable {

name = "ENVIRONMENT"

value = var.environment

}

environment_variable {

name = "REGION"

value = var.secondary_region

}

}

source {

type = "GITHUB"

location = var.flyway_repository_url

buildspec = "buildspec-flyway.yml"

git_clone_depth = 1

git_submodules_config {

fetch_submodules = true

}

}

logs_config {

cloudwatch_logs {

group_name =
"/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration"

stream_name = "osaka"

}

}

tags = local.osaka_tags

}

\# Flyway CodeBuild用IAMロール（東京）

resource "aws_iam_role" "flyway_codebuild_role" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-codebuild-role"

description = "Role for Flyway migration CodeBuild project"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codebuild.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# Flyway CodeBuild用IAMロール（大阪）

resource "aws_iam_role" "flyway_codebuild_role_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-codebuild-role"

description = "Role for Flyway migration CodeBuild project (DR region)"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "codebuild.amazonaws.com"

}

}\]

})

tags = local.osaka_tags

}

\# Flyway用IAMポリシー（東京）

resource "aws_iam_policy" "flyway_policy" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-flyway-policy"

description = "Policy for Flyway migration CodeBuild project"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource =
"arn:aws:logs:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:log-group:/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration:\*"

},

{

Action = \[

"secretsmanager:GetSecretValue"

\],

Effect = "Allow",

Resource = var.db_secrets_arn

},

{

Action = \[

"rds-db:connect"

\],

Effect = "Allow",

Resource =
"arn:aws:rds-db:\${var.primary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${aws_rds_cluster.aurora_tokyo.cluster_resource_id}/\*"

},

{

Action = \[

"s3:GetObject",

"s3:PutObject",

"s3:ListBucket"

\],

Effect = "Allow",

Resource = \[

"\${aws_s3_bucket.flyway_migrations.arn}",

"\${aws_s3_bucket.flyway_migrations.arn}/\*"

\]

}

\]

})

tags = local.tokyo_tags

}

\# Flyway用IAMポリシー（大阪）

resource "aws_iam_policy" "flyway_policy_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-flyway-policy"

description = "Policy for Flyway migration CodeBuild project (DR
region)"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents"

\],

Effect = "Allow",

Resource =
"arn:aws:logs:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:log-group:/aws/codebuild/\${var.application}-\${var.environment}-flyway-migration:\*"

},

{

Action = \[

"secretsmanager:GetSecretValue"

\],

Effect = "Allow",

Resource = var.db_secrets_arn_osaka

},

{

Action = \[

"rds-db:connect"

\],

Effect = "Allow",

Resource =
"arn:aws:rds-db:\${var.secondary_region}:\${data.aws_caller_identity.current.account_id}:dbuser:\${aws_rds_cluster.aurora_osaka\[0\].cluster_resource_id}/\*"

},

{

Action = \[

"s3:GetObject",

"s3:PutObject",

"s3:ListBucket"

\],

Effect = "Allow",

Resource = \[

"\${aws_s3_bucket.flyway_migrations.arn}",

"\${aws_s3_bucket.flyway_migrations.arn}/\*"

\]

}

\]

})

tags = local.osaka_tags

}

\# ポリシーのアタッチ（東京）

resource "aws_iam_role_policy_attachment" "flyway_policy_attachment" {

provider = aws.tokyo

role = aws_iam_role.flyway_codebuild_role.name

policy_arn = aws_iam_policy.flyway_policy.arn

}

\# ポリシーのアタッチ（大阪）

resource "aws_iam_role_policy_attachment"
"flyway_policy_attachment_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

role = aws_iam_role.flyway_codebuild_role_osaka\[0\].name

policy_arn = aws_iam_policy.flyway_policy_osaka\[0\].arn

}

\# Flywayマイグレーションスクリプト用S3バケット

resource "aws_s3_bucket" "flyway_migrations" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-flyway-migrations-\${data.aws_caller_identity.current.account_id}"

tags = local.tokyo_tags

}

\# S3バケットバージョニング

resource "aws_s3_bucket_versioning" "flyway_migrations_versioning" {

provider = aws.tokyo

bucket = aws_s3_bucket.flyway_migrations.id

versioning_configuration {

status = "Enabled"

}

}

\# S3バケット暗号化

resource "aws_s3_bucket_server_side_encryption_configuration"
"flyway_migrations_encryption" {

provider = aws.tokyo

bucket = aws_s3_bucket.flyway_migrations.id

rule {

apply_server_side_encryption_by_default {

sse_algorithm = "AES256"

}

}

}

\# マイグレーション実行用CloudWatchイベントルール

resource "aws_cloudwatch_event_rule" "flyway_migration_schedule" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-flyway-migration-schedule"

description = "Schedule for automatic database migrations"

schedule_expression = var.environment == "prod" ? "cron(0 20 ? \* SUN
\*)" : "cron(0 20 ? \* MON-FRI \*)"

tags = local.tokyo_tags

}

\# CloudWatchイベントターゲット

resource "aws_cloudwatch_event_target" "flyway_migration_target" {

provider = aws.tokyo

rule = aws_cloudwatch_event_rule.flyway_migration_schedule.name

target_id = "RunFlywayMigration"

arn = aws_codebuild_project.flyway_migration_tokyo.arn

role_arn = aws_iam_role.events_to_codebuild_role.arn

}

\# イベントからCodeBuildを実行するためのロール

resource "aws_iam_role" "events_to_codebuild_role" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-events-to-codebuild-role"

description = "Role for CloudWatch Events to start CodeBuild project"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "events.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# イベントからCodeBuildを実行するためのポリシー

resource "aws_iam_policy" "events_to_codebuild_policy" {

provider = aws.tokyo

name =
"\${var.application}-\${var.environment}-events-to-codebuild-policy"

description = "Policy for CloudWatch Events to start CodeBuild project"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "codebuild:StartBuild"

Effect = "Allow"

Resource = aws_codebuild_project.flyway_migration_tokyo.arn

}\]

})

tags = local.tokyo_tags

}

\# ポリシーのアタッチ

resource "aws_iam_role_policy_attachment"
"events_to_codebuild_policy_attachment" {

provider = aws.tokyo

role = aws_iam_role.events_to_codebuild_role.name

policy_arn = aws_iam_policy.events_to_codebuild_policy.arn

}

## Flyway用のビルドスペック例

\# buildspec-flyway.yml

version: 0.2

phases:

install:

runtime-versions:

java: corretto11

commands:

\- echo "Installing tools..."

\- yum install -y jq wget unzip

\- wget -qO-
https://repo1.maven.org/maven2/org/flywaydb/flyway-commandline/8.5.0/flyway-commandline-8.5.0-linux-x64.tar.gz
\| tar xvz

\- mv flyway-8.5.0 /opt/flyway

\- ln -s /opt/flyway/flyway /usr/local/bin/flyway

pre_build:

commands:

\- echo "Retrieving database credentials..."

\- DB_CREDS=\$(aws secretsmanager get-secret-value --secret-id
\$DB_SECRET_ARN --region \$REGION --query SecretString --output text)

\- DB_USERNAME=\$(echo \$DB_CREDS \| jq -r .username)

\- DB_PASSWORD=\$(echo \$DB_CREDS \| jq -r .password)

\- echo "Configuring Flyway..."

\- mkdir -p flyway/conf

\- echo "flyway.url=jdbc:mysql://\${DB_ENDPOINT}:3306/\${DB_NAME}" \>
flyway/conf/flyway.conf

\- echo "flyway.user=\${DB_USERNAME}" \>\> flyway/conf/flyway.conf

\- echo "flyway.password=\${DB_PASSWORD}" \>\> flyway/conf/flyway.conf

\- echo "flyway.locations=filesystem:./migrations" \>\>
flyway/conf/flyway.conf

\- echo "flyway.schemas=\${DB_NAME}" \>\> flyway/conf/flyway.conf

\- echo "flyway.baselineOnMigrate=true" \>\> flyway/conf/flyway.conf

\- echo "flyway.validateOnMigrate=true" \>\> flyway/conf/flyway.conf

\- mkdir -p flyway/migrations

\- echo "Downloading migration scripts from S3..."

\- aws s3 sync
s3://\${APPLICATION}-\${ENVIRONMENT}-flyway-migrations-\${AWS_ACCOUNT_ID}/migrations/
flyway/migrations/

build:

commands:

\- echo "Running Flyway migration..."

\- cd flyway

\- flyway info

\# 実行前のバックアップ（本番環境のみ）

\- \|

if \[ "\${ENVIRONMENT}" = "prod" \]; then

echo "Running in production - creating database backup before
migration..."

BACKUP_TIMESTAMP=\$(date +%Y%m%d%H%M%S)

echo "Creating SQL dump..."

\# Backup logic here

echo "Backup completed and stored at \${BACKUP_FILE}"

fi

\# マイグレーション実行

\- echo "Executing migration..."

\- flyway migrate

\# マイグレーション後の検証

\- echo "Verifying migration..."

\- flyway validate

\- flyway info

post_build:

commands:

\- echo "Migration completed at \$(date)"

\- \|

if \[ \$CODEBUILD_BUILD_SUCCEEDING -eq 1 \]; then

MIGRATION_STATUS="SUCCESS"

else

MIGRATION_STATUS="FAILED"

fi

\# 実行結果の通知（SNS）

\- \|

aws sns publish \\

--topic-arn
arn:aws:sns:\${REGION}:\${AWS_ACCOUNT_ID}:\${APPLICATION}-\${ENVIRONMENT}-db-migration-notification
\\

--subject "\[\${ENVIRONMENT}\] \${APPLICATION} Database Migration
\${MIGRATION_STATUS}" \\

--message "Database migration for \${APPLICATION} in \${ENVIRONMENT}
environment completed with status: \${MIGRATION_STATUS}.\n\nRegion:
\${REGION}\nTimestamp: \$(date)\n\nSee CodeBuild logs for details:
https://console.aws.amazon.com/codesuite/codebuild/projects/\${APPLICATION}-\${ENVIRONMENT}-flyway-migration/build/detail?region=\${REGION}"
\\

--region \${REGION}

artifacts:

files:

\- flyway/logs/\*\*/\*

discard-paths: no

## マルチリージョン対応のAFTカスタムベースラインの例

\# aft/custom-baselines/main.tf

\# 東京リージョンのCFnスタック

resource "aws_cloudformation_stack" "baseline_tokyo" {

provider = aws.tokyo

name = "aft-account-baseline"

template_body = file("\${path.module}/templates/baseline.yaml")

parameters = {

Environment = var.environment

Application = var.application

Team = var.team

CostCenter = var.cost_center

Region = "Tokyo"

PrimaryRegion = "true"

}

capabilities = \["CAPABILITY_NAMED_IAM"\]

tags = local.tokyo_tags

}

\# 大阪リージョンのCFnスタック（本番環境のDR用）

resource "aws_cloudformation_stack" "baseline_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "aft-account-baseline"

template_body = file("\${path.module}/templates/baseline.yaml")

parameters = {

Environment = var.environment

Application = var.application

Team = var.team

CostCenter = var.cost_center

Region = "Osaka"

PrimaryRegion = "false"

DREnabled = "true"

}

capabilities = \["CAPABILITY_NAMED_IAM"\]

tags = local.osaka_tags

}

\# セキュリティ通知用SNSトピック（東京）

resource "aws_sns_topic" "security_notifications_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-security-notifications"

tags = local.tokyo_tags

}

\# セキュリティ通知用SNSトピック（大阪）

resource "aws_sns_topic" "security_notifications_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

name = "\${var.application}-\${var.environment}-security-notifications"

tags = local.osaka_tags

}

\# EC2インスタンスプロファイル（共通ベースライン用）

resource "aws_iam_instance_profile" "ec2_baseline_profile" {

provider = aws.tokyo

name = "ec2-baseline-profile-\${var.environment}"

role = aws_iam_role.ec2_baseline_role.name

tags = local.tokyo_tags

}

\# EC2ベースラインロール

resource "aws_iam_role" "ec2_baseline_role" {

provider = aws.tokyo

name = "ec2-baseline-role-\${var.environment}"

description = "Baseline IAM role for EC2 instances"

assume_role_policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = "sts:AssumeRole"

Effect = "Allow"

Principal = {

Service = "ec2.amazonaws.com"

}

}\]

})

tags = local.tokyo_tags

}

\# CloudWatch Logsへのアクセスポリシー

resource "aws_iam_policy" "cloudwatch_logs_access" {

provider = aws.tokyo

name = "cloudwatch-logs-access-\${var.environment}"

description = "Allow writing to CloudWatch Logs"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = \[

"logs:CreateLogGroup",

"logs:CreateLogStream",

"logs:PutLogEvents",

"logs:DescribeLogStreams"

\],

Effect = "Allow",

Resource = "arn:aws:logs:\*:\*:\*"

}\]

})

tags = local.tokyo_tags

}

\# SSMエージェント用ポリシー

resource "aws_iam_policy" "ssm_access" {

provider = aws.tokyo

name = "ssm-access-\${var.environment}"

description = "Allow SSM agent to communicate with SSM service"

policy = jsonencode({

Version = "2012-10-17"

Statement = \[{

Action = \[

"ssm:DescribeAssociation",

"ssm:GetDeployablePatchSnapshotForInstance",

"ssm:GetDocument",

"ssm:DescribeDocument",

"ssm:GetManifest",

"ssm:GetParameter",

"ssm:GetParameters",

"ssm:ListAssociations",

"ssm:ListInstanceAssociations",

"ssm:PutInventory",

"ssm:PutComplianceItems",

"ssm:PutConfigurePackageResult",

"ssm:UpdateAssociationStatus",

"ssm:UpdateInstanceAssociationStatus",

"ssm:UpdateInstanceInformation"

\],

Effect = "Allow",

Resource = "\*"

},

{

Action = \[

"ssmmessages:CreateControlChannel",

"ssmmessages:CreateDataChannel",

"ssmmessages:OpenControlChannel",

"ssmmessages:OpenDataChannel"

\],

Effect = "Allow",

Resource = "\*"

},

{

Action = \[

"ec2messages:AcknowledgeMessage",

"ec2messages:DeleteMessage",

"ec2messages:FailMessage",

"ec2messages:GetEndpoint",

"ec2messages:GetMessages",

"ec2messages:SendReply"

\],

Effect = "Allow",

Resource = "\*"

}\]

})

tags = local.tokyo_tags

}

\# IAMポリシーアタッチメント

resource "aws_iam_role_policy_attachment" "cloudwatch_logs_attachment" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = aws_iam_policy.cloudwatch_logs_access.arn

}

resource "aws_iam_role_policy_attachment" "ssm_attachment" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = aws_iam_policy.ssm_access.arn

}

resource "aws_iam_role_policy_attachment" "ssm_managed_instance_core" {

provider = aws.tokyo

role = aws_iam_role.ec2_baseline_role.name

policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"

}

\# S3アクセスログバケット（東京）

resource "aws_s3_bucket" "access_logs_tokyo" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-access-logs-\${data.aws_caller_identity.current.account_id}-\${var.primary_region}"

tags = local.tokyo_tags

}

\# S3アクセスログバケット（大阪）

resource "aws_s3_bucket" "access_logs_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket =
"\${var.application}-\${var.environment}-access-logs-\${data.aws_caller_identity.current.account_id}-\${var.secondary_region}"

tags = local.osaka_tags

}

\# S3アクセスログバケットポリシー（東京）

resource "aws_s3_bucket_policy" "access_logs_policy_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.access_logs_tokyo.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSLogDeliveryWrite"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:PutObject"

Resource = "\${aws_s3_bucket.access_logs_tokyo.arn}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

},

{

Sid = "AWSLogDeliveryAclCheck"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.access_logs_tokyo.arn

}

\]

})

}

\# S3アクセスログバケットポリシー（大阪）

resource "aws_s3_bucket_policy" "access_logs_policy_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket = aws_s3_bucket.access_logs_osaka\[0\].id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSLogDeliveryWrite"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:PutObject"

Resource = "\${aws_s3_bucket.access_logs_osaka\[0\].arn}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

},

{

Sid = "AWSLogDeliveryAclCheck"

Effect = "Allow"

Principal = { Service = "delivery.logs.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.access_logs_osaka\[0\].arn

}

\]

})

}

\# S3バケットライフサイクルポリシー（東京）

resource "aws_s3_bucket_lifecycle_configuration"
"access_logs_lifecycle_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.access_logs_tokyo.id

rule {

id = "log-expiration"

status = "Enabled"

expiration {

days = var.environment == "prod" ? 365 : 90

}

transition {

days = 30

storage_class = "STANDARD_IA"

}

transition {

days = var.environment == "prod" ? 90 : 60

storage_class = "GLACIER"

}

}

}

\# S3バケットライフサイクルポリシー（大阪）

resource "aws_s3_bucket_lifecycle_configuration"
"access_logs_lifecycle_osaka" {

provider = aws.osaka

count = var.environment == "prod" && var.dr_enabled ? 1 : 0

bucket = aws_s3_bucket.access_logs_osaka\[0\].id

rule {

id = "log-expiration"

status = "Enabled"

expiration {

days = 365

}

transition {

days = 30

storage_class = "STANDARD_IA"

}

transition {

days = 90

storage_class = "GLACIER"

}

}

}

\# CloudTrail設定（東京）

resource "aws_cloudtrail" "baseline_cloudtrail_tokyo" {

provider = aws.tokyo

name = "\${var.application}-\${var.environment}-trail"

s3_bucket_name = aws_s3_bucket.cloudtrail_logs_tokyo.id

include_global_service_events = true

is_multi_region_trail = true

enable_log_file_validation = true

event_selector {

read_write_type = "All"

include_management_events = true

data_resource {

type = "AWS::S3::Object"

values = \["arn:aws:s3:::"\]

}

}

tags = local.tokyo_tags

}

\# CloudTrailログ用S3バケット（東京）

resource "aws_s3_bucket" "cloudtrail_logs_tokyo" {

provider = aws.tokyo

bucket =
"\${var.application}-\${var.environment}-cloudtrail-logs-\${data.aws_caller_identity.current.account_id}"

tags = local.tokyo_tags

}

\# CloudTrailログ用S3バケットポリシー（東京）

resource "aws_s3_bucket_policy" "cloudtrail_logs_policy_tokyo" {

provider = aws.tokyo

bucket = aws_s3_bucket.cloudtrail_logs_tokyo.id

policy = jsonencode({

Version = "2012-10-17"

Statement = \[

{

Sid = "AWSCloudTrailAclCheck"

Effect = "Allow"

Principal = { Service = "cloudtrail.amazonaws.com" }

Action = "s3:GetBucketAcl"

Resource = aws_s3_bucket.cloudtrail_logs_tokyo.arn

},

{

Sid = "AWSCloudTrailWrite"

Effect = "Allow"

Principal = { Service = "cloudtrail.amazonaws.com" }

Action = "s3:PutObject"

Resource =
"\${aws_s3_bucket.cloudtrail_logs_tokyo.arn}/AWSLogs/\${data.aws_caller_identity.current.account_id}/\*"

Condition = {

StringEquals = {

"s3:x-amz-acl" = "bucket-owner-full-control"

}

}

}

\]

})

}

## AFTカスタムベースラインのCloudFormationテンプレート例

\# aft/custom-baselines/templates/baseline.yaml

AWSTemplateFormatVersion: '2010-09-09'

Description: 'AFT Account Baseline Configuration for TechNova
Microservices'

Parameters:

Environment:

Type: String

Description: 'Deployment environment name'

AllowedValues:

\- 'dev'

\- 'test'

\- 'staging'

\- 'prod'

Default: 'dev'

Application:

Type: String

Description: 'Application name'

Team:

Type: String

Description: 'Team name'

CostCenter:

Type: String

Description: 'Cost center code'

Region:

Type: String

Description: 'AWS region name (e.g., Tokyo, Osaka)'

PrimaryRegion:

Type: String

Description: 'Whether this is the primary region (true/false)'

AllowedValues:

\- 'true'

\- 'false'

Default: 'true'

DREnabled:

Type: String

Description: 'Whether DR is enabled for this account (true/false)'

AllowedValues:

\- 'true'

\- 'false'

Default: 'false'

Conditions:

IsProd: !Equals \[ !Ref Environment, 'prod' \]

IsPrimary: !Equals \[ !Ref PrimaryRegion, 'true' \]

IsDREnabled: !Equals \[ !Ref DREnabled, 'true' \]

IsTokyo: !Or \[ !Equals \[ !Ref Region, 'Tokyo' \], !Equals \[ !Ref
Region, 'tokyo' \] \]

IsOsaka: !Or \[ !Equals \[ !Ref Region, 'Osaka' \], !Equals \[ !Ref
Region, 'osaka' \] \]

\# 組み合わせ条件

IsProdPrimary: !And \[ !Condition IsProd, !Condition IsPrimary \]

IsProdDR: !And \[ !Condition IsProd, !Condition IsDREnabled, !Not \[
!Condition IsPrimary \] \]

Resources:

\# セキュリティグループ基本設定 - 内部アクセス用

InternalAccessSecurityGroup:

Type: 'AWS::EC2::SecurityGroup'

Properties:

GroupDescription: 'Internal access security group'

VpcId: !ImportValue 'DefaultVPC'

Tags:

\- Key: Name

Value: !Sub '\${Application}-\${Environment}-internal-sg'

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# CloudWatch Logsロググループ

ApplicationLogGroup:

Type: 'AWS::Logs::LogGroup'

Properties:

LogGroupName: !Sub '/aws/\${Application}/\${Environment}'

RetentionInDays: !If \[ IsProd, 365, 30 \]

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# Config Recorder設定

ConfigRecorder:

Type: 'AWS::Config::ConfigurationRecorder'

Properties:

Name: !Sub '\${Application}-\${Environment}-config-recorder'

RecordingGroup:

AllSupported: true

IncludeGlobalResourceTypes: !Condition IsPrimary

RoleARN: !GetAtt ConfigRole.Arn

\# Config Delivery Channel

ConfigDeliveryChannel:

Type: 'AWS::Config::DeliveryChannel'

Properties:

Name: !Sub '\${Application}-\${Environment}-config-delivery'

ConfigSnapshotDeliveryProperties:

DeliveryFrequency: !If \[ IsProd, 'One_Hour', 'Six_Hours' \]

S3BucketName: !Ref ConfigBucket

S3KeyPrefix: !Ref Application

\# Config用IAMロール

ConfigRole:

Type: 'AWS::IAM::Role'

Properties:

AssumeRolePolicyDocument:

Version: '2012-10-17'

Statement:

\- Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 'sts:AssumeRole'

ManagedPolicyArns:

\- 'arn:aws:iam::aws:policy/service-role/AWS_ConfigRole'

Path: /

\# Config用S3バケット

ConfigBucket:

Type: 'AWS::S3::Bucket'

Properties:

BucketName: !Sub
'\${Application}-\${Environment}-config-\${AWS::AccountId}-\${AWS::Region}'

VersioningConfiguration:

Status: Enabled

BucketEncryption:

ServerSideEncryptionConfiguration:

\- ServerSideEncryptionByDefault:

SSEAlgorithm: AES256

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# Config用バケットポリシー

ConfigBucketPolicy:

Type: 'AWS::S3::BucketPolicy'

Properties:

Bucket: !Ref ConfigBucket

PolicyDocument:

Version: '2012-10-17'

Statement:

\- Sid: AWSConfigBucketPermissionsCheck

Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 's3:GetBucketAcl'

Resource: !Sub 'arn:aws:s3:::\${ConfigBucket}'

\- Sid: AWSConfigBucketDelivery

Effect: Allow

Principal:

Service: config.amazonaws.com

Action: 's3:PutObject'

Resource: !Sub
'arn:aws:s3:::\${ConfigBucket}/AWSLogs/\${AWS::AccountId}/\*'

Condition:

StringEquals:

's3:x-amz-acl': 'bucket-owner-full-control'

\# GuardDuty Detector（本番環境のみ）

GuardDutyDetector:

Type: 'AWS::GuardDuty::Detector'

Condition: IsProd

Properties:

Enable: true

FindingPublishingFrequency: 'FIFTEEN_MINUTES'

\# 本番環境用Security Hub有効化

SecurityHub:

Type: 'AWS::SecurityHub::Hub'

Condition: IsProd

Properties:

Tags:

Environment: !Ref Environment

Application: !Ref Application

Team: !Ref Team

CostCenter: !Ref CostCenter

Region: !Ref Region

ManagedBy: 'AFT'

\# バックアップボールト（本番環境のみ）

BackupVault:

Type: 'AWS::Backup::BackupVault'

Condition: IsProd

Properties:

BackupVaultName: !Sub '\${Application}-\${Environment}-vault'

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

\# バックアップポリシー（本番環境のみ）

BackupPolicy:

Type: 'AWS::Backup::BackupPlan'

Condition: IsProd

Properties:

BackupPlan:

BackupPlanName: !Sub '\${Application}-\${Environment}-backup-plan'

BackupPlanRule:

\- RuleName: 'DailyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 \* \* ? \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 30

\- RuleName: 'WeeklyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 ? \* SAT \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 90

MoveToColdStorageAfterDays: 30

\- RuleName: 'MonthlyBackups'

TargetBackupVault: !Ref BackupVault

ScheduleExpression: 'cron(0 1 1 \* ? \*)'

StartWindowMinutes: 60

CompletionWindowMinutes: 180

Lifecycle:

DeleteAfterDays: 365

MoveToColdStorageAfterDays: 90

Tags:

\- Key: Environment

Value: !Ref Environment

\- Key: Application

Value: !Ref Application

\- Key: Team

Value: !Ref Team

\- Key: CostCenter

Value: !Ref CostCenter

\- Key: Region

Value: !Ref Region

\- Key: ManagedBy

Value: 'AFT'

Outputs:

InternalSecurityGroupId:

Description: 'ID of the internal access security group'

Value: !Ref InternalAccessSecurityGroup

Export:

Name: !Sub '\${Application}-\${Environment}-internal-sg-id'

LogGroupName:

Description: 'Name of the application log group'

Value: !Ref ApplicationLogGroup

Export:

Name: !Sub '\${Application}-\${Environment}-log-group-name'

ConfigBucketName:

Description: 'Name of the AWS Config bucket'

Value: !Ref ConfigBucket

Export:

Name: !Sub '\${Application}-\${Environment}-config-bucket-name'

## AFTアカウント申請JSONのサンプル（本番環境用のマルチリージョン対応）

{

"account_name": "prod-manufacturing-management",

"email": "aws-prod-manufacturing@technova.com",

"organizational_unit": "Production",

"tags": {

"Environment": "prod",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "manufacturing-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "prod",

"/dr_enabled": "true",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3",

"/vpc_cidr_tokyo": "10.0.0.0/16",

"/vpc_cidr_osaka": "10.1.0.0/16",

"/backup_retention_days": "30",

"/backup_schedule": "cron(0 1 \* \* ? \*)",

"/high_availability": "true",

"/auto_scaling_min": "2",

"/auto_scaling_max": "10"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true,

"terraform_version": "1.5.0",

"static_analyzers": \["tfsec", "tflint", "checkov"\],

"dynamic_analyzers": \["iam_access_analyzer"\],

"enable_dr": true,

"dr_region": "ap-northeast-3"

}

}

## 開発環境用のAFTアカウント申請JSONサンプル

{

"account_name": "dev-manufacturing-management",

"email": "aws-dev-manufacturing@technova.com",

"organizational_unit": "Development",

"tags": {

"Environment": "dev",

"Team": "manufacturing",

"CostCenter": "MFG-1234",

"Application": "manufacturing-management",

"ProvisionedBy": "AFT"

},

"ssm_parameters": {

"/team": "manufacturing",

"/env": "dev",

"/dr_enabled": "false",

"/primary_region": "ap-northeast-1",

"/secondary_region": "ap-northeast-3",

"/vpc_cidr_tokyo": "10.10.0.0/16",

"/backup_retention_days": "7",

"/backup_schedule": "cron(0 1 ? \* SAT \*)",

"/high_availability": "false",

"/auto_scaling_min": "1",

"/auto_scaling_max": "3"

},

"customizations": {

"vpc_required": true,

"enable_ecr": true,

"enable_ecs": true,

"enable_api_gateway": true,

"enable_cognito": true,

"enable_aurora": true,

"enable_step_functions": true,

"enable_shared_storage": true,

"terraform_version": "1.5.0",

"static_analyzers": \["tfsec", "tflint", "checkov"\],

"dynamic_analyzers": \["iam_access_analyzer"\],

"enable_dr": false

}

}

## 実用的なFlywayマイグレーションスクリプト例

-- V1\_\_initial_schema.sql - 生産管理マイクロサービスの初期スキーマ

CREATE TABLE production_orders (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

order_number VARCHAR(50) NOT NULL UNIQUE COMMENT '生産指示番号',

product_code VARCHAR(50) NOT NULL COMMENT '製品コード',

quantity INT NOT NULL COMMENT '生産数量',

planned_start_date DATE NOT NULL COMMENT '予定開始日',

planned_end_date DATE NOT NULL COMMENT '予定完了日',

status VARCHAR(20) NOT NULL COMMENT 'ステータス(PLANNED, IN_PROGRESS,
COMPLETED, CANCELLED)',

priority INT NOT NULL DEFAULT 3 COMMENT '優先度(1=高, 2=中, 3=低)',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

created_by VARCHAR(255) COMMENT '作成者',

updated_by VARCHAR(255) COMMENT '更新者',

INDEX idx_order_number (order_number),

INDEX idx_product_code (product_code),

INDEX idx_status (status),

INDEX idx_dates (planned_start_date, planned_end_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE production_materials (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

material_code VARCHAR(50) NOT NULL COMMENT '原材料コード',

required_quantity DECIMAL(10, 2) NOT NULL COMMENT '必要数量',

allocated_quantity DECIMAL(10, 2) DEFAULT 0 COMMENT '引当数量',

unit VARCHAR(10) NOT NULL COMMENT '単位',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_material_code (material_code)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE production_workflow_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

step_name VARCHAR(50) NOT NULL COMMENT '工程名',

step_order INT NOT NULL COMMENT '工程順序',

start_time TIMESTAMP NULL COMMENT '開始時刻',

end_time TIMESTAMP NULL COMMENT '終了時刻',

status VARCHAR(20) NOT NULL COMMENT 'ステータス(PENDING, IN_PROGRESS,
COMPLETED, SKIPPED)',

notes TEXT COMMENT '備考',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

CREATE TABLE inventory_transactions (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

transaction_type VARCHAR(20) NOT NULL COMMENT
'トランザクションタイプ(ALLOCATION, DEALLOCATION, CONSUMPTION)',

material_code VARCHAR(50) NOT NULL COMMENT '原材料コード',

quantity DECIMAL(10, 2) NOT NULL COMMENT '数量',

unit VARCHAR(10) NOT NULL COMMENT '単位',

production_order_id BIGINT NULL COMMENT '関連生産指示ID',

transaction_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT
'トランザクション時刻',

created_by VARCHAR(255) COMMENT '作成者',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE SET NULL,

INDEX idx_material_code (material_code),

INDEX idx_production_order_id (production_order_id),

INDEX idx_transaction_time (transaction_time)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 監査ログテーブル

CREATE TABLE audit_logs (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

entity_type VARCHAR(50) NOT NULL COMMENT 'エンティティタイプ',

entity_id BIGINT NOT NULL COMMENT 'エンティティID',

action VARCHAR(20) NOT NULL COMMENT 'アクション(CREATE, UPDATE,
DELETE)',

changed_data JSON COMMENT '変更内容',

user_id VARCHAR(255) COMMENT 'ユーザーID',

timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'タイムスタンプ',

INDEX idx_entity (entity_type, entity_id),

INDEX idx_user_id (user_id),

INDEX idx_timestamp (timestamp)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- V2\_\_add_workcenters_and_resources.sql -
生産工程マスターデータの追加

-- 作業区画テーブルの作成

CREATE TABLE work_centers (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

center_code VARCHAR(20) NOT NULL UNIQUE COMMENT '作業区画コード',

center_name VARCHAR(100) NOT NULL COMMENT '作業区画名',

location VARCHAR(50) COMMENT '場所',

capacity INT NOT NULL DEFAULT 1 COMMENT '処理可能同時数',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

INDEX idx_center_code (center_code),

INDEX idx_is_active (is_active)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 作業区画の担当工程テーブルの作成

CREATE TABLE work_center_capabilities (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

process_name VARCHAR(50) NOT NULL COMMENT '工程名',

setup_time INT NOT NULL DEFAULT 0 COMMENT '段取時間(分)',

process_time_per_unit INT NOT NULL COMMENT '1個あたり処理時間(分)',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_process (work_center_id, process_name),

INDEX idx_process_name (process_name)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産指示と作業区画の割り当てテーブルの作成

CREATE TABLE production_work_center_assignments (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '割り当て日時',

assigned_by VARCHAR(255) COMMENT '割り当て者',

status VARCHAR(20) NOT NULL DEFAULT 'ASSIGNED' COMMENT
'ステータス(ASSIGNED, IN_PROGRESS, COMPLETED, CANCELLED)',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_work_center_id (work_center_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 機械設備マスターテーブルの作成

CREATE TABLE equipment (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

equipment_code VARCHAR(20) NOT NULL UNIQUE COMMENT '設備コード',

equipment_name VARCHAR(100) NOT NULL COMMENT '設備名',

equipment_type VARCHAR(50) NOT NULL COMMENT '設備タイプ',

work_center_id BIGINT COMMENT '配置作業区画ID',

status VARCHAR(20) NOT NULL DEFAULT 'OPERATIONAL' COMMENT
'ステータス(OPERATIONAL, MAINTENANCE, BREAKDOWN)',

last_maintenance_date DATE COMMENT '最終メンテナンス日',

next_maintenance_date DATE COMMENT '次回メンテナンス予定日',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE SET
NULL,

INDEX idx_equipment_code (equipment_code),

INDEX idx_work_center_id (work_center_id),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 設備割り当てテーブルの作成

CREATE TABLE equipment_assignments (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

equipment_id BIGINT NOT NULL COMMENT '設備ID',

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

start_time TIMESTAMP NULL COMMENT '開始時刻',

end_time TIMESTAMP NULL COMMENT '終了時刻',

status VARCHAR(20) NOT NULL DEFAULT 'SCHEDULED' COMMENT
'ステータス(SCHEDULED, IN_USE, COMPLETED, CANCELLED)',

FOREIGN KEY (equipment_id) REFERENCES equipment(id) ON DELETE CASCADE,

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

INDEX idx_equipment_id (equipment_id),

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_status (status),

INDEX idx_time_range (start_time, end_time)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 作業区画の作業日カレンダーテーブルの作成

CREATE TABLE work_center_calendar (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

calendar_date DATE NOT NULL COMMENT '日付',

shift_pattern VARCHAR(20) NOT NULL DEFAULT 'REGULAR' COMMENT
'シフトパターン(REGULAR, EXTENDED, HOLIDAY)',

start_time TIME NOT NULL DEFAULT '09:00:00' COMMENT '開始時刻',

end_time TIME NOT NULL DEFAULT '17:00:00' COMMENT '終了時刻',

capacity_adjustment DECIMAL(5, 2) DEFAULT 1.0 COMMENT '能力調整係数',

notes VARCHAR(255) COMMENT '備考',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_date (work_center_id, calendar_date),

INDEX idx_calendar_date (calendar_date),

INDEX idx_shift_pattern (shift_pattern)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 既存の生産ワークフロー工程テーブルにワークセンター参照を追加

ALTER TABLE production_workflow_steps

ADD COLUMN work_center_id BIGINT NULL COMMENT '担当作業区画ID' AFTER
step_order,

ADD CONSTRAINT fk_workflow_step_work_center FOREIGN KEY (work_center_id)
REFERENCES work_centers(id) ON DELETE SET NULL;

-- V3\_\_add_production_plan_tables.sql - 生産計画テーブルの追加

-- 生産計画テーブルの作成

CREATE TABLE production_plans (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

plan_number VARCHAR(50) NOT NULL UNIQUE COMMENT '計画番号',

plan_name VARCHAR(100) NOT NULL COMMENT '計画名',

plan_start_date DATE NOT NULL COMMENT '計画開始日',

plan_end_date DATE NOT NULL COMMENT '計画終了日',

status VARCHAR(20) NOT NULL DEFAULT 'DRAFT' COMMENT 'ステータス(DRAFT,
APPROVED, IN_PROGRESS, COMPLETED, CANCELLED)',

version INT NOT NULL DEFAULT 1 COMMENT 'バージョン',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

created_by VARCHAR(255) COMMENT '作成者',

updated_by VARCHAR(255) COMMENT '更新者',

INDEX idx_plan_number (plan_number),

INDEX idx_date_range (plan_start_date, plan_end_date),

INDEX idx_status (status)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産指示に計画ID参照を追加

ALTER TABLE production_orders

ADD COLUMN production_plan_id BIGINT NULL COMMENT '生産計画ID' AFTER
order_number,

ADD CONSTRAINT fk_order_plan FOREIGN KEY (production_plan_id) REFERENCES
production_plans(id) ON DELETE SET NULL;

-- 生産能力計画テーブルの作成

CREATE TABLE capacity_plans (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

plan_date DATE NOT NULL COMMENT '計画日',

capacity_hours DECIMAL(5, 2) NOT NULL COMMENT '能力時間',

planned_hours DECIMAL(5, 2) DEFAULT 0 COMMENT '計画済時間',

available_hours DECIMAL(5, 2) GENERATED ALWAYS AS (capacity_hours -
planned_hours) STORED COMMENT '利用可能時間',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

UNIQUE KEY uk_work_center_date (work_center_id, plan_date),

INDEX idx_plan_date (plan_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 生産予定表テーブルの作成

CREATE TABLE production_schedules (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

production_order_id BIGINT NOT NULL COMMENT '生産指示ID',

workflow_step_id BIGINT NOT NULL COMMENT '工程ID',

work_center_id BIGINT NOT NULL COMMENT '作業区画ID',

scheduled_start_date DATE NOT NULL COMMENT '予定開始日',

scheduled_end_date DATE NOT NULL COMMENT '予定終了日',

scheduled_start_time TIME COMMENT '予定開始時刻',

scheduled_end_time TIME COMMENT '予定終了時刻',

estimated_hours DECIMAL(5, 2) NOT NULL COMMENT '見積時間',

is_fixed BOOLEAN NOT NULL DEFAULT FALSE COMMENT '固定フラグ',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (production_order_id) REFERENCES production_orders(id) ON
DELETE CASCADE,

FOREIGN KEY (workflow_step_id) REFERENCES production_workflow_steps(id)
ON DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE
CASCADE,

INDEX idx_production_order_id (production_order_id),

INDEX idx_workflow_step_id (workflow_step_id),

INDEX idx_work_center_id (work_center_id),

INDEX idx_scheduled_dates (scheduled_start_date, scheduled_end_date)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品マスターテーブルの作成

CREATE TABLE products (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_code VARCHAR(50) NOT NULL UNIQUE COMMENT '製品コード',

product_name VARCHAR(100) NOT NULL COMMENT '製品名',

product_category VARCHAR(50) COMMENT '製品カテゴリ',

unit VARCHAR(10) NOT NULL DEFAULT 'PCS' COMMENT '単位',

lead_time_days INT NOT NULL DEFAULT 1 COMMENT 'リードタイム(日)',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

INDEX idx_product_code (product_code),

INDEX idx_product_category (product_category),

INDEX idx_is_active (is_active)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品工程テーブルの作成

CREATE TABLE product_routings (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_id BIGINT NOT NULL COMMENT '製品ID',

routing_version VARCHAR(20) NOT NULL DEFAULT '1.0' COMMENT
'工程表バージョン',

is_default BOOLEAN NOT NULL DEFAULT TRUE COMMENT 'デフォルトフラグ',

is_active BOOLEAN NOT NULL DEFAULT TRUE COMMENT '有効/無効',

effective_from DATE NOT NULL COMMENT '有効開始日',

effective_to DATE COMMENT '有効終了日',

created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '作成日時',

updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE
CURRENT_TIMESTAMP COMMENT '更新日時',

FOREIGN KEY (product_id) REFERENCES products(id) ON DELETE CASCADE,

UNIQUE KEY uk_product_routing_version (product_id, routing_version),

INDEX idx_is_default (is_default),

INDEX idx_is_active (is_active),

INDEX idx_effective_range (effective_from, effective_to)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品工程詳細テーブルの作成

CREATE TABLE product_routing_steps (

id BIGINT AUTO_INCREMENT PRIMARY KEY,

product_routing_id BIGINT NOT NULL COMMENT '製品工程ID',

step_order INT NOT NULL COMMENT '工程順序',

step_name VARCHAR(50) NOT NULL COMMENT '工程名',

work_center_id BIGINT COMMENT '推奨作業区画ID',

setup_time INT NOT NULL DEFAULT 0 COMMENT '段取時間(分)',

process_time_per_unit INT NOT NULL COMMENT '1個あたり処理時間(分)',

wait_time INT NOT NULL DEFAULT 0 COMMENT '待機時間(分)',

description TEXT COMMENT '工程説明',

FOREIGN KEY (product_routing_id) REFERENCES product_routings(id) ON
DELETE CASCADE,

FOREIGN KEY (work_center_id) REFERENCES work_centers(id) ON DELETE SET
NULL,

UNIQUE KEY uk_routing_step_order (product_routing_id, step_order),

INDEX idx_step_name (step_name),

INDEX idx_work_center_id (work_center_id)

) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 製品と生産指示の関連付け

ALTER TABLE production_orders

ADD COLUMN product_id BIGINT NULL COMMENT '製品ID' AFTER product_code,

ADD CONSTRAINT fk_order_product FOREIGN KEY (product_id) REFERENCES
products(id) ON DELETE SET NULL;

上記のようなFlywayのマイグレーションスクリプトを実装することで、データベーススキーマの段階的な進化と変更追跡が可能になります。このアプローチによって、TechNova社は環境間で一貫性のあるデータベーススキーマを確保し、安全なデータベース変更を実現できます。

## まとめ

以上の実装例を通じて、TechNova社のオンプレミス基幹システムのAWS移行・マイクロサービス化プロジェクトにおける、主要な追加要件の対応方法を具体的に示しました。

1.  **静的解析ツールの統合（tfsec、TFLint、checkov）**

    - CI/CDパイプラインへの統合により、セキュリティ問題やベストプラクティス違反を早期に検出可能

    - 検出結果のレポート化と手動承認プロセスの組み込みによる問題対応の促進

2.  **動的解析（IAM Access Analyzer）**

    - IAMポリシーの自動分析によるセキュリティリスクの検出

    - 本番環境へのデプロイ前の重要なセキュリティ問題の特定と修正

3.  **CI/CD手動承認プロセス**

    - 重要な変更やエラーが検出された場合の手動承認ワークフロー

    - エラー情報の可視化と決定支援による安全なデプロイ

4.  **環境タグ付けと環境変数管理**

    - 環境（dev/test/staging/prod）に基づく一貫したタグ付け

    - 環境変数を活用したモジュール管理と設定制御

5.  **マルチリージョン対応（東京・大阪）**

    - 両リージョンを並記したプロバイダー設定

    - リージョン固有のリソース設定と環境変数による制御

    - DR（災害対策）環境の条件付き構築（本番環境のみ）

これらの実装は、セキュリティ、品質、可用性を確保しながら、TechNova社の基幹システムを効率的にAWS環境に移行するための重要な基盤となります。特に、静的/動的解析ツールの統合と手動承認プロセスは、安全かつ高品質なインフラ構築を実現し、マルチリージョン対応はビジネス継続性を強化します。
